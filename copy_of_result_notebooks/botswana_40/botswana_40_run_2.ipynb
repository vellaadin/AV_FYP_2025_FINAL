{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependancy Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:42:32.166406Z",
     "iopub.status.busy": "2025-05-08T19:42:32.165405Z",
     "iopub.status.idle": "2025-05-08T19:42:32.170229Z",
     "shell.execute_reply": "2025-05-08T19:42:32.170229Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:42:32.174234Z",
     "iopub.status.busy": "2025-05-08T19:42:32.174234Z",
     "iopub.status.idle": "2025-05-08T19:42:34.530158Z",
     "shell.execute_reply": "2025-05-08T19:42:34.530158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-metric-learning in c:\\users\\vella\\anaconda3\\lib\\site-packages (2.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (1.5.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (2.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (4.66.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (4.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vella\\anaconda3\\lib\\site-packages (from tqdm->pytorch-metric-learning) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:42:34.533079Z",
     "iopub.status.busy": "2025-05-08T19:42:34.532062Z",
     "iopub.status.idle": "2025-05-08T19:42:38.213669Z",
     "shell.execute_reply": "2025-05-08T19:42:38.213669Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import random_split, TensorDataset, DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nbformat\n",
    "from torchmetrics.image import PeakSignalNoiseRatio\n",
    "from torch.amp import autocast, GradScaler\n",
    "from pytorch_metric_learning.samplers import MPerClassSampler\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:42:38.216680Z",
     "iopub.status.busy": "2025-05-08T19:42:38.216680Z",
     "iopub.status.idle": "2025-05-08T19:42:38.234782Z",
     "shell.execute_reply": "2025-05-08T19:42:38.234782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:42:38.237790Z",
     "iopub.status.busy": "2025-05-08T19:42:38.237790Z",
     "iopub.status.idle": "2025-05-08T19:42:39.189568Z",
     "shell.execute_reply": "2025-05-08T19:42:39.189568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: (1476, 256)\n",
      "Hypercube shape: (1476, 256, 145)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dir = r\"C:\\Users\\vella\\Documents\\GitHub\\FYP2425_LOCAL\\FYP_DATASET\"\n",
    "\n",
    "gt_files = 'Botswana_gt.mat'\n",
    "data_files = 'Botswana.mat'\n",
    "label_files = 'Botswana_gt'\n",
    "hypercube_files = 'Botswana'\n",
    "\n",
    "def extract_Features():\n",
    "    gt_file = os.path.join(dataset_dir, gt_files)\n",
    "    data_file = os.path.join(dataset_dir, data_files)\n",
    "\n",
    "    gt = sio.loadmat(gt_file)\n",
    "    labels = gt[label_files]\n",
    "\n",
    "    data = sio.loadmat(data_file)\n",
    "    hypercube = data[hypercube_files]\n",
    "    #scaling the data in place and setting to float32 to reduce memory usage\n",
    "    max_value = np.max(hypercube)\n",
    "    hypercube = (hypercube / max_value).astype(np.float32)\n",
    "\n",
    "\n",
    "    #shapes of loaded data\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Hypercube shape: {hypercube.shape}\")\n",
    "\n",
    "    #visualisation of label map and a given band of hyperspectral data\n",
    "    plt.figure()\n",
    "    plt.imshow(labels)\n",
    "    plt.title('Labels')\n",
    "\n",
    "    band = 101\n",
    "    plt.figure()\n",
    "    plt.imshow(hypercube[:,:,band])\n",
    "    plt.title(f'Hyperspectral Band {band}')\n",
    "    plt.show()\n",
    "\n",
    "    return hypercube, labels\n",
    "\n",
    "hypercube, labels = extract_Features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:42:39.192574Z",
     "iopub.status.busy": "2025-05-08T19:42:39.192574Z",
     "iopub.status.idle": "2025-05-08T19:42:39.198008Z",
     "shell.execute_reply": "2025-05-08T19:42:39.198008Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_windows(data, labels, window_size):\n",
    "    extract_windows_save_dir = 'extracted_windows_labels'\n",
    "    if not os.path.exists(extract_windows_save_dir):\n",
    "        os.makedirs(extract_windows_save_dir)\n",
    "        print(f\"Created directory: {extract_windows_save_dir}\")\n",
    "\n",
    "    margin = window_size // 2\n",
    "    padded_data = np.pad(data, ((margin, margin), (margin, margin), (0, 0)), mode='constant')\n",
    "    padded_labels = np.pad(labels, ((margin, margin), (margin, margin)), mode='constant')\n",
    "\n",
    "    X_windows = []  #extracted windows\n",
    "    y_labels = []   #corresponding labels\n",
    "\n",
    "    print(\"Starting window extraction...\")\n",
    "    for i in range(margin, padded_data.shape[0] - margin):\n",
    "        for j in range(margin, padded_data.shape[1] - margin):\n",
    "            window = padded_data[i-margin:i+margin+1, j-margin:j+margin+1, :]\n",
    "            label = padded_labels[i, j]\n",
    "\n",
    "            if label != 0:\n",
    "                #print('ignoring label 0 (background)')\n",
    "                X_windows.append(window)\n",
    "                y_labels.append(label)\n",
    "\n",
    "    #convertying to numpy arrays\n",
    "    X_windows = np.array(X_windows)\n",
    "    y_labels = np.array(y_labels)\n",
    "\n",
    "    #saving extracted windows and labels\n",
    "    windows_file = os.path.join(extract_windows_save_dir, 'extracted_windows.npy')\n",
    "    labels_file = os.path.join(extract_windows_save_dir, 'extracted_labels.npy')\n",
    "\n",
    "    np.save(windows_file, X_windows)\n",
    "    np.save(labels_file, y_labels)\n",
    "\n",
    "    print(f\"Saved extracted windows to: {windows_file}\")\n",
    "    print(f\"Saved corresponding labels to: {labels_file}\")\n",
    "    print(f\"\\nTotal windows extracted: {len(X_windows)}\")\n",
    "    print(f\"Extracted windows shape: {X_windows.shape}\")\n",
    "    print(f\"Corresponding labels shape: {y_labels.shape}\")\n",
    "\n",
    "    return X_windows, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:42:39.200537Z",
     "iopub.status.busy": "2025-05-08T19:42:39.200537Z",
     "iopub.status.idle": "2025-05-08T19:42:40.074321Z",
     "shell.execute_reply": "2025-05-08T19:42:40.073819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: extracted_windows_labels\n",
      "Starting window extraction...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved extracted windows to: extracted_windows_labels\\extracted_windows.npy\n",
      "Saved corresponding labels to: extracted_windows_labels\\extracted_labels.npy\n",
      "\n",
      "Total windows extracted: 3248\n",
      "Extracted windows shape: (3248, 5, 5, 145)\n",
      "Corresponding labels shape: (3248,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 5\n",
    "\n",
    "X_windows, y_labels = extract_windows(hypercube, labels, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:42:40.077377Z",
     "iopub.status.busy": "2025-05-08T19:42:40.076325Z",
     "iopub.status.idle": "2025-05-08T19:42:40.085022Z",
     "shell.execute_reply": "2025-05-08T19:42:40.085022Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_samples(X_windows, y_labels, samples_per_class):\n",
    "    \n",
    "    indices_save_dir = 'indices'\n",
    "    if not os.path.exists(indices_save_dir):\n",
    "        os.makedirs(indices_save_dir)\n",
    "        print(f\"Created directory: {indices_save_dir}\")\n",
    "    \n",
    "    #get unique classes\n",
    "    classes = np.unique(y_labels)\n",
    "    print(f\"Unique classes found as: {classes}\")\n",
    "\n",
    "    #init lists\n",
    "    X_sampled = [] #to store training samples\n",
    "    y_sampled = [] #to store training labels\n",
    "\n",
    "    X_val = [] # to store validation samples\n",
    "    y_val = [] # to store validation labels\n",
    "\n",
    "    selected_indices_total = [] #to store indices of selected training and validation samples\n",
    "    validation_selected = [] #temp storage for validation indices\n",
    "    validation_total = [] #to store all validation indices\n",
    "\n",
    "    print(\"\\n == STARTING SAMPLING PROCESS ==\")\n",
    "    for cls in classes:\n",
    "        if cls == 0:\n",
    "            print(f\"!! SKIPPING CLASS 0 !!\")\n",
    "            continue\n",
    "\n",
    "        #getting the indices for the current class:\n",
    "        class_indices = np.where(y_labels == cls)[0]\n",
    "        print(f\"Class: {cls}: Found {len(class_indices)} samples\")\n",
    "\n",
    "        # shuffle class-specific indices to ensure randomness\n",
    "        np.random.shuffle(class_indices)\n",
    "        print(f\"Shuffled class indices for class '{cls}'\")\n",
    "\n",
    "        #select 'samples_per_class' samples for training\n",
    "        selected_indices = class_indices[:samples_per_class]\n",
    "        #selecting 5 samples for validation\n",
    "        validation_selected = class_indices[samples_per_class:samples_per_class+5]\n",
    "\n",
    "        print(f\"Selected {len(selected_indices)} training samples and {len(validation_selected)} validation samples for class '{cls}'\\n\")\n",
    "\n",
    "        #store selected indices for training and validation\n",
    "        selected_indices_total.extend(selected_indices)\n",
    "        validation_total.extend(validation_selected)\n",
    "\n",
    "        # appending the selected samples and their labels to the lists\n",
    "        X_sampled.append(X_windows[selected_indices])\n",
    "        y_sampled.append(y_labels[selected_indices])\n",
    "\n",
    "        X_val.append(X_windows[validation_selected])\n",
    "        y_val.append(y_labels[validation_selected])\n",
    "\n",
    "    #concat the sampled arrays for training\n",
    "    X_train = np.vstack(X_sampled)\n",
    "    y_train = np.hstack(y_sampled)\n",
    "\n",
    "    # shift labels to start from 0\n",
    "    y_train = y_train - 1\n",
    "\n",
    "    print(f\"\\n -- Training set created with: \\n\\t{X_train.shape[0]} samples\\n\\tshape {X_train.shape} --\")\n",
    "\n",
    "    #concat the sampled arrays for validation\n",
    "    X_val = np.vstack(X_val)\n",
    "    y_val = np.hstack(y_val)\n",
    "    y_val = y_val - 1\n",
    "\n",
    "    print(f\"\\n -- Validation set created with: \\n\\t{X_val.shape[0]} samples\\n\\tshape {X_val.shape} --\")\n",
    "\n",
    "    #create the test set from the remaining data (i.e. that which is not selected for training or validation)\n",
    "    selected_indices_total.extend(validation_total)\n",
    "\n",
    "    #getting indices not in the training or val sets\n",
    "    test_indices = np.setdiff1d(np.arange(X_windows.shape[0]), selected_indices_total)\n",
    "    X_test = X_windows[test_indices]\n",
    "    y_test = y_labels[test_indices]\n",
    "    y_test = y_test - 1\n",
    "\n",
    "    print(f\"\\n -- Test set created with: \\n\\t{X_test.shape[0]} samples\\n\\tshape {X_test.shape} --\\n\")\n",
    "\n",
    "    # Save the datasets to the 'datasets' folder\n",
    "    np.save(os.path.join(indices_save_dir, 'X_train.npy'), X_train)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_train.npy'), y_train)\n",
    "    np.save(os.path.join(indices_save_dir, 'X_val.npy'), X_val)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_val.npy'), y_val)\n",
    "    np.save(os.path.join(indices_save_dir, 'X_test.npy'), X_test)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_test.npy'), y_test)\n",
    "\n",
    "    print(f\"\\nAll datasets saved to the '{indices_save_dir}' folder.\")\n",
    "\n",
    "    #return the training, val, test sets + selected indices\n",
    "    return X_train, X_test, y_train, y_test, X_val, y_val, selected_indices_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:42:40.087030Z",
     "iopub.status.busy": "2025-05-08T19:42:40.087030Z",
     "iopub.status.idle": "2025-05-08T19:42:40.302665Z",
     "shell.execute_reply": "2025-05-08T19:42:40.302665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: indices\n",
      "Unique classes found as: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      " == STARTING SAMPLING PROCESS ==\n",
      "Class: 1: Found 270 samples\n",
      "Shuffled class indices for class '1'\n",
      "Selected 40 training samples and 5 validation samples for class '1'\n",
      "\n",
      "Class: 2: Found 101 samples\n",
      "Shuffled class indices for class '2'\n",
      "Selected 40 training samples and 5 validation samples for class '2'\n",
      "\n",
      "Class: 3: Found 251 samples\n",
      "Shuffled class indices for class '3'\n",
      "Selected 40 training samples and 5 validation samples for class '3'\n",
      "\n",
      "Class: 4: Found 215 samples\n",
      "Shuffled class indices for class '4'\n",
      "Selected 40 training samples and 5 validation samples for class '4'\n",
      "\n",
      "Class: 5: Found 269 samples\n",
      "Shuffled class indices for class '5'\n",
      "Selected 40 training samples and 5 validation samples for class '5'\n",
      "\n",
      "Class: 6: Found 269 samples\n",
      "Shuffled class indices for class '6'\n",
      "Selected 40 training samples and 5 validation samples for class '6'\n",
      "\n",
      "Class: 7: Found 259 samples\n",
      "Shuffled class indices for class '7'\n",
      "Selected 40 training samples and 5 validation samples for class '7'\n",
      "\n",
      "Class: 8: Found 203 samples\n",
      "Shuffled class indices for class '8'\n",
      "Selected 40 training samples and 5 validation samples for class '8'\n",
      "\n",
      "Class: 9: Found 314 samples\n",
      "Shuffled class indices for class '9'\n",
      "Selected 40 training samples and 5 validation samples for class '9'\n",
      "\n",
      "Class: 10: Found 248 samples\n",
      "Shuffled class indices for class '10'\n",
      "Selected 40 training samples and 5 validation samples for class '10'\n",
      "\n",
      "Class: 11: Found 305 samples\n",
      "Shuffled class indices for class '11'\n",
      "Selected 40 training samples and 5 validation samples for class '11'\n",
      "\n",
      "Class: 12: Found 181 samples\n",
      "Shuffled class indices for class '12'\n",
      "Selected 40 training samples and 5 validation samples for class '12'\n",
      "\n",
      "Class: 13: Found 268 samples\n",
      "Shuffled class indices for class '13'\n",
      "Selected 40 training samples and 5 validation samples for class '13'\n",
      "\n",
      "Class: 14: Found 95 samples\n",
      "Shuffled class indices for class '14'\n",
      "Selected 40 training samples and 5 validation samples for class '14'\n",
      "\n",
      "\n",
      " -- Training set created with: \n",
      "\t560 samples\n",
      "\tshape (560, 5, 5, 145) --\n",
      "\n",
      " -- Validation set created with: \n",
      "\t70 samples\n",
      "\tshape (70, 5, 5, 145) --\n",
      "\n",
      " -- Test set created with: \n",
      "\t2618 samples\n",
      "\tshape (2618, 5, 5, 145) --\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All datasets saved to the 'indices' folder.\n",
      "(560, 5, 5, 145)\n",
      "(70, 5, 5, 145)\n",
      "(2618, 5, 5, 145)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_val, y_val, selected_indices_total = get_samples(X_windows, y_labels, 40)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:42:40.306185Z",
     "iopub.status.busy": "2025-05-08T19:42:40.306185Z",
     "iopub.status.idle": "2025-05-08T19:42:40.310195Z",
     "shell.execute_reply": "2025-05-08T19:42:40.310195Z"
    }
   },
   "outputs": [],
   "source": [
    "class HyperspectralDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (numpy.ndarray): Hyperspectral data of shape (num_samples, height, width, num_bands).\n",
    "            y (numpy.ndarray): Labels of shape (num_samples,).\n",
    "        \"\"\"\n",
    "        #converting to pytorch tensor\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:42:40.313203Z",
     "iopub.status.busy": "2025-05-08T19:42:40.313203Z",
     "iopub.status.idle": "2025-05-08T19:42:40.380890Z",
     "shell.execute_reply": "2025-05-08T19:42:40.379885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 2 applied\n",
      "DataLoaders created successfully!\n",
      "Training batch size: 280\n",
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20, 9: 20, 10: 20, 11: 20, 12: 20, 13: 20}\n"
     ]
    }
   ],
   "source": [
    "#loading the saved datasets\n",
    "X_train = np.load('indices/X_train.npy')\n",
    "y_train = np.load('indices/y_train.npy')\n",
    "X_val = np.load('indices/X_val.npy')\n",
    "y_val = np.load('indices/y_val.npy')\n",
    "X_test = np.load('indices/X_test.npy')\n",
    "y_test = np.load('indices/y_test.npy')\n",
    "\n",
    "\n",
    "#creating pytorch datasets\n",
    "train_dataset = HyperspectralDataset(X_train, y_train)\n",
    "val_dataset = HyperspectralDataset(X_val, y_val)\n",
    "test_dataset = HyperspectralDataset(X_test, y_test)\n",
    "\n",
    "m = 20\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "#theoretical batch size calc\n",
    "required_batch_size = m * num_classes  # 10 * 9 = 90\n",
    "\n",
    "#ensuring batch size doesn't exceed training set size\n",
    "if required_batch_size > len(train_dataset):\n",
    "    #case 1: not enough samples - reduce m proportionally\n",
    "    print(\"Case 1 applied\")\n",
    "    max_possible_m = len(train_dataset) // num_classes\n",
    "    m = max(1, max_possible_m)\n",
    "    batch_size_train = m * num_classes\n",
    "else:\n",
    "    #case 2: use full batch size\n",
    "    print(\"Case 2 applied\")\n",
    "    batch_size_train = required_batch_size\n",
    "\n",
    "sampler = MPerClassSampler(labels = y_train, m=m, batch_size = batch_size_train, length_before_new_iter = len(train_dataset))\n",
    "\n",
    "#dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size_train, sampler=sampler)\n",
    "\n",
    "batch_size = 256\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")\n",
    "\n",
    "#class dist in first batch\n",
    "for X_batch, y_batch in train_loader:\n",
    "    unique, counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(f\"Training batch size: {batch_size_train}\")\n",
    "    print(\"Class distribution in batch:\", dict(zip(unique, counts)))\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating directory for saving model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:42:40.383889Z",
     "iopub.status.busy": "2025-05-08T19:42:40.383889Z",
     "iopub.status.idle": "2025-05-08T19:42:40.389397Z",
     "shell.execute_reply": "2025-05-08T19:42:40.389397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dir: model_predictions\n"
     ]
    }
   ],
   "source": [
    "predictions_dir = 'model_predictions'\n",
    "os.makedirs(predictions_dir, exist_ok=True)\n",
    "print(f\"Created dir: {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset splits and Dataloaders for unsupervised tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:42:40.392402Z",
     "iopub.status.busy": "2025-05-08T19:42:40.392402Z",
     "iopub.status.idle": "2025-05-08T19:42:40.409945Z",
     "shell.execute_reply": "2025-05-08T19:42:40.409945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2598, 5, 5, 145)\n",
      "Validation data shape: (650, 5, 5, 145)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val = train_test_split(X_windows, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:42:40.413341Z",
     "iopub.status.busy": "2025-05-08T19:42:40.412339Z",
     "iopub.status.idle": "2025-05-08T19:42:40.416426Z",
     "shell.execute_reply": "2025-05-08T19:42:40.416426Z"
    }
   },
   "outputs": [],
   "source": [
    "class UnsupervisedDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)  #converting to pytorch tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:42:40.419948Z",
     "iopub.status.busy": "2025-05-08T19:42:40.418942Z",
     "iopub.status.idle": "2025-05-08T19:42:40.429262Z",
     "shell.execute_reply": "2025-05-08T19:42:40.428257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created successfully!\n"
     ]
    }
   ],
   "source": [
    "#creating datasets for unsupervised task\n",
    "unsup_train_dataset = UnsupervisedDataset(X_train)\n",
    "unsup_val_dataset = UnsupervisedDataset(X_val)\n",
    "\n",
    "#dataloaders for unsupervised task\n",
    "batch_size = 64\n",
    "train_loader_cae = DataLoader(unsup_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader_cae = DataLoader(unsup_val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:42:40.431467Z",
     "iopub.status.busy": "2025-05-08T19:42:40.431467Z",
     "iopub.status.idle": "2025-05-08T19:42:40.434698Z",
     "shell.execute_reply": "2025-05-08T19:42:40.434698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n"
     ]
    }
   ],
   "source": [
    "window_num_channels = X_windows.shape[3]\n",
    "print(window_num_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:42:40.437707Z",
     "iopub.status.busy": "2025-05-08T19:42:40.437707Z",
     "iopub.status.idle": "2025-05-08T19:42:40.443087Z",
     "shell.execute_reply": "2025-05-08T19:42:40.443087Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncode(nn.Module):\n",
    "    def __init__(self, dropout_prob=0.1):\n",
    "        super(ConvAutoEncode, self).__init__()\n",
    "\n",
    "        #encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            #Block 1\n",
    "            nn.Conv2d(window_num_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 5x5 -> 2x2\n",
    "\n",
    "            #Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            #Bottleneck\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2)  # 2x2 -> 1x1\n",
    "        )\n",
    "\n",
    "        #decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.ConvTranspose2d(64, window_num_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:42:40.446092Z",
     "iopub.status.busy": "2025-05-08T19:42:40.446092Z",
     "iopub.status.idle": "2025-05-08T19:43:02.830076Z",
     "shell.execute_reply": "2025-05-08T19:43:02.829511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1/41], Loss: 0.2184, PSNR: -8.3640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Training Loss: 0.2121, PSNR: -8.6923\n",
      "\t[Val]   Batch [1/11] Loss: 0.2056, PSNR: -6.1672\n",
      "\t[Val]   Batch [10/11] Loss: 0.2057, PSNR: -8.4059\n",
      "Epoch [1/50] Validation Loss: 0.2056, PSNR: -8.0980\n",
      "\n",
      "LOG: Epoch [2/50]\n",
      "\t Training Batch [1/41], Loss: 0.1962, PSNR: -5.9650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] Training Loss: 0.1900, PSNR: -8.2770\n",
      "\t[Val]   Batch [1/11] Loss: 0.1796, PSNR: -5.5809\n",
      "\t[Val]   Batch [10/11] Loss: 0.1799, PSNR: -7.8237\n",
      "Epoch [2/50] Validation Loss: 0.1796, PSNR: -7.5101\n",
      "\n",
      "LOG: Epoch [3/50]\n",
      "\t Training Batch [1/41], Loss: 0.1764, PSNR: -9.4344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] Training Loss: 0.1691, PSNR: -7.7442\n",
      "\t[Val]   Batch [1/11] Loss: 0.1555, PSNR: -4.9538\n",
      "\t[Val]   Batch [10/11] Loss: 0.1555, PSNR: -7.1906\n",
      "Epoch [3/50] Validation Loss: 0.1553, PSNR: -6.8795\n",
      "\n",
      "LOG: Epoch [4/50]\n",
      "\t Training Batch [1/41], Loss: 0.1544, PSNR: -7.9356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] Training Loss: 0.1489, PSNR: -7.4050\n",
      "\t[Val]   Batch [1/11] Loss: 0.1345, PSNR: -4.3227\n",
      "\t[Val]   Batch [10/11] Loss: 0.1345, PSNR: -6.5611\n",
      "Epoch [4/50] Validation Loss: 0.1343, PSNR: -6.2474\n",
      "\n",
      "LOG: Epoch [5/50]\n",
      "\t Training Batch [1/41], Loss: 0.1359, PSNR: -8.5923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] Training Loss: 0.1298, PSNR: -6.8121\n",
      "\t[Val]   Batch [1/11] Loss: 0.1131, PSNR: -3.5714\n",
      "\t[Val]   Batch [10/11] Loss: 0.1131, PSNR: -5.8077\n",
      "Epoch [5/50] Validation Loss: 0.1129, PSNR: -5.4946\n",
      "\n",
      "LOG: Epoch [6/50]\n",
      "\t Training Batch [1/41], Loss: 0.1190, PSNR: -5.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] Training Loss: 0.1122, PSNR: -5.9061\n",
      "\t[Val]   Batch [1/11] Loss: 0.0995, PSNR: -3.0142\n",
      "\t[Val]   Batch [10/11] Loss: 0.0994, PSNR: -5.2485\n",
      "Epoch [6/50] Validation Loss: 0.0993, PSNR: -4.9356\n",
      "\n",
      "LOG: Epoch [7/50]\n",
      "\t Training Batch [1/41], Loss: 0.1022, PSNR: -5.9373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] Training Loss: 0.0965, PSNR: -5.3691\n",
      "\t[Val]   Batch [1/11] Loss: 0.0842, PSNR: -2.2882\n",
      "\t[Val]   Batch [10/11] Loss: 0.0841, PSNR: -4.5205\n",
      "Epoch [7/50] Validation Loss: 0.0840, PSNR: -4.2094\n",
      "\n",
      "LOG: Epoch [8/50]\n",
      "\t Training Batch [1/41], Loss: 0.0875, PSNR: -3.7744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] Training Loss: 0.0831, PSNR: -4.7429\n",
      "\t[Val]   Batch [1/11] Loss: 0.0751, PSNR: -1.7908\n",
      "\t[Val]   Batch [10/11] Loss: 0.0750, PSNR: -4.0216\n",
      "Epoch [8/50] Validation Loss: 0.0749, PSNR: -3.7122\n",
      "\n",
      "LOG: Epoch [9/50]\n",
      "\t Training Batch [1/41], Loss: 0.0763, PSNR: -5.7936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] Training Loss: 0.0717, PSNR: -4.1184\n",
      "\t[Val]   Batch [1/11] Loss: 0.0643, PSNR: -1.1171\n",
      "\t[Val]   Batch [10/11] Loss: 0.0642, PSNR: -3.3509\n",
      "Epoch [9/50] Validation Loss: 0.0642, PSNR: -3.0403\n",
      "\n",
      "LOG: Epoch [10/50]\n",
      "\t Training Batch [1/41], Loss: 0.0650, PSNR: -1.1688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] Training Loss: 0.0621, PSNR: -3.2631\n",
      "\t[Val]   Batch [1/11] Loss: 0.0576, PSNR: -0.6401\n",
      "\t[Val]   Batch [10/11] Loss: 0.0575, PSNR: -2.8732\n",
      "Epoch [10/50] Validation Loss: 0.0575, PSNR: -2.5615\n",
      "\n",
      "LOG: Epoch [11/50]\n",
      "\t Training Batch [1/41], Loss: 0.0571, PSNR: -0.6064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50] Training Loss: 0.0542, PSNR: -2.7390\n",
      "\t[Val]   Batch [1/11] Loss: 0.0498, PSNR: -0.0099\n",
      "\t[Val]   Batch [10/11] Loss: 0.0498, PSNR: -2.2460\n",
      "Epoch [11/50] Validation Loss: 0.0497, PSNR: -1.9319\n",
      "\n",
      "LOG: Epoch [12/50]\n",
      "\t Training Batch [1/41], Loss: 0.0490, PSNR: 0.0571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50] Training Loss: 0.0476, PSNR: -2.2535\n",
      "\t[Val]   Batch [1/11] Loss: 0.0453, PSNR: 0.4003\n",
      "\t[Val]   Batch [10/11] Loss: 0.0453, PSNR: -1.8344\n",
      "Epoch [12/50] Validation Loss: 0.0452, PSNR: -1.5215\n",
      "\n",
      "LOG: Epoch [13/50]\n",
      "\t Training Batch [1/41], Loss: 0.0431, PSNR: -2.1812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50] Training Loss: 0.0421, PSNR: -1.8524\n",
      "\t[Val]   Batch [1/11] Loss: 0.0392, PSNR: 1.0274\n",
      "\t[Val]   Batch [10/11] Loss: 0.0392, PSNR: -1.2084\n",
      "Epoch [13/50] Validation Loss: 0.0391, PSNR: -0.8948\n",
      "\n",
      "LOG: Epoch [14/50]\n",
      "\t Training Batch [1/41], Loss: 0.0385, PSNR: -3.1558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50] Training Loss: 0.0374, PSNR: -1.3290\n",
      "\t[Val]   Batch [1/11] Loss: 0.0367, PSNR: 1.3155\n",
      "\t[Val]   Batch [10/11] Loss: 0.0367, PSNR: -0.9181\n",
      "Epoch [14/50] Validation Loss: 0.0366, PSNR: -0.6053\n",
      "\n",
      "LOG: Epoch [15/50]\n",
      "\t Training Batch [1/41], Loss: 0.0345, PSNR: -1.2174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50] Training Loss: 0.0335, PSNR: -0.6629\n",
      "\t[Val]   Batch [1/11] Loss: 0.0320, PSNR: 1.9107\n",
      "\t[Val]   Batch [10/11] Loss: 0.0320, PSNR: -0.3242\n",
      "Epoch [15/50] Validation Loss: 0.0319, PSNR: -0.0099\n",
      "\n",
      "LOG: Epoch [16/50]\n",
      "\t Training Batch [1/41], Loss: 0.0314, PSNR: 1.9996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50] Training Loss: 0.0302, PSNR: -0.4468\n",
      "\t[Val]   Batch [1/11] Loss: 0.0292, PSNR: 2.3084\n",
      "\t[Val]   Batch [10/11] Loss: 0.0292, PSNR: 0.0749\n",
      "Epoch [16/50] Validation Loss: 0.0291, PSNR: 0.3883\n",
      "\n",
      "LOG: Epoch [17/50]\n",
      "\t Training Batch [1/41], Loss: 0.0278, PSNR: 1.1991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50] Training Loss: 0.0273, PSNR: -0.0557\n",
      "\t[Val]   Batch [1/11] Loss: 0.0268, PSNR: 2.6815\n",
      "\t[Val]   Batch [10/11] Loss: 0.0268, PSNR: 0.4508\n",
      "Epoch [17/50] Validation Loss: 0.0267, PSNR: 0.7617\n",
      "\n",
      "LOG: Epoch [18/50]\n",
      "\t Training Batch [1/41], Loss: 0.0256, PSNR: 1.2441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50] Training Loss: 0.0249, PSNR: 0.5374\n",
      "\t[Val]   Batch [1/11] Loss: 0.0241, PSNR: 3.1481\n",
      "\t[Val]   Batch [10/11] Loss: 0.0240, PSNR: 0.9181\n",
      "Epoch [18/50] Validation Loss: 0.0240, PSNR: 1.2287\n",
      "\n",
      "LOG: Epoch [19/50]\n",
      "\t Training Batch [1/41], Loss: 0.0235, PSNR: 3.2553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50] Training Loss: 0.0227, PSNR: 1.0385\n",
      "\t[Val]   Batch [1/11] Loss: 0.0225, PSNR: 3.4397\n",
      "\t[Val]   Batch [10/11] Loss: 0.0225, PSNR: 1.2103\n",
      "Epoch [19/50] Validation Loss: 0.0224, PSNR: 1.5214\n",
      "\n",
      "LOG: Epoch [20/50]\n",
      "\t Training Batch [1/41], Loss: 0.0209, PSNR: 1.8184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50] Training Loss: 0.0208, PSNR: 1.1200\n",
      "\t[Val]   Batch [1/11] Loss: 0.0205, PSNR: 3.8385\n",
      "\t[Val]   Batch [10/11] Loss: 0.0205, PSNR: 1.6075\n",
      "Epoch [20/50] Validation Loss: 0.0205, PSNR: 1.9206\n",
      "\n",
      "LOG: Epoch [21/50]\n",
      "\t Training Batch [1/41], Loss: 0.0193, PSNR: 1.3095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50] Training Loss: 0.0192, PSNR: 1.6704\n",
      "\t[Val]   Batch [1/11] Loss: 0.0188, PSNR: 4.2252\n",
      "\t[Val]   Batch [10/11] Loss: 0.0188, PSNR: 1.9913\n",
      "Epoch [21/50] Validation Loss: 0.0187, PSNR: 2.3065\n",
      "\n",
      "LOG: Epoch [22/50]\n",
      "\t Training Batch [1/41], Loss: 0.0180, PSNR: 0.1515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50] Training Loss: 0.0177, PSNR: 1.9474\n",
      "\t[Val]   Batch [1/11] Loss: 0.0177, PSNR: 4.4885\n",
      "\t[Val]   Batch [10/11] Loss: 0.0177, PSNR: 2.2555\n",
      "Epoch [22/50] Validation Loss: 0.0176, PSNR: 2.5691\n",
      "\n",
      "LOG: Epoch [23/50]\n",
      "\t Training Batch [1/41], Loss: 0.0169, PSNR: 4.6778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50] Training Loss: 0.0164, PSNR: 2.2678\n",
      "\t[Val]   Batch [1/11] Loss: 0.0162, PSNR: 4.8699\n",
      "\t[Val]   Batch [10/11] Loss: 0.0162, PSNR: 2.6366\n",
      "Epoch [23/50] Validation Loss: 0.0162, PSNR: 2.9499\n",
      "\n",
      "LOG: Epoch [24/50]\n",
      "\t Training Batch [1/41], Loss: 0.0161, PSNR: 2.3098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50] Training Loss: 0.0152, PSNR: 2.6579\n",
      "\t[Val]   Batch [1/11] Loss: 0.0151, PSNR: 5.1825\n",
      "\t[Val]   Batch [10/11] Loss: 0.0151, PSNR: 2.9500\n",
      "Epoch [24/50] Validation Loss: 0.0150, PSNR: 3.2629\n",
      "\n",
      "LOG: Epoch [25/50]\n",
      "\t Training Batch [1/41], Loss: 0.0149, PSNR: 2.6298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50] Training Loss: 0.0142, PSNR: 3.2365\n",
      "\t[Val]   Batch [1/11] Loss: 0.0142, PSNR: 5.4325\n",
      "\t[Val]   Batch [10/11] Loss: 0.0142, PSNR: 3.2023\n",
      "Epoch [25/50] Validation Loss: 0.0142, PSNR: 3.5144\n",
      "\n",
      "LOG: Epoch [26/50]\n",
      "\t Training Batch [1/41], Loss: 0.0136, PSNR: 4.0513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50] Training Loss: 0.0133, PSNR: 3.3576\n",
      "\t[Val]   Batch [1/11] Loss: 0.0133, PSNR: 5.7269\n",
      "\t[Val]   Batch [10/11] Loss: 0.0133, PSNR: 3.4969\n",
      "Epoch [26/50] Validation Loss: 0.0132, PSNR: 3.8100\n",
      "\n",
      "LOG: Epoch [27/50]\n",
      "\t Training Batch [1/41], Loss: 0.0126, PSNR: 2.0326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50] Training Loss: 0.0124, PSNR: 3.5186\n",
      "\t[Val]   Batch [1/11] Loss: 0.0124, PSNR: 6.0377\n",
      "\t[Val]   Batch [10/11] Loss: 0.0124, PSNR: 3.8069\n",
      "Epoch [27/50] Validation Loss: 0.0123, PSNR: 4.1211\n",
      "\n",
      "LOG: Epoch [28/50]\n",
      "\t Training Batch [1/41], Loss: 0.0120, PSNR: 1.9637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50] Training Loss: 0.0116, PSNR: 3.6831\n",
      "\t[Val]   Batch [1/11] Loss: 0.0117, PSNR: 6.2875\n",
      "\t[Val]   Batch [10/11] Loss: 0.0117, PSNR: 4.0576\n",
      "Epoch [28/50] Validation Loss: 0.0116, PSNR: 4.3714\n",
      "\n",
      "LOG: Epoch [29/50]\n",
      "\t Training Batch [1/41], Loss: 0.0114, PSNR: 4.7916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50] Training Loss: 0.0110, PSNR: 4.0548\n",
      "\t[Val]   Batch [1/11] Loss: 0.0110, PSNR: 6.5480\n",
      "\t[Val]   Batch [10/11] Loss: 0.0110, PSNR: 4.3177\n",
      "Epoch [29/50] Validation Loss: 0.0110, PSNR: 4.6314\n",
      "\n",
      "LOG: Epoch [30/50]\n",
      "\t Training Batch [1/41], Loss: 0.0105, PSNR: 2.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50] Training Loss: 0.0103, PSNR: 4.3603\n",
      "\t[Val]   Batch [1/11] Loss: 0.0103, PSNR: 6.8170\n",
      "\t[Val]   Batch [10/11] Loss: 0.0103, PSNR: 4.5864\n",
      "Epoch [30/50] Validation Loss: 0.0103, PSNR: 4.9004\n",
      "\n",
      "LOG: Epoch [31/50]\n",
      "\t Training Batch [1/41], Loss: 0.0099, PSNR: 7.0260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50] Training Loss: 0.0097, PSNR: 4.4712\n",
      "\t[Val]   Batch [1/11] Loss: 0.0098, PSNR: 7.0585\n",
      "\t[Val]   Batch [10/11] Loss: 0.0098, PSNR: 4.8289\n",
      "Epoch [31/50] Validation Loss: 0.0098, PSNR: 5.1416\n",
      "\n",
      "LOG: Epoch [32/50]\n",
      "\t Training Batch [1/41], Loss: 0.0094, PSNR: 4.9830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50] Training Loss: 0.0092, PSNR: 4.7551\n",
      "\t[Val]   Batch [1/11] Loss: 0.0093, PSNR: 7.2957\n",
      "\t[Val]   Batch [10/11] Loss: 0.0092, PSNR: 5.0683\n",
      "Epoch [32/50] Validation Loss: 0.0092, PSNR: 5.3796\n",
      "\n",
      "LOG: Epoch [33/50]\n",
      "\t Training Batch [1/41], Loss: 0.0089, PSNR: 7.4835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50] Training Loss: 0.0087, PSNR: 4.9861\n",
      "\t[Val]   Batch [1/11] Loss: 0.0087, PSNR: 7.5579\n",
      "\t[Val]   Batch [10/11] Loss: 0.0087, PSNR: 5.3296\n",
      "Epoch [33/50] Validation Loss: 0.0087, PSNR: 5.6418\n",
      "\n",
      "LOG: Epoch [34/50]\n",
      "\t Training Batch [1/41], Loss: 0.0085, PSNR: 3.3969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50] Training Loss: 0.0082, PSNR: 5.3095\n",
      "\t[Val]   Batch [1/11] Loss: 0.0083, PSNR: 7.7526\n",
      "\t[Val]   Batch [10/11] Loss: 0.0083, PSNR: 5.5240\n",
      "Epoch [34/50] Validation Loss: 0.0083, PSNR: 5.8370\n",
      "\n",
      "LOG: Epoch [35/50]\n",
      "\t Training Batch [1/41], Loss: 0.0080, PSNR: 5.0289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50] Training Loss: 0.0078, PSNR: 5.4116\n",
      "\t[Val]   Batch [1/11] Loss: 0.0079, PSNR: 7.9799\n",
      "\t[Val]   Batch [10/11] Loss: 0.0079, PSNR: 5.7523\n",
      "Epoch [35/50] Validation Loss: 0.0079, PSNR: 6.0648\n",
      "\n",
      "LOG: Epoch [36/50]\n",
      "\t Training Batch [1/41], Loss: 0.0075, PSNR: 6.8948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50] Training Loss: 0.0074, PSNR: 5.7243\n",
      "\t[Val]   Batch [1/11] Loss: 0.0075, PSNR: 8.2251\n",
      "\t[Val]   Batch [10/11] Loss: 0.0075, PSNR: 5.9991\n",
      "Epoch [36/50] Validation Loss: 0.0074, PSNR: 6.3105\n",
      "\n",
      "LOG: Epoch [37/50]\n",
      "\t Training Batch [1/41], Loss: 0.0074, PSNR: 4.8298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50] Training Loss: 0.0071, PSNR: 5.9436\n",
      "\t[Val]   Batch [1/11] Loss: 0.0071, PSNR: 8.4308\n",
      "\t[Val]   Batch [10/11] Loss: 0.0071, PSNR: 6.2049\n",
      "Epoch [37/50] Validation Loss: 0.0071, PSNR: 6.5160\n",
      "\n",
      "LOG: Epoch [38/50]\n",
      "\t Training Batch [1/41], Loss: 0.0072, PSNR: 6.4792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50] Training Loss: 0.0067, PSNR: 6.2443\n",
      "\t[Val]   Batch [1/11] Loss: 0.0068, PSNR: 8.6547\n",
      "\t[Val]   Batch [10/11] Loss: 0.0068, PSNR: 6.4285\n",
      "Epoch [38/50] Validation Loss: 0.0067, PSNR: 6.7400\n",
      "\n",
      "LOG: Epoch [39/50]\n",
      "\t Training Batch [1/41], Loss: 0.0065, PSNR: 5.9805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50] Training Loss: 0.0064, PSNR: 6.4598\n",
      "\t[Val]   Batch [1/11] Loss: 0.0065, PSNR: 8.8315\n",
      "\t[Val]   Batch [10/11] Loss: 0.0065, PSNR: 6.6051\n",
      "Epoch [39/50] Validation Loss: 0.0065, PSNR: 6.9174\n",
      "\n",
      "LOG: Epoch [40/50]\n",
      "\t Training Batch [1/41], Loss: 0.0060, PSNR: 6.3545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50] Training Loss: 0.0061, PSNR: 6.6766\n",
      "\t[Val]   Batch [1/11] Loss: 0.0063, PSNR: 9.0028\n",
      "\t[Val]   Batch [10/11] Loss: 0.0062, PSNR: 6.7766\n",
      "Epoch [40/50] Validation Loss: 0.0062, PSNR: 7.0894\n",
      "\n",
      "LOG: Epoch [41/50]\n",
      "\t Training Batch [1/41], Loss: 0.0058, PSNR: 7.6730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50] Training Loss: 0.0059, PSNR: 6.9085\n",
      "\t[Val]   Batch [1/11] Loss: 0.0059, PSNR: 9.2326\n",
      "\t[Val]   Batch [10/11] Loss: 0.0059, PSNR: 7.0058\n",
      "Epoch [41/50] Validation Loss: 0.0059, PSNR: 7.3192\n",
      "\n",
      "LOG: Epoch [42/50]\n",
      "\t Training Batch [1/41], Loss: 0.0057, PSNR: 9.4139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50] Training Loss: 0.0056, PSNR: 7.0353\n",
      "\t[Val]   Batch [1/11] Loss: 0.0057, PSNR: 9.4239\n",
      "\t[Val]   Batch [10/11] Loss: 0.0057, PSNR: 7.1965\n",
      "Epoch [42/50] Validation Loss: 0.0057, PSNR: 7.5110\n",
      "\n",
      "LOG: Epoch [43/50]\n",
      "\t Training Batch [1/41], Loss: 0.0056, PSNR: 6.6419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50] Training Loss: 0.0054, PSNR: 7.1699\n",
      "\t[Val]   Batch [1/11] Loss: 0.0054, PSNR: 9.6014\n",
      "\t[Val]   Batch [10/11] Loss: 0.0054, PSNR: 7.3747\n",
      "Epoch [43/50] Validation Loss: 0.0054, PSNR: 7.6890\n",
      "\n",
      "LOG: Epoch [44/50]\n",
      "\t Training Batch [1/41], Loss: 0.0050, PSNR: 7.0464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50] Training Loss: 0.0052, PSNR: 7.3553\n",
      "\t[Val]   Batch [1/11] Loss: 0.0052, PSNR: 9.7818\n",
      "\t[Val]   Batch [10/11] Loss: 0.0052, PSNR: 7.5560\n",
      "Epoch [44/50] Validation Loss: 0.0052, PSNR: 7.8689\n",
      "\n",
      "LOG: Epoch [45/50]\n",
      "\t Training Batch [1/41], Loss: 0.0049, PSNR: 6.5982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50] Training Loss: 0.0049, PSNR: 7.6089\n",
      "\t[Val]   Batch [1/11] Loss: 0.0050, PSNR: 9.9526\n",
      "\t[Val]   Batch [10/11] Loss: 0.0050, PSNR: 7.7273\n",
      "Epoch [45/50] Validation Loss: 0.0050, PSNR: 8.0394\n",
      "\n",
      "LOG: Epoch [46/50]\n",
      "\t Training Batch [1/41], Loss: 0.0047, PSNR: 5.7203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50] Training Loss: 0.0047, PSNR: 7.8881\n",
      "\t[Val]   Batch [1/11] Loss: 0.0048, PSNR: 10.1249\n",
      "\t[Val]   Batch [10/11] Loss: 0.0048, PSNR: 7.8997\n",
      "Epoch [46/50] Validation Loss: 0.0048, PSNR: 8.2119\n",
      "\n",
      "LOG: Epoch [47/50]\n",
      "\t Training Batch [1/41], Loss: 0.0045, PSNR: 9.1556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50] Training Loss: 0.0046, PSNR: 7.8400\n",
      "\t[Val]   Batch [1/11] Loss: 0.0046, PSNR: 10.3069\n",
      "\t[Val]   Batch [10/11] Loss: 0.0046, PSNR: 8.0814\n",
      "Epoch [47/50] Validation Loss: 0.0046, PSNR: 8.3942\n",
      "\n",
      "LOG: Epoch [48/50]\n",
      "\t Training Batch [1/41], Loss: 0.0044, PSNR: 8.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50] Training Loss: 0.0044, PSNR: 8.0904\n",
      "\t[Val]   Batch [1/11] Loss: 0.0045, PSNR: 10.4724\n",
      "\t[Val]   Batch [10/11] Loss: 0.0044, PSNR: 8.2468\n",
      "Epoch [48/50] Validation Loss: 0.0044, PSNR: 8.5605\n",
      "\n",
      "LOG: Epoch [49/50]\n",
      "\t Training Batch [1/41], Loss: 0.0044, PSNR: 10.4849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50] Training Loss: 0.0042, PSNR: 8.2907\n",
      "\t[Val]   Batch [1/11] Loss: 0.0043, PSNR: 10.6324\n",
      "\t[Val]   Batch [10/11] Loss: 0.0043, PSNR: 8.4054\n",
      "Epoch [49/50] Validation Loss: 0.0043, PSNR: 8.7204\n",
      "\n",
      "LOG: Epoch [50/50]\n",
      "\t Training Batch [1/41], Loss: 0.0043, PSNR: 6.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50] Training Loss: 0.0041, PSNR: 8.4145\n",
      "\t[Val]   Batch [1/11] Loss: 0.0041, PSNR: 10.8017\n",
      "\t[Val]   Batch [10/11] Loss: 0.0041, PSNR: 8.5743\n",
      "Epoch [50/50] Validation Loss: 0.0041, PSNR: 8.8894\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_cae = ConvAutoEncode()\n",
    "criterion_cae = nn.MSELoss()\n",
    "optimizer_cae = optim.Adam(model_cae.parameters(), lr=0.0001)\n",
    "\n",
    "#parameters for CAE\n",
    "num_epochs_cae = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_cae = model_cae.to(device)\n",
    "\n",
    "#early stopping parameters\n",
    "patience = 3  # number of epochs to wait for improvement\n",
    "tolerance = 1e-4\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "#grad accumulation parameters\n",
    "accumulation_steps = 8 \n",
    "\n",
    "# for loss and metrics tracking\n",
    "autoencoder_epoch_losses_cae = []\n",
    "validation_epoch_losses_cae = []\n",
    "train_psnr = []\n",
    "val_psnr = []\n",
    "\n",
    "psnr = PeakSignalNoiseRatio().to(device)\n",
    "\n",
    "# mixed precision training\n",
    "scaler = GradScaler()  # Gradient scaler for mixed precision\n",
    "\n",
    "for epoch in range(num_epochs_cae):\n",
    "    # training\n",
    "    model_cae.train()\n",
    "    running_loss = 0.0\n",
    "    running_psnr = 0.0\n",
    "\n",
    "    print(f\"\\nLOG: Epoch [{epoch + 1}/{num_epochs_cae}]\")\n",
    "\n",
    "    optimizer_cae.zero_grad()\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader_cae):\n",
    "        data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "        # mixed precision forward pass\n",
    "        with autocast(device_type='cuda', dtype=torch.float16):\n",
    "            _, decoded = model_cae(data)\n",
    "            loss = criterion_cae(decoded, data) / accumulation_steps\n",
    "\n",
    "            with torch.no_grad():\n",
    "                nan_in_out = torch.isnan(decoded).any().item()\n",
    "                inf_in_out = torch.isinf(decoded).any().item()\n",
    "\n",
    "        #backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        loss_value = loss.item() * accumulation_steps\n",
    "        running_loss += loss_value\n",
    "\n",
    "        psnr_value = psnr(decoded, data).item()\n",
    "        running_psnr += psnr_value\n",
    "\n",
    "\n",
    "        # performing optimizer step and reset gradients after `accumulation_steps` batches\n",
    "        if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader_cae):\n",
    "            scaler.step(optimizer_cae)\n",
    "            scaler.update()\n",
    "            optimizer_cae.zero_grad()\n",
    "\n",
    "        if batch_idx == 0 or (batch_idx + 1) % 200 == 0:\n",
    "            print(\n",
    "    f\"\\t Training Batch [{batch_idx + 1}/{len(train_loader_cae)}], \"\n",
    "    f\"Loss: {loss_value:.4f}, PSNR: {psnr_value:.4f}\"\n",
    ")\n",
    "\n",
    "\n",
    "        #delete intermediate variables and clear GPU cache\n",
    "        del data, decoded, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    #compute average metrics for the epoch\n",
    "    avg_train_loss = running_loss / len(train_loader_cae)\n",
    "    avg_train_psnr = running_psnr / len(train_loader_cae)\n",
    "\n",
    "    autoencoder_epoch_losses_cae.append(avg_train_loss)\n",
    "    train_psnr.append(avg_train_psnr)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs_cae}] Training Loss: {avg_train_loss:.4f}, PSNR: {avg_train_psnr:.4f}\")\n",
    "\n",
    "    #clear GPU cache after training\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    #validation\n",
    "    model_cae.eval()\n",
    "    validation_loss = 0.0\n",
    "    val_psnr_epoch = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(val_loader_cae):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "            # Mixed precision forward pass for validation\n",
    "            with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                _, decoded = model_cae(data)\n",
    "                loss = criterion_cae(decoded, data)\n",
    "\n",
    "            validation_loss += loss.item()\n",
    "            val_psnr_epoch += psnr(decoded, data).item()\n",
    "\n",
    "            if batch_idx == 0 or (batch_idx + 1) % 10 == 0:\n",
    "                loss_val = loss.item()\n",
    "                psnr_val = psnr(decoded, data).item()\n",
    "                print(\n",
    "                    f\"\\t[Val]   Batch [{batch_idx + 1}/{len(val_loader_cae)}] \"\n",
    "                    f\"Loss: {loss_val:.4f}, PSNR: {psnr_val:.4f}\"\n",
    "                )\n",
    "\n",
    "            del data, decoded, loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # average validation metrics for the epoch\n",
    "    avg_val_loss = validation_loss / len(val_loader_cae)\n",
    "    avg_val_psnr = val_psnr_epoch / len(val_loader_cae)\n",
    "\n",
    "    validation_epoch_losses_cae.append(avg_val_loss)\n",
    "    val_psnr.append(avg_val_psnr)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs_cae}] Validation Loss: {avg_val_loss:.4f}, PSNR: {avg_val_psnr:.4f}\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if avg_val_loss < best_val_loss - tolerance:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0  # Reset counter\n",
    "        #best model checkpoint\n",
    "        #torch.save(model_cae.state_dict(), 'best_model_cae.pth')\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}. No improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "#plot for training and validation loss trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(autoencoder_epoch_losses_cae) + 1), autoencoder_epoch_losses_cae, marker='o', label=\"Training Loss\")\n",
    "plt.plot(range(1, len(validation_epoch_losses_cae) + 1), validation_epoch_losses_cae, marker='x', label=\"Validation Loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Trend Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#plot for PSNR trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_psnr) + 1), train_psnr, marker='o', label=\"Training PSNR\")\n",
    "plt.plot(range(1, len(val_psnr) + 1), val_psnr, marker='x', label=\"Validation PSNR\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('PSNR Trend Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the encoder section of CAE as feature extractor to generate compact representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:43:02.833081Z",
     "iopub.status.busy": "2025-05-08T19:43:02.832081Z",
     "iopub.status.idle": "2025-05-08T19:43:02.989731Z",
     "shell.execute_reply": "2025-05-08T19:43:02.989215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting representations for the train dataset...\n",
      "    Processed batch 1/2 for train dataset.\n",
      "    Processed batch 2/2 for train dataset.\n",
      "Completed encoding for the train dataset.\n",
      "\n",
      "Extracting representations for the val dataset...\n",
      "    Processed batch 1/1 for val dataset.\n",
      "Completed encoding for the val dataset.\n",
      "\n",
      "Extracting representations for the test dataset...\n",
      "    Processed batch 1/11 for test dataset.\n",
      "Completed encoding for the test dataset.\n",
      "Feature extraction completed for all subsets.\n"
     ]
    }
   ],
   "source": [
    "#dir to save encoded representations\n",
    "encoded_dir = 'encoded_representations'\n",
    "os.makedirs(encoded_dir, exist_ok=True)\n",
    "\n",
    "loaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "model_cae.eval()\n",
    "\n",
    "# Feature extraction\n",
    "with torch.no_grad():\n",
    "    for subset_name, loader in loaders.items():\n",
    "        print(f\"\\nExtracting representations for the {subset_name} dataset...\")\n",
    "\n",
    "        # dir for the given subset's encoded features\n",
    "        subset_encoded_dir = os.path.join(encoded_dir, subset_name)\n",
    "        os.makedirs(subset_encoded_dir, exist_ok=True)\n",
    "\n",
    "        for batch_idx, (data, labels) in enumerate(loader):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "            # passing data through the encoder to obtain representations\n",
    "            encoded_features, _ = model_cae(data)  # latent representation\n",
    "\n",
    "            # moving to CPU and convert to NumPy\n",
    "            encoded_features = encoded_features.cpu().numpy()  \n",
    "            labels = labels.cpu().numpy() \n",
    "\n",
    "            #saving the encoded features and labels\n",
    "            np.save(os.path.join(subset_encoded_dir, f'encoded_batch_{batch_idx}.npy'), encoded_features)\n",
    "            np.save(os.path.join(subset_encoded_dir, f'labels_batch_{batch_idx}.npy'), labels)\n",
    "\n",
    "            if batch_idx % 1 == 0 and subset_name != 'test':\n",
    "                print(f\"    Processed batch {batch_idx + 1}/{len(loader)} for {subset_name} dataset.\")\n",
    "            elif subset_name == 'test' and batch_idx % 100 == 0:  # Log less frequently for the test set\n",
    "                print(f\"    Processed batch {batch_idx + 1}/{len(loader)} for {subset_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed encoding for the {subset_name} dataset.\")\n",
    "\n",
    "print(\"Feature extraction completed for all subsets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-To-End CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:43:02.991736Z",
     "iopub.status.busy": "2025-05-08T19:43:02.991736Z",
     "iopub.status.idle": "2025-05-08T19:43:02.996744Z",
     "shell.execute_reply": "2025-05-08T19:43:02.996744Z"
    }
   },
   "outputs": [],
   "source": [
    "class hyperspectralCNN(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(hyperspectralCNN, self).__init__()\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 5x5 -> 2x2\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Bottleneck\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2)  # 2x2 -> 1x1\n",
    "        )\n",
    "\n",
    "        #fully connected layers for classification\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),  #3D to 1D vector for input to FC layers\n",
    "            nn.Linear(16 * 2 * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:43:02.999598Z",
     "iopub.status.busy": "2025-05-08T19:43:02.999598Z",
     "iopub.status.idle": "2025-05-08T19:43:21.153874Z",
     "shell.execute_reply": "2025-05-08T19:43:21.153874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] completed, Average Training Loss: 2.6226\n",
      "    Validation Batch [1/1], Loss: 2.6469\n",
      "Validation Loss: 2.6469, Validation Accuracy: 7.14%\n",
      "Validation loss improved from inf to 2.6469. Saving model...\n",
      "\n",
      "LOG: Epoch [2/1000] - Training\n",
      "Epoch [2/1000] completed, Average Training Loss: 2.5585\n",
      "    Validation Batch [1/1], Loss: 2.6470\n",
      "Validation Loss: 2.6470, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [3/1000] - Training\n",
      "Epoch [3/1000] completed, Average Training Loss: 2.5240\n",
      "    Validation Batch [1/1], Loss: 2.6470\n",
      "Validation Loss: 2.6470, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [4/1000] - Training\n",
      "Epoch [4/1000] completed, Average Training Loss: 2.4897\n",
      "    Validation Batch [1/1], Loss: 2.6472\n",
      "Validation Loss: 2.6472, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [5/1000] - Training\n",
      "Epoch [5/1000] completed, Average Training Loss: 2.4634\n",
      "    Validation Batch [1/1], Loss: 2.6474\n",
      "Validation Loss: 2.6474, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [6/1000] - Training\n",
      "Epoch [6/1000] completed, Average Training Loss: 2.4409\n",
      "    Validation Batch [1/1], Loss: 2.6476\n",
      "Validation Loss: 2.6476, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [7/1000] - Training\n",
      "Epoch [7/1000] completed, Average Training Loss: 2.4129\n",
      "    Validation Batch [1/1], Loss: 2.6479\n",
      "Validation Loss: 2.6479, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [8/1000] - Training\n",
      "Epoch [8/1000] completed, Average Training Loss: 2.3971\n",
      "    Validation Batch [1/1], Loss: 2.6483\n",
      "Validation Loss: 2.6483, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [9/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/1000] completed, Average Training Loss: 2.3689\n",
      "    Validation Batch [1/1], Loss: 2.6488\n",
      "Validation Loss: 2.6488, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [10/1000] - Training\n",
      "Epoch [10/1000] completed, Average Training Loss: 2.3486\n",
      "    Validation Batch [1/1], Loss: 2.6494\n",
      "Validation Loss: 2.6494, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [11/1000] - Training\n",
      "Epoch [11/1000] completed, Average Training Loss: 2.3339\n",
      "    Validation Batch [1/1], Loss: 2.6500\n",
      "Validation Loss: 2.6500, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [12/1000] - Training\n",
      "Epoch [12/1000] completed, Average Training Loss: 2.3224\n",
      "    Validation Batch [1/1], Loss: 2.6507\n",
      "Validation Loss: 2.6507, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [13/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/1000] completed, Average Training Loss: 2.2979\n",
      "    Validation Batch [1/1], Loss: 2.6516\n",
      "Validation Loss: 2.6516, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [14/1000] - Training\n",
      "Epoch [14/1000] completed, Average Training Loss: 2.2866\n",
      "    Validation Batch [1/1], Loss: 2.6529\n",
      "Validation Loss: 2.6529, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [15/1000] - Training\n",
      "Epoch [15/1000] completed, Average Training Loss: 2.2616\n",
      "    Validation Batch [1/1], Loss: 2.6542\n",
      "Validation Loss: 2.6542, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [16/1000] - Training\n",
      "Epoch [16/1000] completed, Average Training Loss: 2.2490\n",
      "    Validation Batch [1/1], Loss: 2.6558\n",
      "Validation Loss: 2.6558, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [17/1000] - Training\n",
      "Epoch [17/1000] completed, Average Training Loss: 2.2212\n",
      "    Validation Batch [1/1], Loss: 2.6570\n",
      "Validation Loss: 2.6570, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [18/1000] - Training\n",
      "Epoch [18/1000] completed, Average Training Loss: 2.2003\n",
      "    Validation Batch [1/1], Loss: 2.6574\n",
      "Validation Loss: 2.6574, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [19/1000] - Training\n",
      "Epoch [19/1000] completed, Average Training Loss: 2.1947\n",
      "    Validation Batch [1/1], Loss: 2.6571\n",
      "Validation Loss: 2.6571, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [20/1000] - Training\n",
      "Epoch [20/1000] completed, Average Training Loss: 2.1701\n",
      "    Validation Batch [1/1], Loss: 2.6563\n",
      "Validation Loss: 2.6563, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [21/1000] - Training\n",
      "Epoch [21/1000] completed, Average Training Loss: 2.1520\n",
      "    Validation Batch [1/1], Loss: 2.6552\n",
      "Validation Loss: 2.6552, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [22/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/1000] completed, Average Training Loss: 2.1478\n",
      "    Validation Batch [1/1], Loss: 2.6527\n",
      "Validation Loss: 2.6527, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [23/1000] - Training\n",
      "Epoch [23/1000] completed, Average Training Loss: 2.1337\n",
      "    Validation Batch [1/1], Loss: 2.6483\n",
      "Validation Loss: 2.6483, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [24/1000] - Training\n",
      "Epoch [24/1000] completed, Average Training Loss: 2.1104\n",
      "    Validation Batch [1/1], Loss: 2.6418\n",
      "Validation Loss: 2.6418, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6469 to 2.6418. Saving model...\n",
      "\n",
      "LOG: Epoch [25/1000] - Training\n",
      "Epoch [25/1000] completed, Average Training Loss: 2.0994\n",
      "    Validation Batch [1/1], Loss: 2.6333\n",
      "Validation Loss: 2.6333, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6418 to 2.6333. Saving model...\n",
      "\n",
      "LOG: Epoch [26/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/1000] completed, Average Training Loss: 2.0823\n",
      "    Validation Batch [1/1], Loss: 2.6220\n",
      "Validation Loss: 2.6220, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6333 to 2.6220. Saving model...\n",
      "\n",
      "LOG: Epoch [27/1000] - Training\n",
      "Epoch [27/1000] completed, Average Training Loss: 2.0754\n",
      "    Validation Batch [1/1], Loss: 2.6062\n",
      "Validation Loss: 2.6062, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6220 to 2.6062. Saving model...\n",
      "\n",
      "LOG: Epoch [28/1000] - Training\n",
      "Epoch [28/1000] completed, Average Training Loss: 2.0520\n",
      "    Validation Batch [1/1], Loss: 2.5872\n",
      "Validation Loss: 2.5872, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6062 to 2.5872. Saving model...\n",
      "\n",
      "LOG: Epoch [29/1000] - Training\n",
      "Epoch [29/1000] completed, Average Training Loss: 2.0469\n",
      "    Validation Batch [1/1], Loss: 2.5653\n",
      "Validation Loss: 2.5653, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.5872 to 2.5653. Saving model...\n",
      "\n",
      "LOG: Epoch [30/1000] - Training\n",
      "Epoch [30/1000] completed, Average Training Loss: 2.0320\n",
      "    Validation Batch [1/1], Loss: 2.5424\n",
      "Validation Loss: 2.5424, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.5653 to 2.5424. Saving model...\n",
      "\n",
      "LOG: Epoch [31/1000] - Training\n",
      "Epoch [31/1000] completed, Average Training Loss: 2.0141\n",
      "    Validation Batch [1/1], Loss: 2.5082\n",
      "Validation Loss: 2.5082, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.5424 to 2.5082. Saving model...\n",
      "\n",
      "LOG: Epoch [32/1000] - Training\n",
      "Epoch [32/1000] completed, Average Training Loss: 1.9973\n",
      "    Validation Batch [1/1], Loss: 2.4743\n",
      "Validation Loss: 2.4743, Validation Accuracy: 12.86%\n",
      "Validation loss improved from 2.5082 to 2.4743. Saving model...\n",
      "\n",
      "LOG: Epoch [33/1000] - Training\n",
      "Epoch [33/1000] completed, Average Training Loss: 1.9819\n",
      "    Validation Batch [1/1], Loss: 2.4408\n",
      "Validation Loss: 2.4408, Validation Accuracy: 20.00%\n",
      "Validation loss improved from 2.4743 to 2.4408. Saving model...\n",
      "\n",
      "LOG: Epoch [34/1000] - Training\n",
      "Epoch [34/1000] completed, Average Training Loss: 1.9795\n",
      "    Validation Batch [1/1], Loss: 2.3987\n",
      "Validation Loss: 2.3987, Validation Accuracy: 21.43%\n",
      "Validation loss improved from 2.4408 to 2.3987. Saving model...\n",
      "\n",
      "LOG: Epoch [35/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/1000] completed, Average Training Loss: 1.9601\n",
      "    Validation Batch [1/1], Loss: 2.3666\n",
      "Validation Loss: 2.3666, Validation Accuracy: 24.29%\n",
      "Validation loss improved from 2.3987 to 2.3666. Saving model...\n",
      "\n",
      "LOG: Epoch [36/1000] - Training\n",
      "Epoch [36/1000] completed, Average Training Loss: 1.9431\n",
      "    Validation Batch [1/1], Loss: 2.3213\n",
      "Validation Loss: 2.3213, Validation Accuracy: 28.57%\n",
      "Validation loss improved from 2.3666 to 2.3213. Saving model...\n",
      "\n",
      "LOG: Epoch [37/1000] - Training\n",
      "Epoch [37/1000] completed, Average Training Loss: 1.9267\n",
      "    Validation Batch [1/1], Loss: 2.2703\n",
      "Validation Loss: 2.2703, Validation Accuracy: 28.57%\n",
      "Validation loss improved from 2.3213 to 2.2703. Saving model...\n",
      "\n",
      "LOG: Epoch [38/1000] - Training\n",
      "Epoch [38/1000] completed, Average Training Loss: 1.9090\n",
      "    Validation Batch [1/1], Loss: 2.2331\n",
      "Validation Loss: 2.2331, Validation Accuracy: 28.57%\n",
      "Validation loss improved from 2.2703 to 2.2331. Saving model...\n",
      "\n",
      "LOG: Epoch [39/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/1000] completed, Average Training Loss: 1.8894\n",
      "    Validation Batch [1/1], Loss: 2.1818\n",
      "Validation Loss: 2.1818, Validation Accuracy: 28.57%\n",
      "Validation loss improved from 2.2331 to 2.1818. Saving model...\n",
      "\n",
      "LOG: Epoch [40/1000] - Training\n",
      "Epoch [40/1000] completed, Average Training Loss: 1.8819\n",
      "    Validation Batch [1/1], Loss: 2.1242\n",
      "Validation Loss: 2.1242, Validation Accuracy: 32.86%\n",
      "Validation loss improved from 2.1818 to 2.1242. Saving model...\n",
      "\n",
      "LOG: Epoch [41/1000] - Training\n",
      "Epoch [41/1000] completed, Average Training Loss: 1.8754\n",
      "    Validation Batch [1/1], Loss: 2.1031\n",
      "Validation Loss: 2.1031, Validation Accuracy: 37.14%\n",
      "Validation loss improved from 2.1242 to 2.1031. Saving model...\n",
      "\n",
      "LOG: Epoch [42/1000] - Training\n",
      "Epoch [42/1000] completed, Average Training Loss: 1.8523\n",
      "    Validation Batch [1/1], Loss: 2.0611\n",
      "Validation Loss: 2.0611, Validation Accuracy: 40.00%\n",
      "Validation loss improved from 2.1031 to 2.0611. Saving model...\n",
      "\n",
      "LOG: Epoch [43/1000] - Training\n",
      "Epoch [43/1000] completed, Average Training Loss: 1.8401\n",
      "    Validation Batch [1/1], Loss: 2.0062\n",
      "Validation Loss: 2.0062, Validation Accuracy: 45.71%\n",
      "Validation loss improved from 2.0611 to 2.0062. Saving model...\n",
      "\n",
      "LOG: Epoch [44/1000] - Training\n",
      "Epoch [44/1000] completed, Average Training Loss: 1.8387\n",
      "    Validation Batch [1/1], Loss: 1.9692\n",
      "Validation Loss: 1.9692, Validation Accuracy: 50.00%\n",
      "Validation loss improved from 2.0062 to 1.9692. Saving model...\n",
      "\n",
      "LOG: Epoch [45/1000] - Training\n",
      "Epoch [45/1000] completed, Average Training Loss: 1.8117\n",
      "    Validation Batch [1/1], Loss: 1.9415\n",
      "Validation Loss: 1.9415, Validation Accuracy: 55.71%\n",
      "Validation loss improved from 1.9692 to 1.9415. Saving model...\n",
      "\n",
      "LOG: Epoch [46/1000] - Training\n",
      "Epoch [46/1000] completed, Average Training Loss: 1.8106\n",
      "    Validation Batch [1/1], Loss: 1.9503\n",
      "Validation Loss: 1.9503, Validation Accuracy: 54.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [47/1000] - Training\n",
      "Epoch [47/1000] completed, Average Training Loss: 1.7685\n",
      "    Validation Batch [1/1], Loss: 1.8680\n",
      "Validation Loss: 1.8680, Validation Accuracy: 62.86%\n",
      "Validation loss improved from 1.9415 to 1.8680. Saving model...\n",
      "\n",
      "LOG: Epoch [48/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/1000] completed, Average Training Loss: 1.7662\n",
      "    Validation Batch [1/1], Loss: 1.8253\n",
      "Validation Loss: 1.8253, Validation Accuracy: 64.29%\n",
      "Validation loss improved from 1.8680 to 1.8253. Saving model...\n",
      "\n",
      "LOG: Epoch [49/1000] - Training\n",
      "Epoch [49/1000] completed, Average Training Loss: 1.7507\n",
      "    Validation Batch [1/1], Loss: 1.8340\n",
      "Validation Loss: 1.8340, Validation Accuracy: 58.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [50/1000] - Training\n",
      "Epoch [50/1000] completed, Average Training Loss: 1.7335\n",
      "    Validation Batch [1/1], Loss: 1.7900\n",
      "Validation Loss: 1.7900, Validation Accuracy: 68.57%\n",
      "Validation loss improved from 1.8253 to 1.7900. Saving model...\n",
      "\n",
      "LOG: Epoch [51/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/1000] completed, Average Training Loss: 1.7392\n",
      "    Validation Batch [1/1], Loss: 1.7569\n",
      "Validation Loss: 1.7569, Validation Accuracy: 71.43%\n",
      "Validation loss improved from 1.7900 to 1.7569. Saving model...\n",
      "\n",
      "LOG: Epoch [52/1000] - Training\n",
      "Epoch [52/1000] completed, Average Training Loss: 1.7129\n",
      "    Validation Batch [1/1], Loss: 1.7341\n",
      "Validation Loss: 1.7341, Validation Accuracy: 72.86%\n",
      "Validation loss improved from 1.7569 to 1.7341. Saving model...\n",
      "\n",
      "LOG: Epoch [53/1000] - Training\n",
      "Epoch [53/1000] completed, Average Training Loss: 1.6999\n",
      "    Validation Batch [1/1], Loss: 1.7067\n",
      "Validation Loss: 1.7067, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.7341 to 1.7067. Saving model...\n",
      "\n",
      "LOG: Epoch [54/1000] - Training\n",
      "Epoch [54/1000] completed, Average Training Loss: 1.6702\n",
      "    Validation Batch [1/1], Loss: 1.6671\n",
      "Validation Loss: 1.6671, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.7067 to 1.6671. Saving model...\n",
      "\n",
      "LOG: Epoch [55/1000] - Training\n",
      "Epoch [55/1000] completed, Average Training Loss: 1.6459\n",
      "    Validation Batch [1/1], Loss: 1.6417\n",
      "Validation Loss: 1.6417, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.6671 to 1.6417. Saving model...\n",
      "\n",
      "LOG: Epoch [56/1000] - Training\n",
      "Epoch [56/1000] completed, Average Training Loss: 1.6498\n",
      "    Validation Batch [1/1], Loss: 1.6456\n",
      "Validation Loss: 1.6456, Validation Accuracy: 75.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [57/1000] - Training\n",
      "Epoch [57/1000] completed, Average Training Loss: 1.6429\n",
      "    Validation Batch [1/1], Loss: 1.6053\n",
      "Validation Loss: 1.6053, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.6417 to 1.6053. Saving model...\n",
      "\n",
      "LOG: Epoch [58/1000] - Training\n",
      "Epoch [58/1000] completed, Average Training Loss: 1.6251\n",
      "    Validation Batch [1/1], Loss: 1.6066\n",
      "Validation Loss: 1.6066, Validation Accuracy: 80.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [59/1000] - Training\n",
      "Epoch [59/1000] completed, Average Training Loss: 1.6034\n",
      "    Validation Batch [1/1], Loss: 1.5915\n",
      "Validation Loss: 1.5915, Validation Accuracy: 82.86%\n",
      "Validation loss improved from 1.6053 to 1.5915. Saving model...\n",
      "\n",
      "LOG: Epoch [60/1000] - Training\n",
      "Epoch [60/1000] completed, Average Training Loss: 1.5915\n",
      "    Validation Batch [1/1], Loss: 1.5717\n",
      "Validation Loss: 1.5717, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.5915 to 1.5717. Saving model...\n",
      "\n",
      "LOG: Epoch [61/1000] - Training\n",
      "Epoch [61/1000] completed, Average Training Loss: 1.5722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 1.5561\n",
      "Validation Loss: 1.5561, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.5717 to 1.5561. Saving model...\n",
      "\n",
      "LOG: Epoch [62/1000] - Training\n",
      "Epoch [62/1000] completed, Average Training Loss: 1.5525\n",
      "    Validation Batch [1/1], Loss: 1.5382\n",
      "Validation Loss: 1.5382, Validation Accuracy: 84.29%\n",
      "Validation loss improved from 1.5561 to 1.5382. Saving model...\n",
      "\n",
      "LOG: Epoch [63/1000] - Training\n",
      "Epoch [63/1000] completed, Average Training Loss: 1.5463\n",
      "    Validation Batch [1/1], Loss: 1.5432\n",
      "Validation Loss: 1.5432, Validation Accuracy: 81.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [64/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/1000] completed, Average Training Loss: 1.5454\n",
      "    Validation Batch [1/1], Loss: 1.4921\n",
      "Validation Loss: 1.4921, Validation Accuracy: 82.86%\n",
      "Validation loss improved from 1.5382 to 1.4921. Saving model...\n",
      "\n",
      "LOG: Epoch [65/1000] - Training\n",
      "Epoch [65/1000] completed, Average Training Loss: 1.5271\n",
      "    Validation Batch [1/1], Loss: 1.4820\n",
      "Validation Loss: 1.4820, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.4921 to 1.4820. Saving model...\n",
      "\n",
      "LOG: Epoch [66/1000] - Training\n",
      "Epoch [66/1000] completed, Average Training Loss: 1.5026\n",
      "    Validation Batch [1/1], Loss: 1.5078\n",
      "Validation Loss: 1.5078, Validation Accuracy: 78.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [67/1000] - Training\n",
      "Epoch [67/1000] completed, Average Training Loss: 1.4879\n",
      "    Validation Batch [1/1], Loss: 1.4606\n",
      "Validation Loss: 1.4606, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.4820 to 1.4606. Saving model...\n",
      "\n",
      "LOG: Epoch [68/1000] - Training\n",
      "Epoch [68/1000] completed, Average Training Loss: 1.4673\n",
      "    Validation Batch [1/1], Loss: 1.4299\n",
      "Validation Loss: 1.4299, Validation Accuracy: 84.29%\n",
      "Validation loss improved from 1.4606 to 1.4299. Saving model...\n",
      "\n",
      "LOG: Epoch [69/1000] - Training\n",
      "Epoch [69/1000] completed, Average Training Loss: 1.4807\n",
      "    Validation Batch [1/1], Loss: 1.4247\n",
      "Validation Loss: 1.4247, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.4299 to 1.4247. Saving model...\n",
      "\n",
      "LOG: Epoch [70/1000] - Training\n",
      "Epoch [70/1000] completed, Average Training Loss: 1.4527\n",
      "    Validation Batch [1/1], Loss: 1.4258\n",
      "Validation Loss: 1.4258, Validation Accuracy: 85.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [71/1000] - Training\n",
      "Epoch [71/1000] completed, Average Training Loss: 1.4352\n",
      "    Validation Batch [1/1], Loss: 1.3936\n",
      "Validation Loss: 1.3936, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.4247 to 1.3936. Saving model...\n",
      "\n",
      "LOG: Epoch [72/1000] - Training\n",
      "Epoch [72/1000] completed, Average Training Loss: 1.4252\n",
      "    Validation Batch [1/1], Loss: 1.3793\n",
      "Validation Loss: 1.3793, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.3936 to 1.3793. Saving model...\n",
      "\n",
      "LOG: Epoch [73/1000] - Training\n",
      "Epoch [73/1000] completed, Average Training Loss: 1.4185\n",
      "    Validation Batch [1/1], Loss: 1.3923\n",
      "Validation Loss: 1.3923, Validation Accuracy: 81.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [74/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/1000] completed, Average Training Loss: 1.3884\n",
      "    Validation Batch [1/1], Loss: 1.4188\n",
      "Validation Loss: 1.4188, Validation Accuracy: 84.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [75/1000] - Training\n",
      "Epoch [75/1000] completed, Average Training Loss: 1.3726\n",
      "    Validation Batch [1/1], Loss: 1.3078\n",
      "Validation Loss: 1.3078, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.3793 to 1.3078. Saving model...\n",
      "\n",
      "LOG: Epoch [76/1000] - Training\n",
      "Epoch [76/1000] completed, Average Training Loss: 1.3806\n",
      "    Validation Batch [1/1], Loss: 1.3079\n",
      "Validation Loss: 1.3079, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [77/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/1000] completed, Average Training Loss: 1.3544\n",
      "    Validation Batch [1/1], Loss: 1.3394\n",
      "Validation Loss: 1.3394, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [78/1000] - Training\n",
      "Epoch [78/1000] completed, Average Training Loss: 1.3428\n",
      "    Validation Batch [1/1], Loss: 1.2777\n",
      "Validation Loss: 1.2777, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.3078 to 1.2777. Saving model...\n",
      "\n",
      "LOG: Epoch [79/1000] - Training\n",
      "Epoch [79/1000] completed, Average Training Loss: 1.3360\n",
      "    Validation Batch [1/1], Loss: 1.2983\n",
      "Validation Loss: 1.2983, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [80/1000] - Training\n",
      "Epoch [80/1000] completed, Average Training Loss: 1.3059\n",
      "    Validation Batch [1/1], Loss: 1.2988\n",
      "Validation Loss: 1.2988, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [81/1000] - Training\n",
      "Epoch [81/1000] completed, Average Training Loss: 1.3094\n",
      "    Validation Batch [1/1], Loss: 1.2346\n",
      "Validation Loss: 1.2346, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 1.2777 to 1.2346. Saving model...\n",
      "\n",
      "LOG: Epoch [82/1000] - Training\n",
      "Epoch [82/1000] completed, Average Training Loss: 1.2978\n",
      "    Validation Batch [1/1], Loss: 1.2291\n",
      "Validation Loss: 1.2291, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 1.2346 to 1.2291. Saving model...\n",
      "\n",
      "LOG: Epoch [83/1000] - Training\n",
      "Epoch [83/1000] completed, Average Training Loss: 1.2753\n",
      "    Validation Batch [1/1], Loss: 1.2164\n",
      "Validation Loss: 1.2164, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 1.2291 to 1.2164. Saving model...\n",
      "\n",
      "LOG: Epoch [84/1000] - Training\n",
      "Epoch [84/1000] completed, Average Training Loss: 1.2507\n",
      "    Validation Batch [1/1], Loss: 1.2074\n",
      "Validation Loss: 1.2074, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 1.2164 to 1.2074. Saving model...\n",
      "\n",
      "LOG: Epoch [85/1000] - Training\n",
      "Epoch [85/1000] completed, Average Training Loss: 1.2423\n",
      "    Validation Batch [1/1], Loss: 1.1829\n",
      "Validation Loss: 1.1829, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.2074 to 1.1829. Saving model...\n",
      "\n",
      "LOG: Epoch [86/1000] - Training\n",
      "Epoch [86/1000] completed, Average Training Loss: 1.2301\n",
      "    Validation Batch [1/1], Loss: 1.1913\n",
      "Validation Loss: 1.1913, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [87/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/1000] completed, Average Training Loss: 1.2035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 1.1694\n",
      "Validation Loss: 1.1694, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 1.1829 to 1.1694. Saving model...\n",
      "\n",
      "LOG: Epoch [88/1000] - Training\n",
      "Epoch [88/1000] completed, Average Training Loss: 1.2056\n",
      "    Validation Batch [1/1], Loss: 1.1426\n",
      "Validation Loss: 1.1426, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 1.1694 to 1.1426. Saving model...\n",
      "\n",
      "LOG: Epoch [89/1000] - Training\n",
      "Epoch [89/1000] completed, Average Training Loss: 1.1618\n",
      "    Validation Batch [1/1], Loss: 1.1782\n",
      "Validation Loss: 1.1782, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [90/1000] - Training\n",
      "Epoch [90/1000] completed, Average Training Loss: 1.1776\n",
      "    Validation Batch [1/1], Loss: 1.1462\n",
      "Validation Loss: 1.1462, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [91/1000] - Training\n",
      "Epoch [91/1000] completed, Average Training Loss: 1.1538\n",
      "    Validation Batch [1/1], Loss: 1.0823\n",
      "Validation Loss: 1.0823, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 1.1426 to 1.0823. Saving model...\n",
      "\n",
      "LOG: Epoch [92/1000] - Training\n",
      "Epoch [92/1000] completed, Average Training Loss: 1.1293\n",
      "    Validation Batch [1/1], Loss: 1.0855\n",
      "Validation Loss: 1.0855, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [93/1000] - Training\n",
      "Epoch [93/1000] completed, Average Training Loss: 1.1377\n",
      "    Validation Batch [1/1], Loss: 1.0894\n",
      "Validation Loss: 1.0894, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [94/1000] - Training\n",
      "Epoch [94/1000] completed, Average Training Loss: 1.1152\n",
      "    Validation Batch [1/1], Loss: 1.0448\n",
      "Validation Loss: 1.0448, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 1.0823 to 1.0448. Saving model...\n",
      "\n",
      "LOG: Epoch [95/1000] - Training\n",
      "Epoch [95/1000] completed, Average Training Loss: 1.1109\n",
      "    Validation Batch [1/1], Loss: 1.0374\n",
      "Validation Loss: 1.0374, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 1.0448 to 1.0374. Saving model...\n",
      "\n",
      "LOG: Epoch [96/1000] - Training\n",
      "Epoch [96/1000] completed, Average Training Loss: 1.1062\n",
      "    Validation Batch [1/1], Loss: 1.0142\n",
      "Validation Loss: 1.0142, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 1.0374 to 1.0142. Saving model...\n",
      "\n",
      "LOG: Epoch [97/1000] - Training\n",
      "Epoch [97/1000] completed, Average Training Loss: 1.0684\n",
      "    Validation Batch [1/1], Loss: 1.0272\n",
      "Validation Loss: 1.0272, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [98/1000] - Training\n",
      "Epoch [98/1000] completed, Average Training Loss: 1.0464\n",
      "    Validation Batch [1/1], Loss: 1.0294\n",
      "Validation Loss: 1.0294, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [99/1000] - Training\n",
      "Epoch [99/1000] completed, Average Training Loss: 1.0412\n",
      "    Validation Batch [1/1], Loss: 0.9834\n",
      "Validation Loss: 0.9834, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 1.0142 to 0.9834. Saving model...\n",
      "\n",
      "LOG: Epoch [100/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000] completed, Average Training Loss: 1.0312\n",
      "    Validation Batch [1/1], Loss: 0.9596\n",
      "Validation Loss: 0.9596, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 0.9834 to 0.9596. Saving model...\n",
      "\n",
      "LOG: Epoch [101/1000] - Training\n",
      "Epoch [101/1000] completed, Average Training Loss: 1.0192\n",
      "    Validation Batch [1/1], Loss: 0.9614\n",
      "Validation Loss: 0.9614, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [102/1000] - Training\n",
      "Epoch [102/1000] completed, Average Training Loss: 1.0005\n",
      "    Validation Batch [1/1], Loss: 0.9649\n",
      "Validation Loss: 0.9649, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [103/1000] - Training\n",
      "Epoch [103/1000] completed, Average Training Loss: 0.9803\n",
      "    Validation Batch [1/1], Loss: 0.9320\n",
      "Validation Loss: 0.9320, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.9596 to 0.9320. Saving model...\n",
      "\n",
      "LOG: Epoch [104/1000] - Training\n",
      "Epoch [104/1000] completed, Average Training Loss: 0.9645\n",
      "    Validation Batch [1/1], Loss: 0.9358\n",
      "Validation Loss: 0.9358, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [105/1000] - Training\n",
      "Epoch [105/1000] completed, Average Training Loss: 0.9508\n",
      "    Validation Batch [1/1], Loss: 0.9402\n",
      "Validation Loss: 0.9402, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [106/1000] - Training\n",
      "Epoch [106/1000] completed, Average Training Loss: 0.9475\n",
      "    Validation Batch [1/1], Loss: 0.8763\n",
      "Validation Loss: 0.8763, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.9320 to 0.8763. Saving model...\n",
      "\n",
      "LOG: Epoch [107/1000] - Training\n",
      "Epoch [107/1000] completed, Average Training Loss: 0.9178\n",
      "    Validation Batch [1/1], Loss: 0.8887\n",
      "Validation Loss: 0.8887, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [108/1000] - Training\n",
      "Epoch [108/1000] completed, Average Training Loss: 0.9381\n",
      "    Validation Batch [1/1], Loss: 0.8882\n",
      "Validation Loss: 0.8882, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [109/1000] - Training\n",
      "Epoch [109/1000] completed, Average Training Loss: 0.9197\n",
      "    Validation Batch [1/1], Loss: 0.8581\n",
      "Validation Loss: 0.8581, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.8763 to 0.8581. Saving model...\n",
      "\n",
      "LOG: Epoch [110/1000] - Training\n",
      "Epoch [110/1000] completed, Average Training Loss: 0.8817\n",
      "    Validation Batch [1/1], Loss: 0.8507\n",
      "Validation Loss: 0.8507, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.8581 to 0.8507. Saving model...\n",
      "\n",
      "LOG: Epoch [111/1000] - Training\n",
      "Epoch [111/1000] completed, Average Training Loss: 0.8661\n",
      "    Validation Batch [1/1], Loss: 0.8266\n",
      "Validation Loss: 0.8266, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.8507 to 0.8266. Saving model...\n",
      "\n",
      "LOG: Epoch [112/1000] - Training\n",
      "Epoch [112/1000] completed, Average Training Loss: 0.8616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.8310\n",
      "Validation Loss: 0.8310, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [113/1000] - Training\n",
      "Epoch [113/1000] completed, Average Training Loss: 0.8318\n",
      "    Validation Batch [1/1], Loss: 0.7943\n",
      "Validation Loss: 0.7943, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.8266 to 0.7943. Saving model...\n",
      "\n",
      "LOG: Epoch [114/1000] - Training\n",
      "Epoch [114/1000] completed, Average Training Loss: 0.8194\n",
      "    Validation Batch [1/1], Loss: 0.8182\n",
      "Validation Loss: 0.8182, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [115/1000] - Training\n",
      "Epoch [115/1000] completed, Average Training Loss: 0.8298\n",
      "    Validation Batch [1/1], Loss: 0.7482\n",
      "Validation Loss: 0.7482, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.7943 to 0.7482. Saving model...\n",
      "\n",
      "LOG: Epoch [116/1000] - Training\n",
      "Epoch [116/1000] completed, Average Training Loss: 0.8007\n",
      "    Validation Batch [1/1], Loss: 0.7652\n",
      "Validation Loss: 0.7652, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [117/1000] - Training\n",
      "Epoch [117/1000] completed, Average Training Loss: 0.7585\n",
      "    Validation Batch [1/1], Loss: 0.7616\n",
      "Validation Loss: 0.7616, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [118/1000] - Training\n",
      "Epoch [118/1000] completed, Average Training Loss: 0.7731\n",
      "    Validation Batch [1/1], Loss: 0.7230\n",
      "Validation Loss: 0.7230, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.7482 to 0.7230. Saving model...\n",
      "\n",
      "LOG: Epoch [119/1000] - Training\n",
      "Epoch [119/1000] completed, Average Training Loss: 0.7752\n",
      "    Validation Batch [1/1], Loss: 0.7305\n",
      "Validation Loss: 0.7305, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [120/1000] - Training\n",
      "Epoch [120/1000] completed, Average Training Loss: 0.7515\n",
      "    Validation Batch [1/1], Loss: 0.6918\n",
      "Validation Loss: 0.6918, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.7230 to 0.6918. Saving model...\n",
      "\n",
      "LOG: Epoch [121/1000] - Training\n",
      "Epoch [121/1000] completed, Average Training Loss: 0.7507\n",
      "    Validation Batch [1/1], Loss: 0.6635\n",
      "Validation Loss: 0.6635, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.6918 to 0.6635. Saving model...\n",
      "\n",
      "LOG: Epoch [122/1000] - Training\n",
      "Epoch [122/1000] completed, Average Training Loss: 0.7329\n",
      "    Validation Batch [1/1], Loss: 0.6947\n",
      "Validation Loss: 0.6947, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [123/1000] - Training\n",
      "Epoch [123/1000] completed, Average Training Loss: 0.7010\n",
      "    Validation Batch [1/1], Loss: 0.7042\n",
      "Validation Loss: 0.7042, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [124/1000] - Training\n",
      "Epoch [124/1000] completed, Average Training Loss: 0.7044\n",
      "    Validation Batch [1/1], Loss: 0.7146\n",
      "Validation Loss: 0.7146, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [125/1000] - Training\n",
      "Epoch [125/1000] completed, Average Training Loss: 0.6834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.6267\n",
      "Validation Loss: 0.6267, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.6635 to 0.6267. Saving model...\n",
      "\n",
      "LOG: Epoch [126/1000] - Training\n",
      "Epoch [126/1000] completed, Average Training Loss: 0.7033\n",
      "    Validation Batch [1/1], Loss: 0.6211\n",
      "Validation Loss: 0.6211, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6267 to 0.6211. Saving model...\n",
      "\n",
      "LOG: Epoch [127/1000] - Training\n",
      "Epoch [127/1000] completed, Average Training Loss: 0.6727\n",
      "    Validation Batch [1/1], Loss: 0.6412\n",
      "Validation Loss: 0.6412, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [128/1000] - Training\n",
      "Epoch [128/1000] completed, Average Training Loss: 0.6476\n",
      "    Validation Batch [1/1], Loss: 0.6971\n",
      "Validation Loss: 0.6971, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [129/1000] - Training\n",
      "Epoch [129/1000] completed, Average Training Loss: 0.6325\n",
      "    Validation Batch [1/1], Loss: 0.7521\n",
      "Validation Loss: 0.7521, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [130/1000] - Training\n",
      "Epoch [130/1000] completed, Average Training Loss: 0.6175\n",
      "    Validation Batch [1/1], Loss: 0.5887\n",
      "Validation Loss: 0.5887, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.6211 to 0.5887. Saving model...\n",
      "\n",
      "LOG: Epoch [131/1000] - Training\n",
      "Epoch [131/1000] completed, Average Training Loss: 0.6061\n",
      "    Validation Batch [1/1], Loss: 0.5496\n",
      "Validation Loss: 0.5496, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.5887 to 0.5496. Saving model...\n",
      "\n",
      "LOG: Epoch [132/1000] - Training\n",
      "Epoch [132/1000] completed, Average Training Loss: 0.5859\n",
      "    Validation Batch [1/1], Loss: 0.6104\n",
      "Validation Loss: 0.6104, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [133/1000] - Training\n",
      "Epoch [133/1000] completed, Average Training Loss: 0.5833\n",
      "    Validation Batch [1/1], Loss: 0.5402\n",
      "Validation Loss: 0.5402, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.5496 to 0.5402. Saving model...\n",
      "\n",
      "LOG: Epoch [134/1000] - Training\n",
      "Epoch [134/1000] completed, Average Training Loss: 0.5577\n",
      "    Validation Batch [1/1], Loss: 0.5121\n",
      "Validation Loss: 0.5121, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.5402 to 0.5121. Saving model...\n",
      "\n",
      "LOG: Epoch [135/1000] - Training\n",
      "Epoch [135/1000] completed, Average Training Loss: 0.5426\n",
      "    Validation Batch [1/1], Loss: 0.5234\n",
      "Validation Loss: 0.5234, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [136/1000] - Training\n",
      "Epoch [136/1000] completed, Average Training Loss: 0.5400\n",
      "    Validation Batch [1/1], Loss: 0.4886\n",
      "Validation Loss: 0.4886, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.5121 to 0.4886. Saving model...\n",
      "\n",
      "LOG: Epoch [137/1000] - Training\n",
      "Epoch [137/1000] completed, Average Training Loss: 0.5482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.4528\n",
      "Validation Loss: 0.4528, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.4886 to 0.4528. Saving model...\n",
      "\n",
      "LOG: Epoch [138/1000] - Training\n",
      "Epoch [138/1000] completed, Average Training Loss: 0.5399\n",
      "    Validation Batch [1/1], Loss: 0.4851\n",
      "Validation Loss: 0.4851, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [139/1000] - Training\n",
      "Epoch [139/1000] completed, Average Training Loss: 0.4865\n",
      "    Validation Batch [1/1], Loss: 0.4640\n",
      "Validation Loss: 0.4640, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [140/1000] - Training\n",
      "Epoch [140/1000] completed, Average Training Loss: 0.5066\n",
      "    Validation Batch [1/1], Loss: 0.4492\n",
      "Validation Loss: 0.4492, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.4528 to 0.4492. Saving model...\n",
      "\n",
      "LOG: Epoch [141/1000] - Training\n",
      "Epoch [141/1000] completed, Average Training Loss: 0.4931\n",
      "    Validation Batch [1/1], Loss: 0.4378\n",
      "Validation Loss: 0.4378, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4492 to 0.4378. Saving model...\n",
      "\n",
      "LOG: Epoch [142/1000] - Training\n",
      "Epoch [142/1000] completed, Average Training Loss: 0.4811\n",
      "    Validation Batch [1/1], Loss: 0.3990\n",
      "Validation Loss: 0.3990, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.4378 to 0.3990. Saving model...\n",
      "\n",
      "LOG: Epoch [143/1000] - Training\n",
      "Epoch [143/1000] completed, Average Training Loss: 0.4941\n",
      "    Validation Batch [1/1], Loss: 0.4163\n",
      "Validation Loss: 0.4163, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [144/1000] - Training\n",
      "Epoch [144/1000] completed, Average Training Loss: 0.4632\n",
      "    Validation Batch [1/1], Loss: 0.3975\n",
      "Validation Loss: 0.3975, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3990 to 0.3975. Saving model...\n",
      "\n",
      "LOG: Epoch [145/1000] - Training\n",
      "Epoch [145/1000] completed, Average Training Loss: 0.4599\n",
      "    Validation Batch [1/1], Loss: 0.3862\n",
      "Validation Loss: 0.3862, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3975 to 0.3862. Saving model...\n",
      "\n",
      "LOG: Epoch [146/1000] - Training\n",
      "Epoch [146/1000] completed, Average Training Loss: 0.4449\n",
      "    Validation Batch [1/1], Loss: 0.3845\n",
      "Validation Loss: 0.3845, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3862 to 0.3845. Saving model...\n",
      "\n",
      "LOG: Epoch [147/1000] - Training\n",
      "Epoch [147/1000] completed, Average Training Loss: 0.4449\n",
      "    Validation Batch [1/1], Loss: 0.3622\n",
      "Validation Loss: 0.3622, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3845 to 0.3622. Saving model...\n",
      "\n",
      "LOG: Epoch [148/1000] - Training\n",
      "Epoch [148/1000] completed, Average Training Loss: 0.4354\n",
      "    Validation Batch [1/1], Loss: 0.3634\n",
      "Validation Loss: 0.3634, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [149/1000] - Training\n",
      "Epoch [149/1000] completed, Average Training Loss: 0.4040\n",
      "    Validation Batch [1/1], Loss: 0.4043\n",
      "Validation Loss: 0.4043, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [150/1000] - Training\n",
      "Epoch [150/1000] completed, Average Training Loss: 0.4229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.3462\n",
      "Validation Loss: 0.3462, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3622 to 0.3462. Saving model...\n",
      "\n",
      "LOG: Epoch [151/1000] - Training\n",
      "Epoch [151/1000] completed, Average Training Loss: 0.3995\n",
      "    Validation Batch [1/1], Loss: 0.3418\n",
      "Validation Loss: 0.3418, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3462 to 0.3418. Saving model...\n",
      "\n",
      "LOG: Epoch [152/1000] - Training\n",
      "Epoch [152/1000] completed, Average Training Loss: 0.4148\n",
      "    Validation Batch [1/1], Loss: 0.3572\n",
      "Validation Loss: 0.3572, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [153/1000] - Training\n",
      "Epoch [153/1000] completed, Average Training Loss: 0.3862\n",
      "    Validation Batch [1/1], Loss: 0.3207\n",
      "Validation Loss: 0.3207, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3418 to 0.3207. Saving model...\n",
      "\n",
      "LOG: Epoch [154/1000] - Training\n",
      "Epoch [154/1000] completed, Average Training Loss: 0.3771\n",
      "    Validation Batch [1/1], Loss: 0.3143\n",
      "Validation Loss: 0.3143, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3207 to 0.3143. Saving model...\n",
      "\n",
      "LOG: Epoch [155/1000] - Training\n",
      "Epoch [155/1000] completed, Average Training Loss: 0.3676\n",
      "    Validation Batch [1/1], Loss: 0.3226\n",
      "Validation Loss: 0.3226, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [156/1000] - Training\n",
      "Epoch [156/1000] completed, Average Training Loss: 0.3702\n",
      "    Validation Batch [1/1], Loss: 0.3106\n",
      "Validation Loss: 0.3106, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3143 to 0.3106. Saving model...\n",
      "\n",
      "LOG: Epoch [157/1000] - Training\n",
      "Epoch [157/1000] completed, Average Training Loss: 0.3746\n",
      "    Validation Batch [1/1], Loss: 0.2887\n",
      "Validation Loss: 0.2887, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3106 to 0.2887. Saving model...\n",
      "\n",
      "LOG: Epoch [158/1000] - Training\n",
      "Epoch [158/1000] completed, Average Training Loss: 0.3476\n",
      "    Validation Batch [1/1], Loss: 0.3363\n",
      "Validation Loss: 0.3363, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [159/1000] - Training\n",
      "Epoch [159/1000] completed, Average Training Loss: 0.3517\n",
      "    Validation Batch [1/1], Loss: 0.2737\n",
      "Validation Loss: 0.2737, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2887 to 0.2737. Saving model...\n",
      "\n",
      "LOG: Epoch [160/1000] - Training\n",
      "Epoch [160/1000] completed, Average Training Loss: 0.3120\n",
      "    Validation Batch [1/1], Loss: 0.2665\n",
      "Validation Loss: 0.2665, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2737 to 0.2665. Saving model...\n",
      "\n",
      "LOG: Epoch [161/1000] - Training\n",
      "Epoch [161/1000] completed, Average Training Loss: 0.3403\n",
      "    Validation Batch [1/1], Loss: 0.2718\n",
      "Validation Loss: 0.2718, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [162/1000] - Training\n",
      "Epoch [162/1000] completed, Average Training Loss: 0.3213\n",
      "    Validation Batch [1/1], Loss: 0.2928\n",
      "Validation Loss: 0.2928, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [163/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [163/1000] completed, Average Training Loss: 0.3201\n",
      "    Validation Batch [1/1], Loss: 0.2610\n",
      "Validation Loss: 0.2610, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2665 to 0.2610. Saving model...\n",
      "\n",
      "LOG: Epoch [164/1000] - Training\n",
      "Epoch [164/1000] completed, Average Training Loss: 0.3444\n",
      "    Validation Batch [1/1], Loss: 0.2377\n",
      "Validation Loss: 0.2377, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2610 to 0.2377. Saving model...\n",
      "\n",
      "LOG: Epoch [165/1000] - Training\n",
      "Epoch [165/1000] completed, Average Training Loss: 0.3082\n",
      "    Validation Batch [1/1], Loss: 0.2502\n",
      "Validation Loss: 0.2502, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [166/1000] - Training\n",
      "Epoch [166/1000] completed, Average Training Loss: 0.2917\n",
      "    Validation Batch [1/1], Loss: 0.2295\n",
      "Validation Loss: 0.2295, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2377 to 0.2295. Saving model...\n",
      "\n",
      "LOG: Epoch [167/1000] - Training\n",
      "Epoch [167/1000] completed, Average Training Loss: 0.2905\n",
      "    Validation Batch [1/1], Loss: 0.2240\n",
      "Validation Loss: 0.2240, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2295 to 0.2240. Saving model...\n",
      "\n",
      "LOG: Epoch [168/1000] - Training\n",
      "Epoch [168/1000] completed, Average Training Loss: 0.2988\n",
      "    Validation Batch [1/1], Loss: 0.2258\n",
      "Validation Loss: 0.2258, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [169/1000] - Training\n",
      "Epoch [169/1000] completed, Average Training Loss: 0.2913\n",
      "    Validation Batch [1/1], Loss: 0.2143\n",
      "Validation Loss: 0.2143, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2240 to 0.2143. Saving model...\n",
      "\n",
      "LOG: Epoch [170/1000] - Training\n",
      "Epoch [170/1000] completed, Average Training Loss: 0.2761\n",
      "    Validation Batch [1/1], Loss: 0.2080\n",
      "Validation Loss: 0.2080, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2143 to 0.2080. Saving model...\n",
      "\n",
      "LOG: Epoch [171/1000] - Training\n",
      "Epoch [171/1000] completed, Average Training Loss: 0.2798\n",
      "    Validation Batch [1/1], Loss: 0.2245\n",
      "Validation Loss: 0.2245, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [172/1000] - Training\n",
      "Epoch [172/1000] completed, Average Training Loss: 0.2748\n",
      "    Validation Batch [1/1], Loss: 0.2054\n",
      "Validation Loss: 0.2054, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2080 to 0.2054. Saving model...\n",
      "\n",
      "LOG: Epoch [173/1000] - Training\n",
      "Epoch [173/1000] completed, Average Training Loss: 0.2659\n",
      "    Validation Batch [1/1], Loss: 0.2133\n",
      "Validation Loss: 0.2133, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [174/1000] - Training\n",
      "Epoch [174/1000] completed, Average Training Loss: 0.2630\n",
      "    Validation Batch [1/1], Loss: 0.2095\n",
      "Validation Loss: 0.2095, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [175/1000] - Training\n",
      "Epoch [175/1000] completed, Average Training Loss: 0.2672\n",
      "    Validation Batch [1/1], Loss: 0.1883\n",
      "Validation Loss: 0.1883, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2054 to 0.1883. Saving model...\n",
      "\n",
      "LOG: Epoch [176/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [176/1000] completed, Average Training Loss: 0.2645\n",
      "    Validation Batch [1/1], Loss: 0.1952\n",
      "Validation Loss: 0.1952, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [177/1000] - Training\n",
      "Epoch [177/1000] completed, Average Training Loss: 0.2531\n",
      "    Validation Batch [1/1], Loss: 0.2064\n",
      "Validation Loss: 0.2064, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [178/1000] - Training\n",
      "Epoch [178/1000] completed, Average Training Loss: 0.2606\n",
      "    Validation Batch [1/1], Loss: 0.1819\n",
      "Validation Loss: 0.1819, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1883 to 0.1819. Saving model...\n",
      "\n",
      "LOG: Epoch [179/1000] - Training\n",
      "Epoch [179/1000] completed, Average Training Loss: 0.2566\n",
      "    Validation Batch [1/1], Loss: 0.2162\n",
      "Validation Loss: 0.2162, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [180/1000] - Training\n",
      "Epoch [180/1000] completed, Average Training Loss: 0.2322\n",
      "    Validation Batch [1/1], Loss: 0.2037\n",
      "Validation Loss: 0.2037, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [181/1000] - Training\n",
      "Epoch [181/1000] completed, Average Training Loss: 0.2272\n",
      "    Validation Batch [1/1], Loss: 0.1954\n",
      "Validation Loss: 0.1954, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [182/1000] - Training\n",
      "Epoch [182/1000] completed, Average Training Loss: 0.2280\n",
      "    Validation Batch [1/1], Loss: 0.1787\n",
      "Validation Loss: 0.1787, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1819 to 0.1787. Saving model...\n",
      "\n",
      "LOG: Epoch [183/1000] - Training\n",
      "Epoch [183/1000] completed, Average Training Loss: 0.2311\n",
      "    Validation Batch [1/1], Loss: 0.2095\n",
      "Validation Loss: 0.2095, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [184/1000] - Training\n",
      "Epoch [184/1000] completed, Average Training Loss: 0.2287\n",
      "    Validation Batch [1/1], Loss: 0.1764\n",
      "Validation Loss: 0.1764, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1787 to 0.1764. Saving model...\n",
      "\n",
      "LOG: Epoch [185/1000] - Training\n",
      "Epoch [185/1000] completed, Average Training Loss: 0.2387\n",
      "    Validation Batch [1/1], Loss: 0.1521\n",
      "Validation Loss: 0.1521, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1764 to 0.1521. Saving model...\n",
      "\n",
      "LOG: Epoch [186/1000] - Training\n",
      "Epoch [186/1000] completed, Average Training Loss: 0.2128\n",
      "    Validation Batch [1/1], Loss: 0.1766\n",
      "Validation Loss: 0.1766, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [187/1000] - Training\n",
      "Epoch [187/1000] completed, Average Training Loss: 0.1979\n",
      "    Validation Batch [1/1], Loss: 0.1450\n",
      "Validation Loss: 0.1450, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1521 to 0.1450. Saving model...\n",
      "\n",
      "LOG: Epoch [188/1000] - Training\n",
      "Epoch [188/1000] completed, Average Training Loss: 0.1945\n",
      "    Validation Batch [1/1], Loss: 0.1492\n",
      "Validation Loss: 0.1492, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [189/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [189/1000] completed, Average Training Loss: 0.2071\n",
      "    Validation Batch [1/1], Loss: 0.1649\n",
      "Validation Loss: 0.1649, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [190/1000] - Training\n",
      "Epoch [190/1000] completed, Average Training Loss: 0.2016\n",
      "    Validation Batch [1/1], Loss: 0.1532\n",
      "Validation Loss: 0.1532, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [191/1000] - Training\n",
      "Epoch [191/1000] completed, Average Training Loss: 0.2041\n",
      "    Validation Batch [1/1], Loss: 0.1477\n",
      "Validation Loss: 0.1477, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [192/1000] - Training\n",
      "Epoch [192/1000] completed, Average Training Loss: 0.1851\n",
      "    Validation Batch [1/1], Loss: 0.1615\n",
      "Validation Loss: 0.1615, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [193/1000] - Training\n",
      "Epoch [193/1000] completed, Average Training Loss: 0.1842\n",
      "    Validation Batch [1/1], Loss: 0.1600\n",
      "Validation Loss: 0.1600, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [194/1000] - Training\n",
      "Epoch [194/1000] completed, Average Training Loss: 0.2037\n",
      "    Validation Batch [1/1], Loss: 0.1745\n",
      "Validation Loss: 0.1745, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [195/1000] - Training\n",
      "Epoch [195/1000] completed, Average Training Loss: 0.1905\n",
      "    Validation Batch [1/1], Loss: 0.1345\n",
      "Validation Loss: 0.1345, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1450 to 0.1345. Saving model...\n",
      "\n",
      "LOG: Epoch [196/1000] - Training\n",
      "Epoch [196/1000] completed, Average Training Loss: 0.1835\n",
      "    Validation Batch [1/1], Loss: 0.1768\n",
      "Validation Loss: 0.1768, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [197/1000] - Training\n",
      "Epoch [197/1000] completed, Average Training Loss: 0.1846\n",
      "    Validation Batch [1/1], Loss: 0.1342\n",
      "Validation Loss: 0.1342, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1345 to 0.1342. Saving model...\n",
      "\n",
      "LOG: Epoch [198/1000] - Training\n",
      "Epoch [198/1000] completed, Average Training Loss: 0.1754\n",
      "    Validation Batch [1/1], Loss: 0.1353\n",
      "Validation Loss: 0.1353, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [199/1000] - Training\n",
      "Epoch [199/1000] completed, Average Training Loss: 0.1622\n",
      "    Validation Batch [1/1], Loss: 0.1484\n",
      "Validation Loss: 0.1484, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [200/1000] - Training\n",
      "Epoch [200/1000] completed, Average Training Loss: 0.1914\n",
      "    Validation Batch [1/1], Loss: 0.1557\n",
      "Validation Loss: 0.1557, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [201/1000] - Training\n",
      "Epoch [201/1000] completed, Average Training Loss: 0.1764\n",
      "    Validation Batch [1/1], Loss: 0.1220\n",
      "Validation Loss: 0.1220, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1342 to 0.1220. Saving model...\n",
      "\n",
      "LOG: Epoch [202/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [202/1000] completed, Average Training Loss: 0.1716\n",
      "    Validation Batch [1/1], Loss: 0.1391\n",
      "Validation Loss: 0.1391, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [203/1000] - Training\n",
      "Epoch [203/1000] completed, Average Training Loss: 0.1597\n",
      "    Validation Batch [1/1], Loss: 0.1246\n",
      "Validation Loss: 0.1246, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [204/1000] - Training\n",
      "Epoch [204/1000] completed, Average Training Loss: 0.1607\n",
      "    Validation Batch [1/1], Loss: 0.1335\n",
      "Validation Loss: 0.1335, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [205/1000] - Training\n",
      "Epoch [205/1000] completed, Average Training Loss: 0.1622\n",
      "    Validation Batch [1/1], Loss: 0.1172\n",
      "Validation Loss: 0.1172, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1220 to 0.1172. Saving model...\n",
      "\n",
      "LOG: Epoch [206/1000] - Training\n",
      "Epoch [206/1000] completed, Average Training Loss: 0.1599\n",
      "    Validation Batch [1/1], Loss: 0.1030\n",
      "Validation Loss: 0.1030, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1172 to 0.1030. Saving model...\n",
      "\n",
      "LOG: Epoch [207/1000] - Training\n",
      "Epoch [207/1000] completed, Average Training Loss: 0.1522\n",
      "    Validation Batch [1/1], Loss: 0.1015\n",
      "Validation Loss: 0.1015, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1030 to 0.1015. Saving model...\n",
      "\n",
      "LOG: Epoch [208/1000] - Training\n",
      "Epoch [208/1000] completed, Average Training Loss: 0.1548\n",
      "    Validation Batch [1/1], Loss: 0.1114\n",
      "Validation Loss: 0.1114, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [209/1000] - Training\n",
      "Epoch [209/1000] completed, Average Training Loss: 0.1502\n",
      "    Validation Batch [1/1], Loss: 0.1105\n",
      "Validation Loss: 0.1105, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [210/1000] - Training\n",
      "Epoch [210/1000] completed, Average Training Loss: 0.1628\n",
      "    Validation Batch [1/1], Loss: 0.1155\n",
      "Validation Loss: 0.1155, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [211/1000] - Training\n",
      "Epoch [211/1000] completed, Average Training Loss: 0.1494\n",
      "    Validation Batch [1/1], Loss: 0.1064\n",
      "Validation Loss: 0.1064, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [212/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [212/1000] completed, Average Training Loss: 0.1505\n",
      "    Validation Batch [1/1], Loss: 0.0923\n",
      "Validation Loss: 0.0923, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1015 to 0.0923. Saving model...\n",
      "\n",
      "LOG: Epoch [213/1000] - Training\n",
      "Epoch [213/1000] completed, Average Training Loss: 0.1501\n",
      "    Validation Batch [1/1], Loss: 0.0924\n",
      "Validation Loss: 0.0924, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [214/1000] - Training\n",
      "Epoch [214/1000] completed, Average Training Loss: 0.1425\n",
      "    Validation Batch [1/1], Loss: 0.0875\n",
      "Validation Loss: 0.0875, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0923 to 0.0875. Saving model...\n",
      "\n",
      "LOG: Epoch [215/1000] - Training\n",
      "Epoch [215/1000] completed, Average Training Loss: 0.1455\n",
      "    Validation Batch [1/1], Loss: 0.0963\n",
      "Validation Loss: 0.0963, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [216/1000] - Training\n",
      "Epoch [216/1000] completed, Average Training Loss: 0.1389\n",
      "    Validation Batch [1/1], Loss: 0.0902\n",
      "Validation Loss: 0.0902, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [217/1000] - Training\n",
      "Epoch [217/1000] completed, Average Training Loss: 0.1344\n",
      "    Validation Batch [1/1], Loss: 0.0898\n",
      "Validation Loss: 0.0898, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [218/1000] - Training\n",
      "Epoch [218/1000] completed, Average Training Loss: 0.1395\n",
      "    Validation Batch [1/1], Loss: 0.0921\n",
      "Validation Loss: 0.0921, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [219/1000] - Training\n",
      "Epoch [219/1000] completed, Average Training Loss: 0.1388\n",
      "    Validation Batch [1/1], Loss: 0.0889\n",
      "Validation Loss: 0.0889, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [220/1000] - Training\n",
      "Epoch [220/1000] completed, Average Training Loss: 0.1335\n",
      "    Validation Batch [1/1], Loss: 0.0924\n",
      "Validation Loss: 0.0924, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [221/1000] - Training\n",
      "Epoch [221/1000] completed, Average Training Loss: 0.1294\n",
      "    Validation Batch [1/1], Loss: 0.0914\n",
      "Validation Loss: 0.0914, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [222/1000] - Training\n",
      "Epoch [222/1000] completed, Average Training Loss: 0.1263\n",
      "    Validation Batch [1/1], Loss: 0.1016\n",
      "Validation Loss: 0.1016, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [223/1000] - Training\n",
      "Epoch [223/1000] completed, Average Training Loss: 0.1434\n",
      "    Validation Batch [1/1], Loss: 0.0880\n",
      "Validation Loss: 0.0880, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [224/1000] - Training\n",
      "Epoch [224/1000] completed, Average Training Loss: 0.1379\n",
      "    Validation Batch [1/1], Loss: 0.0959\n",
      "Validation Loss: 0.0959, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [225/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [225/1000] completed, Average Training Loss: 0.1263\n",
      "    Validation Batch [1/1], Loss: 0.0950\n",
      "Validation Loss: 0.0950, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [226/1000] - Training\n",
      "Epoch [226/1000] completed, Average Training Loss: 0.1219\n",
      "    Validation Batch [1/1], Loss: 0.0928\n",
      "Validation Loss: 0.0928, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [227/1000] - Training\n",
      "Epoch [227/1000] completed, Average Training Loss: 0.1203\n",
      "    Validation Batch [1/1], Loss: 0.0801\n",
      "Validation Loss: 0.0801, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0875 to 0.0801. Saving model...\n",
      "\n",
      "LOG: Epoch [228/1000] - Training\n",
      "Epoch [228/1000] completed, Average Training Loss: 0.1136\n",
      "    Validation Batch [1/1], Loss: 0.0751\n",
      "Validation Loss: 0.0751, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0801 to 0.0751. Saving model...\n",
      "\n",
      "LOG: Epoch [229/1000] - Training\n",
      "Epoch [229/1000] completed, Average Training Loss: 0.1311\n",
      "    Validation Batch [1/1], Loss: 0.0930\n",
      "Validation Loss: 0.0930, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [230/1000] - Training\n",
      "Epoch [230/1000] completed, Average Training Loss: 0.1236\n",
      "    Validation Batch [1/1], Loss: 0.0861\n",
      "Validation Loss: 0.0861, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [231/1000] - Training\n",
      "Epoch [231/1000] completed, Average Training Loss: 0.1223\n",
      "    Validation Batch [1/1], Loss: 0.0679\n",
      "Validation Loss: 0.0679, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0751 to 0.0679. Saving model...\n",
      "\n",
      "LOG: Epoch [232/1000] - Training\n",
      "Epoch [232/1000] completed, Average Training Loss: 0.1107\n",
      "    Validation Batch [1/1], Loss: 0.0676\n",
      "Validation Loss: 0.0676, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0679 to 0.0676. Saving model...\n",
      "\n",
      "LOG: Epoch [233/1000] - Training\n",
      "Epoch [233/1000] completed, Average Training Loss: 0.1166\n",
      "    Validation Batch [1/1], Loss: 0.0781\n",
      "Validation Loss: 0.0781, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [234/1000] - Training\n",
      "Epoch [234/1000] completed, Average Training Loss: 0.1112\n",
      "    Validation Batch [1/1], Loss: 0.0751\n",
      "Validation Loss: 0.0751, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [235/1000] - Training\n",
      "Epoch [235/1000] completed, Average Training Loss: 0.1118\n",
      "    Validation Batch [1/1], Loss: 0.0735\n",
      "Validation Loss: 0.0735, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [236/1000] - Training\n",
      "Epoch [236/1000] completed, Average Training Loss: 0.1107\n",
      "    Validation Batch [1/1], Loss: 0.1184\n",
      "Validation Loss: 0.1184, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [237/1000] - Training\n",
      "Epoch [237/1000] completed, Average Training Loss: 0.1092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0783\n",
      "Validation Loss: 0.0783, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [238/1000] - Training\n",
      "Epoch [238/1000] completed, Average Training Loss: 0.1092\n",
      "    Validation Batch [1/1], Loss: 0.0696\n",
      "Validation Loss: 0.0696, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [239/1000] - Training\n",
      "Epoch [239/1000] completed, Average Training Loss: 0.1075\n",
      "    Validation Batch [1/1], Loss: 0.0700\n",
      "Validation Loss: 0.0700, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [240/1000] - Training\n",
      "Epoch [240/1000] completed, Average Training Loss: 0.1151\n",
      "    Validation Batch [1/1], Loss: 0.0849\n",
      "Validation Loss: 0.0849, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [241/1000] - Training\n",
      "Epoch [241/1000] completed, Average Training Loss: 0.1127\n",
      "    Validation Batch [1/1], Loss: 0.0658\n",
      "Validation Loss: 0.0658, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0676 to 0.0658. Saving model...\n",
      "\n",
      "LOG: Epoch [242/1000] - Training\n",
      "Epoch [242/1000] completed, Average Training Loss: 0.1059\n",
      "    Validation Batch [1/1], Loss: 0.0583\n",
      "Validation Loss: 0.0583, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0658 to 0.0583. Saving model...\n",
      "\n",
      "LOG: Epoch [243/1000] - Training\n",
      "Epoch [243/1000] completed, Average Training Loss: 0.0976\n",
      "    Validation Batch [1/1], Loss: 0.0603\n",
      "Validation Loss: 0.0603, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [244/1000] - Training\n",
      "Epoch [244/1000] completed, Average Training Loss: 0.1054\n",
      "    Validation Batch [1/1], Loss: 0.0728\n",
      "Validation Loss: 0.0728, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [245/1000] - Training\n",
      "Epoch [245/1000] completed, Average Training Loss: 0.0993\n",
      "    Validation Batch [1/1], Loss: 0.0662\n",
      "Validation Loss: 0.0662, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [246/1000] - Training\n",
      "Epoch [246/1000] completed, Average Training Loss: 0.0998\n",
      "    Validation Batch [1/1], Loss: 0.0590\n",
      "Validation Loss: 0.0590, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [247/1000] - Training\n",
      "Epoch [247/1000] completed, Average Training Loss: 0.1043\n",
      "    Validation Batch [1/1], Loss: 0.0565\n",
      "Validation Loss: 0.0565, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0583 to 0.0565. Saving model...\n",
      "\n",
      "LOG: Epoch [248/1000] - Training\n",
      "Epoch [248/1000] completed, Average Training Loss: 0.0978\n",
      "    Validation Batch [1/1], Loss: 0.0601\n",
      "Validation Loss: 0.0601, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [249/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [249/1000] completed, Average Training Loss: 0.0960\n",
      "    Validation Batch [1/1], Loss: 0.0640\n",
      "Validation Loss: 0.0640, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [250/1000] - Training\n",
      "Epoch [250/1000] completed, Average Training Loss: 0.0931\n",
      "    Validation Batch [1/1], Loss: 0.0605\n",
      "Validation Loss: 0.0605, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [251/1000] - Training\n",
      "Epoch [251/1000] completed, Average Training Loss: 0.1018\n",
      "    Validation Batch [1/1], Loss: 0.0556\n",
      "Validation Loss: 0.0556, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0565 to 0.0556. Saving model...\n",
      "\n",
      "LOG: Epoch [252/1000] - Training\n",
      "Epoch [252/1000] completed, Average Training Loss: 0.0918\n",
      "    Validation Batch [1/1], Loss: 0.0577\n",
      "Validation Loss: 0.0577, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [253/1000] - Training\n",
      "Epoch [253/1000] completed, Average Training Loss: 0.0940\n",
      "    Validation Batch [1/1], Loss: 0.0619\n",
      "Validation Loss: 0.0619, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [254/1000] - Training\n",
      "Epoch [254/1000] completed, Average Training Loss: 0.1077\n",
      "    Validation Batch [1/1], Loss: 0.0587\n",
      "Validation Loss: 0.0587, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [255/1000] - Training\n",
      "Epoch [255/1000] completed, Average Training Loss: 0.0876\n",
      "    Validation Batch [1/1], Loss: 0.0529\n",
      "Validation Loss: 0.0529, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0556 to 0.0529. Saving model...\n",
      "\n",
      "LOG: Epoch [256/1000] - Training\n",
      "Epoch [256/1000] completed, Average Training Loss: 0.0822\n",
      "    Validation Batch [1/1], Loss: 0.0541\n",
      "Validation Loss: 0.0541, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [257/1000] - Training\n",
      "Epoch [257/1000] completed, Average Training Loss: 0.0817\n",
      "    Validation Batch [1/1], Loss: 0.0514\n",
      "Validation Loss: 0.0514, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0529 to 0.0514. Saving model...\n",
      "\n",
      "LOG: Epoch [258/1000] - Training\n",
      "Epoch [258/1000] completed, Average Training Loss: 0.0837\n",
      "    Validation Batch [1/1], Loss: 0.0551\n",
      "Validation Loss: 0.0551, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [259/1000] - Training\n",
      "Epoch [259/1000] completed, Average Training Loss: 0.0869\n",
      "    Validation Batch [1/1], Loss: 0.0576\n",
      "Validation Loss: 0.0576, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [260/1000] - Training\n",
      "Epoch [260/1000] completed, Average Training Loss: 0.0888\n",
      "    Validation Batch [1/1], Loss: 0.0542\n",
      "Validation Loss: 0.0542, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [261/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [261/1000] completed, Average Training Loss: 0.0910\n",
      "    Validation Batch [1/1], Loss: 0.0538\n",
      "Validation Loss: 0.0538, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [262/1000] - Training\n",
      "Epoch [262/1000] completed, Average Training Loss: 0.0835\n",
      "    Validation Batch [1/1], Loss: 0.0521\n",
      "Validation Loss: 0.0521, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [263/1000] - Training\n",
      "Epoch [263/1000] completed, Average Training Loss: 0.0869\n",
      "    Validation Batch [1/1], Loss: 0.0515\n",
      "Validation Loss: 0.0515, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [264/1000] - Training\n",
      "Epoch [264/1000] completed, Average Training Loss: 0.0822\n",
      "    Validation Batch [1/1], Loss: 0.0491\n",
      "Validation Loss: 0.0491, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0514 to 0.0491. Saving model...\n",
      "\n",
      "LOG: Epoch [265/1000] - Training\n",
      "Epoch [265/1000] completed, Average Training Loss: 0.0837\n",
      "    Validation Batch [1/1], Loss: 0.0508\n",
      "Validation Loss: 0.0508, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [266/1000] - Training\n",
      "Epoch [266/1000] completed, Average Training Loss: 0.0764\n",
      "    Validation Batch [1/1], Loss: 0.0628\n",
      "Validation Loss: 0.0628, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [267/1000] - Training\n",
      "Epoch [267/1000] completed, Average Training Loss: 0.0855\n",
      "    Validation Batch [1/1], Loss: 0.0503\n",
      "Validation Loss: 0.0503, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [268/1000] - Training\n",
      "Epoch [268/1000] completed, Average Training Loss: 0.0785\n",
      "    Validation Batch [1/1], Loss: 0.0536\n",
      "Validation Loss: 0.0536, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [269/1000] - Training\n",
      "Epoch [269/1000] completed, Average Training Loss: 0.0753\n",
      "    Validation Batch [1/1], Loss: 0.0465\n",
      "Validation Loss: 0.0465, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0491 to 0.0465. Saving model...\n",
      "\n",
      "LOG: Epoch [270/1000] - Training\n",
      "Epoch [270/1000] completed, Average Training Loss: 0.0849\n",
      "    Validation Batch [1/1], Loss: 0.0524\n",
      "Validation Loss: 0.0524, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [271/1000] - Training\n",
      "Epoch [271/1000] completed, Average Training Loss: 0.0710\n",
      "    Validation Batch [1/1], Loss: 0.0581\n",
      "Validation Loss: 0.0581, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [272/1000] - Training\n",
      "Epoch [272/1000] completed, Average Training Loss: 0.0721\n",
      "    Validation Batch [1/1], Loss: 0.0495\n",
      "Validation Loss: 0.0495, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [273/1000] - Training\n",
      "Epoch [273/1000] completed, Average Training Loss: 0.0809\n",
      "    Validation Batch [1/1], Loss: 0.0487\n",
      "Validation Loss: 0.0487, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [274/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [274/1000] completed, Average Training Loss: 0.0735\n",
      "    Validation Batch [1/1], Loss: 0.0453\n",
      "Validation Loss: 0.0453, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0465 to 0.0453. Saving model...\n",
      "\n",
      "LOG: Epoch [275/1000] - Training\n",
      "Epoch [275/1000] completed, Average Training Loss: 0.0796\n",
      "    Validation Batch [1/1], Loss: 0.0431\n",
      "Validation Loss: 0.0431, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0453 to 0.0431. Saving model...\n",
      "\n",
      "LOG: Epoch [276/1000] - Training\n",
      "Epoch [276/1000] completed, Average Training Loss: 0.0741\n",
      "    Validation Batch [1/1], Loss: 0.0451\n",
      "Validation Loss: 0.0451, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [277/1000] - Training\n",
      "Epoch [277/1000] completed, Average Training Loss: 0.0786\n",
      "    Validation Batch [1/1], Loss: 0.0432\n",
      "Validation Loss: 0.0432, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [278/1000] - Training\n",
      "Epoch [278/1000] completed, Average Training Loss: 0.0702\n",
      "    Validation Batch [1/1], Loss: 0.0431\n",
      "Validation Loss: 0.0431, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [279/1000] - Training\n",
      "Epoch [279/1000] completed, Average Training Loss: 0.0716\n",
      "    Validation Batch [1/1], Loss: 0.0500\n",
      "Validation Loss: 0.0500, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [280/1000] - Training\n",
      "Epoch [280/1000] completed, Average Training Loss: 0.0713\n",
      "    Validation Batch [1/1], Loss: 0.0635\n",
      "Validation Loss: 0.0635, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [281/1000] - Training\n",
      "Epoch [281/1000] completed, Average Training Loss: 0.0704\n",
      "    Validation Batch [1/1], Loss: 0.0412\n",
      "Validation Loss: 0.0412, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0431 to 0.0412. Saving model...\n",
      "\n",
      "LOG: Epoch [282/1000] - Training\n",
      "Epoch [282/1000] completed, Average Training Loss: 0.0724\n",
      "    Validation Batch [1/1], Loss: 0.0454\n",
      "Validation Loss: 0.0454, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [283/1000] - Training\n",
      "Epoch [283/1000] completed, Average Training Loss: 0.0656\n",
      "    Validation Batch [1/1], Loss: 0.0442\n",
      "Validation Loss: 0.0442, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [284/1000] - Training\n",
      "Epoch [284/1000] completed, Average Training Loss: 0.0664\n",
      "    Validation Batch [1/1], Loss: 0.0378\n",
      "Validation Loss: 0.0378, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0412 to 0.0378. Saving model...\n",
      "\n",
      "LOG: Epoch [285/1000] - Training\n",
      "Epoch [285/1000] completed, Average Training Loss: 0.0652\n",
      "    Validation Batch [1/1], Loss: 0.0390\n",
      "Validation Loss: 0.0390, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [286/1000] - Training\n",
      "Epoch [286/1000] completed, Average Training Loss: 0.0678\n",
      "    Validation Batch [1/1], Loss: 0.0432\n",
      "Validation Loss: 0.0432, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [287/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [287/1000] completed, Average Training Loss: 0.0648\n",
      "    Validation Batch [1/1], Loss: 0.0457\n",
      "Validation Loss: 0.0457, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [288/1000] - Training\n",
      "Epoch [288/1000] completed, Average Training Loss: 0.0644\n",
      "    Validation Batch [1/1], Loss: 0.0387\n",
      "Validation Loss: 0.0387, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [289/1000] - Training\n",
      "Epoch [289/1000] completed, Average Training Loss: 0.0626\n",
      "    Validation Batch [1/1], Loss: 0.0359\n",
      "Validation Loss: 0.0359, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0378 to 0.0359. Saving model...\n",
      "\n",
      "LOG: Epoch [290/1000] - Training\n",
      "Epoch [290/1000] completed, Average Training Loss: 0.0626\n",
      "    Validation Batch [1/1], Loss: 0.0398\n",
      "Validation Loss: 0.0398, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [291/1000] - Training\n",
      "Epoch [291/1000] completed, Average Training Loss: 0.0641\n",
      "    Validation Batch [1/1], Loss: 0.0337\n",
      "Validation Loss: 0.0337, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0359 to 0.0337. Saving model...\n",
      "\n",
      "LOG: Epoch [292/1000] - Training\n",
      "Epoch [292/1000] completed, Average Training Loss: 0.0579\n",
      "    Validation Batch [1/1], Loss: 0.0384\n",
      "Validation Loss: 0.0384, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [293/1000] - Training\n",
      "Epoch [293/1000] completed, Average Training Loss: 0.0556\n",
      "    Validation Batch [1/1], Loss: 0.0381\n",
      "Validation Loss: 0.0381, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [294/1000] - Training\n",
      "Epoch [294/1000] completed, Average Training Loss: 0.0624\n",
      "    Validation Batch [1/1], Loss: 0.0339\n",
      "Validation Loss: 0.0339, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [295/1000] - Training\n",
      "Epoch [295/1000] completed, Average Training Loss: 0.0624\n",
      "    Validation Batch [1/1], Loss: 0.0365\n",
      "Validation Loss: 0.0365, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [296/1000] - Training\n",
      "Epoch [296/1000] completed, Average Training Loss: 0.0581\n",
      "    Validation Batch [1/1], Loss: 0.0339\n",
      "Validation Loss: 0.0339, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [297/1000] - Training\n",
      "Epoch [297/1000] completed, Average Training Loss: 0.0645\n",
      "    Validation Batch [1/1], Loss: 0.0356\n",
      "Validation Loss: 0.0356, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [298/1000] - Training\n",
      "Epoch [298/1000] completed, Average Training Loss: 0.0600\n",
      "    Validation Batch [1/1], Loss: 0.0323\n",
      "Validation Loss: 0.0323, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0337 to 0.0323. Saving model...\n",
      "\n",
      "LOG: Epoch [299/1000] - Training\n",
      "Epoch [299/1000] completed, Average Training Loss: 0.0620\n",
      "    Validation Batch [1/1], Loss: 0.0326\n",
      "Validation Loss: 0.0326, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [300/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [300/1000] completed, Average Training Loss: 0.0679\n",
      "    Validation Batch [1/1], Loss: 0.0464\n",
      "Validation Loss: 0.0464, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [301/1000] - Training\n",
      "Epoch [301/1000] completed, Average Training Loss: 0.0594\n",
      "    Validation Batch [1/1], Loss: 0.0496\n",
      "Validation Loss: 0.0496, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [302/1000] - Training\n",
      "Epoch [302/1000] completed, Average Training Loss: 0.0565\n",
      "    Validation Batch [1/1], Loss: 0.0314\n",
      "Validation Loss: 0.0314, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0323 to 0.0314. Saving model...\n",
      "\n",
      "LOG: Epoch [303/1000] - Training\n",
      "Epoch [303/1000] completed, Average Training Loss: 0.0580\n",
      "    Validation Batch [1/1], Loss: 0.0385\n",
      "Validation Loss: 0.0385, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [304/1000] - Training\n",
      "Epoch [304/1000] completed, Average Training Loss: 0.0670\n",
      "    Validation Batch [1/1], Loss: 0.0291\n",
      "Validation Loss: 0.0291, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0314 to 0.0291. Saving model...\n",
      "\n",
      "LOG: Epoch [305/1000] - Training\n",
      "Epoch [305/1000] completed, Average Training Loss: 0.0559\n",
      "    Validation Batch [1/1], Loss: 0.0416\n",
      "Validation Loss: 0.0416, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [306/1000] - Training\n",
      "Epoch [306/1000] completed, Average Training Loss: 0.0620\n",
      "    Validation Batch [1/1], Loss: 0.0433\n",
      "Validation Loss: 0.0433, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [307/1000] - Training\n",
      "Epoch [307/1000] completed, Average Training Loss: 0.0672\n",
      "    Validation Batch [1/1], Loss: 0.0322\n",
      "Validation Loss: 0.0322, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [308/1000] - Training\n",
      "Epoch [308/1000] completed, Average Training Loss: 0.0554\n",
      "    Validation Batch [1/1], Loss: 0.0358\n",
      "Validation Loss: 0.0358, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [309/1000] - Training\n",
      "Epoch [309/1000] completed, Average Training Loss: 0.0513\n",
      "    Validation Batch [1/1], Loss: 0.0278\n",
      "Validation Loss: 0.0278, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0291 to 0.0278. Saving model...\n",
      "\n",
      "LOG: Epoch [310/1000] - Training\n",
      "Epoch [310/1000] completed, Average Training Loss: 0.0528\n",
      "    Validation Batch [1/1], Loss: 0.0284\n",
      "Validation Loss: 0.0284, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [311/1000] - Training\n",
      "Epoch [311/1000] completed, Average Training Loss: 0.0533\n",
      "    Validation Batch [1/1], Loss: 0.0303\n",
      "Validation Loss: 0.0303, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [312/1000] - Training\n",
      "Epoch [312/1000] completed, Average Training Loss: 0.0496\n",
      "    Validation Batch [1/1], Loss: 0.0274\n",
      "Validation Loss: 0.0274, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0278 to 0.0274. Saving model...\n",
      "\n",
      "LOG: Epoch [313/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [313/1000] completed, Average Training Loss: 0.0537\n",
      "    Validation Batch [1/1], Loss: 0.0283\n",
      "Validation Loss: 0.0283, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [314/1000] - Training\n",
      "Epoch [314/1000] completed, Average Training Loss: 0.0590\n",
      "    Validation Batch [1/1], Loss: 0.0279\n",
      "Validation Loss: 0.0279, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [315/1000] - Training\n",
      "Epoch [315/1000] completed, Average Training Loss: 0.0492\n",
      "    Validation Batch [1/1], Loss: 0.0361\n",
      "Validation Loss: 0.0361, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [316/1000] - Training\n",
      "Epoch [316/1000] completed, Average Training Loss: 0.0535\n",
      "    Validation Batch [1/1], Loss: 0.0339\n",
      "Validation Loss: 0.0339, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [317/1000] - Training\n",
      "Epoch [317/1000] completed, Average Training Loss: 0.0493\n",
      "    Validation Batch [1/1], Loss: 0.0263\n",
      "Validation Loss: 0.0263, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0274 to 0.0263. Saving model...\n",
      "\n",
      "LOG: Epoch [318/1000] - Training\n",
      "Epoch [318/1000] completed, Average Training Loss: 0.0504\n",
      "    Validation Batch [1/1], Loss: 0.0252\n",
      "Validation Loss: 0.0252, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0263 to 0.0252. Saving model...\n",
      "\n",
      "LOG: Epoch [319/1000] - Training\n",
      "Epoch [319/1000] completed, Average Training Loss: 0.0566\n",
      "    Validation Batch [1/1], Loss: 0.0283\n",
      "Validation Loss: 0.0283, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [320/1000] - Training\n",
      "Epoch [320/1000] completed, Average Training Loss: 0.0524\n",
      "    Validation Batch [1/1], Loss: 0.0286\n",
      "Validation Loss: 0.0286, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [321/1000] - Training\n",
      "Epoch [321/1000] completed, Average Training Loss: 0.0481\n",
      "    Validation Batch [1/1], Loss: 0.0333\n",
      "Validation Loss: 0.0333, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [322/1000] - Training\n",
      "Epoch [322/1000] completed, Average Training Loss: 0.0477\n",
      "    Validation Batch [1/1], Loss: 0.0494\n",
      "Validation Loss: 0.0494, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [323/1000] - Training\n",
      "Epoch [323/1000] completed, Average Training Loss: 0.0494\n",
      "    Validation Batch [1/1], Loss: 0.0405\n",
      "Validation Loss: 0.0405, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [324/1000] - Training\n",
      "Epoch [324/1000] completed, Average Training Loss: 0.0498\n",
      "    Validation Batch [1/1], Loss: 0.0309\n",
      "Validation Loss: 0.0309, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [325/1000] - Training\n",
      "Epoch [325/1000] completed, Average Training Loss: 0.0413\n",
      "    Validation Batch [1/1], Loss: 0.0306\n",
      "Validation Loss: 0.0306, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [326/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [326/1000] completed, Average Training Loss: 0.0430\n",
      "    Validation Batch [1/1], Loss: 0.0295\n",
      "Validation Loss: 0.0295, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [327/1000] - Training\n",
      "Epoch [327/1000] completed, Average Training Loss: 0.0434\n",
      "    Validation Batch [1/1], Loss: 0.0295\n",
      "Validation Loss: 0.0295, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [328/1000] - Training\n",
      "Epoch [328/1000] completed, Average Training Loss: 0.0420\n",
      "    Validation Batch [1/1], Loss: 0.0278\n",
      "Validation Loss: 0.0278, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [329/1000] - Training\n",
      "Epoch [329/1000] completed, Average Training Loss: 0.0454\n",
      "    Validation Batch [1/1], Loss: 0.0259\n",
      "Validation Loss: 0.0259, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [330/1000] - Training\n",
      "Epoch [330/1000] completed, Average Training Loss: 0.0426\n",
      "    Validation Batch [1/1], Loss: 0.0233\n",
      "Validation Loss: 0.0233, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0252 to 0.0233. Saving model...\n",
      "\n",
      "LOG: Epoch [331/1000] - Training\n",
      "Epoch [331/1000] completed, Average Training Loss: 0.0470\n",
      "    Validation Batch [1/1], Loss: 0.0232\n",
      "Validation Loss: 0.0232, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0233 to 0.0232. Saving model...\n",
      "\n",
      "LOG: Epoch [332/1000] - Training\n",
      "Epoch [332/1000] completed, Average Training Loss: 0.0492\n",
      "    Validation Batch [1/1], Loss: 0.0243\n",
      "Validation Loss: 0.0243, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [333/1000] - Training\n",
      "Epoch [333/1000] completed, Average Training Loss: 0.0448\n",
      "    Validation Batch [1/1], Loss: 0.0240\n",
      "Validation Loss: 0.0240, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [334/1000] - Training\n",
      "Epoch [334/1000] completed, Average Training Loss: 0.0504\n",
      "    Validation Batch [1/1], Loss: 0.0248\n",
      "Validation Loss: 0.0248, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [335/1000] - Training\n",
      "Epoch [335/1000] completed, Average Training Loss: 0.0529\n",
      "    Validation Batch [1/1], Loss: 0.0255\n",
      "Validation Loss: 0.0255, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [336/1000] - Training\n",
      "Epoch [336/1000] completed, Average Training Loss: 0.0447\n",
      "    Validation Batch [1/1], Loss: 0.0247\n",
      "Validation Loss: 0.0247, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [337/1000] - Training\n",
      "Epoch [337/1000] completed, Average Training Loss: 0.0476\n",
      "    Validation Batch [1/1], Loss: 0.0225\n",
      "Validation Loss: 0.0225, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0232 to 0.0225. Saving model...\n",
      "\n",
      "LOG: Epoch [338/1000] - Training\n",
      "Epoch [338/1000] completed, Average Training Loss: 0.0388\n",
      "    Validation Batch [1/1], Loss: 0.0223\n",
      "Validation Loss: 0.0223, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0225 to 0.0223. Saving model...\n",
      "\n",
      "LOG: Epoch [339/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [339/1000] completed, Average Training Loss: 0.0443\n",
      "    Validation Batch [1/1], Loss: 0.0247\n",
      "Validation Loss: 0.0247, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [340/1000] - Training\n",
      "Epoch [340/1000] completed, Average Training Loss: 0.0384\n",
      "    Validation Batch [1/1], Loss: 0.0239\n",
      "Validation Loss: 0.0239, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [341/1000] - Training\n",
      "Epoch [341/1000] completed, Average Training Loss: 0.0396\n",
      "    Validation Batch [1/1], Loss: 0.0195\n",
      "Validation Loss: 0.0195, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0223 to 0.0195. Saving model...\n",
      "\n",
      "LOG: Epoch [342/1000] - Training\n",
      "Epoch [342/1000] completed, Average Training Loss: 0.0402\n",
      "    Validation Batch [1/1], Loss: 0.0203\n",
      "Validation Loss: 0.0203, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [343/1000] - Training\n",
      "Epoch [343/1000] completed, Average Training Loss: 0.0403\n",
      "    Validation Batch [1/1], Loss: 0.0244\n",
      "Validation Loss: 0.0244, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [344/1000] - Training\n",
      "Epoch [344/1000] completed, Average Training Loss: 0.0448\n",
      "    Validation Batch [1/1], Loss: 0.0258\n",
      "Validation Loss: 0.0258, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [345/1000] - Training\n",
      "Epoch [345/1000] completed, Average Training Loss: 0.0390\n",
      "    Validation Batch [1/1], Loss: 0.0277\n",
      "Validation Loss: 0.0277, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [346/1000] - Training\n",
      "Epoch [346/1000] completed, Average Training Loss: 0.0367\n",
      "    Validation Batch [1/1], Loss: 0.0259\n",
      "Validation Loss: 0.0259, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [347/1000] - Training\n",
      "Epoch [347/1000] completed, Average Training Loss: 0.0434\n",
      "    Validation Batch [1/1], Loss: 0.0261\n",
      "Validation Loss: 0.0261, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [348/1000] - Training\n",
      "Epoch [348/1000] completed, Average Training Loss: 0.0440\n",
      "    Validation Batch [1/1], Loss: 0.0221\n",
      "Validation Loss: 0.0221, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [349/1000] - Training\n",
      "Epoch [349/1000] completed, Average Training Loss: 0.0387\n",
      "    Validation Batch [1/1], Loss: 0.0174\n",
      "Validation Loss: 0.0174, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0195 to 0.0174. Saving model...\n",
      "\n",
      "LOG: Epoch [350/1000] - Training\n",
      "Epoch [350/1000] completed, Average Training Loss: 0.0411\n",
      "    Validation Batch [1/1], Loss: 0.0181\n",
      "Validation Loss: 0.0181, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [351/1000] - Training\n",
      "Epoch [351/1000] completed, Average Training Loss: 0.0429\n",
      "    Validation Batch [1/1], Loss: 0.0220\n",
      "Validation Loss: 0.0220, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [352/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [352/1000] completed, Average Training Loss: 0.0425\n",
      "    Validation Batch [1/1], Loss: 0.0208\n",
      "Validation Loss: 0.0208, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [353/1000] - Training\n",
      "Epoch [353/1000] completed, Average Training Loss: 0.0372\n",
      "    Validation Batch [1/1], Loss: 0.0199\n",
      "Validation Loss: 0.0199, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [354/1000] - Training\n",
      "Epoch [354/1000] completed, Average Training Loss: 0.0446\n",
      "    Validation Batch [1/1], Loss: 0.0205\n",
      "Validation Loss: 0.0205, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [355/1000] - Training\n",
      "Epoch [355/1000] completed, Average Training Loss: 0.0383\n",
      "    Validation Batch [1/1], Loss: 0.0193\n",
      "Validation Loss: 0.0193, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [356/1000] - Training\n",
      "Epoch [356/1000] completed, Average Training Loss: 0.0361\n",
      "    Validation Batch [1/1], Loss: 0.0190\n",
      "Validation Loss: 0.0190, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [357/1000] - Training\n",
      "Epoch [357/1000] completed, Average Training Loss: 0.0425\n",
      "    Validation Batch [1/1], Loss: 0.0191\n",
      "Validation Loss: 0.0191, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [358/1000] - Training\n",
      "Epoch [358/1000] completed, Average Training Loss: 0.0397\n",
      "    Validation Batch [1/1], Loss: 0.0180\n",
      "Validation Loss: 0.0180, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [359/1000] - Training\n",
      "Epoch [359/1000] completed, Average Training Loss: 0.0406\n",
      "    Validation Batch [1/1], Loss: 0.0179\n",
      "Validation Loss: 0.0179, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [360/1000] - Training\n",
      "Epoch [360/1000] completed, Average Training Loss: 0.0399\n",
      "    Validation Batch [1/1], Loss: 0.0233\n",
      "Validation Loss: 0.0233, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [361/1000] - Training\n",
      "Epoch [361/1000] completed, Average Training Loss: 0.0304\n",
      "    Validation Batch [1/1], Loss: 0.0223\n",
      "Validation Loss: 0.0223, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [362/1000] - Training\n",
      "Epoch [362/1000] completed, Average Training Loss: 0.0399\n",
      "    Validation Batch [1/1], Loss: 0.0186\n",
      "Validation Loss: 0.0186, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [363/1000] - Training\n",
      "Epoch [363/1000] completed, Average Training Loss: 0.0353\n",
      "    Validation Batch [1/1], Loss: 0.0210\n",
      "Validation Loss: 0.0210, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [364/1000] - Training\n",
      "Epoch [364/1000] completed, Average Training Loss: 0.0411\n",
      "    Validation Batch [1/1], Loss: 0.0231\n",
      "Validation Loss: 0.0231, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [365/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [365/1000] completed, Average Training Loss: 0.0359\n",
      "    Validation Batch [1/1], Loss: 0.0215\n",
      "Validation Loss: 0.0215, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [366/1000] - Training\n",
      "Epoch [366/1000] completed, Average Training Loss: 0.0367\n",
      "    Validation Batch [1/1], Loss: 0.0238\n",
      "Validation Loss: 0.0238, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [367/1000] - Training\n",
      "Epoch [367/1000] completed, Average Training Loss: 0.0382\n",
      "    Validation Batch [1/1], Loss: 0.0323\n",
      "Validation Loss: 0.0323, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [368/1000] - Training\n",
      "Epoch [368/1000] completed, Average Training Loss: 0.0345\n",
      "    Validation Batch [1/1], Loss: 0.0226\n",
      "Validation Loss: 0.0226, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [369/1000] - Training\n",
      "Epoch [369/1000] completed, Average Training Loss: 0.0399\n",
      "    Validation Batch [1/1], Loss: 0.0188\n",
      "Validation Loss: 0.0188, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [370/1000] - Training\n",
      "Epoch [370/1000] completed, Average Training Loss: 0.0365\n",
      "    Validation Batch [1/1], Loss: 0.0283\n",
      "Validation Loss: 0.0283, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [371/1000] - Training\n",
      "Epoch [371/1000] completed, Average Training Loss: 0.0366\n",
      "    Validation Batch [1/1], Loss: 0.0340\n",
      "Validation Loss: 0.0340, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [372/1000] - Training\n",
      "Epoch [372/1000] completed, Average Training Loss: 0.0344\n",
      "    Validation Batch [1/1], Loss: 0.0187\n",
      "Validation Loss: 0.0187, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [373/1000] - Training\n",
      "Epoch [373/1000] completed, Average Training Loss: 0.0343\n",
      "    Validation Batch [1/1], Loss: 0.0191\n",
      "Validation Loss: 0.0191, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [374/1000] - Training\n",
      "Epoch [374/1000] completed, Average Training Loss: 0.0354\n",
      "    Validation Batch [1/1], Loss: 0.0222\n",
      "Validation Loss: 0.0222, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [375/1000] - Training\n",
      "Epoch [375/1000] completed, Average Training Loss: 0.0325\n",
      "    Validation Batch [1/1], Loss: 0.0257\n",
      "Validation Loss: 0.0257, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [376/1000] - Training\n",
      "Epoch [376/1000] completed, Average Training Loss: 0.0407\n",
      "    Validation Batch [1/1], Loss: 0.0177\n",
      "Validation Loss: 0.0177, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [377/1000] - Training\n",
      "Epoch [377/1000] completed, Average Training Loss: 0.0370\n",
      "    Validation Batch [1/1], Loss: 0.0340\n",
      "Validation Loss: 0.0340, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [378/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [378/1000] completed, Average Training Loss: 0.0336\n",
      "    Validation Batch [1/1], Loss: 0.0388\n",
      "Validation Loss: 0.0388, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [379/1000] - Training\n",
      "Epoch [379/1000] completed, Average Training Loss: 0.0347\n",
      "    Validation Batch [1/1], Loss: 0.0204\n",
      "Validation Loss: 0.0204, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [380/1000] - Training\n",
      "Epoch [380/1000] completed, Average Training Loss: 0.0320\n",
      "    Validation Batch [1/1], Loss: 0.0188\n",
      "Validation Loss: 0.0188, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [381/1000] - Training\n",
      "Epoch [381/1000] completed, Average Training Loss: 0.0365\n",
      "    Validation Batch [1/1], Loss: 0.0218\n",
      "Validation Loss: 0.0218, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [382/1000] - Training\n",
      "Epoch [382/1000] completed, Average Training Loss: 0.0289\n",
      "    Validation Batch [1/1], Loss: 0.0197\n",
      "Validation Loss: 0.0197, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [383/1000] - Training\n",
      "Epoch [383/1000] completed, Average Training Loss: 0.0307\n",
      "    Validation Batch [1/1], Loss: 0.0173\n",
      "Validation Loss: 0.0173, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0174 to 0.0173. Saving model...\n",
      "\n",
      "LOG: Epoch [384/1000] - Training\n",
      "Epoch [384/1000] completed, Average Training Loss: 0.0312\n",
      "    Validation Batch [1/1], Loss: 0.0173\n",
      "Validation Loss: 0.0173, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [385/1000] - Training\n",
      "Epoch [385/1000] completed, Average Training Loss: 0.0349\n",
      "    Validation Batch [1/1], Loss: 0.0228\n",
      "Validation Loss: 0.0228, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [386/1000] - Training\n",
      "Epoch [386/1000] completed, Average Training Loss: 0.0360\n",
      "    Validation Batch [1/1], Loss: 0.0190\n",
      "Validation Loss: 0.0190, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [387/1000] - Training\n",
      "Epoch [387/1000] completed, Average Training Loss: 0.0328\n",
      "    Validation Batch [1/1], Loss: 0.0170\n",
      "Validation Loss: 0.0170, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0173 to 0.0170. Saving model...\n",
      "\n",
      "LOG: Epoch [388/1000] - Training\n",
      "Epoch [388/1000] completed, Average Training Loss: 0.0284\n",
      "    Validation Batch [1/1], Loss: 0.0158\n",
      "Validation Loss: 0.0158, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0170 to 0.0158. Saving model...\n",
      "\n",
      "LOG: Epoch [389/1000] - Training\n",
      "Epoch [389/1000] completed, Average Training Loss: 0.0293\n",
      "    Validation Batch [1/1], Loss: 0.0148\n",
      "Validation Loss: 0.0148, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0158 to 0.0148. Saving model...\n",
      "\n",
      "LOG: Epoch [390/1000] - Training\n",
      "Epoch [390/1000] completed, Average Training Loss: 0.0292\n",
      "    Validation Batch [1/1], Loss: 0.0151\n",
      "Validation Loss: 0.0151, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [391/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [391/1000] completed, Average Training Loss: 0.0306\n",
      "    Validation Batch [1/1], Loss: 0.0179\n",
      "Validation Loss: 0.0179, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [392/1000] - Training\n",
      "Epoch [392/1000] completed, Average Training Loss: 0.0283\n",
      "    Validation Batch [1/1], Loss: 0.0187\n",
      "Validation Loss: 0.0187, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [393/1000] - Training\n",
      "Epoch [393/1000] completed, Average Training Loss: 0.0303\n",
      "    Validation Batch [1/1], Loss: 0.0135\n",
      "Validation Loss: 0.0135, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0148 to 0.0135. Saving model...\n",
      "\n",
      "LOG: Epoch [394/1000] - Training\n",
      "Epoch [394/1000] completed, Average Training Loss: 0.0304\n",
      "    Validation Batch [1/1], Loss: 0.0139\n",
      "Validation Loss: 0.0139, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [395/1000] - Training\n",
      "Epoch [395/1000] completed, Average Training Loss: 0.0314\n",
      "    Validation Batch [1/1], Loss: 0.0155\n",
      "Validation Loss: 0.0155, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [396/1000] - Training\n",
      "Epoch [396/1000] completed, Average Training Loss: 0.0282\n",
      "    Validation Batch [1/1], Loss: 0.0163\n",
      "Validation Loss: 0.0163, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [397/1000] - Training\n",
      "Epoch [397/1000] completed, Average Training Loss: 0.0309\n",
      "    Validation Batch [1/1], Loss: 0.0251\n",
      "Validation Loss: 0.0251, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [398/1000] - Training\n",
      "Epoch [398/1000] completed, Average Training Loss: 0.0268\n",
      "    Validation Batch [1/1], Loss: 0.0225\n",
      "Validation Loss: 0.0225, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [399/1000] - Training\n",
      "Epoch [399/1000] completed, Average Training Loss: 0.0313\n",
      "    Validation Batch [1/1], Loss: 0.0163\n",
      "Validation Loss: 0.0163, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [400/1000] - Training\n",
      "Epoch [400/1000] completed, Average Training Loss: 0.0306\n",
      "    Validation Batch [1/1], Loss: 0.0161\n",
      "Validation Loss: 0.0161, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [401/1000] - Training\n",
      "Epoch [401/1000] completed, Average Training Loss: 0.0319\n",
      "    Validation Batch [1/1], Loss: 0.0189\n",
      "Validation Loss: 0.0189, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [402/1000] - Training\n",
      "Epoch [402/1000] completed, Average Training Loss: 0.0315\n",
      "    Validation Batch [1/1], Loss: 0.0164\n",
      "Validation Loss: 0.0164, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [403/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [403/1000] completed, Average Training Loss: 0.0297\n",
      "    Validation Batch [1/1], Loss: 0.0174\n",
      "Validation Loss: 0.0174, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [404/1000] - Training\n",
      "Epoch [404/1000] completed, Average Training Loss: 0.0305\n",
      "    Validation Batch [1/1], Loss: 0.0172\n",
      "Validation Loss: 0.0172, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [405/1000] - Training\n",
      "Epoch [405/1000] completed, Average Training Loss: 0.0289\n",
      "    Validation Batch [1/1], Loss: 0.0163\n",
      "Validation Loss: 0.0163, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [406/1000] - Training\n",
      "Epoch [406/1000] completed, Average Training Loss: 0.0309\n",
      "    Validation Batch [1/1], Loss: 0.0139\n",
      "Validation Loss: 0.0139, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [407/1000] - Training\n",
      "Epoch [407/1000] completed, Average Training Loss: 0.0298\n",
      "    Validation Batch [1/1], Loss: 0.0133\n",
      "Validation Loss: 0.0133, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0135 to 0.0133. Saving model...\n",
      "\n",
      "LOG: Epoch [408/1000] - Training\n",
      "Epoch [408/1000] completed, Average Training Loss: 0.0271\n",
      "    Validation Batch [1/1], Loss: 0.0119\n",
      "Validation Loss: 0.0119, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0133 to 0.0119. Saving model...\n",
      "\n",
      "LOG: Epoch [409/1000] - Training\n",
      "Epoch [409/1000] completed, Average Training Loss: 0.0260\n",
      "    Validation Batch [1/1], Loss: 0.0108\n",
      "Validation Loss: 0.0108, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0119 to 0.0108. Saving model...\n",
      "\n",
      "LOG: Epoch [410/1000] - Training\n",
      "Epoch [410/1000] completed, Average Training Loss: 0.0290\n",
      "    Validation Batch [1/1], Loss: 0.0131\n",
      "Validation Loss: 0.0131, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [411/1000] - Training\n",
      "Epoch [411/1000] completed, Average Training Loss: 0.0313\n",
      "    Validation Batch [1/1], Loss: 0.0143\n",
      "Validation Loss: 0.0143, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [412/1000] - Training\n",
      "Epoch [412/1000] completed, Average Training Loss: 0.0294\n",
      "    Validation Batch [1/1], Loss: 0.0139\n",
      "Validation Loss: 0.0139, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [413/1000] - Training\n",
      "Epoch [413/1000] completed, Average Training Loss: 0.0286\n",
      "    Validation Batch [1/1], Loss: 0.0147\n",
      "Validation Loss: 0.0147, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [414/1000] - Training\n",
      "Epoch [414/1000] completed, Average Training Loss: 0.0254\n",
      "    Validation Batch [1/1], Loss: 0.0151\n",
      "Validation Loss: 0.0151, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [415/1000] - Training\n",
      "Epoch [415/1000] completed, Average Training Loss: 0.0288\n",
      "    Validation Batch [1/1], Loss: 0.0134\n",
      "Validation Loss: 0.0134, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [416/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [416/1000] completed, Average Training Loss: 0.0256\n",
      "    Validation Batch [1/1], Loss: 0.0135\n",
      "Validation Loss: 0.0135, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [417/1000] - Training\n",
      "Epoch [417/1000] completed, Average Training Loss: 0.0238\n",
      "    Validation Batch [1/1], Loss: 0.0138\n",
      "Validation Loss: 0.0138, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [418/1000] - Training\n",
      "Epoch [418/1000] completed, Average Training Loss: 0.0285\n",
      "    Validation Batch [1/1], Loss: 0.0155\n",
      "Validation Loss: 0.0155, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [419/1000] - Training\n",
      "Epoch [419/1000] completed, Average Training Loss: 0.0263\n",
      "    Validation Batch [1/1], Loss: 0.0117\n",
      "Validation Loss: 0.0117, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [420/1000] - Training\n",
      "Epoch [420/1000] completed, Average Training Loss: 0.0242\n",
      "    Validation Batch [1/1], Loss: 0.0115\n",
      "Validation Loss: 0.0115, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [421/1000] - Training\n",
      "Epoch [421/1000] completed, Average Training Loss: 0.0244\n",
      "    Validation Batch [1/1], Loss: 0.0128\n",
      "Validation Loss: 0.0128, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [422/1000] - Training\n",
      "Epoch [422/1000] completed, Average Training Loss: 0.0268\n",
      "    Validation Batch [1/1], Loss: 0.0197\n",
      "Validation Loss: 0.0197, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [423/1000] - Training\n",
      "Epoch [423/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.0210\n",
      "Validation Loss: 0.0210, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [424/1000] - Training\n",
      "Epoch [424/1000] completed, Average Training Loss: 0.0254\n",
      "    Validation Batch [1/1], Loss: 0.0140\n",
      "Validation Loss: 0.0140, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [425/1000] - Training\n",
      "Epoch [425/1000] completed, Average Training Loss: 0.0237\n",
      "    Validation Batch [1/1], Loss: 0.0118\n",
      "Validation Loss: 0.0118, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [426/1000] - Training\n",
      "Epoch [426/1000] completed, Average Training Loss: 0.0252\n",
      "    Validation Batch [1/1], Loss: 0.0114\n",
      "Validation Loss: 0.0114, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [427/1000] - Training\n",
      "Epoch [427/1000] completed, Average Training Loss: 0.0230\n",
      "    Validation Batch [1/1], Loss: 0.0155\n",
      "Validation Loss: 0.0155, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [428/1000] - Training\n",
      "Epoch [428/1000] completed, Average Training Loss: 0.0261\n",
      "    Validation Batch [1/1], Loss: 0.0194\n",
      "Validation Loss: 0.0194, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [429/1000] - Training\n",
      "Epoch [429/1000] completed, Average Training Loss: 0.0276\n",
      "    Validation Batch [1/1], Loss: 0.0123\n",
      "Validation Loss: 0.0123, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [430/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [430/1000] completed, Average Training Loss: 0.0241\n",
      "    Validation Batch [1/1], Loss: 0.0101\n",
      "Validation Loss: 0.0101, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0108 to 0.0101. Saving model...\n",
      "\n",
      "LOG: Epoch [431/1000] - Training\n",
      "Epoch [431/1000] completed, Average Training Loss: 0.0274\n",
      "    Validation Batch [1/1], Loss: 0.0101\n",
      "Validation Loss: 0.0101, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [432/1000] - Training\n",
      "Epoch [432/1000] completed, Average Training Loss: 0.0266\n",
      "    Validation Batch [1/1], Loss: 0.0112\n",
      "Validation Loss: 0.0112, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [433/1000] - Training\n",
      "Epoch [433/1000] completed, Average Training Loss: 0.0197\n",
      "    Validation Batch [1/1], Loss: 0.0120\n",
      "Validation Loss: 0.0120, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [434/1000] - Training\n",
      "Epoch [434/1000] completed, Average Training Loss: 0.0197\n",
      "    Validation Batch [1/1], Loss: 0.0143\n",
      "Validation Loss: 0.0143, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [435/1000] - Training\n",
      "Epoch [435/1000] completed, Average Training Loss: 0.0244\n",
      "    Validation Batch [1/1], Loss: 0.0135\n",
      "Validation Loss: 0.0135, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [436/1000] - Training\n",
      "Epoch [436/1000] completed, Average Training Loss: 0.0243\n",
      "    Validation Batch [1/1], Loss: 0.0112\n",
      "Validation Loss: 0.0112, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [437/1000] - Training\n",
      "Epoch [437/1000] completed, Average Training Loss: 0.0258\n",
      "    Validation Batch [1/1], Loss: 0.0096\n",
      "Validation Loss: 0.0096, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0101 to 0.0096. Saving model...\n",
      "\n",
      "LOG: Epoch [438/1000] - Training\n",
      "Epoch [438/1000] completed, Average Training Loss: 0.0243\n",
      "    Validation Batch [1/1], Loss: 0.0112\n",
      "Validation Loss: 0.0112, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [439/1000] - Training\n",
      "Epoch [439/1000] completed, Average Training Loss: 0.0253\n",
      "    Validation Batch [1/1], Loss: 0.0116\n",
      "Validation Loss: 0.0116, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [440/1000] - Training\n",
      "Epoch [440/1000] completed, Average Training Loss: 0.0237\n",
      "    Validation Batch [1/1], Loss: 0.0125\n",
      "Validation Loss: 0.0125, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [441/1000] - Training\n",
      "Epoch [441/1000] completed, Average Training Loss: 0.0233\n",
      "    Validation Batch [1/1], Loss: 0.0136\n",
      "Validation Loss: 0.0136, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [442/1000] - Training\n",
      "Epoch [442/1000] completed, Average Training Loss: 0.0251\n",
      "    Validation Batch [1/1], Loss: 0.0191\n",
      "Validation Loss: 0.0191, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [443/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [443/1000] completed, Average Training Loss: 0.0218\n",
      "    Validation Batch [1/1], Loss: 0.0212\n",
      "Validation Loss: 0.0212, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [444/1000] - Training\n",
      "Epoch [444/1000] completed, Average Training Loss: 0.0195\n",
      "    Validation Batch [1/1], Loss: 0.0154\n",
      "Validation Loss: 0.0154, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [445/1000] - Training\n",
      "Epoch [445/1000] completed, Average Training Loss: 0.0234\n",
      "    Validation Batch [1/1], Loss: 0.0114\n",
      "Validation Loss: 0.0114, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [446/1000] - Training\n",
      "Epoch [446/1000] completed, Average Training Loss: 0.0254\n",
      "    Validation Batch [1/1], Loss: 0.0117\n",
      "Validation Loss: 0.0117, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [447/1000] - Training\n",
      "Epoch [447/1000] completed, Average Training Loss: 0.0227\n",
      "    Validation Batch [1/1], Loss: 0.0094\n",
      "Validation Loss: 0.0094, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0096 to 0.0094. Saving model...\n",
      "\n",
      "LOG: Epoch [448/1000] - Training\n",
      "Epoch [448/1000] completed, Average Training Loss: 0.0221\n",
      "    Validation Batch [1/1], Loss: 0.0092\n",
      "Validation Loss: 0.0092, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0094 to 0.0092. Saving model...\n",
      "\n",
      "LOG: Epoch [449/1000] - Training\n",
      "Epoch [449/1000] completed, Average Training Loss: 0.0216\n",
      "    Validation Batch [1/1], Loss: 0.0138\n",
      "Validation Loss: 0.0138, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [450/1000] - Training\n",
      "Epoch [450/1000] completed, Average Training Loss: 0.0241\n",
      "    Validation Batch [1/1], Loss: 0.0137\n",
      "Validation Loss: 0.0137, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [451/1000] - Training\n",
      "Epoch [451/1000] completed, Average Training Loss: 0.0239\n",
      "    Validation Batch [1/1], Loss: 0.0101\n",
      "Validation Loss: 0.0101, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [452/1000] - Training\n",
      "Epoch [452/1000] completed, Average Training Loss: 0.0227\n",
      "    Validation Batch [1/1], Loss: 0.0099\n",
      "Validation Loss: 0.0099, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [453/1000] - Training\n",
      "Epoch [453/1000] completed, Average Training Loss: 0.0239\n",
      "    Validation Batch [1/1], Loss: 0.0096\n",
      "Validation Loss: 0.0096, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [454/1000] - Training\n",
      "Epoch [454/1000] completed, Average Training Loss: 0.0219\n",
      "    Validation Batch [1/1], Loss: 0.0095\n",
      "Validation Loss: 0.0095, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [455/1000] - Training\n",
      "Epoch [455/1000] completed, Average Training Loss: 0.0238\n",
      "    Validation Batch [1/1], Loss: 0.0109\n",
      "Validation Loss: 0.0109, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [456/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [456/1000] completed, Average Training Loss: 0.0191\n",
      "    Validation Batch [1/1], Loss: 0.0166\n",
      "Validation Loss: 0.0166, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [457/1000] - Training\n",
      "Epoch [457/1000] completed, Average Training Loss: 0.0186\n",
      "    Validation Batch [1/1], Loss: 0.0141\n",
      "Validation Loss: 0.0141, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [458/1000] - Training\n",
      "Epoch [458/1000] completed, Average Training Loss: 0.0201\n",
      "    Validation Batch [1/1], Loss: 0.0074\n",
      "Validation Loss: 0.0074, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0092 to 0.0074. Saving model...\n",
      "\n",
      "LOG: Epoch [459/1000] - Training\n",
      "Epoch [459/1000] completed, Average Training Loss: 0.0234\n",
      "    Validation Batch [1/1], Loss: 0.0083\n",
      "Validation Loss: 0.0083, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [460/1000] - Training\n",
      "Epoch [460/1000] completed, Average Training Loss: 0.0215\n",
      "    Validation Batch [1/1], Loss: 0.0089\n",
      "Validation Loss: 0.0089, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [461/1000] - Training\n",
      "Epoch [461/1000] completed, Average Training Loss: 0.0208\n",
      "    Validation Batch [1/1], Loss: 0.0104\n",
      "Validation Loss: 0.0104, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [462/1000] - Training\n",
      "Epoch [462/1000] completed, Average Training Loss: 0.0235\n",
      "    Validation Batch [1/1], Loss: 0.0117\n",
      "Validation Loss: 0.0117, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [463/1000] - Training\n",
      "Epoch [463/1000] completed, Average Training Loss: 0.0204\n",
      "    Validation Batch [1/1], Loss: 0.0096\n",
      "Validation Loss: 0.0096, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [464/1000] - Training\n",
      "Epoch [464/1000] completed, Average Training Loss: 0.0195\n",
      "    Validation Batch [1/1], Loss: 0.0098\n",
      "Validation Loss: 0.0098, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [465/1000] - Training\n",
      "Epoch [465/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.0122\n",
      "Validation Loss: 0.0122, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [466/1000] - Training\n",
      "Epoch [466/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.0141\n",
      "Validation Loss: 0.0141, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [467/1000] - Training\n",
      "Epoch [467/1000] completed, Average Training Loss: 0.0227\n",
      "    Validation Batch [1/1], Loss: 0.0105\n",
      "Validation Loss: 0.0105, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [468/1000] - Training\n",
      "Epoch [468/1000] completed, Average Training Loss: 0.0241\n",
      "    Validation Batch [1/1], Loss: 0.0079\n",
      "Validation Loss: 0.0079, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [469/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [469/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.0091\n",
      "Validation Loss: 0.0091, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [470/1000] - Training\n",
      "Epoch [470/1000] completed, Average Training Loss: 0.0174\n",
      "    Validation Batch [1/1], Loss: 0.0088\n",
      "Validation Loss: 0.0088, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [471/1000] - Training\n",
      "Epoch [471/1000] completed, Average Training Loss: 0.0205\n",
      "    Validation Batch [1/1], Loss: 0.0064\n",
      "Validation Loss: 0.0064, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0074 to 0.0064. Saving model...\n",
      "\n",
      "LOG: Epoch [472/1000] - Training\n",
      "Epoch [472/1000] completed, Average Training Loss: 0.0227\n",
      "    Validation Batch [1/1], Loss: 0.0072\n",
      "Validation Loss: 0.0072, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [473/1000] - Training\n",
      "Epoch [473/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.0075\n",
      "Validation Loss: 0.0075, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [474/1000] - Training\n",
      "Epoch [474/1000] completed, Average Training Loss: 0.0201\n",
      "    Validation Batch [1/1], Loss: 0.0074\n",
      "Validation Loss: 0.0074, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [475/1000] - Training\n",
      "Epoch [475/1000] completed, Average Training Loss: 0.0191\n",
      "    Validation Batch [1/1], Loss: 0.0075\n",
      "Validation Loss: 0.0075, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [476/1000] - Training\n",
      "Epoch [476/1000] completed, Average Training Loss: 0.0176\n",
      "    Validation Batch [1/1], Loss: 0.0075\n",
      "Validation Loss: 0.0075, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [477/1000] - Training\n",
      "Epoch [477/1000] completed, Average Training Loss: 0.0197\n",
      "    Validation Batch [1/1], Loss: 0.0096\n",
      "Validation Loss: 0.0096, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [478/1000] - Training\n",
      "Epoch [478/1000] completed, Average Training Loss: 0.0210\n",
      "    Validation Batch [1/1], Loss: 0.0088\n",
      "Validation Loss: 0.0088, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [479/1000] - Training\n",
      "Epoch [479/1000] completed, Average Training Loss: 0.0210\n",
      "    Validation Batch [1/1], Loss: 0.0085\n",
      "Validation Loss: 0.0085, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [480/1000] - Training\n",
      "Epoch [480/1000] completed, Average Training Loss: 0.0207\n",
      "    Validation Batch [1/1], Loss: 0.0093\n",
      "Validation Loss: 0.0093, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [481/1000] - Training\n",
      "Epoch [481/1000] completed, Average Training Loss: 0.0211\n",
      "    Validation Batch [1/1], Loss: 0.0084\n",
      "Validation Loss: 0.0084, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [482/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [482/1000] completed, Average Training Loss: 0.0242\n",
      "    Validation Batch [1/1], Loss: 0.0075\n",
      "Validation Loss: 0.0075, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [483/1000] - Training\n",
      "Epoch [483/1000] completed, Average Training Loss: 0.0172\n",
      "    Validation Batch [1/1], Loss: 0.0080\n",
      "Validation Loss: 0.0080, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [484/1000] - Training\n",
      "Epoch [484/1000] completed, Average Training Loss: 0.0218\n",
      "    Validation Batch [1/1], Loss: 0.0095\n",
      "Validation Loss: 0.0095, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [485/1000] - Training\n",
      "Epoch [485/1000] completed, Average Training Loss: 0.0183\n",
      "    Validation Batch [1/1], Loss: 0.0093\n",
      "Validation Loss: 0.0093, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [486/1000] - Training\n",
      "Epoch [486/1000] completed, Average Training Loss: 0.0192\n",
      "    Validation Batch [1/1], Loss: 0.0081\n",
      "Validation Loss: 0.0081, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [487/1000] - Training\n",
      "Epoch [487/1000] completed, Average Training Loss: 0.0217\n",
      "    Validation Batch [1/1], Loss: 0.0072\n",
      "Validation Loss: 0.0072, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [488/1000] - Training\n",
      "Epoch [488/1000] completed, Average Training Loss: 0.0228\n",
      "    Validation Batch [1/1], Loss: 0.0077\n",
      "Validation Loss: 0.0077, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [489/1000] - Training\n",
      "Epoch [489/1000] completed, Average Training Loss: 0.0162\n",
      "    Validation Batch [1/1], Loss: 0.0081\n",
      "Validation Loss: 0.0081, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [490/1000] - Training\n",
      "Epoch [490/1000] completed, Average Training Loss: 0.0187\n",
      "    Validation Batch [1/1], Loss: 0.0081\n",
      "Validation Loss: 0.0081, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [491/1000] - Training\n",
      "Epoch [491/1000] completed, Average Training Loss: 0.0178\n",
      "    Validation Batch [1/1], Loss: 0.0090\n",
      "Validation Loss: 0.0090, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [492/1000] - Training\n",
      "Epoch [492/1000] completed, Average Training Loss: 0.0166\n",
      "    Validation Batch [1/1], Loss: 0.0115\n",
      "Validation Loss: 0.0115, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [493/1000] - Training\n",
      "Epoch [493/1000] completed, Average Training Loss: 0.0220\n",
      "    Validation Batch [1/1], Loss: 0.0087\n",
      "Validation Loss: 0.0087, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [494/1000] - Training\n",
      "Epoch [494/1000] completed, Average Training Loss: 0.0188\n",
      "    Validation Batch [1/1], Loss: 0.0095\n",
      "Validation Loss: 0.0095, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [495/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [495/1000] completed, Average Training Loss: 0.0188\n",
      "    Validation Batch [1/1], Loss: 0.0094\n",
      "Validation Loss: 0.0094, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [496/1000] - Training\n",
      "Epoch [496/1000] completed, Average Training Loss: 0.0148\n",
      "    Validation Batch [1/1], Loss: 0.0094\n",
      "Validation Loss: 0.0094, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [497/1000] - Training\n",
      "Epoch [497/1000] completed, Average Training Loss: 0.0173\n",
      "    Validation Batch [1/1], Loss: 0.0089\n",
      "Validation Loss: 0.0089, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [498/1000] - Training\n",
      "Epoch [498/1000] completed, Average Training Loss: 0.0160\n",
      "    Validation Batch [1/1], Loss: 0.0085\n",
      "Validation Loss: 0.0085, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [499/1000] - Training\n",
      "Epoch [499/1000] completed, Average Training Loss: 0.0183\n",
      "    Validation Batch [1/1], Loss: 0.0089\n",
      "Validation Loss: 0.0089, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [500/1000] - Training\n",
      "Epoch [500/1000] completed, Average Training Loss: 0.0200\n",
      "    Validation Batch [1/1], Loss: 0.0081\n",
      "Validation Loss: 0.0081, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [501/1000] - Training\n",
      "Epoch [501/1000] completed, Average Training Loss: 0.0163\n",
      "    Validation Batch [1/1], Loss: 0.0099\n",
      "Validation Loss: 0.0099, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [502/1000] - Training\n",
      "Epoch [502/1000] completed, Average Training Loss: 0.0164\n",
      "    Validation Batch [1/1], Loss: 0.0124\n",
      "Validation Loss: 0.0124, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [503/1000] - Training\n",
      "Epoch [503/1000] completed, Average Training Loss: 0.0165\n",
      "    Validation Batch [1/1], Loss: 0.0098\n",
      "Validation Loss: 0.0098, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [504/1000] - Training\n",
      "Epoch [504/1000] completed, Average Training Loss: 0.0174\n",
      "    Validation Batch [1/1], Loss: 0.0101\n",
      "Validation Loss: 0.0101, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [505/1000] - Training\n",
      "Epoch [505/1000] completed, Average Training Loss: 0.0172\n",
      "    Validation Batch [1/1], Loss: 0.0349\n",
      "Validation Loss: 0.0349, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [506/1000] - Training\n",
      "Epoch [506/1000] completed, Average Training Loss: 0.0161\n",
      "    Validation Batch [1/1], Loss: 0.0277\n",
      "Validation Loss: 0.0277, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [507/1000] - Training\n",
      "Epoch [507/1000] completed, Average Training Loss: 0.0150\n",
      "    Validation Batch [1/1], Loss: 0.0073\n",
      "Validation Loss: 0.0073, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [508/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [508/1000] completed, Average Training Loss: 0.0188\n",
      "    Validation Batch [1/1], Loss: 0.0109\n",
      "Validation Loss: 0.0109, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [509/1000] - Training\n",
      "Epoch [509/1000] completed, Average Training Loss: 0.0157\n",
      "    Validation Batch [1/1], Loss: 0.0126\n",
      "Validation Loss: 0.0126, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [510/1000] - Training\n",
      "Epoch [510/1000] completed, Average Training Loss: 0.0173\n",
      "    Validation Batch [1/1], Loss: 0.0071\n",
      "Validation Loss: 0.0071, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [511/1000] - Training\n",
      "Epoch [511/1000] completed, Average Training Loss: 0.0179\n",
      "    Validation Batch [1/1], Loss: 0.0117\n",
      "Validation Loss: 0.0117, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [512/1000] - Training\n",
      "Epoch [512/1000] completed, Average Training Loss: 0.0164\n",
      "    Validation Batch [1/1], Loss: 0.0104\n",
      "Validation Loss: 0.0104, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [513/1000] - Training\n",
      "Epoch [513/1000] completed, Average Training Loss: 0.0153\n",
      "    Validation Batch [1/1], Loss: 0.0088\n",
      "Validation Loss: 0.0088, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [514/1000] - Training\n",
      "Epoch [514/1000] completed, Average Training Loss: 0.0208\n",
      "    Validation Batch [1/1], Loss: 0.0081\n",
      "Validation Loss: 0.0081, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [515/1000] - Training\n",
      "Epoch [515/1000] completed, Average Training Loss: 0.0156\n",
      "    Validation Batch [1/1], Loss: 0.0105\n",
      "Validation Loss: 0.0105, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [516/1000] - Training\n",
      "Epoch [516/1000] completed, Average Training Loss: 0.0163\n",
      "    Validation Batch [1/1], Loss: 0.0121\n",
      "Validation Loss: 0.0121, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [517/1000] - Training\n",
      "Epoch [517/1000] completed, Average Training Loss: 0.0144\n",
      "    Validation Batch [1/1], Loss: 0.0091\n",
      "Validation Loss: 0.0091, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [518/1000] - Training\n",
      "Epoch [518/1000] completed, Average Training Loss: 0.0172\n",
      "    Validation Batch [1/1], Loss: 0.0092\n",
      "Validation Loss: 0.0092, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [519/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [519/1000] completed, Average Training Loss: 0.0209\n",
      "    Validation Batch [1/1], Loss: 0.0106\n",
      "Validation Loss: 0.0106, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [520/1000] - Training\n",
      "Epoch [520/1000] completed, Average Training Loss: 0.0155\n",
      "    Validation Batch [1/1], Loss: 0.0112\n",
      "Validation Loss: 0.0112, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [521/1000] - Training\n",
      "Epoch [521/1000] completed, Average Training Loss: 0.0126\n",
      "    Validation Batch [1/1], Loss: 0.0084\n",
      "Validation Loss: 0.0084, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [522/1000] - Training\n",
      "Epoch [522/1000] completed, Average Training Loss: 0.0158\n",
      "    Validation Batch [1/1], Loss: 0.0072\n",
      "Validation Loss: 0.0072, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [523/1000] - Training\n",
      "Epoch [523/1000] completed, Average Training Loss: 0.0171\n",
      "    Validation Batch [1/1], Loss: 0.0083\n",
      "Validation Loss: 0.0083, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [524/1000] - Training\n",
      "Epoch [524/1000] completed, Average Training Loss: 0.0154\n",
      "    Validation Batch [1/1], Loss: 0.0085\n",
      "Validation Loss: 0.0085, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [525/1000] - Training\n",
      "Epoch [525/1000] completed, Average Training Loss: 0.0163\n",
      "    Validation Batch [1/1], Loss: 0.0066\n",
      "Validation Loss: 0.0066, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [526/1000] - Training\n",
      "Epoch [526/1000] completed, Average Training Loss: 0.0163\n",
      "    Validation Batch [1/1], Loss: 0.0074\n",
      "Validation Loss: 0.0074, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [527/1000] - Training\n",
      "Epoch [527/1000] completed, Average Training Loss: 0.0163\n",
      "    Validation Batch [1/1], Loss: 0.0121\n",
      "Validation Loss: 0.0121, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [528/1000] - Training\n",
      "Epoch [528/1000] completed, Average Training Loss: 0.0140\n",
      "    Validation Batch [1/1], Loss: 0.0116\n",
      "Validation Loss: 0.0116, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [529/1000] - Training\n",
      "Epoch [529/1000] completed, Average Training Loss: 0.0181\n",
      "    Validation Batch [1/1], Loss: 0.0092\n",
      "Validation Loss: 0.0092, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [530/1000] - Training\n",
      "Epoch [530/1000] completed, Average Training Loss: 0.0146\n",
      "    Validation Batch [1/1], Loss: 0.0084\n",
      "Validation Loss: 0.0084, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [531/1000] - Training\n",
      "Epoch [531/1000] completed, Average Training Loss: 0.0145\n",
      "    Validation Batch [1/1], Loss: 0.0067\n",
      "Validation Loss: 0.0067, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [532/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [532/1000] completed, Average Training Loss: 0.0141\n",
      "    Validation Batch [1/1], Loss: 0.0055\n",
      "Validation Loss: 0.0055, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0064 to 0.0055. Saving model...\n",
      "\n",
      "LOG: Epoch [533/1000] - Training\n",
      "Epoch [533/1000] completed, Average Training Loss: 0.0142\n",
      "    Validation Batch [1/1], Loss: 0.0052\n",
      "Validation Loss: 0.0052, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0055 to 0.0052. Saving model...\n",
      "\n",
      "LOG: Epoch [534/1000] - Training\n",
      "Epoch [534/1000] completed, Average Training Loss: 0.0145\n",
      "    Validation Batch [1/1], Loss: 0.0055\n",
      "Validation Loss: 0.0055, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [535/1000] - Training\n",
      "Epoch [535/1000] completed, Average Training Loss: 0.0148\n",
      "    Validation Batch [1/1], Loss: 0.0056\n",
      "Validation Loss: 0.0056, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [536/1000] - Training\n",
      "Epoch [536/1000] completed, Average Training Loss: 0.0123\n",
      "    Validation Batch [1/1], Loss: 0.0058\n",
      "Validation Loss: 0.0058, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [537/1000] - Training\n",
      "Epoch [537/1000] completed, Average Training Loss: 0.0167\n",
      "    Validation Batch [1/1], Loss: 0.0058\n",
      "Validation Loss: 0.0058, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [538/1000] - Training\n",
      "Epoch [538/1000] completed, Average Training Loss: 0.0163\n",
      "    Validation Batch [1/1], Loss: 0.0055\n",
      "Validation Loss: 0.0055, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [539/1000] - Training\n",
      "Epoch [539/1000] completed, Average Training Loss: 0.0150\n",
      "    Validation Batch [1/1], Loss: 0.0052\n",
      "Validation Loss: 0.0052, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0052 to 0.0052. Saving model...\n",
      "\n",
      "LOG: Epoch [540/1000] - Training\n",
      "Epoch [540/1000] completed, Average Training Loss: 0.0151\n",
      "    Validation Batch [1/1], Loss: 0.0055\n",
      "Validation Loss: 0.0055, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [541/1000] - Training\n",
      "Epoch [541/1000] completed, Average Training Loss: 0.0153\n",
      "    Validation Batch [1/1], Loss: 0.0063\n",
      "Validation Loss: 0.0063, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [542/1000] - Training\n",
      "Epoch [542/1000] completed, Average Training Loss: 0.0157\n",
      "    Validation Batch [1/1], Loss: 0.0063\n",
      "Validation Loss: 0.0063, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [543/1000] - Training\n",
      "Epoch [543/1000] completed, Average Training Loss: 0.0135\n",
      "    Validation Batch [1/1], Loss: 0.0059\n",
      "Validation Loss: 0.0059, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [544/1000] - Training\n",
      "Epoch [544/1000] completed, Average Training Loss: 0.0131\n",
      "    Validation Batch [1/1], Loss: 0.0055\n",
      "Validation Loss: 0.0055, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [545/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [545/1000] completed, Average Training Loss: 0.0154\n",
      "    Validation Batch [1/1], Loss: 0.0059\n",
      "Validation Loss: 0.0059, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [546/1000] - Training\n",
      "Epoch [546/1000] completed, Average Training Loss: 0.0156\n",
      "    Validation Batch [1/1], Loss: 0.0051\n",
      "Validation Loss: 0.0051, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0052 to 0.0051. Saving model...\n",
      "\n",
      "LOG: Epoch [547/1000] - Training\n",
      "Epoch [547/1000] completed, Average Training Loss: 0.0193\n",
      "    Validation Batch [1/1], Loss: 0.0038\n",
      "Validation Loss: 0.0038, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0051 to 0.0038. Saving model...\n",
      "\n",
      "LOG: Epoch [548/1000] - Training\n",
      "Epoch [548/1000] completed, Average Training Loss: 0.0142\n",
      "    Validation Batch [1/1], Loss: 0.0045\n",
      "Validation Loss: 0.0045, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [549/1000] - Training\n",
      "Epoch [549/1000] completed, Average Training Loss: 0.0130\n",
      "    Validation Batch [1/1], Loss: 0.0064\n",
      "Validation Loss: 0.0064, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [550/1000] - Training\n",
      "Epoch [550/1000] completed, Average Training Loss: 0.0151\n",
      "    Validation Batch [1/1], Loss: 0.0072\n",
      "Validation Loss: 0.0072, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [551/1000] - Training\n",
      "Epoch [551/1000] completed, Average Training Loss: 0.0168\n",
      "    Validation Batch [1/1], Loss: 0.0097\n",
      "Validation Loss: 0.0097, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [552/1000] - Training\n",
      "Epoch [552/1000] completed, Average Training Loss: 0.0131\n",
      "    Validation Batch [1/1], Loss: 0.0139\n",
      "Validation Loss: 0.0139, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [553/1000] - Training\n",
      "Epoch [553/1000] completed, Average Training Loss: 0.0112\n",
      "    Validation Batch [1/1], Loss: 0.0137\n",
      "Validation Loss: 0.0137, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [554/1000] - Training\n",
      "Epoch [554/1000] completed, Average Training Loss: 0.0144\n",
      "    Validation Batch [1/1], Loss: 0.0111\n",
      "Validation Loss: 0.0111, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [555/1000] - Training\n",
      "Epoch [555/1000] completed, Average Training Loss: 0.0159\n",
      "    Validation Batch [1/1], Loss: 0.0102\n",
      "Validation Loss: 0.0102, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [556/1000] - Training\n",
      "Epoch [556/1000] completed, Average Training Loss: 0.0128\n",
      "    Validation Batch [1/1], Loss: 0.0090\n",
      "Validation Loss: 0.0090, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [557/1000] - Training\n",
      "Epoch [557/1000] completed, Average Training Loss: 0.0119\n",
      "    Validation Batch [1/1], Loss: 0.0076\n",
      "Validation Loss: 0.0076, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [558/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [558/1000] completed, Average Training Loss: 0.0134\n",
      "    Validation Batch [1/1], Loss: 0.0065\n",
      "Validation Loss: 0.0065, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [559/1000] - Training\n",
      "Epoch [559/1000] completed, Average Training Loss: 0.0182\n",
      "    Validation Batch [1/1], Loss: 0.0044\n",
      "Validation Loss: 0.0044, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [560/1000] - Training\n",
      "Epoch [560/1000] completed, Average Training Loss: 0.0138\n",
      "    Validation Batch [1/1], Loss: 0.0040\n",
      "Validation Loss: 0.0040, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [561/1000] - Training\n",
      "Epoch [561/1000] completed, Average Training Loss: 0.0106\n",
      "    Validation Batch [1/1], Loss: 0.0047\n",
      "Validation Loss: 0.0047, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [562/1000] - Training\n",
      "Epoch [562/1000] completed, Average Training Loss: 0.0151\n",
      "    Validation Batch [1/1], Loss: 0.0051\n",
      "Validation Loss: 0.0051, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [563/1000] - Training\n",
      "Epoch [563/1000] completed, Average Training Loss: 0.0133\n",
      "    Validation Batch [1/1], Loss: 0.0109\n",
      "Validation Loss: 0.0109, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [564/1000] - Training\n",
      "Epoch [564/1000] completed, Average Training Loss: 0.0121\n",
      "    Validation Batch [1/1], Loss: 0.0157\n",
      "Validation Loss: 0.0157, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [565/1000] - Training\n",
      "Epoch [565/1000] completed, Average Training Loss: 0.0113\n",
      "    Validation Batch [1/1], Loss: 0.0105\n",
      "Validation Loss: 0.0105, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [566/1000] - Training\n",
      "Epoch [566/1000] completed, Average Training Loss: 0.0134\n",
      "    Validation Batch [1/1], Loss: 0.0059\n",
      "Validation Loss: 0.0059, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [567/1000] - Training\n",
      "Epoch [567/1000] completed, Average Training Loss: 0.0132\n",
      "    Validation Batch [1/1], Loss: 0.0065\n",
      "Validation Loss: 0.0065, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [568/1000] - Training\n",
      "Epoch [568/1000] completed, Average Training Loss: 0.0132\n",
      "    Validation Batch [1/1], Loss: 0.0083\n",
      "Validation Loss: 0.0083, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [569/1000] - Training\n",
      "Epoch [569/1000] completed, Average Training Loss: 0.0126\n",
      "    Validation Batch [1/1], Loss: 0.0075\n",
      "Validation Loss: 0.0075, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [570/1000] - Training\n",
      "Epoch [570/1000] completed, Average Training Loss: 0.0132\n",
      "    Validation Batch [1/1], Loss: 0.0065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0065, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [571/1000] - Training\n",
      "Epoch [571/1000] completed, Average Training Loss: 0.0120\n",
      "    Validation Batch [1/1], Loss: 0.0065\n",
      "Validation Loss: 0.0065, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [572/1000] - Training\n",
      "Epoch [572/1000] completed, Average Training Loss: 0.0148\n",
      "    Validation Batch [1/1], Loss: 0.0073\n",
      "Validation Loss: 0.0073, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [573/1000] - Training\n",
      "Epoch [573/1000] completed, Average Training Loss: 0.0168\n",
      "    Validation Batch [1/1], Loss: 0.0057\n",
      "Validation Loss: 0.0057, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [574/1000] - Training\n",
      "Epoch [574/1000] completed, Average Training Loss: 0.0120\n",
      "    Validation Batch [1/1], Loss: 0.0040\n",
      "Validation Loss: 0.0040, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [575/1000] - Training\n",
      "Epoch [575/1000] completed, Average Training Loss: 0.0140\n",
      "    Validation Batch [1/1], Loss: 0.0035\n",
      "Validation Loss: 0.0035, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0038 to 0.0035. Saving model...\n",
      "\n",
      "LOG: Epoch [576/1000] - Training\n",
      "Epoch [576/1000] completed, Average Training Loss: 0.0140\n",
      "    Validation Batch [1/1], Loss: 0.0041\n",
      "Validation Loss: 0.0041, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [577/1000] - Training\n",
      "Epoch [577/1000] completed, Average Training Loss: 0.0138\n",
      "    Validation Batch [1/1], Loss: 0.0056\n",
      "Validation Loss: 0.0056, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [578/1000] - Training\n",
      "Epoch [578/1000] completed, Average Training Loss: 0.0132\n",
      "    Validation Batch [1/1], Loss: 0.0052\n",
      "Validation Loss: 0.0052, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [579/1000] - Training\n",
      "Epoch [579/1000] completed, Average Training Loss: 0.0143\n",
      "    Validation Batch [1/1], Loss: 0.0045\n",
      "Validation Loss: 0.0045, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [580/1000] - Training\n",
      "Epoch [580/1000] completed, Average Training Loss: 0.0157\n",
      "    Validation Batch [1/1], Loss: 0.0041\n",
      "Validation Loss: 0.0041, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [581/1000] - Training\n",
      "Epoch [581/1000] completed, Average Training Loss: 0.0116\n",
      "    Validation Batch [1/1], Loss: 0.0042\n",
      "Validation Loss: 0.0042, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [582/1000] - Training\n",
      "Epoch [582/1000] completed, Average Training Loss: 0.0117\n",
      "    Validation Batch [1/1], Loss: 0.0044\n",
      "Validation Loss: 0.0044, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [583/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [583/1000] completed, Average Training Loss: 0.0120\n",
      "    Validation Batch [1/1], Loss: 0.0047\n",
      "Validation Loss: 0.0047, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [584/1000] - Training\n",
      "Epoch [584/1000] completed, Average Training Loss: 0.0107\n",
      "    Validation Batch [1/1], Loss: 0.0051\n",
      "Validation Loss: 0.0051, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [585/1000] - Training\n",
      "Epoch [585/1000] completed, Average Training Loss: 0.0151\n",
      "    Validation Batch [1/1], Loss: 0.0061\n",
      "Validation Loss: 0.0061, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [586/1000] - Training\n",
      "Epoch [586/1000] completed, Average Training Loss: 0.0096\n",
      "    Validation Batch [1/1], Loss: 0.0073\n",
      "Validation Loss: 0.0073, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [587/1000] - Training\n",
      "Epoch [587/1000] completed, Average Training Loss: 0.0105\n",
      "    Validation Batch [1/1], Loss: 0.0075\n",
      "Validation Loss: 0.0075, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [588/1000] - Training\n",
      "Epoch [588/1000] completed, Average Training Loss: 0.0117\n",
      "    Validation Batch [1/1], Loss: 0.0066\n",
      "Validation Loss: 0.0066, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [589/1000] - Training\n",
      "Epoch [589/1000] completed, Average Training Loss: 0.0144\n",
      "    Validation Batch [1/1], Loss: 0.0060\n",
      "Validation Loss: 0.0060, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [590/1000] - Training\n",
      "Epoch [590/1000] completed, Average Training Loss: 0.0116\n",
      "    Validation Batch [1/1], Loss: 0.0063\n",
      "Validation Loss: 0.0063, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [591/1000] - Training\n",
      "Epoch [591/1000] completed, Average Training Loss: 0.0110\n",
      "    Validation Batch [1/1], Loss: 0.0066\n",
      "Validation Loss: 0.0066, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [592/1000] - Training\n",
      "Epoch [592/1000] completed, Average Training Loss: 0.0090\n",
      "    Validation Batch [1/1], Loss: 0.0064\n",
      "Validation Loss: 0.0064, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [593/1000] - Training\n",
      "Epoch [593/1000] completed, Average Training Loss: 0.0117\n",
      "    Validation Batch [1/1], Loss: 0.0051\n",
      "Validation Loss: 0.0051, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [594/1000] - Training\n",
      "Epoch [594/1000] completed, Average Training Loss: 0.0135\n",
      "    Validation Batch [1/1], Loss: 0.0045\n",
      "Validation Loss: 0.0045, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [595/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [595/1000] completed, Average Training Loss: 0.0144\n",
      "    Validation Batch [1/1], Loss: 0.0053\n",
      "Validation Loss: 0.0053, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [596/1000] - Training\n",
      "Epoch [596/1000] completed, Average Training Loss: 0.0162\n",
      "    Validation Batch [1/1], Loss: 0.0043\n",
      "Validation Loss: 0.0043, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [597/1000] - Training\n",
      "Epoch [597/1000] completed, Average Training Loss: 0.0140\n",
      "    Validation Batch [1/1], Loss: 0.0040\n",
      "Validation Loss: 0.0040, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [598/1000] - Training\n",
      "Epoch [598/1000] completed, Average Training Loss: 0.0117\n",
      "    Validation Batch [1/1], Loss: 0.0040\n",
      "Validation Loss: 0.0040, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [599/1000] - Training\n",
      "Epoch [599/1000] completed, Average Training Loss: 0.0158\n",
      "    Validation Batch [1/1], Loss: 0.0041\n",
      "Validation Loss: 0.0041, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [600/1000] - Training\n",
      "Epoch [600/1000] completed, Average Training Loss: 0.0120\n",
      "    Validation Batch [1/1], Loss: 0.0051\n",
      "Validation Loss: 0.0051, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [601/1000] - Training\n",
      "Epoch [601/1000] completed, Average Training Loss: 0.0149\n",
      "    Validation Batch [1/1], Loss: 0.0065\n",
      "Validation Loss: 0.0065, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [602/1000] - Training\n",
      "Epoch [602/1000] completed, Average Training Loss: 0.0100\n",
      "    Validation Batch [1/1], Loss: 0.0068\n",
      "Validation Loss: 0.0068, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [603/1000] - Training\n",
      "Epoch [603/1000] completed, Average Training Loss: 0.0119\n",
      "    Validation Batch [1/1], Loss: 0.0048\n",
      "Validation Loss: 0.0048, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [604/1000] - Training\n",
      "Epoch [604/1000] completed, Average Training Loss: 0.0145\n",
      "    Validation Batch [1/1], Loss: 0.0108\n",
      "Validation Loss: 0.0108, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [605/1000] - Training\n",
      "Epoch [605/1000] completed, Average Training Loss: 0.0092\n",
      "    Validation Batch [1/1], Loss: 0.0181\n",
      "Validation Loss: 0.0181, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [606/1000] - Training\n",
      "Epoch [606/1000] completed, Average Training Loss: 0.0114\n",
      "    Validation Batch [1/1], Loss: 0.0059\n",
      "Validation Loss: 0.0059, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [607/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [607/1000] completed, Average Training Loss: 0.0138\n",
      "    Validation Batch [1/1], Loss: 0.0070\n",
      "Validation Loss: 0.0070, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [608/1000] - Training\n",
      "Epoch [608/1000] completed, Average Training Loss: 0.0149\n",
      "    Validation Batch [1/1], Loss: 0.0109\n",
      "Validation Loss: 0.0109, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [609/1000] - Training\n",
      "Epoch [609/1000] completed, Average Training Loss: 0.0111\n",
      "    Validation Batch [1/1], Loss: 0.0092\n",
      "Validation Loss: 0.0092, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [610/1000] - Training\n",
      "Epoch [610/1000] completed, Average Training Loss: 0.0118\n",
      "    Validation Batch [1/1], Loss: 0.0046\n",
      "Validation Loss: 0.0046, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [611/1000] - Training\n",
      "Epoch [611/1000] completed, Average Training Loss: 0.0117\n",
      "    Validation Batch [1/1], Loss: 0.0045\n",
      "Validation Loss: 0.0045, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [612/1000] - Training\n",
      "Epoch [612/1000] completed, Average Training Loss: 0.0118\n",
      "    Validation Batch [1/1], Loss: 0.0163\n",
      "Validation Loss: 0.0163, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [613/1000] - Training\n",
      "Epoch [613/1000] completed, Average Training Loss: 0.0128\n",
      "    Validation Batch [1/1], Loss: 0.0113\n",
      "Validation Loss: 0.0113, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [614/1000] - Training\n",
      "Epoch [614/1000] completed, Average Training Loss: 0.0105\n",
      "    Validation Batch [1/1], Loss: 0.0070\n",
      "Validation Loss: 0.0070, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [615/1000] - Training\n",
      "Epoch [615/1000] completed, Average Training Loss: 0.0125\n",
      "    Validation Batch [1/1], Loss: 0.0138\n",
      "Validation Loss: 0.0138, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [616/1000] - Training\n",
      "Epoch [616/1000] completed, Average Training Loss: 0.0102\n",
      "    Validation Batch [1/1], Loss: 0.0192\n",
      "Validation Loss: 0.0192, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [617/1000] - Training\n",
      "Epoch [617/1000] completed, Average Training Loss: 0.0123\n",
      "    Validation Batch [1/1], Loss: 0.0114\n",
      "Validation Loss: 0.0114, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [618/1000] - Training\n",
      "Epoch [618/1000] completed, Average Training Loss: 0.0111\n",
      "    Validation Batch [1/1], Loss: 0.0067\n",
      "Validation Loss: 0.0067, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [619/1000] - Training\n",
      "Epoch [619/1000] completed, Average Training Loss: 0.0102\n",
      "    Validation Batch [1/1], Loss: 0.0060\n",
      "Validation Loss: 0.0060, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [620/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [620/1000] completed, Average Training Loss: 0.0109\n",
      "    Validation Batch [1/1], Loss: 0.0071\n",
      "Validation Loss: 0.0071, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [621/1000] - Training\n",
      "Epoch [621/1000] completed, Average Training Loss: 0.0095\n",
      "    Validation Batch [1/1], Loss: 0.0064\n",
      "Validation Loss: 0.0064, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [622/1000] - Training\n",
      "Epoch [622/1000] completed, Average Training Loss: 0.0106\n",
      "    Validation Batch [1/1], Loss: 0.0054\n",
      "Validation Loss: 0.0054, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [623/1000] - Training\n",
      "Epoch [623/1000] completed, Average Training Loss: 0.0100\n",
      "    Validation Batch [1/1], Loss: 0.0054\n",
      "Validation Loss: 0.0054, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [624/1000] - Training\n",
      "Epoch [624/1000] completed, Average Training Loss: 0.0099\n",
      "    Validation Batch [1/1], Loss: 0.0059\n",
      "Validation Loss: 0.0059, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [625/1000] - Training\n",
      "Epoch [625/1000] completed, Average Training Loss: 0.0106\n",
      "    Validation Batch [1/1], Loss: 0.0070\n",
      "Validation Loss: 0.0070, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [626/1000] - Training\n",
      "Epoch [626/1000] completed, Average Training Loss: 0.0110\n",
      "    Validation Batch [1/1], Loss: 0.0049\n",
      "Validation Loss: 0.0049, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [627/1000] - Training\n",
      "Epoch [627/1000] completed, Average Training Loss: 0.0108\n",
      "    Validation Batch [1/1], Loss: 0.0037\n",
      "Validation Loss: 0.0037, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [628/1000] - Training\n",
      "Epoch [628/1000] completed, Average Training Loss: 0.0115\n",
      "    Validation Batch [1/1], Loss: 0.0035\n",
      "Validation Loss: 0.0035, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0035 to 0.0035. Saving model...\n",
      "\n",
      "LOG: Epoch [629/1000] - Training\n",
      "Epoch [629/1000] completed, Average Training Loss: 0.0118\n",
      "    Validation Batch [1/1], Loss: 0.0040\n",
      "Validation Loss: 0.0040, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [630/1000] - Training\n",
      "Epoch [630/1000] completed, Average Training Loss: 0.0127\n",
      "    Validation Batch [1/1], Loss: 0.0059\n",
      "Validation Loss: 0.0059, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [631/1000] - Training\n",
      "Epoch [631/1000] completed, Average Training Loss: 0.0097\n",
      "    Validation Batch [1/1], Loss: 0.0068\n",
      "Validation Loss: 0.0068, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [632/1000] - Training\n",
      "Epoch [632/1000] completed, Average Training Loss: 0.0153\n",
      "    Validation Batch [1/1], Loss: 0.0052\n",
      "Validation Loss: 0.0052, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [633/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [633/1000] completed, Average Training Loss: 0.0100\n",
      "    Validation Batch [1/1], Loss: 0.0057\n",
      "Validation Loss: 0.0057, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [634/1000] - Training\n",
      "Epoch [634/1000] completed, Average Training Loss: 0.0099\n",
      "    Validation Batch [1/1], Loss: 0.0056\n",
      "Validation Loss: 0.0056, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [635/1000] - Training\n",
      "Epoch [635/1000] completed, Average Training Loss: 0.0104\n",
      "    Validation Batch [1/1], Loss: 0.0092\n",
      "Validation Loss: 0.0092, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [636/1000] - Training\n",
      "Epoch [636/1000] completed, Average Training Loss: 0.0084\n",
      "    Validation Batch [1/1], Loss: 0.0128\n",
      "Validation Loss: 0.0128, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [637/1000] - Training\n",
      "Epoch [637/1000] completed, Average Training Loss: 0.0095\n",
      "    Validation Batch [1/1], Loss: 0.0132\n",
      "Validation Loss: 0.0132, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [638/1000] - Training\n",
      "Epoch [638/1000] completed, Average Training Loss: 0.0088\n",
      "    Validation Batch [1/1], Loss: 0.0096\n",
      "Validation Loss: 0.0096, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [639/1000] - Training\n",
      "Epoch [639/1000] completed, Average Training Loss: 0.0101\n",
      "    Validation Batch [1/1], Loss: 0.0055\n",
      "Validation Loss: 0.0055, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [640/1000] - Training\n",
      "Epoch [640/1000] completed, Average Training Loss: 0.0082\n",
      "    Validation Batch [1/1], Loss: 0.0040\n",
      "Validation Loss: 0.0040, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [641/1000] - Training\n",
      "Epoch [641/1000] completed, Average Training Loss: 0.0095\n",
      "    Validation Batch [1/1], Loss: 0.0035\n",
      "Validation Loss: 0.0035, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [642/1000] - Training\n",
      "Epoch [642/1000] completed, Average Training Loss: 0.0106\n",
      "    Validation Batch [1/1], Loss: 0.0047\n",
      "Validation Loss: 0.0047, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [643/1000] - Training\n",
      "Epoch [643/1000] completed, Average Training Loss: 0.0122\n",
      "    Validation Batch [1/1], Loss: 0.0069\n",
      "Validation Loss: 0.0069, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [644/1000] - Training\n",
      "Epoch [644/1000] completed, Average Training Loss: 0.0110\n",
      "    Validation Batch [1/1], Loss: 0.0112\n",
      "Validation Loss: 0.0112, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [645/1000] - Training\n",
      "Epoch [645/1000] completed, Average Training Loss: 0.0130\n",
      "    Validation Batch [1/1], Loss: 0.0045\n",
      "Validation Loss: 0.0045, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [646/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [646/1000] completed, Average Training Loss: 0.0135\n",
      "    Validation Batch [1/1], Loss: 0.0039\n",
      "Validation Loss: 0.0039, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [647/1000] - Training\n",
      "Epoch [647/1000] completed, Average Training Loss: 0.0113\n",
      "    Validation Batch [1/1], Loss: 0.0080\n",
      "Validation Loss: 0.0080, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [648/1000] - Training\n",
      "Epoch [648/1000] completed, Average Training Loss: 0.0134\n",
      "    Validation Batch [1/1], Loss: 0.0041\n",
      "Validation Loss: 0.0041, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [649/1000] - Training\n",
      "Epoch [649/1000] completed, Average Training Loss: 0.0093\n",
      "    Validation Batch [1/1], Loss: 0.0029\n",
      "Validation Loss: 0.0029, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0035 to 0.0029. Saving model...\n",
      "\n",
      "LOG: Epoch [650/1000] - Training\n",
      "Epoch [650/1000] completed, Average Training Loss: 0.0102\n",
      "    Validation Batch [1/1], Loss: 0.0056\n",
      "Validation Loss: 0.0056, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [651/1000] - Training\n",
      "Epoch [651/1000] completed, Average Training Loss: 0.0096\n",
      "    Validation Batch [1/1], Loss: 0.0105\n",
      "Validation Loss: 0.0105, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [652/1000] - Training\n",
      "Epoch [652/1000] completed, Average Training Loss: 0.0116\n",
      "    Validation Batch [1/1], Loss: 0.0036\n",
      "Validation Loss: 0.0036, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [653/1000] - Training\n",
      "Epoch [653/1000] completed, Average Training Loss: 0.0090\n",
      "    Validation Batch [1/1], Loss: 0.0084\n",
      "Validation Loss: 0.0084, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [654/1000] - Training\n",
      "Epoch [654/1000] completed, Average Training Loss: 0.0108\n",
      "    Validation Batch [1/1], Loss: 0.0115\n",
      "Validation Loss: 0.0115, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [655/1000] - Training\n",
      "Epoch [655/1000] completed, Average Training Loss: 0.0125\n",
      "    Validation Batch [1/1], Loss: 0.0062\n",
      "Validation Loss: 0.0062, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [656/1000] - Training\n",
      "Epoch [656/1000] completed, Average Training Loss: 0.0118\n",
      "    Validation Batch [1/1], Loss: 0.0037\n",
      "Validation Loss: 0.0037, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [657/1000] - Training\n",
      "Epoch [657/1000] completed, Average Training Loss: 0.0086\n",
      "    Validation Batch [1/1], Loss: 0.0034\n",
      "Validation Loss: 0.0034, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [658/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [658/1000] completed, Average Training Loss: 0.0094\n",
      "    Validation Batch [1/1], Loss: 0.0034\n",
      "Validation Loss: 0.0034, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [659/1000] - Training\n",
      "Epoch [659/1000] completed, Average Training Loss: 0.0100\n",
      "    Validation Batch [1/1], Loss: 0.0035\n",
      "Validation Loss: 0.0035, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [660/1000] - Training\n",
      "Epoch [660/1000] completed, Average Training Loss: 0.0084\n",
      "    Validation Batch [1/1], Loss: 0.0036\n",
      "Validation Loss: 0.0036, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [661/1000] - Training\n",
      "Epoch [661/1000] completed, Average Training Loss: 0.0088\n",
      "    Validation Batch [1/1], Loss: 0.0035\n",
      "Validation Loss: 0.0035, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [662/1000] - Training\n",
      "Epoch [662/1000] completed, Average Training Loss: 0.0079\n",
      "    Validation Batch [1/1], Loss: 0.0033\n",
      "Validation Loss: 0.0033, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [663/1000] - Training\n",
      "Epoch [663/1000] completed, Average Training Loss: 0.0081\n",
      "    Validation Batch [1/1], Loss: 0.0034\n",
      "Validation Loss: 0.0034, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [664/1000] - Training\n",
      "Epoch [664/1000] completed, Average Training Loss: 0.0100\n",
      "    Validation Batch [1/1], Loss: 0.0036\n",
      "Validation Loss: 0.0036, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [665/1000] - Training\n",
      "Epoch [665/1000] completed, Average Training Loss: 0.0101\n",
      "    Validation Batch [1/1], Loss: 0.0064\n",
      "Validation Loss: 0.0064, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [666/1000] - Training\n",
      "Epoch [666/1000] completed, Average Training Loss: 0.0095\n",
      "    Validation Batch [1/1], Loss: 0.0075\n",
      "Validation Loss: 0.0075, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [667/1000] - Training\n",
      "Epoch [667/1000] completed, Average Training Loss: 0.0087\n",
      "    Validation Batch [1/1], Loss: 0.0047\n",
      "Validation Loss: 0.0047, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [668/1000] - Training\n",
      "Epoch [668/1000] completed, Average Training Loss: 0.0086\n",
      "    Validation Batch [1/1], Loss: 0.0034\n",
      "Validation Loss: 0.0034, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [669/1000] - Training\n",
      "Epoch [669/1000] completed, Average Training Loss: 0.0110\n",
      "    Validation Batch [1/1], Loss: 0.0030\n",
      "Validation Loss: 0.0030, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [670/1000] - Training\n",
      "Epoch [670/1000] completed, Average Training Loss: 0.0075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0035\n",
      "Validation Loss: 0.0035, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [671/1000] - Training\n",
      "Epoch [671/1000] completed, Average Training Loss: 0.0097\n",
      "    Validation Batch [1/1], Loss: 0.0038\n",
      "Validation Loss: 0.0038, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [672/1000] - Training\n",
      "Epoch [672/1000] completed, Average Training Loss: 0.0124\n",
      "    Validation Batch [1/1], Loss: 0.0038\n",
      "Validation Loss: 0.0038, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [673/1000] - Training\n",
      "Epoch [673/1000] completed, Average Training Loss: 0.0078\n",
      "    Validation Batch [1/1], Loss: 0.0037\n",
      "Validation Loss: 0.0037, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [674/1000] - Training\n",
      "Epoch [674/1000] completed, Average Training Loss: 0.0080\n",
      "    Validation Batch [1/1], Loss: 0.0040\n",
      "Validation Loss: 0.0040, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [675/1000] - Training\n",
      "Epoch [675/1000] completed, Average Training Loss: 0.0076\n",
      "    Validation Batch [1/1], Loss: 0.0042\n",
      "Validation Loss: 0.0042, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [676/1000] - Training\n",
      "Epoch [676/1000] completed, Average Training Loss: 0.0084\n",
      "    Validation Batch [1/1], Loss: 0.0039\n",
      "Validation Loss: 0.0039, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [677/1000] - Training\n",
      "Epoch [677/1000] completed, Average Training Loss: 0.0087\n",
      "    Validation Batch [1/1], Loss: 0.0036\n",
      "Validation Loss: 0.0036, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [678/1000] - Training\n",
      "Epoch [678/1000] completed, Average Training Loss: 0.0104\n",
      "    Validation Batch [1/1], Loss: 0.0036\n",
      "Validation Loss: 0.0036, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [679/1000] - Training\n",
      "Epoch [679/1000] completed, Average Training Loss: 0.0097\n",
      "    Validation Batch [1/1], Loss: 0.0031\n",
      "Validation Loss: 0.0031, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [680/1000] - Training\n",
      "Epoch [680/1000] completed, Average Training Loss: 0.0089\n",
      "    Validation Batch [1/1], Loss: 0.0037\n",
      "Validation Loss: 0.0037, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [681/1000] - Training\n",
      "Epoch [681/1000] completed, Average Training Loss: 0.0110\n",
      "    Validation Batch [1/1], Loss: 0.0048\n",
      "Validation Loss: 0.0048, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [682/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [682/1000] completed, Average Training Loss: 0.0094\n",
      "    Validation Batch [1/1], Loss: 0.0046\n",
      "Validation Loss: 0.0046, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [683/1000] - Training\n",
      "Epoch [683/1000] completed, Average Training Loss: 0.0078\n",
      "    Validation Batch [1/1], Loss: 0.0038\n",
      "Validation Loss: 0.0038, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [684/1000] - Training\n",
      "Epoch [684/1000] completed, Average Training Loss: 0.0074\n",
      "    Validation Batch [1/1], Loss: 0.0035\n",
      "Validation Loss: 0.0035, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [685/1000] - Training\n",
      "Epoch [685/1000] completed, Average Training Loss: 0.0094\n",
      "    Validation Batch [1/1], Loss: 0.0026\n",
      "Validation Loss: 0.0026, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0029 to 0.0026. Saving model...\n",
      "\n",
      "LOG: Epoch [686/1000] - Training\n",
      "Epoch [686/1000] completed, Average Training Loss: 0.0114\n",
      "    Validation Batch [1/1], Loss: 0.0026\n",
      "Validation Loss: 0.0026, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0026 to 0.0026. Saving model...\n",
      "\n",
      "LOG: Epoch [687/1000] - Training\n",
      "Epoch [687/1000] completed, Average Training Loss: 0.0081\n",
      "    Validation Batch [1/1], Loss: 0.0028\n",
      "Validation Loss: 0.0028, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [688/1000] - Training\n",
      "Epoch [688/1000] completed, Average Training Loss: 0.0092\n",
      "    Validation Batch [1/1], Loss: 0.0029\n",
      "Validation Loss: 0.0029, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [689/1000] - Training\n",
      "Epoch [689/1000] completed, Average Training Loss: 0.0091\n",
      "    Validation Batch [1/1], Loss: 0.0034\n",
      "Validation Loss: 0.0034, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [690/1000] - Training\n",
      "Epoch [690/1000] completed, Average Training Loss: 0.0073\n",
      "    Validation Batch [1/1], Loss: 0.0040\n",
      "Validation Loss: 0.0040, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [691/1000] - Training\n",
      "Epoch [691/1000] completed, Average Training Loss: 0.0083\n",
      "    Validation Batch [1/1], Loss: 0.0038\n",
      "Validation Loss: 0.0038, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [692/1000] - Training\n",
      "Epoch [692/1000] completed, Average Training Loss: 0.0128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0038\n",
      "Validation Loss: 0.0038, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [693/1000] - Training\n",
      "Epoch [693/1000] completed, Average Training Loss: 0.0088\n",
      "    Validation Batch [1/1], Loss: 0.0059\n",
      "Validation Loss: 0.0059, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [694/1000] - Training\n",
      "Epoch [694/1000] completed, Average Training Loss: 0.0078\n",
      "    Validation Batch [1/1], Loss: 0.0083\n",
      "Validation Loss: 0.0083, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [695/1000] - Training\n",
      "Epoch [695/1000] completed, Average Training Loss: 0.0090\n",
      "    Validation Batch [1/1], Loss: 0.0046\n",
      "Validation Loss: 0.0046, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [696/1000] - Training\n",
      "Epoch [696/1000] completed, Average Training Loss: 0.0094\n",
      "    Validation Batch [1/1], Loss: 0.0037\n",
      "Validation Loss: 0.0037, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [697/1000] - Training\n",
      "Epoch [697/1000] completed, Average Training Loss: 0.0095\n",
      "    Validation Batch [1/1], Loss: 0.0051\n",
      "Validation Loss: 0.0051, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [698/1000] - Training\n",
      "Epoch [698/1000] completed, Average Training Loss: 0.0066\n",
      "    Validation Batch [1/1], Loss: 0.0041\n",
      "Validation Loss: 0.0041, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [699/1000] - Training\n",
      "Epoch [699/1000] completed, Average Training Loss: 0.0090\n",
      "    Validation Batch [1/1], Loss: 0.0034\n",
      "Validation Loss: 0.0034, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [700/1000] - Training\n",
      "Epoch [700/1000] completed, Average Training Loss: 0.0091\n",
      "    Validation Batch [1/1], Loss: 0.0054\n",
      "Validation Loss: 0.0054, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [701/1000] - Training\n",
      "Epoch [701/1000] completed, Average Training Loss: 0.0096\n",
      "    Validation Batch [1/1], Loss: 0.0067\n",
      "Validation Loss: 0.0067, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [702/1000] - Training\n",
      "Epoch [702/1000] completed, Average Training Loss: 0.0074\n",
      "    Validation Batch [1/1], Loss: 0.0070\n",
      "Validation Loss: 0.0070, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [703/1000] - Training\n",
      "Epoch [703/1000] completed, Average Training Loss: 0.0073\n",
      "    Validation Batch [1/1], Loss: 0.0095\n",
      "Validation Loss: 0.0095, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [704/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [704/1000] completed, Average Training Loss: 0.0077\n",
      "    Validation Batch [1/1], Loss: 0.0057\n",
      "Validation Loss: 0.0057, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [705/1000] - Training\n",
      "Epoch [705/1000] completed, Average Training Loss: 0.0081\n",
      "    Validation Batch [1/1], Loss: 0.0043\n",
      "Validation Loss: 0.0043, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [706/1000] - Training\n",
      "Epoch [706/1000] completed, Average Training Loss: 0.0074\n",
      "    Validation Batch [1/1], Loss: 0.0052\n",
      "Validation Loss: 0.0052, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [707/1000] - Training\n",
      "Epoch [707/1000] completed, Average Training Loss: 0.0089\n",
      "    Validation Batch [1/1], Loss: 0.0112\n",
      "Validation Loss: 0.0112, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [708/1000] - Training\n",
      "Epoch [708/1000] completed, Average Training Loss: 0.0086\n",
      "    Validation Batch [1/1], Loss: 0.0148\n",
      "Validation Loss: 0.0148, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [709/1000] - Training\n",
      "Epoch [709/1000] completed, Average Training Loss: 0.0087\n",
      "    Validation Batch [1/1], Loss: 0.0075\n",
      "Validation Loss: 0.0075, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [710/1000] - Training\n",
      "Epoch [710/1000] completed, Average Training Loss: 0.0103\n",
      "    Validation Batch [1/1], Loss: 0.0047\n",
      "Validation Loss: 0.0047, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [711/1000] - Training\n",
      "Epoch [711/1000] completed, Average Training Loss: 0.0066\n",
      "    Validation Batch [1/1], Loss: 0.0082\n",
      "Validation Loss: 0.0082, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [712/1000] - Training\n",
      "Epoch [712/1000] completed, Average Training Loss: 0.0082\n",
      "    Validation Batch [1/1], Loss: 0.0160\n",
      "Validation Loss: 0.0160, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [713/1000] - Training\n",
      "Epoch [713/1000] completed, Average Training Loss: 0.0083\n",
      "    Validation Batch [1/1], Loss: 0.0176\n",
      "Validation Loss: 0.0176, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [714/1000] - Training\n",
      "Epoch [714/1000] completed, Average Training Loss: 0.0105\n",
      "    Validation Batch [1/1], Loss: 0.0078\n",
      "Validation Loss: 0.0078, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [715/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [715/1000] completed, Average Training Loss: 0.0071\n",
      "    Validation Batch [1/1], Loss: 0.0056\n",
      "Validation Loss: 0.0056, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [716/1000] - Training\n",
      "Epoch [716/1000] completed, Average Training Loss: 0.0074\n",
      "    Validation Batch [1/1], Loss: 0.0044\n",
      "Validation Loss: 0.0044, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [717/1000] - Training\n",
      "Epoch [717/1000] completed, Average Training Loss: 0.0088\n",
      "    Validation Batch [1/1], Loss: 0.0042\n",
      "Validation Loss: 0.0042, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [718/1000] - Training\n",
      "Epoch [718/1000] completed, Average Training Loss: 0.0091\n",
      "    Validation Batch [1/1], Loss: 0.0051\n",
      "Validation Loss: 0.0051, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [719/1000] - Training\n",
      "Epoch [719/1000] completed, Average Training Loss: 0.0081\n",
      "    Validation Batch [1/1], Loss: 0.0039\n",
      "Validation Loss: 0.0039, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [720/1000] - Training\n",
      "Epoch [720/1000] completed, Average Training Loss: 0.0064\n",
      "    Validation Batch [1/1], Loss: 0.0031\n",
      "Validation Loss: 0.0031, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [721/1000] - Training\n",
      "Epoch [721/1000] completed, Average Training Loss: 0.0061\n",
      "    Validation Batch [1/1], Loss: 0.0032\n",
      "Validation Loss: 0.0032, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [722/1000] - Training\n",
      "Epoch [722/1000] completed, Average Training Loss: 0.0062\n",
      "    Validation Batch [1/1], Loss: 0.0038\n",
      "Validation Loss: 0.0038, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [723/1000] - Training\n",
      "Epoch [723/1000] completed, Average Training Loss: 0.0077\n",
      "    Validation Batch [1/1], Loss: 0.0041\n",
      "Validation Loss: 0.0041, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [724/1000] - Training\n",
      "Epoch [724/1000] completed, Average Training Loss: 0.0079\n",
      "    Validation Batch [1/1], Loss: 0.0033\n",
      "Validation Loss: 0.0033, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [725/1000] - Training\n",
      "Epoch [725/1000] completed, Average Training Loss: 0.0085\n",
      "    Validation Batch [1/1], Loss: 0.0038\n",
      "Validation Loss: 0.0038, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [726/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [726/1000] completed, Average Training Loss: 0.0082\n",
      "    Validation Batch [1/1], Loss: 0.0045\n",
      "Validation Loss: 0.0045, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [727/1000] - Training\n",
      "Epoch [727/1000] completed, Average Training Loss: 0.0078\n",
      "    Validation Batch [1/1], Loss: 0.0039\n",
      "Validation Loss: 0.0039, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [728/1000] - Training\n",
      "Epoch [728/1000] completed, Average Training Loss: 0.0086\n",
      "    Validation Batch [1/1], Loss: 0.0028\n",
      "Validation Loss: 0.0028, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [729/1000] - Training\n",
      "Epoch [729/1000] completed, Average Training Loss: 0.0061\n",
      "    Validation Batch [1/1], Loss: 0.0028\n",
      "Validation Loss: 0.0028, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [730/1000] - Training\n",
      "Epoch [730/1000] completed, Average Training Loss: 0.0064\n",
      "    Validation Batch [1/1], Loss: 0.0032\n",
      "Validation Loss: 0.0032, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [731/1000] - Training\n",
      "Epoch [731/1000] completed, Average Training Loss: 0.0065\n",
      "    Validation Batch [1/1], Loss: 0.0035\n",
      "Validation Loss: 0.0035, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [732/1000] - Training\n",
      "Epoch [732/1000] completed, Average Training Loss: 0.0101\n",
      "    Validation Batch [1/1], Loss: 0.0039\n",
      "Validation Loss: 0.0039, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [733/1000] - Training\n",
      "Epoch [733/1000] completed, Average Training Loss: 0.0075\n",
      "    Validation Batch [1/1], Loss: 0.0037\n",
      "Validation Loss: 0.0037, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [734/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [734/1000] completed, Average Training Loss: 0.0073\n",
      "    Validation Batch [1/1], Loss: 0.0034\n",
      "Validation Loss: 0.0034, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [735/1000] - Training\n",
      "Epoch [735/1000] completed, Average Training Loss: 0.0084\n",
      "    Validation Batch [1/1], Loss: 0.0032\n",
      "Validation Loss: 0.0032, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [736/1000] - Training\n",
      "Epoch [736/1000] completed, Average Training Loss: 0.0068\n",
      "    Validation Batch [1/1], Loss: 0.0031\n",
      "Validation Loss: 0.0031, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [737/1000] - Training\n",
      "Epoch [737/1000] completed, Average Training Loss: 0.0113\n",
      "    Validation Batch [1/1], Loss: 0.0029\n",
      "Validation Loss: 0.0029, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [738/1000] - Training\n",
      "Epoch [738/1000] completed, Average Training Loss: 0.0090\n",
      "    Validation Batch [1/1], Loss: 0.0026\n",
      "Validation Loss: 0.0026, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [739/1000] - Training\n",
      "Epoch [739/1000] completed, Average Training Loss: 0.0085\n",
      "    Validation Batch [1/1], Loss: 0.0030\n",
      "Validation Loss: 0.0030, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [740/1000] - Training\n",
      "Epoch [740/1000] completed, Average Training Loss: 0.0075\n",
      "    Validation Batch [1/1], Loss: 0.0045\n",
      "Validation Loss: 0.0045, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [741/1000] - Training\n",
      "Epoch [741/1000] completed, Average Training Loss: 0.0064\n",
      "    Validation Batch [1/1], Loss: 0.0042\n",
      "Validation Loss: 0.0042, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [742/1000] - Training\n",
      "Epoch [742/1000] completed, Average Training Loss: 0.0065\n",
      "    Validation Batch [1/1], Loss: 0.0027\n",
      "Validation Loss: 0.0027, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [743/1000] - Training\n",
      "Epoch [743/1000] completed, Average Training Loss: 0.0060\n",
      "    Validation Batch [1/1], Loss: 0.0022\n",
      "Validation Loss: 0.0022, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0026 to 0.0022. Saving model...\n",
      "\n",
      "LOG: Epoch [744/1000] - Training\n",
      "Epoch [744/1000] completed, Average Training Loss: 0.0075\n",
      "    Validation Batch [1/1], Loss: 0.0027\n",
      "Validation Loss: 0.0027, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [745/1000] - Training\n",
      "Epoch [745/1000] completed, Average Training Loss: 0.0098\n",
      "    Validation Batch [1/1], Loss: 0.0043\n",
      "Validation Loss: 0.0043, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [746/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [746/1000] completed, Average Training Loss: 0.0062\n",
      "    Validation Batch [1/1], Loss: 0.0053\n",
      "Validation Loss: 0.0053, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [747/1000] - Training\n",
      "Epoch [747/1000] completed, Average Training Loss: 0.0083\n",
      "    Validation Batch [1/1], Loss: 0.0047\n",
      "Validation Loss: 0.0047, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [748/1000] - Training\n",
      "Epoch [748/1000] completed, Average Training Loss: 0.0058\n",
      "    Validation Batch [1/1], Loss: 0.0029\n",
      "Validation Loss: 0.0029, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [749/1000] - Training\n",
      "Epoch [749/1000] completed, Average Training Loss: 0.0070\n",
      "    Validation Batch [1/1], Loss: 0.0029\n",
      "Validation Loss: 0.0029, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [750/1000] - Training\n",
      "Epoch [750/1000] completed, Average Training Loss: 0.0069\n",
      "    Validation Batch [1/1], Loss: 0.0034\n",
      "Validation Loss: 0.0034, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [751/1000] - Training\n",
      "Epoch [751/1000] completed, Average Training Loss: 0.0063\n",
      "    Validation Batch [1/1], Loss: 0.0046\n",
      "Validation Loss: 0.0046, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [752/1000] - Training\n",
      "Epoch [752/1000] completed, Average Training Loss: 0.0095\n",
      "    Validation Batch [1/1], Loss: 0.0064\n",
      "Validation Loss: 0.0064, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [753/1000] - Training\n",
      "Epoch [753/1000] completed, Average Training Loss: 0.0063\n",
      "    Validation Batch [1/1], Loss: 0.0060\n",
      "Validation Loss: 0.0060, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [754/1000] - Training\n",
      "Epoch [754/1000] completed, Average Training Loss: 0.0064\n",
      "    Validation Batch [1/1], Loss: 0.0038\n",
      "Validation Loss: 0.0038, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [755/1000] - Training\n",
      "Epoch [755/1000] completed, Average Training Loss: 0.0076\n",
      "    Validation Batch [1/1], Loss: 0.0026\n",
      "Validation Loss: 0.0026, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [756/1000] - Training\n",
      "Epoch [756/1000] completed, Average Training Loss: 0.0054\n",
      "    Validation Batch [1/1], Loss: 0.0022\n",
      "Validation Loss: 0.0022, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0022 to 0.0022. Saving model...\n",
      "\n",
      "LOG: Epoch [757/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [757/1000] completed, Average Training Loss: 0.0080\n",
      "    Validation Batch [1/1], Loss: 0.0020\n",
      "Validation Loss: 0.0020, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0022 to 0.0020. Saving model...\n",
      "\n",
      "LOG: Epoch [758/1000] - Training\n",
      "Epoch [758/1000] completed, Average Training Loss: 0.0075\n",
      "    Validation Batch [1/1], Loss: 0.0021\n",
      "Validation Loss: 0.0021, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [759/1000] - Training\n",
      "Epoch [759/1000] completed, Average Training Loss: 0.0076\n",
      "    Validation Batch [1/1], Loss: 0.0028\n",
      "Validation Loss: 0.0028, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [760/1000] - Training\n",
      "Epoch [760/1000] completed, Average Training Loss: 0.0071\n",
      "    Validation Batch [1/1], Loss: 0.0029\n",
      "Validation Loss: 0.0029, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [761/1000] - Training\n",
      "Epoch [761/1000] completed, Average Training Loss: 0.0065\n",
      "    Validation Batch [1/1], Loss: 0.0031\n",
      "Validation Loss: 0.0031, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [762/1000] - Training\n",
      "Epoch [762/1000] completed, Average Training Loss: 0.0049\n",
      "    Validation Batch [1/1], Loss: 0.0036\n",
      "Validation Loss: 0.0036, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [763/1000] - Training\n",
      "Epoch [763/1000] completed, Average Training Loss: 0.0067\n",
      "    Validation Batch [1/1], Loss: 0.0036\n",
      "Validation Loss: 0.0036, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [764/1000] - Training\n",
      "Epoch [764/1000] completed, Average Training Loss: 0.0076\n",
      "    Validation Batch [1/1], Loss: 0.0035\n",
      "Validation Loss: 0.0035, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [765/1000] - Training\n",
      "Epoch [765/1000] completed, Average Training Loss: 0.0064\n",
      "    Validation Batch [1/1], Loss: 0.0030\n",
      "Validation Loss: 0.0030, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [766/1000] - Training\n",
      "Epoch [766/1000] completed, Average Training Loss: 0.0072\n",
      "    Validation Batch [1/1], Loss: 0.0042\n",
      "Validation Loss: 0.0042, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [767/1000] - Training\n",
      "Epoch [767/1000] completed, Average Training Loss: 0.0053\n",
      "    Validation Batch [1/1], Loss: 0.0054\n",
      "Validation Loss: 0.0054, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [768/1000] - Training\n",
      "Epoch [768/1000] completed, Average Training Loss: 0.0088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0037\n",
      "Validation Loss: 0.0037, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [769/1000] - Training\n",
      "Epoch [769/1000] completed, Average Training Loss: 0.0096\n",
      "    Validation Batch [1/1], Loss: 0.0034\n",
      "Validation Loss: 0.0034, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [770/1000] - Training\n",
      "Epoch [770/1000] completed, Average Training Loss: 0.0062\n",
      "    Validation Batch [1/1], Loss: 0.0039\n",
      "Validation Loss: 0.0039, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [771/1000] - Training\n",
      "Epoch [771/1000] completed, Average Training Loss: 0.0063\n",
      "    Validation Batch [1/1], Loss: 0.0043\n",
      "Validation Loss: 0.0043, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [772/1000] - Training\n",
      "Epoch [772/1000] completed, Average Training Loss: 0.0061\n",
      "    Validation Batch [1/1], Loss: 0.0049\n",
      "Validation Loss: 0.0049, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [773/1000] - Training\n",
      "Epoch [773/1000] completed, Average Training Loss: 0.0058\n",
      "    Validation Batch [1/1], Loss: 0.0050\n",
      "Validation Loss: 0.0050, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [774/1000] - Training\n",
      "Epoch [774/1000] completed, Average Training Loss: 0.0083\n",
      "    Validation Batch [1/1], Loss: 0.0049\n",
      "Validation Loss: 0.0049, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [775/1000] - Training\n",
      "Epoch [775/1000] completed, Average Training Loss: 0.0072\n",
      "    Validation Batch [1/1], Loss: 0.0042\n",
      "Validation Loss: 0.0042, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [776/1000] - Training\n",
      "Epoch [776/1000] completed, Average Training Loss: 0.0052\n",
      "    Validation Batch [1/1], Loss: 0.0042\n",
      "Validation Loss: 0.0042, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [777/1000] - Training\n",
      "Epoch [777/1000] completed, Average Training Loss: 0.0072\n",
      "    Validation Batch [1/1], Loss: 0.0043\n",
      "Validation Loss: 0.0043, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [778/1000] - Training\n",
      "Epoch [778/1000] completed, Average Training Loss: 0.0080\n",
      "    Validation Batch [1/1], Loss: 0.0035\n",
      "Validation Loss: 0.0035, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [779/1000] - Training\n",
      "Epoch [779/1000] completed, Average Training Loss: 0.0049\n",
      "    Validation Batch [1/1], Loss: 0.0034\n",
      "Validation Loss: 0.0034, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [780/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [780/1000] completed, Average Training Loss: 0.0091\n",
      "    Validation Batch [1/1], Loss: 0.0034\n",
      "Validation Loss: 0.0034, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [781/1000] - Training\n",
      "Epoch [781/1000] completed, Average Training Loss: 0.0081\n",
      "    Validation Batch [1/1], Loss: 0.0036\n",
      "Validation Loss: 0.0036, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [782/1000] - Training\n",
      "Epoch [782/1000] completed, Average Training Loss: 0.0076\n",
      "    Validation Batch [1/1], Loss: 0.0029\n",
      "Validation Loss: 0.0029, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [783/1000] - Training\n",
      "Epoch [783/1000] completed, Average Training Loss: 0.0049\n",
      "    Validation Batch [1/1], Loss: 0.0030\n",
      "Validation Loss: 0.0030, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [784/1000] - Training\n",
      "Epoch [784/1000] completed, Average Training Loss: 0.0075\n",
      "    Validation Batch [1/1], Loss: 0.0036\n",
      "Validation Loss: 0.0036, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [785/1000] - Training\n",
      "Epoch [785/1000] completed, Average Training Loss: 0.0060\n",
      "    Validation Batch [1/1], Loss: 0.0049\n",
      "Validation Loss: 0.0049, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [786/1000] - Training\n",
      "Epoch [786/1000] completed, Average Training Loss: 0.0075\n",
      "    Validation Batch [1/1], Loss: 0.0071\n",
      "Validation Loss: 0.0071, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [787/1000] - Training\n",
      "Epoch [787/1000] completed, Average Training Loss: 0.0059\n",
      "    Validation Batch [1/1], Loss: 0.0094\n",
      "Validation Loss: 0.0094, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [788/1000] - Training\n",
      "Epoch [788/1000] completed, Average Training Loss: 0.0068\n",
      "    Validation Batch [1/1], Loss: 0.0067\n",
      "Validation Loss: 0.0067, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [789/1000] - Training\n",
      "Epoch [789/1000] completed, Average Training Loss: 0.0058\n",
      "    Validation Batch [1/1], Loss: 0.0035\n",
      "Validation Loss: 0.0035, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [790/1000] - Training\n",
      "Epoch [790/1000] completed, Average Training Loss: 0.0078\n",
      "    Validation Batch [1/1], Loss: 0.0022\n",
      "Validation Loss: 0.0022, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [791/1000] - Training\n",
      "Epoch [791/1000] completed, Average Training Loss: 0.0067\n",
      "    Validation Batch [1/1], Loss: 0.0057\n",
      "Validation Loss: 0.0057, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [792/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [792/1000] completed, Average Training Loss: 0.0058\n",
      "    Validation Batch [1/1], Loss: 0.0127\n",
      "Validation Loss: 0.0127, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [793/1000] - Training\n",
      "Epoch [793/1000] completed, Average Training Loss: 0.0081\n",
      "    Validation Batch [1/1], Loss: 0.0085\n",
      "Validation Loss: 0.0085, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [794/1000] - Training\n",
      "Epoch [794/1000] completed, Average Training Loss: 0.0062\n",
      "    Validation Batch [1/1], Loss: 0.0037\n",
      "Validation Loss: 0.0037, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [795/1000] - Training\n",
      "Epoch [795/1000] completed, Average Training Loss: 0.0056\n",
      "    Validation Batch [1/1], Loss: 0.0023\n",
      "Validation Loss: 0.0023, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [796/1000] - Training\n",
      "Epoch [796/1000] completed, Average Training Loss: 0.0067\n",
      "    Validation Batch [1/1], Loss: 0.0019\n",
      "Validation Loss: 0.0019, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0020 to 0.0019. Saving model...\n",
      "\n",
      "LOG: Epoch [797/1000] - Training\n",
      "Epoch [797/1000] completed, Average Training Loss: 0.0062\n",
      "    Validation Batch [1/1], Loss: 0.0027\n",
      "Validation Loss: 0.0027, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [798/1000] - Training\n",
      "Epoch [798/1000] completed, Average Training Loss: 0.0055\n",
      "    Validation Batch [1/1], Loss: 0.0048\n",
      "Validation Loss: 0.0048, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [799/1000] - Training\n",
      "Epoch [799/1000] completed, Average Training Loss: 0.0097\n",
      "    Validation Batch [1/1], Loss: 0.0211\n",
      "Validation Loss: 0.0211, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [800/1000] - Training\n",
      "Epoch [800/1000] completed, Average Training Loss: 0.0069\n",
      "    Validation Batch [1/1], Loss: 0.0527\n",
      "Validation Loss: 0.0527, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [801/1000] - Training\n",
      "Epoch [801/1000] completed, Average Training Loss: 0.0063\n",
      "    Validation Batch [1/1], Loss: 0.0655\n",
      "Validation Loss: 0.0655, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [802/1000] - Training\n",
      "Epoch [802/1000] completed, Average Training Loss: 0.0071\n",
      "    Validation Batch [1/1], Loss: 0.0125\n",
      "Validation Loss: 0.0125, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [803/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [803/1000] completed, Average Training Loss: 0.0063\n",
      "    Validation Batch [1/1], Loss: 0.0035\n",
      "Validation Loss: 0.0035, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [804/1000] - Training\n",
      "Epoch [804/1000] completed, Average Training Loss: 0.0060\n",
      "    Validation Batch [1/1], Loss: 0.0035\n",
      "Validation Loss: 0.0035, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [805/1000] - Training\n",
      "Epoch [805/1000] completed, Average Training Loss: 0.0061\n",
      "    Validation Batch [1/1], Loss: 0.0031\n",
      "Validation Loss: 0.0031, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [806/1000] - Training\n",
      "Epoch [806/1000] completed, Average Training Loss: 0.0064\n",
      "    Validation Batch [1/1], Loss: 0.0047\n",
      "Validation Loss: 0.0047, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [807/1000] - Training\n",
      "Epoch [807/1000] completed, Average Training Loss: 0.0063\n",
      "    Validation Batch [1/1], Loss: 0.0091\n",
      "Validation Loss: 0.0091, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [808/1000] - Training\n",
      "Epoch [808/1000] completed, Average Training Loss: 0.0067\n",
      "    Validation Batch [1/1], Loss: 0.0094\n",
      "Validation Loss: 0.0094, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [809/1000] - Training\n",
      "Epoch [809/1000] completed, Average Training Loss: 0.0073\n",
      "    Validation Batch [1/1], Loss: 0.0028\n",
      "Validation Loss: 0.0028, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [810/1000] - Training\n",
      "Epoch [810/1000] completed, Average Training Loss: 0.0076\n",
      "    Validation Batch [1/1], Loss: 0.0031\n",
      "Validation Loss: 0.0031, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [811/1000] - Training\n",
      "Epoch [811/1000] completed, Average Training Loss: 0.0065\n",
      "    Validation Batch [1/1], Loss: 0.0206\n",
      "Validation Loss: 0.0206, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [812/1000] - Training\n",
      "Epoch [812/1000] completed, Average Training Loss: 0.0054\n",
      "    Validation Batch [1/1], Loss: 0.1153\n",
      "Validation Loss: 0.1153, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [813/1000] - Training\n",
      "Epoch [813/1000] completed, Average Training Loss: 0.0074\n",
      "    Validation Batch [1/1], Loss: 0.0930\n",
      "Validation Loss: 0.0930, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [814/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [814/1000] completed, Average Training Loss: 0.0074\n",
      "    Validation Batch [1/1], Loss: 0.0054\n",
      "Validation Loss: 0.0054, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [815/1000] - Training\n",
      "Epoch [815/1000] completed, Average Training Loss: 0.0074\n",
      "    Validation Batch [1/1], Loss: 0.0028\n",
      "Validation Loss: 0.0028, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [816/1000] - Training\n",
      "Epoch [816/1000] completed, Average Training Loss: 0.0065\n",
      "    Validation Batch [1/1], Loss: 0.0035\n",
      "Validation Loss: 0.0035, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [817/1000] - Training\n",
      "Epoch [817/1000] completed, Average Training Loss: 0.0059\n",
      "    Validation Batch [1/1], Loss: 0.0039\n",
      "Validation Loss: 0.0039, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [818/1000] - Training\n",
      "Epoch [818/1000] completed, Average Training Loss: 0.0073\n",
      "    Validation Batch [1/1], Loss: 0.0027\n",
      "Validation Loss: 0.0027, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [819/1000] - Training\n",
      "Epoch [819/1000] completed, Average Training Loss: 0.0058\n",
      "    Validation Batch [1/1], Loss: 0.0018\n",
      "Validation Loss: 0.0018, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0019 to 0.0018. Saving model...\n",
      "\n",
      "LOG: Epoch [820/1000] - Training\n",
      "Epoch [820/1000] completed, Average Training Loss: 0.0067\n",
      "    Validation Batch [1/1], Loss: 0.0016\n",
      "Validation Loss: 0.0016, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0018 to 0.0016. Saving model...\n",
      "\n",
      "LOG: Epoch [821/1000] - Training\n",
      "Epoch [821/1000] completed, Average Training Loss: 0.0054\n",
      "    Validation Batch [1/1], Loss: 0.0016\n",
      "Validation Loss: 0.0016, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0016 to 0.0016. Saving model...\n",
      "\n",
      "LOG: Epoch [822/1000] - Training\n",
      "Epoch [822/1000] completed, Average Training Loss: 0.0053\n",
      "    Validation Batch [1/1], Loss: 0.0020\n",
      "Validation Loss: 0.0020, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [823/1000] - Training\n",
      "Epoch [823/1000] completed, Average Training Loss: 0.0052\n",
      "    Validation Batch [1/1], Loss: 0.0029\n",
      "Validation Loss: 0.0029, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [824/1000] - Training\n",
      "Epoch [824/1000] completed, Average Training Loss: 0.0062\n",
      "    Validation Batch [1/1], Loss: 0.0043\n",
      "Validation Loss: 0.0043, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [825/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [825/1000] completed, Average Training Loss: 0.0053\n",
      "    Validation Batch [1/1], Loss: 0.0030\n",
      "Validation Loss: 0.0030, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [826/1000] - Training\n",
      "Epoch [826/1000] completed, Average Training Loss: 0.0066\n",
      "    Validation Batch [1/1], Loss: 0.0020\n",
      "Validation Loss: 0.0020, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [827/1000] - Training\n",
      "Epoch [827/1000] completed, Average Training Loss: 0.0063\n",
      "    Validation Batch [1/1], Loss: 0.0017\n",
      "Validation Loss: 0.0017, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [828/1000] - Training\n",
      "Epoch [828/1000] completed, Average Training Loss: 0.0064\n",
      "    Validation Batch [1/1], Loss: 0.0015\n",
      "Validation Loss: 0.0015, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0016 to 0.0015. Saving model...\n",
      "\n",
      "LOG: Epoch [829/1000] - Training\n",
      "Epoch [829/1000] completed, Average Training Loss: 0.0045\n",
      "    Validation Batch [1/1], Loss: 0.0015\n",
      "Validation Loss: 0.0015, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [830/1000] - Training\n",
      "Epoch [830/1000] completed, Average Training Loss: 0.0059\n",
      "    Validation Batch [1/1], Loss: 0.0019\n",
      "Validation Loss: 0.0019, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [831/1000] - Training\n",
      "Epoch [831/1000] completed, Average Training Loss: 0.0053\n",
      "    Validation Batch [1/1], Loss: 0.0017\n",
      "Validation Loss: 0.0017, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [832/1000] - Training\n",
      "Epoch [832/1000] completed, Average Training Loss: 0.0074\n",
      "    Validation Batch [1/1], Loss: 0.0015\n",
      "Validation Loss: 0.0015, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [833/1000] - Training\n",
      "Epoch [833/1000] completed, Average Training Loss: 0.0051\n",
      "    Validation Batch [1/1], Loss: 0.0021\n",
      "Validation Loss: 0.0021, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [834/1000] - Training\n",
      "Epoch [834/1000] completed, Average Training Loss: 0.0047\n",
      "    Validation Batch [1/1], Loss: 0.0032\n",
      "Validation Loss: 0.0032, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [835/1000] - Training\n",
      "Epoch [835/1000] completed, Average Training Loss: 0.0051\n",
      "    Validation Batch [1/1], Loss: 0.0024\n",
      "Validation Loss: 0.0024, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [836/1000] - Training\n",
      "Epoch [836/1000] completed, Average Training Loss: 0.0053\n",
      "    Validation Batch [1/1], Loss: 0.0024\n",
      "Validation Loss: 0.0024, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [837/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [837/1000] completed, Average Training Loss: 0.0064\n",
      "    Validation Batch [1/1], Loss: 0.0032\n",
      "Validation Loss: 0.0032, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [838/1000] - Training\n",
      "Epoch [838/1000] completed, Average Training Loss: 0.0056\n",
      "    Validation Batch [1/1], Loss: 0.0042\n",
      "Validation Loss: 0.0042, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [839/1000] - Training\n",
      "Epoch [839/1000] completed, Average Training Loss: 0.0045\n",
      "    Validation Batch [1/1], Loss: 0.0055\n",
      "Validation Loss: 0.0055, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [840/1000] - Training\n",
      "Epoch [840/1000] completed, Average Training Loss: 0.0057\n",
      "    Validation Batch [1/1], Loss: 0.0055\n",
      "Validation Loss: 0.0055, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [841/1000] - Training\n",
      "Epoch [841/1000] completed, Average Training Loss: 0.0060\n",
      "    Validation Batch [1/1], Loss: 0.0047\n",
      "Validation Loss: 0.0047, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [842/1000] - Training\n",
      "Epoch [842/1000] completed, Average Training Loss: 0.0051\n",
      "    Validation Batch [1/1], Loss: 0.0047\n",
      "Validation Loss: 0.0047, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [843/1000] - Training\n",
      "Epoch [843/1000] completed, Average Training Loss: 0.0062\n",
      "    Validation Batch [1/1], Loss: 0.0056\n",
      "Validation Loss: 0.0056, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [844/1000] - Training\n",
      "Epoch [844/1000] completed, Average Training Loss: 0.0052\n",
      "    Validation Batch [1/1], Loss: 0.0063\n",
      "Validation Loss: 0.0063, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [845/1000] - Training\n",
      "Epoch [845/1000] completed, Average Training Loss: 0.0040\n",
      "    Validation Batch [1/1], Loss: 0.0042\n",
      "Validation Loss: 0.0042, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [846/1000] - Training\n",
      "Epoch [846/1000] completed, Average Training Loss: 0.0047\n",
      "    Validation Batch [1/1], Loss: 0.0029\n",
      "Validation Loss: 0.0029, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [847/1000] - Training\n",
      "Epoch [847/1000] completed, Average Training Loss: 0.0043\n",
      "    Validation Batch [1/1], Loss: 0.0022\n",
      "Validation Loss: 0.0022, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [848/1000] - Training\n",
      "Epoch [848/1000] completed, Average Training Loss: 0.0052\n",
      "    Validation Batch [1/1], Loss: 0.0020\n",
      "Validation Loss: 0.0020, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [849/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [849/1000] completed, Average Training Loss: 0.0054\n",
      "    Validation Batch [1/1], Loss: 0.0019\n",
      "Validation Loss: 0.0019, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [850/1000] - Training\n",
      "Epoch [850/1000] completed, Average Training Loss: 0.0064\n",
      "    Validation Batch [1/1], Loss: 0.0026\n",
      "Validation Loss: 0.0026, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [851/1000] - Training\n",
      "Epoch [851/1000] completed, Average Training Loss: 0.0060\n",
      "    Validation Batch [1/1], Loss: 0.0040\n",
      "Validation Loss: 0.0040, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [852/1000] - Training\n",
      "Epoch [852/1000] completed, Average Training Loss: 0.0048\n",
      "    Validation Batch [1/1], Loss: 0.0047\n",
      "Validation Loss: 0.0047, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [853/1000] - Training\n",
      "Epoch [853/1000] completed, Average Training Loss: 0.0055\n",
      "    Validation Batch [1/1], Loss: 0.0052\n",
      "Validation Loss: 0.0052, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [854/1000] - Training\n",
      "Epoch [854/1000] completed, Average Training Loss: 0.0079\n",
      "    Validation Batch [1/1], Loss: 0.0075\n",
      "Validation Loss: 0.0075, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [855/1000] - Training\n",
      "Epoch [855/1000] completed, Average Training Loss: 0.0065\n",
      "    Validation Batch [1/1], Loss: 0.0092\n",
      "Validation Loss: 0.0092, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [856/1000] - Training\n",
      "Epoch [856/1000] completed, Average Training Loss: 0.0065\n",
      "    Validation Batch [1/1], Loss: 0.0051\n",
      "Validation Loss: 0.0051, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [857/1000] - Training\n",
      "Epoch [857/1000] completed, Average Training Loss: 0.0057\n",
      "    Validation Batch [1/1], Loss: 0.0019\n",
      "Validation Loss: 0.0019, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [858/1000] - Training\n",
      "Epoch [858/1000] completed, Average Training Loss: 0.0048\n",
      "    Validation Batch [1/1], Loss: 0.0015\n",
      "Validation Loss: 0.0015, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [859/1000] - Training\n",
      "Epoch [859/1000] completed, Average Training Loss: 0.0055\n",
      "    Validation Batch [1/1], Loss: 0.0026\n",
      "Validation Loss: 0.0026, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [860/1000] - Training\n",
      "Epoch [860/1000] completed, Average Training Loss: 0.0056\n",
      "    Validation Batch [1/1], Loss: 0.0041\n",
      "Validation Loss: 0.0041, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [861/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [861/1000] completed, Average Training Loss: 0.0055\n",
      "    Validation Batch [1/1], Loss: 0.0016\n",
      "Validation Loss: 0.0016, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [862/1000] - Training\n",
      "Epoch [862/1000] completed, Average Training Loss: 0.0055\n",
      "    Validation Batch [1/1], Loss: 0.0010\n",
      "Validation Loss: 0.0010, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0015 to 0.0010. Saving model...\n",
      "\n",
      "LOG: Epoch [863/1000] - Training\n",
      "Epoch [863/1000] completed, Average Training Loss: 0.0064\n",
      "    Validation Batch [1/1], Loss: 0.0010\n",
      "Validation Loss: 0.0010, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0010 to 0.0010. Saving model...\n",
      "\n",
      "LOG: Epoch [864/1000] - Training\n",
      "Epoch [864/1000] completed, Average Training Loss: 0.0061\n",
      "    Validation Batch [1/1], Loss: 0.0015\n",
      "Validation Loss: 0.0015, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [865/1000] - Training\n",
      "Epoch [865/1000] completed, Average Training Loss: 0.0042\n",
      "    Validation Batch [1/1], Loss: 0.0019\n",
      "Validation Loss: 0.0019, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [866/1000] - Training\n",
      "Epoch [866/1000] completed, Average Training Loss: 0.0041\n",
      "    Validation Batch [1/1], Loss: 0.0019\n",
      "Validation Loss: 0.0019, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [867/1000] - Training\n",
      "Epoch [867/1000] completed, Average Training Loss: 0.0066\n",
      "    Validation Batch [1/1], Loss: 0.0018\n",
      "Validation Loss: 0.0018, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [868/1000] - Training\n",
      "Epoch [868/1000] completed, Average Training Loss: 0.0040\n",
      "    Validation Batch [1/1], Loss: 0.0025\n",
      "Validation Loss: 0.0025, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [869/1000] - Training\n",
      "Epoch [869/1000] completed, Average Training Loss: 0.0054\n",
      "    Validation Batch [1/1], Loss: 0.0021\n",
      "Validation Loss: 0.0021, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [870/1000] - Training\n",
      "Epoch [870/1000] completed, Average Training Loss: 0.0057\n",
      "    Validation Batch [1/1], Loss: 0.0033\n",
      "Validation Loss: 0.0033, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [871/1000] - Training\n",
      "Epoch [871/1000] completed, Average Training Loss: 0.0046\n",
      "    Validation Batch [1/1], Loss: 0.0049\n",
      "Validation Loss: 0.0049, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [872/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [872/1000] completed, Average Training Loss: 0.0057\n",
      "    Validation Batch [1/1], Loss: 0.0061\n",
      "Validation Loss: 0.0061, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [873/1000] - Training\n",
      "Epoch [873/1000] completed, Average Training Loss: 0.0046\n",
      "    Validation Batch [1/1], Loss: 0.0075\n",
      "Validation Loss: 0.0075, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [874/1000] - Training\n",
      "Epoch [874/1000] completed, Average Training Loss: 0.0050\n",
      "    Validation Batch [1/1], Loss: 0.0035\n",
      "Validation Loss: 0.0035, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [875/1000] - Training\n",
      "Epoch [875/1000] completed, Average Training Loss: 0.0059\n",
      "    Validation Batch [1/1], Loss: 0.0033\n",
      "Validation Loss: 0.0033, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [876/1000] - Training\n",
      "Epoch [876/1000] completed, Average Training Loss: 0.0047\n",
      "    Validation Batch [1/1], Loss: 0.0041\n",
      "Validation Loss: 0.0041, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [877/1000] - Training\n",
      "Epoch [877/1000] completed, Average Training Loss: 0.0051\n",
      "    Validation Batch [1/1], Loss: 0.0053\n",
      "Validation Loss: 0.0053, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [878/1000] - Training\n",
      "Epoch [878/1000] completed, Average Training Loss: 0.0055\n",
      "    Validation Batch [1/1], Loss: 0.0041\n",
      "Validation Loss: 0.0041, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [879/1000] - Training\n",
      "Epoch [879/1000] completed, Average Training Loss: 0.0074\n",
      "    Validation Batch [1/1], Loss: 0.0027\n",
      "Validation Loss: 0.0027, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [880/1000] - Training\n",
      "Epoch [880/1000] completed, Average Training Loss: 0.0042\n",
      "    Validation Batch [1/1], Loss: 0.0019\n",
      "Validation Loss: 0.0019, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [881/1000] - Training\n",
      "Epoch [881/1000] completed, Average Training Loss: 0.0040\n",
      "    Validation Batch [1/1], Loss: 0.0016\n",
      "Validation Loss: 0.0016, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [882/1000] - Training\n",
      "Epoch [882/1000] completed, Average Training Loss: 0.0040\n",
      "    Validation Batch [1/1], Loss: 0.0017\n",
      "Validation Loss: 0.0017, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [883/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [883/1000] completed, Average Training Loss: 0.0049\n",
      "    Validation Batch [1/1], Loss: 0.0017\n",
      "Validation Loss: 0.0017, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [884/1000] - Training\n",
      "Epoch [884/1000] completed, Average Training Loss: 0.0049\n",
      "    Validation Batch [1/1], Loss: 0.0017\n",
      "Validation Loss: 0.0017, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [885/1000] - Training\n",
      "Epoch [885/1000] completed, Average Training Loss: 0.0056\n",
      "    Validation Batch [1/1], Loss: 0.0023\n",
      "Validation Loss: 0.0023, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [886/1000] - Training\n",
      "Epoch [886/1000] completed, Average Training Loss: 0.0041\n",
      "    Validation Batch [1/1], Loss: 0.0026\n",
      "Validation Loss: 0.0026, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [887/1000] - Training\n",
      "Epoch [887/1000] completed, Average Training Loss: 0.0044\n",
      "    Validation Batch [1/1], Loss: 0.0040\n",
      "Validation Loss: 0.0040, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [888/1000] - Training\n",
      "Epoch [888/1000] completed, Average Training Loss: 0.0071\n",
      "    Validation Batch [1/1], Loss: 0.0056\n",
      "Validation Loss: 0.0056, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [889/1000] - Training\n",
      "Epoch [889/1000] completed, Average Training Loss: 0.0058\n",
      "    Validation Batch [1/1], Loss: 0.0015\n",
      "Validation Loss: 0.0015, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [890/1000] - Training\n",
      "Epoch [890/1000] completed, Average Training Loss: 0.0060\n",
      "    Validation Batch [1/1], Loss: 0.0012\n",
      "Validation Loss: 0.0012, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [891/1000] - Training\n",
      "Epoch [891/1000] completed, Average Training Loss: 0.0050\n",
      "    Validation Batch [1/1], Loss: 0.0017\n",
      "Validation Loss: 0.0017, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [892/1000] - Training\n",
      "Epoch [892/1000] completed, Average Training Loss: 0.0050\n",
      "    Validation Batch [1/1], Loss: 0.0020\n",
      "Validation Loss: 0.0020, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [893/1000] - Training\n",
      "Epoch [893/1000] completed, Average Training Loss: 0.0051\n",
      "    Validation Batch [1/1], Loss: 0.0016\n",
      "Validation Loss: 0.0016, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [894/1000] - Training\n",
      "Epoch [894/1000] completed, Average Training Loss: 0.0045\n",
      "    Validation Batch [1/1], Loss: 0.0013\n",
      "Validation Loss: 0.0013, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [895/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [895/1000] completed, Average Training Loss: 0.0048\n",
      "    Validation Batch [1/1], Loss: 0.0013\n",
      "Validation Loss: 0.0013, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [896/1000] - Training\n",
      "Epoch [896/1000] completed, Average Training Loss: 0.0054\n",
      "    Validation Batch [1/1], Loss: 0.0015\n",
      "Validation Loss: 0.0015, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [897/1000] - Training\n",
      "Epoch [897/1000] completed, Average Training Loss: 0.0048\n",
      "    Validation Batch [1/1], Loss: 0.0021\n",
      "Validation Loss: 0.0021, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [898/1000] - Training\n",
      "Epoch [898/1000] completed, Average Training Loss: 0.0049\n",
      "    Validation Batch [1/1], Loss: 0.0030\n",
      "Validation Loss: 0.0030, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [899/1000] - Training\n",
      "Epoch [899/1000] completed, Average Training Loss: 0.0039\n",
      "    Validation Batch [1/1], Loss: 0.0054\n",
      "Validation Loss: 0.0054, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [900/1000] - Training\n",
      "Epoch [900/1000] completed, Average Training Loss: 0.0045\n",
      "    Validation Batch [1/1], Loss: 0.0057\n",
      "Validation Loss: 0.0057, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [901/1000] - Training\n",
      "Epoch [901/1000] completed, Average Training Loss: 0.0049\n",
      "    Validation Batch [1/1], Loss: 0.0034\n",
      "Validation Loss: 0.0034, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [902/1000] - Training\n",
      "Epoch [902/1000] completed, Average Training Loss: 0.0051\n",
      "    Validation Batch [1/1], Loss: 0.0026\n",
      "Validation Loss: 0.0026, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [903/1000] - Training\n",
      "Epoch [903/1000] completed, Average Training Loss: 0.0050\n",
      "    Validation Batch [1/1], Loss: 0.0025\n",
      "Validation Loss: 0.0025, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [904/1000] - Training\n",
      "Epoch [904/1000] completed, Average Training Loss: 0.0048\n",
      "    Validation Batch [1/1], Loss: 0.0029\n",
      "Validation Loss: 0.0029, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [905/1000] - Training\n",
      "Epoch [905/1000] completed, Average Training Loss: 0.0055\n",
      "    Validation Batch [1/1], Loss: 0.0044\n",
      "Validation Loss: 0.0044, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [906/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [906/1000] completed, Average Training Loss: 0.0059\n",
      "    Validation Batch [1/1], Loss: 0.0027\n",
      "Validation Loss: 0.0027, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [907/1000] - Training\n",
      "Epoch [907/1000] completed, Average Training Loss: 0.0041\n",
      "    Validation Batch [1/1], Loss: 0.0021\n",
      "Validation Loss: 0.0021, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [908/1000] - Training\n",
      "Epoch [908/1000] completed, Average Training Loss: 0.0065\n",
      "    Validation Batch [1/1], Loss: 0.0019\n",
      "Validation Loss: 0.0019, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [909/1000] - Training\n",
      "Epoch [909/1000] completed, Average Training Loss: 0.0061\n",
      "    Validation Batch [1/1], Loss: 0.0018\n",
      "Validation Loss: 0.0018, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [910/1000] - Training\n",
      "Epoch [910/1000] completed, Average Training Loss: 0.0037\n",
      "    Validation Batch [1/1], Loss: 0.0023\n",
      "Validation Loss: 0.0023, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [911/1000] - Training\n",
      "Epoch [911/1000] completed, Average Training Loss: 0.0044\n",
      "    Validation Batch [1/1], Loss: 0.0030\n",
      "Validation Loss: 0.0030, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [912/1000] - Training\n",
      "Epoch [912/1000] completed, Average Training Loss: 0.0049\n",
      "    Validation Batch [1/1], Loss: 0.0020\n",
      "Validation Loss: 0.0020, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [913/1000] - Training\n",
      "Epoch [913/1000] completed, Average Training Loss: 0.0052\n",
      "    Validation Batch [1/1], Loss: 0.0014\n",
      "Validation Loss: 0.0014, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [914/1000] - Training\n",
      "Epoch [914/1000] completed, Average Training Loss: 0.0036\n",
      "    Validation Batch [1/1], Loss: 0.0012\n",
      "Validation Loss: 0.0012, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [915/1000] - Training\n",
      "Epoch [915/1000] completed, Average Training Loss: 0.0032\n",
      "    Validation Batch [1/1], Loss: 0.0012\n",
      "Validation Loss: 0.0012, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [916/1000] - Training\n",
      "Epoch [916/1000] completed, Average Training Loss: 0.0053\n",
      "    Validation Batch [1/1], Loss: 0.0013\n",
      "Validation Loss: 0.0013, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [917/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [917/1000] completed, Average Training Loss: 0.0039\n",
      "    Validation Batch [1/1], Loss: 0.0013\n",
      "Validation Loss: 0.0013, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [918/1000] - Training\n",
      "Epoch [918/1000] completed, Average Training Loss: 0.0038\n",
      "    Validation Batch [1/1], Loss: 0.0010\n",
      "Validation Loss: 0.0010, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [919/1000] - Training\n",
      "Epoch [919/1000] completed, Average Training Loss: 0.0042\n",
      "    Validation Batch [1/1], Loss: 0.0010\n",
      "Validation Loss: 0.0010, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0010 to 0.0010. Saving model...\n",
      "\n",
      "LOG: Epoch [920/1000] - Training\n",
      "Epoch [920/1000] completed, Average Training Loss: 0.0051\n",
      "    Validation Batch [1/1], Loss: 0.0017\n",
      "Validation Loss: 0.0017, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [921/1000] - Training\n",
      "Epoch [921/1000] completed, Average Training Loss: 0.0042\n",
      "    Validation Batch [1/1], Loss: 0.0017\n",
      "Validation Loss: 0.0017, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [922/1000] - Training\n",
      "Epoch [922/1000] completed, Average Training Loss: 0.0037\n",
      "    Validation Batch [1/1], Loss: 0.0013\n",
      "Validation Loss: 0.0013, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [923/1000] - Training\n",
      "Epoch [923/1000] completed, Average Training Loss: 0.0034\n",
      "    Validation Batch [1/1], Loss: 0.0011\n",
      "Validation Loss: 0.0011, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [924/1000] - Training\n",
      "Epoch [924/1000] completed, Average Training Loss: 0.0042\n",
      "    Validation Batch [1/1], Loss: 0.0013\n",
      "Validation Loss: 0.0013, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [925/1000] - Training\n",
      "Epoch [925/1000] completed, Average Training Loss: 0.0057\n",
      "    Validation Batch [1/1], Loss: 0.0020\n",
      "Validation Loss: 0.0020, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [926/1000] - Training\n",
      "Epoch [926/1000] completed, Average Training Loss: 0.0043\n",
      "    Validation Batch [1/1], Loss: 0.0039\n",
      "Validation Loss: 0.0039, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [927/1000] - Training\n",
      "Epoch [927/1000] completed, Average Training Loss: 0.0035\n",
      "    Validation Batch [1/1], Loss: 0.0063\n",
      "Validation Loss: 0.0063, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [928/1000] - Training\n",
      "Epoch [928/1000] completed, Average Training Loss: 0.0041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0051\n",
      "Validation Loss: 0.0051, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [929/1000] - Training\n",
      "Epoch [929/1000] completed, Average Training Loss: 0.0050\n",
      "    Validation Batch [1/1], Loss: 0.0037\n",
      "Validation Loss: 0.0037, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [930/1000] - Training\n",
      "Epoch [930/1000] completed, Average Training Loss: 0.0048\n",
      "    Validation Batch [1/1], Loss: 0.0048\n",
      "Validation Loss: 0.0048, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [931/1000] - Training\n",
      "Epoch [931/1000] completed, Average Training Loss: 0.0043\n",
      "    Validation Batch [1/1], Loss: 0.0054\n",
      "Validation Loss: 0.0054, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [932/1000] - Training\n",
      "Epoch [932/1000] completed, Average Training Loss: 0.0039\n",
      "    Validation Batch [1/1], Loss: 0.0043\n",
      "Validation Loss: 0.0043, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [933/1000] - Training\n",
      "Epoch [933/1000] completed, Average Training Loss: 0.0042\n",
      "    Validation Batch [1/1], Loss: 0.0028\n",
      "Validation Loss: 0.0028, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [934/1000] - Training\n",
      "Epoch [934/1000] completed, Average Training Loss: 0.0042\n",
      "    Validation Batch [1/1], Loss: 0.0021\n",
      "Validation Loss: 0.0021, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [935/1000] - Training\n",
      "Epoch [935/1000] completed, Average Training Loss: 0.0038\n",
      "    Validation Batch [1/1], Loss: 0.0024\n",
      "Validation Loss: 0.0024, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [936/1000] - Training\n",
      "Epoch [936/1000] completed, Average Training Loss: 0.0072\n",
      "    Validation Batch [1/1], Loss: 0.0027\n",
      "Validation Loss: 0.0027, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [937/1000] - Training\n",
      "Epoch [937/1000] completed, Average Training Loss: 0.0033\n",
      "    Validation Batch [1/1], Loss: 0.0025\n",
      "Validation Loss: 0.0025, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [938/1000] - Training\n",
      "Epoch [938/1000] completed, Average Training Loss: 0.0039\n",
      "    Validation Batch [1/1], Loss: 0.0015\n",
      "Validation Loss: 0.0015, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [939/1000] - Training\n",
      "Epoch [939/1000] completed, Average Training Loss: 0.0060\n",
      "    Validation Batch [1/1], Loss: 0.0010\n",
      "Validation Loss: 0.0010, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [940/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [940/1000] completed, Average Training Loss: 0.0047\n",
      "    Validation Batch [1/1], Loss: 0.0010\n",
      "Validation Loss: 0.0010, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [941/1000] - Training\n",
      "Epoch [941/1000] completed, Average Training Loss: 0.0053\n",
      "    Validation Batch [1/1], Loss: 0.0013\n",
      "Validation Loss: 0.0013, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [942/1000] - Training\n",
      "Epoch [942/1000] completed, Average Training Loss: 0.0050\n",
      "    Validation Batch [1/1], Loss: 0.0019\n",
      "Validation Loss: 0.0019, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [943/1000] - Training\n",
      "Epoch [943/1000] completed, Average Training Loss: 0.0041\n",
      "    Validation Batch [1/1], Loss: 0.0022\n",
      "Validation Loss: 0.0022, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [944/1000] - Training\n",
      "Epoch [944/1000] completed, Average Training Loss: 0.0048\n",
      "    Validation Batch [1/1], Loss: 0.0026\n",
      "Validation Loss: 0.0026, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [945/1000] - Training\n",
      "Epoch [945/1000] completed, Average Training Loss: 0.0061\n",
      "    Validation Batch [1/1], Loss: 0.0027\n",
      "Validation Loss: 0.0027, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [946/1000] - Training\n",
      "Epoch [946/1000] completed, Average Training Loss: 0.0035\n",
      "    Validation Batch [1/1], Loss: 0.0025\n",
      "Validation Loss: 0.0025, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [947/1000] - Training\n",
      "Epoch [947/1000] completed, Average Training Loss: 0.0048\n",
      "    Validation Batch [1/1], Loss: 0.0023\n",
      "Validation Loss: 0.0023, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [948/1000] - Training\n",
      "Epoch [948/1000] completed, Average Training Loss: 0.0046\n",
      "    Validation Batch [1/1], Loss: 0.0036\n",
      "Validation Loss: 0.0036, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [949/1000] - Training\n",
      "Epoch [949/1000] completed, Average Training Loss: 0.0035\n",
      "    Validation Batch [1/1], Loss: 0.0084\n",
      "Validation Loss: 0.0084, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [950/1000] - Training\n",
      "Epoch [950/1000] completed, Average Training Loss: 0.0037\n",
      "    Validation Batch [1/1], Loss: 0.0098\n",
      "Validation Loss: 0.0098, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [951/1000] - Training\n",
      "Epoch [951/1000] completed, Average Training Loss: 0.0038\n",
      "    Validation Batch [1/1], Loss: 0.0051\n",
      "Validation Loss: 0.0051, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [952/1000] - Training\n",
      "Epoch [952/1000] completed, Average Training Loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0015\n",
      "Validation Loss: 0.0015, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [953/1000] - Training\n",
      "Epoch [953/1000] completed, Average Training Loss: 0.0048\n",
      "    Validation Batch [1/1], Loss: 0.0009\n",
      "Validation Loss: 0.0009, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0010 to 0.0009. Saving model...\n",
      "\n",
      "LOG: Epoch [954/1000] - Training\n",
      "Epoch [954/1000] completed, Average Training Loss: 0.0055\n",
      "    Validation Batch [1/1], Loss: 0.0008\n",
      "Validation Loss: 0.0008, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0009 to 0.0008. Saving model...\n",
      "\n",
      "LOG: Epoch [955/1000] - Training\n",
      "Epoch [955/1000] completed, Average Training Loss: 0.0035\n",
      "    Validation Batch [1/1], Loss: 0.0016\n",
      "Validation Loss: 0.0016, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [956/1000] - Training\n",
      "Epoch [956/1000] completed, Average Training Loss: 0.0043\n",
      "    Validation Batch [1/1], Loss: 0.0032\n",
      "Validation Loss: 0.0032, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [957/1000] - Training\n",
      "Epoch [957/1000] completed, Average Training Loss: 0.0046\n",
      "    Validation Batch [1/1], Loss: 0.0037\n",
      "Validation Loss: 0.0037, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [958/1000] - Training\n",
      "Epoch [958/1000] completed, Average Training Loss: 0.0036\n",
      "    Validation Batch [1/1], Loss: 0.0028\n",
      "Validation Loss: 0.0028, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [959/1000] - Training\n",
      "Epoch [959/1000] completed, Average Training Loss: 0.0034\n",
      "    Validation Batch [1/1], Loss: 0.0020\n",
      "Validation Loss: 0.0020, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [960/1000] - Training\n",
      "Epoch [960/1000] completed, Average Training Loss: 0.0037\n",
      "    Validation Batch [1/1], Loss: 0.0018\n",
      "Validation Loss: 0.0018, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [961/1000] - Training\n",
      "Epoch [961/1000] completed, Average Training Loss: 0.0080\n",
      "    Validation Batch [1/1], Loss: 0.0015\n",
      "Validation Loss: 0.0015, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [962/1000] - Training\n",
      "Epoch [962/1000] completed, Average Training Loss: 0.0033\n",
      "    Validation Batch [1/1], Loss: 0.0018\n",
      "Validation Loss: 0.0018, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [963/1000] - Training\n",
      "Epoch [963/1000] completed, Average Training Loss: 0.0044\n",
      "    Validation Batch [1/1], Loss: 0.0022\n",
      "Validation Loss: 0.0022, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [964/1000] - Training\n",
      "Epoch [964/1000] completed, Average Training Loss: 0.0042\n",
      "    Validation Batch [1/1], Loss: 0.0023\n",
      "Validation Loss: 0.0023, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [965/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [965/1000] completed, Average Training Loss: 0.0060\n",
      "    Validation Batch [1/1], Loss: 0.0016\n",
      "Validation Loss: 0.0016, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [966/1000] - Training\n",
      "Epoch [966/1000] completed, Average Training Loss: 0.0054\n",
      "    Validation Batch [1/1], Loss: 0.0011\n",
      "Validation Loss: 0.0011, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [967/1000] - Training\n",
      "Epoch [967/1000] completed, Average Training Loss: 0.0048\n",
      "    Validation Batch [1/1], Loss: 0.0019\n",
      "Validation Loss: 0.0019, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [968/1000] - Training\n",
      "Epoch [968/1000] completed, Average Training Loss: 0.0034\n",
      "    Validation Batch [1/1], Loss: 0.0049\n",
      "Validation Loss: 0.0049, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [969/1000] - Training\n",
      "Epoch [969/1000] completed, Average Training Loss: 0.0035\n",
      "    Validation Batch [1/1], Loss: 0.0119\n",
      "Validation Loss: 0.0119, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [970/1000] - Training\n",
      "Epoch [970/1000] completed, Average Training Loss: 0.0039\n",
      "    Validation Batch [1/1], Loss: 0.0137\n",
      "Validation Loss: 0.0137, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [971/1000] - Training\n",
      "Epoch [971/1000] completed, Average Training Loss: 0.0052\n",
      "    Validation Batch [1/1], Loss: 0.0032\n",
      "Validation Loss: 0.0032, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [972/1000] - Training\n",
      "Epoch [972/1000] completed, Average Training Loss: 0.0061\n",
      "    Validation Batch [1/1], Loss: 0.0016\n",
      "Validation Loss: 0.0016, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [973/1000] - Training\n",
      "Epoch [973/1000] completed, Average Training Loss: 0.0055\n",
      "    Validation Batch [1/1], Loss: 0.0013\n",
      "Validation Loss: 0.0013, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [974/1000] - Training\n",
      "Epoch [974/1000] completed, Average Training Loss: 0.0048\n",
      "    Validation Batch [1/1], Loss: 0.0016\n",
      "Validation Loss: 0.0016, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [975/1000] - Training\n",
      "Epoch [975/1000] completed, Average Training Loss: 0.0040\n",
      "    Validation Batch [1/1], Loss: 0.0019\n",
      "Validation Loss: 0.0019, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [976/1000] - Training\n",
      "Epoch [976/1000] completed, Average Training Loss: 0.0034\n",
      "    Validation Batch [1/1], Loss: 0.0017\n",
      "Validation Loss: 0.0017, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [977/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [977/1000] completed, Average Training Loss: 0.0050\n",
      "    Validation Batch [1/1], Loss: 0.0011\n",
      "Validation Loss: 0.0011, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [978/1000] - Training\n",
      "Epoch [978/1000] completed, Average Training Loss: 0.0038\n",
      "    Validation Batch [1/1], Loss: 0.0011\n",
      "Validation Loss: 0.0011, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [979/1000] - Training\n",
      "Epoch [979/1000] completed, Average Training Loss: 0.0040\n",
      "    Validation Batch [1/1], Loss: 0.0015\n",
      "Validation Loss: 0.0015, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [980/1000] - Training\n",
      "Epoch [980/1000] completed, Average Training Loss: 0.0039\n",
      "    Validation Batch [1/1], Loss: 0.0018\n",
      "Validation Loss: 0.0018, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [981/1000] - Training\n",
      "Epoch [981/1000] completed, Average Training Loss: 0.0060\n",
      "    Validation Batch [1/1], Loss: 0.0019\n",
      "Validation Loss: 0.0019, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [982/1000] - Training\n",
      "Epoch [982/1000] completed, Average Training Loss: 0.0033\n",
      "    Validation Batch [1/1], Loss: 0.0019\n",
      "Validation Loss: 0.0019, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [983/1000] - Training\n",
      "Epoch [983/1000] completed, Average Training Loss: 0.0044\n",
      "    Validation Batch [1/1], Loss: 0.0019\n",
      "Validation Loss: 0.0019, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [984/1000] - Training\n",
      "Epoch [984/1000] completed, Average Training Loss: 0.0055\n",
      "    Validation Batch [1/1], Loss: 0.0016\n",
      "Validation Loss: 0.0016, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [985/1000] - Training\n",
      "Epoch [985/1000] completed, Average Training Loss: 0.0041\n",
      "    Validation Batch [1/1], Loss: 0.0015\n",
      "Validation Loss: 0.0015, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [986/1000] - Training\n",
      "Epoch [986/1000] completed, Average Training Loss: 0.0034\n",
      "    Validation Batch [1/1], Loss: 0.0015\n",
      "Validation Loss: 0.0015, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [987/1000] - Training\n",
      "Epoch [987/1000] completed, Average Training Loss: 0.0035\n",
      "    Validation Batch [1/1], Loss: 0.0016\n",
      "Validation Loss: 0.0016, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [988/1000] - Training\n",
      "Epoch [988/1000] completed, Average Training Loss: 0.0080\n",
      "    Validation Batch [1/1], Loss: 0.0022\n",
      "Validation Loss: 0.0022, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [989/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [989/1000] completed, Average Training Loss: 0.0038\n",
      "    Validation Batch [1/1], Loss: 0.0034\n",
      "Validation Loss: 0.0034, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [990/1000] - Training\n",
      "Epoch [990/1000] completed, Average Training Loss: 0.0050\n",
      "    Validation Batch [1/1], Loss: 0.0029\n",
      "Validation Loss: 0.0029, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [991/1000] - Training\n",
      "Epoch [991/1000] completed, Average Training Loss: 0.0031\n",
      "    Validation Batch [1/1], Loss: 0.0038\n",
      "Validation Loss: 0.0038, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [992/1000] - Training\n",
      "Epoch [992/1000] completed, Average Training Loss: 0.0047\n",
      "    Validation Batch [1/1], Loss: 0.0016\n",
      "Validation Loss: 0.0016, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [993/1000] - Training\n",
      "Epoch [993/1000] completed, Average Training Loss: 0.0046\n",
      "    Validation Batch [1/1], Loss: 0.0040\n",
      "Validation Loss: 0.0040, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [994/1000] - Training\n",
      "Epoch [994/1000] completed, Average Training Loss: 0.0054\n",
      "    Validation Batch [1/1], Loss: 0.0069\n",
      "Validation Loss: 0.0069, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [995/1000] - Training\n",
      "Epoch [995/1000] completed, Average Training Loss: 0.0037\n",
      "    Validation Batch [1/1], Loss: 0.0042\n",
      "Validation Loss: 0.0042, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [996/1000] - Training\n",
      "Epoch [996/1000] completed, Average Training Loss: 0.0035\n",
      "    Validation Batch [1/1], Loss: 0.0039\n",
      "Validation Loss: 0.0039, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [997/1000] - Training\n",
      "Epoch [997/1000] completed, Average Training Loss: 0.0033\n",
      "    Validation Batch [1/1], Loss: 0.0038\n",
      "Validation Loss: 0.0038, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [998/1000] - Training\n",
      "Epoch [998/1000] completed, Average Training Loss: 0.0044\n",
      "    Validation Batch [1/1], Loss: 0.0046\n",
      "Validation Loss: 0.0046, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [999/1000] - Training\n",
      "Epoch [999/1000] completed, Average Training Loss: 0.0037\n",
      "    Validation Batch [1/1], Loss: 0.0057\n",
      "Validation Loss: 0.0057, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1000/1000] - Training\n",
      "Epoch [1000/1000] completed, Average Training Loss: 0.0051\n",
      "    Validation Batch [1/1], Loss: 0.0108\n",
      "Validation Loss: 0.0108, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "Loading the best model weights...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on the test set...\n",
      "    Test Batch [1/11], Loss: 0.0006\n",
      "\n",
      "Final Test Loss: 0.0535, Test Accuracy: 98.62%\n",
      "Saved E2E CNN predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.0001\n",
    "\n",
    "#init the model, CrossEntropy loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#getting unique labels from entire dataset (train, validation, test)\n",
    "all_labels = []\n",
    "for loader in [train_loader, val_loader, test_loader]:\n",
    "    for _, labels in loader:\n",
    "        all_labels.extend(labels.tolist())\n",
    "all_labels = np.unique(all_labels)\n",
    "\n",
    "# init model with correct number of classes\n",
    "num_classes = len(all_labels)\n",
    "model = hyperspectralCNN(input_channels=window_num_channels, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#lists to store losses and accuracies\n",
    "classification_epoch_losses = []\n",
    "validation_epoch_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "#early stopping parameters\n",
    "patience = 100\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "best_model_weights = None\n",
    "\n",
    "#training loop + validation with early stopping\n",
    "for epoch in range(num_epochs):\n",
    "    # TRAINING\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    print(f\"\\nLOG: Epoch [{epoch + 1}/{num_epochs}] - Training\")\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device).permute(0, 3, 1, 2) \n",
    "        target = target.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        # backward pass + optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # accum loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"    Training Batch [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc + store average training loss per epoch\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    classification_epoch_losses.append(avg_train_loss)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] completed, Average Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "            target = target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # accu calculation\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "            if batch_idx == 0 or (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"    Validation Batch [{batch_idx + 1}/{len(val_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc + store validation metrics\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    validation_epoch_losses.append(avg_val_loss)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if avg_val_loss <= best_val_loss:\n",
    "        print(f\"Validation loss improved from {best_val_loss:.4f} to {avg_val_loss:.4f}. Saving model...\")\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        best_model_weights = model.state_dict()\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {epochs_without_improvement}/{patience}\")\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}. No improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "# loading the best model weights\n",
    "if best_model_weights is not None:\n",
    "    print(\"Loading the best model weights...\")\n",
    "    model.load_state_dict(best_model_weights)\n",
    "\n",
    "completed_epochs = len(classification_epoch_losses)\n",
    "\n",
    "# plot for loss and accuracy trends over epochs\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, completed_epochs + 1), classification_epoch_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(1, completed_epochs + 1), validation_epoch_losses, label=\"Validation Loss\", marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, completed_epochs + 1), val_accuracies, label=\"Validation Accuracy\", marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Validation Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#test Set Evaluation\n",
    "print(\"\\nEvaluating on the test set...\")\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "e2ecnn_test_predictions = []\n",
    "e2ecnn_test_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = data.to(device).permute(0, 3, 1, 2)\n",
    "        target = target.to(device)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        #accuracy calc\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "        e2ecnn_test_predictions.extend(predicted.cpu().numpy())\n",
    "        e2ecnn_test_true_labels.extend(target.cpu().numpy())\n",
    "\n",
    "        if batch_idx == 0 or (batch_idx + 1) % 1000 == 0:\n",
    "            print(f\"    Test Batch [{batch_idx + 1}/{len(test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "#calc + print test metrics\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"\\nFinal Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Convert to numpy arrays and save\n",
    "e2e_test_predictions = np.array(e2ecnn_test_predictions)\n",
    "e2e_test_true_labels = np.array(e2ecnn_test_true_labels)\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'e2e_cnn_predictions.npy'), e2e_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'e2e_cnn_true_labels.npy'), e2e_test_true_labels)\n",
    "print(f\"Saved E2E CNN predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:43:21.156882Z",
     "iopub.status.busy": "2025-05-08T19:43:21.155878Z",
     "iopub.status.idle": "2025-05-08T19:43:21.248159Z",
     "shell.execute_reply": "2025-05-08T19:43:21.248159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'e2ecnn_representations\\train'.\n",
      "\n",
      "Extracting SCL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'e2ecnn_representations\\val'.\n",
      "\n",
      "Extracting SCL representations for the test dataset...\n",
      "  Processed batch 10/11 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'e2ecnn_representations\\test'.\n",
      "E2E CNN representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the cnn representations\n",
    "e2ecnn_rep_dir = \"e2ecnn_representations\"\n",
    "os.makedirs(e2ecnn_rep_dir, exist_ok=True)\n",
    "\n",
    "e2ecnn_loaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for e2ecnn_split_name, e2ecnn_loader in e2ecnn_loaders.items():\n",
    "        print(f\"\\nExtracting SCL representations for the {e2ecnn_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        e2ecnn_split_dir = os.path.join(e2ecnn_rep_dir, e2ecnn_split_name)\n",
    "        os.makedirs(e2ecnn_split_dir, exist_ok=True)\n",
    "\n",
    "        # processing the data batch-wise\n",
    "        for e2ecnn_batch_idx, (e2ecnn_vectors, e2ecnn_labels) in enumerate(e2ecnn_loader):\n",
    "            e2ecnn_vectors = e2ecnn_vectors.permute(0, 3, 1, 2) \n",
    "            e2ecnn_vectors = e2ecnn_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            e2ecnn_projections = model(e2ecnn_vectors)\n",
    "\n",
    "            # converting projections and labels to np arrays\n",
    "            e2ecnn_projections_np = e2ecnn_projections.cpu().numpy()\n",
    "            e2ecnn_labels_np = e2ecnn_labels.cpu().numpy()\n",
    "\n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(e2ecnn_split_dir, f\"cnn_encoded_batch_{e2ecnn_batch_idx}.npy\"), e2ecnn_projections_np)\n",
    "            np.save(os.path.join(e2ecnn_split_dir, f\"cnn_labels_batch_{e2ecnn_batch_idx}.npy\"), e2ecnn_labels_np)\n",
    "\n",
    "            if (e2ecnn_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {e2ecnn_batch_idx + 1}/{len(e2ecnn_loader)} for {e2ecnn_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {e2ecnn_split_name} dataset. Representations saved in '{e2ecnn_split_dir}'.\")\n",
    "\n",
    "print(\"E2E CNN representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:43:21.251687Z",
     "iopub.status.busy": "2025-05-08T19:43:21.250681Z",
     "iopub.status.idle": "2025-05-08T19:43:21.254923Z",
     "shell.execute_reply": "2025-05-08T19:43:21.254923Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_cnn_reps_and_labels(split_dir):\n",
    "    #gather all the cnn_encoded_batch npy files in sorted order\n",
    "    cnn_rep_files = sorted(glob.glob(os.path.join(split_dir, \"cnn_encoded_batch_*.npy\")))\n",
    "\n",
    "    cnn_all_reps = []\n",
    "    cnn_all_labels = []\n",
    "\n",
    "    for cnn_rep_file in cnn_rep_files:\n",
    "        #deriving label filenames\n",
    "        cnn_label_file = cnn_rep_file.replace(\"cnn_encoded_batch_\", \"cnn_labels_batch_\")\n",
    "\n",
    "        cnn_reps = np.load(cnn_rep_file)\n",
    "        cnn_labels = np.load(cnn_label_file)\n",
    "\n",
    "        cnn_all_reps.append(cnn_reps)\n",
    "        cnn_all_labels.append(cnn_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    cnn_all_reps = np.concatenate(cnn_all_reps, axis = 0)\n",
    "    cnn_all_labels = np.concatenate(cnn_all_labels, axis = 0)\n",
    "\n",
    "    return cnn_all_reps, cnn_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:43:21.257932Z",
     "iopub.status.busy": "2025-05-08T19:43:21.257932Z",
     "iopub.status.idle": "2025-05-08T19:43:21.435815Z",
     "shell.execute_reply": "2025-05-08T19:43:21.435815Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_train_dir = os.path.join(\"e2ecnn_representations\", \"train\")\n",
    "cnn_val_dir   = os.path.join(\"e2ecnn_representations\", \"val\")\n",
    "cnn_test_dir  = os.path.join(\"e2ecnn_representations\", \"test\")\n",
    "\n",
    "cnn_train_reps, cnn_train_labels = load_cnn_reps_and_labels(cnn_train_dir)\n",
    "cnn_val_reps, cnn_val_labels = load_cnn_reps_and_labels(cnn_val_dir)\n",
    "cnn_test_reps, cnn_test_labels = load_cnn_reps_and_labels(cnn_test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:43:21.438828Z",
     "iopub.status.busy": "2025-05-08T19:43:21.438828Z",
     "iopub.status.idle": "2025-05-08T19:43:21.443851Z",
     "shell.execute_reply": "2025-05-08T19:43:21.443341Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_encoded_data(encoded_dir):\n",
    "    print(f\"LOG: Loading encoded data (representations) from {encoded_dir}...\")\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    #iter through batches\n",
    "    for filename in sorted(os.listdir(encoded_dir)):\n",
    "        if filename.startswith('encoded_batch_') and filename.endswith('.npy'):\n",
    "\n",
    "            #load the features\n",
    "            features = np.load(os.path.join(encoded_dir, filename))\n",
    "            features_flat = features.reshape(features.shape[0], -1) #flatten features for LRM\n",
    "            features_list.append(features_flat)\n",
    "        \n",
    "        elif filename.startswith('labels_batch_') and filename.endswith('.npy'):\n",
    "\n",
    "            #load labels\n",
    "            labels = np.load(os.path.join(encoded_dir, filename))\n",
    "            labels_list.append(labels)\n",
    "\n",
    "    #concat all batches into a single array\n",
    "    encoded_features = np.vstack(features_list)\n",
    "    encoded_labels = np.hstack(labels_list)\n",
    "\n",
    "    print(f\"LOG: Loaded {encoded_features.shape[0]} samples with {encoded_features.shape[1]} features each\")\n",
    "    print(f\"LOG: Labels shape: {encoded_labels.shape}\")\n",
    "\n",
    "    return encoded_features, encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:43:21.446852Z",
     "iopub.status.busy": "2025-05-08T19:43:21.446852Z",
     "iopub.status.idle": "2025-05-08T19:43:21.901547Z",
     "shell.execute_reply": "2025-05-08T19:43:21.901547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 560 samples with 64 features each\n",
      "LOG: Labels shape: (560,)\n",
      "\n",
      "Loading validation data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "\n",
      "Loading test data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2618 samples with 64 features each\n",
      "LOG: Labels shape: (2618,)\n",
      "\n",
      "LOG: Training features shape: (560, 64), Training labels shape: (560,)\n",
      "LOG: Validation features shape: (70, 64), Validation labels shape: (70,)\n",
      "LOG: Test features shape: (2618, 64), Test labels shape: (2618,)\n",
      "\n",
      "LOG: Training Logistic Regression model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 77.14%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       0.62      1.00      0.77         5\n",
      "           2       0.71      1.00      0.83         5\n",
      "           3       0.60      0.60      0.60         5\n",
      "           4       1.00      0.40      0.57         5\n",
      "           5       0.40      0.40      0.40         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      0.40      0.57         5\n",
      "           8       1.00      0.60      0.75         5\n",
      "           9       0.62      1.00      0.77         5\n",
      "          10       0.71      1.00      0.83         5\n",
      "          11       0.83      1.00      0.91         5\n",
      "          12       1.00      0.60      0.75         5\n",
      "          13       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.77        70\n",
      "   macro avg       0.82      0.77      0.76        70\n",
      "weighted avg       0.82      0.77      0.76        70\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 79.03%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       225\n",
      "           1       0.39      1.00      0.56        56\n",
      "           2       0.80      0.96      0.88       206\n",
      "           3       0.59      0.90      0.71       170\n",
      "           4       0.81      0.50      0.62       224\n",
      "           5       0.61      0.41      0.49       224\n",
      "           6       0.97      0.96      0.96       214\n",
      "           7       0.94      0.70      0.80       158\n",
      "           8       0.83      0.59      0.69       269\n",
      "           9       0.70      0.89      0.78       203\n",
      "          10       0.86      0.95      0.91       260\n",
      "          11       0.85      0.94      0.90       136\n",
      "          12       0.80      0.69      0.74       223\n",
      "          13       0.98      0.96      0.97        50\n",
      "\n",
      "    accuracy                           0.79      2618\n",
      "   macro avg       0.80      0.82      0.79      2618\n",
      "weighted avg       0.81      0.79      0.79      2618\n",
      "\n",
      "Saved CAE+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "lrm_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "lrm_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "lrm_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "print(\"\\nLoading training data for LRM...\")\n",
    "lrm_train_features, lrm_train_labels = load_encoded_data(lrm_encoded_train_dir)\n",
    "\n",
    "print(\"\\nLoading validation data for LRM...\")\n",
    "lrm_val_features, lrm_val_labels = load_encoded_data(lrm_encoded_val_dir)\n",
    "\n",
    "print(\"\\nLoading test data for LRM...\")\n",
    "lrm_test_features, lrm_test_labels = load_encoded_data(lrm_encoded_test_dir)\n",
    "\n",
    "#verify shapes\n",
    "print(f\"\\nLOG: Training features shape: {lrm_train_features.shape}, Training labels shape: {lrm_train_labels.shape}\")\n",
    "print(f\"LOG: Validation features shape: {lrm_val_features.shape}, Validation labels shape: {lrm_val_labels.shape}\")\n",
    "print(f\"LOG: Test features shape: {lrm_test_features.shape}, Test labels shape: {lrm_test_labels.shape}\")\n",
    "\n",
    "print(\"\\nLOG: Training Logistic Regression model...\")\n",
    "logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight = 'balanced')\n",
    "logistic_clf.fit(lrm_train_features, lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "#eval on Validation Set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "lrm_val_predictions = logistic_clf.predict(lrm_val_features)\n",
    "lrm_val_accuracy = accuracy_score(lrm_val_labels, lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(lrm_val_labels, lrm_val_predictions))\n",
    "\n",
    "#eval on Test Set\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "lrm_test_predictions = logistic_clf.predict(lrm_test_features)\n",
    "lrm_test_accuracy = accuracy_score(lrm_test_labels, lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(lrm_test_labels, lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'cae_lrm_predictions.npy'), lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'cae_lrm_true_labels.npy'), lrm_test_labels)\n",
    "print(f\"Saved CAE+LRM predictions and true labels to {predictions_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying CAE Embeddings with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:43:21.905554Z",
     "iopub.status.busy": "2025-05-08T19:43:21.904554Z",
     "iopub.status.idle": "2025-05-08T19:43:21.909553Z",
     "shell.execute_reply": "2025-05-08T19:43:21.909553Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:43:21.913029Z",
     "iopub.status.busy": "2025-05-08T19:43:21.912030Z",
     "iopub.status.idle": "2025-05-08T19:43:21.923718Z",
     "shell.execute_reply": "2025-05-08T19:43:21.923718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 560 samples with 64 features each\n",
      "LOG: Labels shape: (560,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2618 samples with 64 features each\n",
      "LOG: Labels shape: (2618,)\n",
      "Train reps shape: (560, 64)\n",
      "Train labels shape: (560,)\n",
      "Val reps shape: (70, 64)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2618, 64)\n",
      "Test labels shape: (2618,)\n"
     ]
    }
   ],
   "source": [
    "cae_mlp_train_dir = os.path.join(\"encoded_representations\", \"train\")\n",
    "cae_mlp_val_dir   = os.path.join(\"encoded_representations\", \"val\")\n",
    "cae_mlp_test_dir  = os.path.join(\"encoded_representations\", \"test\")\n",
    "\n",
    "cae_mlp_train_reps, cae_mlp_train_labels = load_encoded_data(cae_mlp_train_dir)\n",
    "cae_mlp_val_reps, cae_mlp_val_labels = load_encoded_data(cae_mlp_val_dir)\n",
    "cae_mlp_test_reps, cae_mlp_test_labels = load_encoded_data(cae_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\",cae_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", cae_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", cae_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", cae_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", cae_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", cae_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:43:21.926723Z",
     "iopub.status.busy": "2025-05-08T19:43:21.926723Z",
     "iopub.status.idle": "2025-05-08T19:43:21.932740Z",
     "shell.execute_reply": "2025-05-08T19:43:21.932235Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "cae_mlp_train_embeddings_torch = torch.tensor(cae_mlp_train_reps, dtype=torch.float32)\n",
    "cae_mlp_train_labels_torch = torch.tensor(cae_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "cae_mlp_val_embeddings_torch = torch.tensor(cae_mlp_val_reps, dtype=torch.float32)\n",
    "cae_mlp_val_labels_torch = torch.tensor(cae_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "cae_mlp_test_embeddings_torch = torch.tensor(cae_mlp_test_reps, dtype=torch.float32)\n",
    "cae_mlp_test_labels_torch = torch.tensor(cae_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "cae_mlp_train_dataset = TensorDataset(cae_mlp_train_embeddings_torch, cae_mlp_train_labels_torch)\n",
    "cae_mlp_val_dataset = TensorDataset(cae_mlp_val_embeddings_torch, cae_mlp_val_labels_torch)\n",
    "cae_mlp_test_dataset = TensorDataset(cae_mlp_test_embeddings_torch, cae_mlp_test_labels_torch)\n",
    "\n",
    "cae_mlp_batch_size = 64\n",
    "cae_mlp_train_loader = DataLoader(cae_mlp_train_dataset, batch_size=cae_mlp_batch_size, shuffle=True)\n",
    "cae_mlp_val_loader = DataLoader(cae_mlp_val_dataset, batch_size=cae_mlp_batch_size, shuffle=False)\n",
    "cae_mlp_test_loader = DataLoader(cae_mlp_test_dataset, batch_size=cae_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:43:21.934746Z",
     "iopub.status.busy": "2025-05-08T19:43:21.934746Z",
     "iopub.status.idle": "2025-05-08T19:43:43.542239Z",
     "shell.execute_reply": "2025-05-08T19:43:43.542239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.6907  |  Val Loss: 2.6245\n",
      "Validation loss improved from inf to 2.6245.\n",
      "[Epoch 2/1000] Train Loss: 2.6206  |  Val Loss: 2.6076\n",
      "Validation loss improved from 2.6245 to 2.6076.\n",
      "[Epoch 3/1000] Train Loss: 2.6003  |  Val Loss: 2.5847\n",
      "Validation loss improved from 2.6076 to 2.5847.\n",
      "[Epoch 4/1000] Train Loss: 2.5842  |  Val Loss: 2.5681\n",
      "Validation loss improved from 2.5847 to 2.5681.\n",
      "[Epoch 5/1000] Train Loss: 2.5604  |  Val Loss: 2.5404\n",
      "Validation loss improved from 2.5681 to 2.5404.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/1000] Train Loss: 2.5291  |  Val Loss: 2.5025\n",
      "Validation loss improved from 2.5404 to 2.5025.\n",
      "[Epoch 7/1000] Train Loss: 2.4926  |  Val Loss: 2.4635\n",
      "Validation loss improved from 2.5025 to 2.4635.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/1000] Train Loss: 2.4526  |  Val Loss: 2.4341\n",
      "Validation loss improved from 2.4635 to 2.4341.\n",
      "[Epoch 9/1000] Train Loss: 2.4135  |  Val Loss: 2.3867\n",
      "Validation loss improved from 2.4341 to 2.3867.\n",
      "[Epoch 10/1000] Train Loss: 2.3592  |  Val Loss: 2.3322\n",
      "Validation loss improved from 2.3867 to 2.3322.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/1000] Train Loss: 2.3053  |  Val Loss: 2.2775\n",
      "Validation loss improved from 2.3322 to 2.2775.\n",
      "[Epoch 12/1000] Train Loss: 2.2546  |  Val Loss: 2.2222\n",
      "Validation loss improved from 2.2775 to 2.2222.\n",
      "[Epoch 13/1000] Train Loss: 2.1894  |  Val Loss: 2.1594\n",
      "Validation loss improved from 2.2222 to 2.1594.\n",
      "[Epoch 14/1000] Train Loss: 2.1250  |  Val Loss: 2.0713\n",
      "Validation loss improved from 2.1594 to 2.0713.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/1000] Train Loss: 2.0595  |  Val Loss: 2.0182\n",
      "Validation loss improved from 2.0713 to 2.0182.\n",
      "[Epoch 16/1000] Train Loss: 2.0006  |  Val Loss: 1.9467\n",
      "Validation loss improved from 2.0182 to 1.9467.\n",
      "[Epoch 17/1000] Train Loss: 1.9383  |  Val Loss: 1.9064\n",
      "Validation loss improved from 1.9467 to 1.9064.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/1000] Train Loss: 1.8754  |  Val Loss: 1.8247\n",
      "Validation loss improved from 1.9064 to 1.8247.\n",
      "[Epoch 19/1000] Train Loss: 1.8120  |  Val Loss: 1.7904\n",
      "Validation loss improved from 1.8247 to 1.7904.\n",
      "[Epoch 20/1000] Train Loss: 1.7758  |  Val Loss: 1.7482\n",
      "Validation loss improved from 1.7904 to 1.7482.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/1000] Train Loss: 1.7182  |  Val Loss: 1.6811\n",
      "Validation loss improved from 1.7482 to 1.6811.\n",
      "[Epoch 22/1000] Train Loss: 1.6682  |  Val Loss: 1.6505\n",
      "Validation loss improved from 1.6811 to 1.6505.\n",
      "[Epoch 23/1000] Train Loss: 1.6348  |  Val Loss: 1.5947\n",
      "Validation loss improved from 1.6505 to 1.5947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24/1000] Train Loss: 1.5950  |  Val Loss: 1.5637\n",
      "Validation loss improved from 1.5947 to 1.5637.\n",
      "[Epoch 25/1000] Train Loss: 1.5626  |  Val Loss: 1.5708\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 26/1000] Train Loss: 1.5320  |  Val Loss: 1.5010\n",
      "Validation loss improved from 1.5637 to 1.5010.\n",
      "[Epoch 27/1000] Train Loss: 1.5090  |  Val Loss: 1.4762\n",
      "Validation loss improved from 1.5010 to 1.4762.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28/1000] Train Loss: 1.4854  |  Val Loss: 1.4739\n",
      "Validation loss improved from 1.4762 to 1.4739.\n",
      "[Epoch 29/1000] Train Loss: 1.4604  |  Val Loss: 1.4273\n",
      "Validation loss improved from 1.4739 to 1.4273.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/1000] Train Loss: 1.4328  |  Val Loss: 1.4159\n",
      "Validation loss improved from 1.4273 to 1.4159.\n",
      "[Epoch 31/1000] Train Loss: 1.4289  |  Val Loss: 1.4327\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 32/1000] Train Loss: 1.4302  |  Val Loss: 1.4186\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33/1000] Train Loss: 1.3866  |  Val Loss: 1.3727\n",
      "Validation loss improved from 1.4159 to 1.3727.\n",
      "[Epoch 34/1000] Train Loss: 1.3801  |  Val Loss: 1.3574\n",
      "Validation loss improved from 1.3727 to 1.3574.\n",
      "[Epoch 35/1000] Train Loss: 1.3569  |  Val Loss: 1.3584\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 36/1000] Train Loss: 1.3615  |  Val Loss: 1.3218\n",
      "Validation loss improved from 1.3574 to 1.3218.\n",
      "[Epoch 37/1000] Train Loss: 1.3601  |  Val Loss: 1.3168\n",
      "Validation loss improved from 1.3218 to 1.3168.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38/1000] Train Loss: 1.3317  |  Val Loss: 1.3271\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 39/1000] Train Loss: 1.3214  |  Val Loss: 1.3472\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 40/1000] Train Loss: 1.3121  |  Val Loss: 1.3124\n",
      "Validation loss improved from 1.3168 to 1.3124.\n",
      "[Epoch 41/1000] Train Loss: 1.3058  |  Val Loss: 1.2758\n",
      "Validation loss improved from 1.3124 to 1.2758.\n",
      "[Epoch 42/1000] Train Loss: 1.3113  |  Val Loss: 1.4948\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 43/1000] Train Loss: 1.3501  |  Val Loss: 1.2863\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 44/1000] Train Loss: 1.3231  |  Val Loss: 1.3720\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 45/1000] Train Loss: 1.2979  |  Val Loss: 1.2581\n",
      "Validation loss improved from 1.2758 to 1.2581.\n",
      "[Epoch 46/1000] Train Loss: 1.2760  |  Val Loss: 1.2480\n",
      "Validation loss improved from 1.2581 to 1.2480.\n",
      "[Epoch 47/1000] Train Loss: 1.2919  |  Val Loss: 1.3291\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 48/1000] Train Loss: 1.2854  |  Val Loss: 1.2438\n",
      "Validation loss improved from 1.2480 to 1.2438.\n",
      "[Epoch 49/1000] Train Loss: 1.2785  |  Val Loss: 1.2981\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 50/1000] Train Loss: 1.2694  |  Val Loss: 1.2547\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 51/1000] Train Loss: 1.2527  |  Val Loss: 1.2743\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 52/1000] Train Loss: 1.2465  |  Val Loss: 1.2762\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 53/1000] Train Loss: 1.2976  |  Val Loss: 1.2207\n",
      "Validation loss improved from 1.2438 to 1.2207.\n",
      "[Epoch 54/1000] Train Loss: 1.2625  |  Val Loss: 1.2337\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 55/1000] Train Loss: 1.2388  |  Val Loss: 1.3238\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 56/1000] Train Loss: 1.2477  |  Val Loss: 1.2082\n",
      "Validation loss improved from 1.2207 to 1.2082.\n",
      "[Epoch 57/1000] Train Loss: 1.2324  |  Val Loss: 1.3022\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 58/1000] Train Loss: 1.2489  |  Val Loss: 1.2069\n",
      "Validation loss improved from 1.2082 to 1.2069.\n",
      "[Epoch 59/1000] Train Loss: 1.2384  |  Val Loss: 1.2903\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 60/1000] Train Loss: 1.2688  |  Val Loss: 1.2063\n",
      "Validation loss improved from 1.2069 to 1.2063.\n",
      "[Epoch 61/1000] Train Loss: 1.2805  |  Val Loss: 1.2332\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 62/1000] Train Loss: 1.2206  |  Val Loss: 1.3317\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 63/1000] Train Loss: 1.2378  |  Val Loss: 1.2092\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 64/1000] Train Loss: 1.2689  |  Val Loss: 1.4749\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 65/1000] Train Loss: 1.2440  |  Val Loss: 1.2017\n",
      "Validation loss improved from 1.2063 to 1.2017.\n",
      "[Epoch 66/1000] Train Loss: 1.2115  |  Val Loss: 1.2013\n",
      "Validation loss improved from 1.2017 to 1.2013.\n",
      "[Epoch 67/1000] Train Loss: 1.2136  |  Val Loss: 1.1873\n",
      "Validation loss improved from 1.2013 to 1.1873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 68/1000] Train Loss: 1.2221  |  Val Loss: 1.4302\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 69/1000] Train Loss: 1.2525  |  Val Loss: 1.1868\n",
      "Validation loss improved from 1.1873 to 1.1868.\n",
      "[Epoch 70/1000] Train Loss: 1.2185  |  Val Loss: 1.1809\n",
      "Validation loss improved from 1.1868 to 1.1809.\n",
      "[Epoch 71/1000] Train Loss: 1.2217  |  Val Loss: 1.2886\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 72/1000] Train Loss: 1.2006  |  Val Loss: 1.2042\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 73/1000] Train Loss: 1.2141  |  Val Loss: 1.2397\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 74/1000] Train Loss: 1.3044  |  Val Loss: 1.3227\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 75/1000] Train Loss: 1.2631  |  Val Loss: 1.2000\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 76/1000] Train Loss: 1.2537  |  Val Loss: 1.1893\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 77/1000] Train Loss: 1.1991  |  Val Loss: 1.3077\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 78/1000] Train Loss: 1.2087  |  Val Loss: 1.2022\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 79/1000] Train Loss: 1.1886  |  Val Loss: 1.2010\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 80/1000] Train Loss: 1.2027  |  Val Loss: 1.2450\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 81/1000] Train Loss: 1.2034  |  Val Loss: 1.1981\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 82/1000] Train Loss: 1.2027  |  Val Loss: 1.1726\n",
      "Validation loss improved from 1.1809 to 1.1726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 83/1000] Train Loss: 1.1968  |  Val Loss: 1.2402\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 84/1000] Train Loss: 1.2075  |  Val Loss: 1.1887\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 85/1000] Train Loss: 1.2202  |  Val Loss: 1.2119\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 86/1000] Train Loss: 1.2311  |  Val Loss: 1.2436\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 87/1000] Train Loss: 1.1932  |  Val Loss: 1.1653\n",
      "Validation loss improved from 1.1726 to 1.1653.\n",
      "[Epoch 88/1000] Train Loss: 1.1949  |  Val Loss: 1.1961\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 89/1000] Train Loss: 1.1804  |  Val Loss: 1.1988\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 90/1000] Train Loss: 1.1801  |  Val Loss: 1.1640\n",
      "Validation loss improved from 1.1653 to 1.1640.\n",
      "[Epoch 91/1000] Train Loss: 1.2133  |  Val Loss: 1.1672\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 92/1000] Train Loss: 1.2022  |  Val Loss: 1.3069\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 93/1000] Train Loss: 1.1929  |  Val Loss: 1.4003\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 94/1000] Train Loss: 1.2548  |  Val Loss: 1.2115\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 95/1000] Train Loss: 1.2862  |  Val Loss: 1.2530\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 96/1000] Train Loss: 1.2675  |  Val Loss: 1.1763\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 97/1000] Train Loss: 1.2374  |  Val Loss: 1.2389\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 98/1000] Train Loss: 1.1806  |  Val Loss: 1.1731\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 99/1000] Train Loss: 1.1722  |  Val Loss: 1.1565\n",
      "Validation loss improved from 1.1640 to 1.1565.\n",
      "[Epoch 100/1000] Train Loss: 1.1654  |  Val Loss: 1.1513\n",
      "Validation loss improved from 1.1565 to 1.1513.\n",
      "[Epoch 101/1000] Train Loss: 1.1716  |  Val Loss: 1.2743\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 102/1000] Train Loss: 1.1893  |  Val Loss: 1.1612\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 103/1000] Train Loss: 1.1734  |  Val Loss: 1.1927\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 104/1000] Train Loss: 1.1603  |  Val Loss: 1.1769\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 105/1000] Train Loss: 1.1581  |  Val Loss: 1.1538\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 106/1000] Train Loss: 1.1672  |  Val Loss: 1.1467\n",
      "Validation loss improved from 1.1513 to 1.1467.\n",
      "[Epoch 107/1000] Train Loss: 1.1575  |  Val Loss: 1.2593\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 108/1000] Train Loss: 1.1677  |  Val Loss: 1.2438\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 109/1000] Train Loss: 1.1559  |  Val Loss: 1.1458\n",
      "Validation loss improved from 1.1467 to 1.1458.\n",
      "[Epoch 110/1000] Train Loss: 1.1853  |  Val Loss: 1.1827\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 111/1000] Train Loss: 1.1616  |  Val Loss: 1.2020\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 112/1000] Train Loss: 1.1654  |  Val Loss: 1.1492\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 113/1000] Train Loss: 1.1551  |  Val Loss: 1.2352\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 114/1000] Train Loss: 1.1802  |  Val Loss: 1.2083\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 115/1000] Train Loss: 1.1446  |  Val Loss: 1.1542\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 116/1000] Train Loss: 1.1564  |  Val Loss: 1.1681\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 117/1000] Train Loss: 1.1493  |  Val Loss: 1.1998\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 118/1000] Train Loss: 1.1763  |  Val Loss: 1.1896\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 119/1000] Train Loss: 1.1532  |  Val Loss: 1.1430\n",
      "Validation loss improved from 1.1458 to 1.1430.\n",
      "[Epoch 120/1000] Train Loss: 1.1605  |  Val Loss: 1.1457\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 121/1000] Train Loss: 1.1395  |  Val Loss: 1.1602\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 122/1000] Train Loss: 1.1541  |  Val Loss: 1.1993\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 123/1000] Train Loss: 1.1365  |  Val Loss: 1.1511\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 124/1000] Train Loss: 1.1517  |  Val Loss: 1.3300\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 125/1000] Train Loss: 1.1590  |  Val Loss: 1.1942\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 126/1000] Train Loss: 1.1705  |  Val Loss: 1.1389\n",
      "Validation loss improved from 1.1430 to 1.1389.\n",
      "[Epoch 127/1000] Train Loss: 1.1548  |  Val Loss: 1.1505\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 128/1000] Train Loss: 1.1472  |  Val Loss: 1.2184\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 129/1000] Train Loss: 1.1460  |  Val Loss: 1.1670\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 130/1000] Train Loss: 1.1304  |  Val Loss: 1.1702\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 131/1000] Train Loss: 1.1292  |  Val Loss: 1.1669\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 132/1000] Train Loss: 1.1272  |  Val Loss: 1.1480\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 133/1000] Train Loss: 1.1329  |  Val Loss: 1.1349\n",
      "Validation loss improved from 1.1389 to 1.1349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 134/1000] Train Loss: 1.1427  |  Val Loss: 1.1644\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 135/1000] Train Loss: 1.1414  |  Val Loss: 1.2158\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 136/1000] Train Loss: 1.1362  |  Val Loss: 1.1339\n",
      "Validation loss improved from 1.1349 to 1.1339.\n",
      "[Epoch 137/1000] Train Loss: 1.1407  |  Val Loss: 1.1401\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 138/1000] Train Loss: 1.1339  |  Val Loss: 1.1875\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 139/1000] Train Loss: 1.1241  |  Val Loss: 1.1435\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 140/1000] Train Loss: 1.1236  |  Val Loss: 1.1371\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 141/1000] Train Loss: 1.1585  |  Val Loss: 1.1651\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 142/1000] Train Loss: 1.1833  |  Val Loss: 1.3565\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 143/1000] Train Loss: 1.1685  |  Val Loss: 1.1381\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 144/1000] Train Loss: 1.1461  |  Val Loss: 1.1316\n",
      "Validation loss improved from 1.1339 to 1.1316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 145/1000] Train Loss: 1.1952  |  Val Loss: 1.3992\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 146/1000] Train Loss: 1.1764  |  Val Loss: 1.1281\n",
      "Validation loss improved from 1.1316 to 1.1281.\n",
      "[Epoch 147/1000] Train Loss: 1.1379  |  Val Loss: 1.1629\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 148/1000] Train Loss: 1.1305  |  Val Loss: 1.1592\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 149/1000] Train Loss: 1.1373  |  Val Loss: 1.1436\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 150/1000] Train Loss: 1.1349  |  Val Loss: 1.2640\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 151/1000] Train Loss: 1.1454  |  Val Loss: 1.1336\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 152/1000] Train Loss: 1.1742  |  Val Loss: 1.1306\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 153/1000] Train Loss: 1.1528  |  Val Loss: 1.2269\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 154/1000] Train Loss: 1.1193  |  Val Loss: 1.2237\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 155/1000] Train Loss: 1.1136  |  Val Loss: 1.1236\n",
      "Validation loss improved from 1.1281 to 1.1236.\n",
      "[Epoch 156/1000] Train Loss: 1.1173  |  Val Loss: 1.2153\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 157/1000] Train Loss: 1.1159  |  Val Loss: 1.2452\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 158/1000] Train Loss: 1.1266  |  Val Loss: 1.1480\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 159/1000] Train Loss: 1.1053  |  Val Loss: 1.1849\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 160/1000] Train Loss: 1.1134  |  Val Loss: 1.2330\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 161/1000] Train Loss: 1.1148  |  Val Loss: 1.1408\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 162/1000] Train Loss: 1.1202  |  Val Loss: 1.1648\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 163/1000] Train Loss: 1.1072  |  Val Loss: 1.1619\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 164/1000] Train Loss: 1.1092  |  Val Loss: 1.1140\n",
      "Validation loss improved from 1.1236 to 1.1140.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 165/1000] Train Loss: 1.1080  |  Val Loss: 1.1306\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 166/1000] Train Loss: 1.1134  |  Val Loss: 1.2164\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 167/1000] Train Loss: 1.1059  |  Val Loss: 1.1109\n",
      "Validation loss improved from 1.1140 to 1.1109.\n",
      "[Epoch 168/1000] Train Loss: 1.1017  |  Val Loss: 1.1390\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 169/1000] Train Loss: 1.0944  |  Val Loss: 1.1904\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 170/1000] Train Loss: 1.0973  |  Val Loss: 1.1176\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 171/1000] Train Loss: 1.1252  |  Val Loss: 1.1243\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 172/1000] Train Loss: 1.1200  |  Val Loss: 1.1861\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 173/1000] Train Loss: 1.0942  |  Val Loss: 1.1222\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 174/1000] Train Loss: 1.1023  |  Val Loss: 1.1360\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 175/1000] Train Loss: 1.1455  |  Val Loss: 1.2592\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 176/1000] Train Loss: 1.1547  |  Val Loss: 1.1790\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 177/1000] Train Loss: 1.1768  |  Val Loss: 1.1767\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 178/1000] Train Loss: 1.1428  |  Val Loss: 1.1883\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 179/1000] Train Loss: 1.0992  |  Val Loss: 1.1222\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 180/1000] Train Loss: 1.1401  |  Val Loss: 1.1279\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 181/1000] Train Loss: 1.1182  |  Val Loss: 1.1481\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 182/1000] Train Loss: 1.0911  |  Val Loss: 1.1066\n",
      "Validation loss improved from 1.1109 to 1.1066.\n",
      "[Epoch 183/1000] Train Loss: 1.0876  |  Val Loss: 1.1336\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 184/1000] Train Loss: 1.0926  |  Val Loss: 1.1881\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 185/1000] Train Loss: 1.0929  |  Val Loss: 1.1374\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 186/1000] Train Loss: 1.0992  |  Val Loss: 1.1100\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 187/1000] Train Loss: 1.1308  |  Val Loss: 1.3688\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 188/1000] Train Loss: 1.1590  |  Val Loss: 1.3683\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 189/1000] Train Loss: 1.1526  |  Val Loss: 1.1090\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 190/1000] Train Loss: 1.1231  |  Val Loss: 1.1112\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 191/1000] Train Loss: 1.1152  |  Val Loss: 1.1513\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 192/1000] Train Loss: 1.1759  |  Val Loss: 1.3475\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 193/1000] Train Loss: 1.0930  |  Val Loss: 1.1287\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 194/1000] Train Loss: 1.0771  |  Val Loss: 1.1499\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 195/1000] Train Loss: 1.1237  |  Val Loss: 1.1095\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 196/1000] Train Loss: 1.1000  |  Val Loss: 1.1561\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 197/1000] Train Loss: 1.0953  |  Val Loss: 1.2615\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 198/1000] Train Loss: 1.1297  |  Val Loss: 1.1992\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 199/1000] Train Loss: 1.0822  |  Val Loss: 1.1207\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 200/1000] Train Loss: 1.1471  |  Val Loss: 1.1247\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 201/1000] Train Loss: 1.1411  |  Val Loss: 1.1974\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 202/1000] Train Loss: 1.1135  |  Val Loss: 1.3234\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 203/1000] Train Loss: 1.0933  |  Val Loss: 1.1335\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 204/1000] Train Loss: 1.0713  |  Val Loss: 1.0995\n",
      "Validation loss improved from 1.1066 to 1.0995.\n",
      "[Epoch 205/1000] Train Loss: 1.0856  |  Val Loss: 1.1011\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 206/1000] Train Loss: 1.1155  |  Val Loss: 1.2842\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 207/1000] Train Loss: 1.1067  |  Val Loss: 1.0985\n",
      "Validation loss improved from 1.0995 to 1.0985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 208/1000] Train Loss: 1.0907  |  Val Loss: 1.1288\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 209/1000] Train Loss: 1.0765  |  Val Loss: 1.2332\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 210/1000] Train Loss: 1.0963  |  Val Loss: 1.1717\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 211/1000] Train Loss: 1.0648  |  Val Loss: 1.1848\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 212/1000] Train Loss: 1.0585  |  Val Loss: 1.1790\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 213/1000] Train Loss: 1.0832  |  Val Loss: 1.1038\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 214/1000] Train Loss: 1.0783  |  Val Loss: 1.1229\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 215/1000] Train Loss: 1.0767  |  Val Loss: 1.2046\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 216/1000] Train Loss: 1.0684  |  Val Loss: 1.1632\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 217/1000] Train Loss: 1.0505  |  Val Loss: 1.1646\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 218/1000] Train Loss: 1.0537  |  Val Loss: 1.1405\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 219/1000] Train Loss: 1.0926  |  Val Loss: 1.0843\n",
      "Validation loss improved from 1.0985 to 1.0843.\n",
      "[Epoch 220/1000] Train Loss: 1.0632  |  Val Loss: 1.1398\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 221/1000] Train Loss: 1.0653  |  Val Loss: 1.1011\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 222/1000] Train Loss: 1.0480  |  Val Loss: 1.1188\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 223/1000] Train Loss: 1.0466  |  Val Loss: 1.1898\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 224/1000] Train Loss: 1.0707  |  Val Loss: 1.1669\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 225/1000] Train Loss: 1.0615  |  Val Loss: 1.1264\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 226/1000] Train Loss: 1.1116  |  Val Loss: 1.1146\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 227/1000] Train Loss: 1.0651  |  Val Loss: 1.2555\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 228/1000] Train Loss: 1.0436  |  Val Loss: 1.0965\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 229/1000] Train Loss: 1.0696  |  Val Loss: 1.0906\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 230/1000] Train Loss: 1.0353  |  Val Loss: 1.1202\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 231/1000] Train Loss: 1.0297  |  Val Loss: 1.0970\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 232/1000] Train Loss: 1.0227  |  Val Loss: 1.0858\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 233/1000] Train Loss: 1.0424  |  Val Loss: 1.1489\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 234/1000] Train Loss: 1.0547  |  Val Loss: 1.1501\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 235/1000] Train Loss: 1.0183  |  Val Loss: 1.0807\n",
      "Validation loss improved from 1.0843 to 1.0807.\n",
      "[Epoch 236/1000] Train Loss: 1.0379  |  Val Loss: 1.0665\n",
      "Validation loss improved from 1.0807 to 1.0665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 237/1000] Train Loss: 1.0298  |  Val Loss: 1.0779\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 238/1000] Train Loss: 1.0251  |  Val Loss: 1.1428\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 239/1000] Train Loss: 1.0524  |  Val Loss: 1.1861\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 240/1000] Train Loss: 1.0467  |  Val Loss: 1.0895\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 241/1000] Train Loss: 1.0061  |  Val Loss: 1.0678\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 242/1000] Train Loss: 1.0301  |  Val Loss: 1.2145\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 243/1000] Train Loss: 1.0124  |  Val Loss: 1.0914\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 244/1000] Train Loss: 1.0062  |  Val Loss: 1.0628\n",
      "Validation loss improved from 1.0665 to 1.0628.\n",
      "[Epoch 245/1000] Train Loss: 1.0122  |  Val Loss: 1.1182\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 246/1000] Train Loss: 0.9988  |  Val Loss: 1.0658\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 247/1000] Train Loss: 1.0129  |  Val Loss: 1.1225\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 248/1000] Train Loss: 1.0176  |  Val Loss: 1.0599\n",
      "Validation loss improved from 1.0628 to 1.0599.\n",
      "[Epoch 249/1000] Train Loss: 1.0111  |  Val Loss: 1.0738\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 250/1000] Train Loss: 0.9942  |  Val Loss: 1.1319\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 251/1000] Train Loss: 1.0241  |  Val Loss: 1.0789\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 252/1000] Train Loss: 1.0163  |  Val Loss: 1.0722\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 253/1000] Train Loss: 1.0239  |  Val Loss: 1.1287\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 254/1000] Train Loss: 1.0326  |  Val Loss: 1.1679\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 255/1000] Train Loss: 1.0298  |  Val Loss: 1.0570\n",
      "Validation loss improved from 1.0599 to 1.0570.\n",
      "[Epoch 256/1000] Train Loss: 0.9952  |  Val Loss: 1.1089\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 257/1000] Train Loss: 0.9913  |  Val Loss: 1.1267\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 258/1000] Train Loss: 1.0238  |  Val Loss: 1.0924\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 259/1000] Train Loss: 1.0135  |  Val Loss: 1.1086\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 260/1000] Train Loss: 1.0347  |  Val Loss: 1.1920\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 261/1000] Train Loss: 1.0379  |  Val Loss: 1.2435\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 262/1000] Train Loss: 1.0130  |  Val Loss: 1.0447\n",
      "Validation loss improved from 1.0570 to 1.0447.\n",
      "[Epoch 263/1000] Train Loss: 1.0088  |  Val Loss: 1.0497\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 264/1000] Train Loss: 0.9694  |  Val Loss: 1.2007\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 265/1000] Train Loss: 1.0303  |  Val Loss: 1.1573\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 266/1000] Train Loss: 0.9971  |  Val Loss: 1.0399\n",
      "Validation loss improved from 1.0447 to 1.0399.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 267/1000] Train Loss: 0.9627  |  Val Loss: 1.0494\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 268/1000] Train Loss: 0.9898  |  Val Loss: 1.0841\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 269/1000] Train Loss: 0.9887  |  Val Loss: 1.1199\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 270/1000] Train Loss: 1.0751  |  Val Loss: 1.0815\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 271/1000] Train Loss: 0.9995  |  Val Loss: 1.1573\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 272/1000] Train Loss: 0.9581  |  Val Loss: 1.0517\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 273/1000] Train Loss: 1.0107  |  Val Loss: 1.0686\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 274/1000] Train Loss: 0.9899  |  Val Loss: 1.1250\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 275/1000] Train Loss: 0.9979  |  Val Loss: 1.2913\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 276/1000] Train Loss: 1.0645  |  Val Loss: 1.0415\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 277/1000] Train Loss: 1.0091  |  Val Loss: 1.0251\n",
      "Validation loss improved from 1.0399 to 1.0251.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 278/1000] Train Loss: 0.9716  |  Val Loss: 1.0602\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 279/1000] Train Loss: 0.9664  |  Val Loss: 1.1065\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 280/1000] Train Loss: 0.9946  |  Val Loss: 1.0268\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 281/1000] Train Loss: 1.0169  |  Val Loss: 1.0259\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 282/1000] Train Loss: 0.9741  |  Val Loss: 1.0456\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 283/1000] Train Loss: 0.9625  |  Val Loss: 1.0844\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 284/1000] Train Loss: 0.9293  |  Val Loss: 1.0237\n",
      "Validation loss improved from 1.0251 to 1.0237.\n",
      "[Epoch 285/1000] Train Loss: 0.9337  |  Val Loss: 1.0464\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 286/1000] Train Loss: 0.9407  |  Val Loss: 1.0126\n",
      "Validation loss improved from 1.0237 to 1.0126.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 287/1000] Train Loss: 0.9373  |  Val Loss: 1.0701\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 288/1000] Train Loss: 0.9455  |  Val Loss: 1.0251\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 289/1000] Train Loss: 0.9557  |  Val Loss: 1.0432\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 290/1000] Train Loss: 0.9898  |  Val Loss: 1.0994\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 291/1000] Train Loss: 0.9333  |  Val Loss: 1.0433\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 292/1000] Train Loss: 0.9479  |  Val Loss: 1.1959\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 293/1000] Train Loss: 0.9572  |  Val Loss: 1.1214\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 294/1000] Train Loss: 0.9638  |  Val Loss: 1.1066\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 295/1000] Train Loss: 1.0140  |  Val Loss: 1.0184\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 296/1000] Train Loss: 1.0176  |  Val Loss: 1.0119\n",
      "Validation loss improved from 1.0126 to 1.0119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 297/1000] Train Loss: 0.9878  |  Val Loss: 1.1813\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 298/1000] Train Loss: 0.9617  |  Val Loss: 1.1688\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 299/1000] Train Loss: 0.9229  |  Val Loss: 1.0147\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 300/1000] Train Loss: 0.9181  |  Val Loss: 1.0235\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 301/1000] Train Loss: 0.9243  |  Val Loss: 1.0906\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 302/1000] Train Loss: 0.9322  |  Val Loss: 1.0528\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 303/1000] Train Loss: 0.9216  |  Val Loss: 1.1253\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 304/1000] Train Loss: 0.9284  |  Val Loss: 1.0683\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 305/1000] Train Loss: 0.9107  |  Val Loss: 1.0456\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 306/1000] Train Loss: 0.8963  |  Val Loss: 0.9882\n",
      "Validation loss improved from 1.0119 to 0.9882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 307/1000] Train Loss: 0.9098  |  Val Loss: 1.0331\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 308/1000] Train Loss: 0.9023  |  Val Loss: 1.0932\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 309/1000] Train Loss: 0.9174  |  Val Loss: 1.0069\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 310/1000] Train Loss: 0.9165  |  Val Loss: 1.0126\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 311/1000] Train Loss: 0.9038  |  Val Loss: 1.1556\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 312/1000] Train Loss: 0.9475  |  Val Loss: 1.0665\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 313/1000] Train Loss: 0.9042  |  Val Loss: 1.0119\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 314/1000] Train Loss: 0.9068  |  Val Loss: 1.0427\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 315/1000] Train Loss: 0.9101  |  Val Loss: 1.1382\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 316/1000] Train Loss: 0.9003  |  Val Loss: 0.9779\n",
      "Validation loss improved from 0.9882 to 0.9779.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 317/1000] Train Loss: 0.8912  |  Val Loss: 0.9957\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 318/1000] Train Loss: 0.8803  |  Val Loss: 1.0268\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 319/1000] Train Loss: 0.8858  |  Val Loss: 1.0978\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 320/1000] Train Loss: 0.9153  |  Val Loss: 0.9739\n",
      "Validation loss improved from 0.9779 to 0.9739.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 321/1000] Train Loss: 0.9391  |  Val Loss: 1.0699\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 322/1000] Train Loss: 0.9049  |  Val Loss: 1.0047\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 323/1000] Train Loss: 0.9158  |  Val Loss: 1.0151\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 324/1000] Train Loss: 0.8721  |  Val Loss: 0.9917\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 325/1000] Train Loss: 0.8783  |  Val Loss: 1.0422\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 326/1000] Train Loss: 0.8684  |  Val Loss: 0.9592\n",
      "Validation loss improved from 0.9739 to 0.9592.\n",
      "[Epoch 327/1000] Train Loss: 0.9155  |  Val Loss: 1.0350\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 328/1000] Train Loss: 0.9742  |  Val Loss: 1.0697\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 329/1000] Train Loss: 0.9064  |  Val Loss: 0.9715\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 330/1000] Train Loss: 0.9036  |  Val Loss: 0.9995\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 331/1000] Train Loss: 0.9163  |  Val Loss: 0.9581\n",
      "Validation loss improved from 0.9592 to 0.9581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 332/1000] Train Loss: 0.9396  |  Val Loss: 1.1891\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 333/1000] Train Loss: 0.8972  |  Val Loss: 1.0192\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 334/1000] Train Loss: 0.8667  |  Val Loss: 0.9527\n",
      "Validation loss improved from 0.9581 to 0.9527.\n",
      "[Epoch 335/1000] Train Loss: 0.8632  |  Val Loss: 0.9565\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 336/1000] Train Loss: 0.9066  |  Val Loss: 1.2079\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 337/1000] Train Loss: 0.8909  |  Val Loss: 1.1202\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 338/1000] Train Loss: 0.8967  |  Val Loss: 1.1028\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 339/1000] Train Loss: 0.9130  |  Val Loss: 1.1635\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 340/1000] Train Loss: 0.9042  |  Val Loss: 0.9764\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 341/1000] Train Loss: 0.8666  |  Val Loss: 0.9899\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 342/1000] Train Loss: 0.8595  |  Val Loss: 1.0517\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 343/1000] Train Loss: 0.8716  |  Val Loss: 0.9531\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 344/1000] Train Loss: 0.8225  |  Val Loss: 0.9571\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 345/1000] Train Loss: 0.8243  |  Val Loss: 0.9525\n",
      "Validation loss improved from 0.9527 to 0.9525.\n",
      "[Epoch 346/1000] Train Loss: 0.8992  |  Val Loss: 1.2076\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 347/1000] Train Loss: 0.8860  |  Val Loss: 1.1751\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 348/1000] Train Loss: 0.9004  |  Val Loss: 0.9490\n",
      "Validation loss improved from 0.9525 to 0.9490.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 349/1000] Train Loss: 0.8857  |  Val Loss: 0.9327\n",
      "Validation loss improved from 0.9490 to 0.9327.\n",
      "[Epoch 350/1000] Train Loss: 0.8468  |  Val Loss: 0.9246\n",
      "Validation loss improved from 0.9327 to 0.9246.\n",
      "[Epoch 351/1000] Train Loss: 0.8212  |  Val Loss: 0.9824\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 352/1000] Train Loss: 0.8077  |  Val Loss: 0.9727\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 353/1000] Train Loss: 0.8089  |  Val Loss: 1.0372\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 354/1000] Train Loss: 0.8240  |  Val Loss: 1.0196\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 355/1000] Train Loss: 0.8141  |  Val Loss: 1.1111\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 356/1000] Train Loss: 0.9605  |  Val Loss: 0.9735\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 357/1000] Train Loss: 0.8876  |  Val Loss: 0.9520\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 358/1000] Train Loss: 0.8106  |  Val Loss: 0.9135\n",
      "Validation loss improved from 0.9246 to 0.9135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 359/1000] Train Loss: 0.8239  |  Val Loss: 0.9220\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 360/1000] Train Loss: 0.8086  |  Val Loss: 1.0119\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 361/1000] Train Loss: 0.8094  |  Val Loss: 0.9855\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 362/1000] Train Loss: 0.8254  |  Val Loss: 0.9360\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 363/1000] Train Loss: 0.7947  |  Val Loss: 0.9355\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 364/1000] Train Loss: 0.7849  |  Val Loss: 0.9489\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 365/1000] Train Loss: 0.8338  |  Val Loss: 0.9241\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 366/1000] Train Loss: 0.8257  |  Val Loss: 0.9430\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 367/1000] Train Loss: 0.8009  |  Val Loss: 0.9362\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 368/1000] Train Loss: 0.7968  |  Val Loss: 0.9386\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 369/1000] Train Loss: 0.8245  |  Val Loss: 0.9018\n",
      "Validation loss improved from 0.9135 to 0.9018.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 370/1000] Train Loss: 0.8073  |  Val Loss: 0.9609\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 371/1000] Train Loss: 0.7978  |  Val Loss: 1.0034\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 372/1000] Train Loss: 0.7812  |  Val Loss: 1.0162\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 373/1000] Train Loss: 0.7865  |  Val Loss: 0.9814\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 374/1000] Train Loss: 0.7973  |  Val Loss: 0.9206\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 375/1000] Train Loss: 0.7715  |  Val Loss: 0.9240\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 376/1000] Train Loss: 0.7814  |  Val Loss: 0.9928\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 377/1000] Train Loss: 0.8152  |  Val Loss: 1.0111\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 378/1000] Train Loss: 0.8328  |  Val Loss: 1.0107\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 379/1000] Train Loss: 0.7937  |  Val Loss: 0.9057\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 380/1000] Train Loss: 0.7641  |  Val Loss: 0.8826\n",
      "Validation loss improved from 0.9018 to 0.8826.\n",
      "[Epoch 381/1000] Train Loss: 0.7746  |  Val Loss: 0.9012\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 382/1000] Train Loss: 0.7812  |  Val Loss: 1.0166\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 383/1000] Train Loss: 0.8194  |  Val Loss: 1.0597\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 384/1000] Train Loss: 0.7874  |  Val Loss: 0.9107\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 385/1000] Train Loss: 0.7653  |  Val Loss: 0.9087\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 386/1000] Train Loss: 0.7683  |  Val Loss: 0.9245\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 387/1000] Train Loss: 0.7790  |  Val Loss: 0.8902\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 388/1000] Train Loss: 0.7788  |  Val Loss: 0.8800\n",
      "Validation loss improved from 0.8826 to 0.8800.\n",
      "[Epoch 389/1000] Train Loss: 0.7913  |  Val Loss: 0.8789\n",
      "Validation loss improved from 0.8800 to 0.8789.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 390/1000] Train Loss: 0.7505  |  Val Loss: 0.9395\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 391/1000] Train Loss: 0.7664  |  Val Loss: 0.8906\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 392/1000] Train Loss: 0.7671  |  Val Loss: 0.8742\n",
      "Validation loss improved from 0.8789 to 0.8742.\n",
      "[Epoch 393/1000] Train Loss: 0.7701  |  Val Loss: 0.9100\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 394/1000] Train Loss: 0.7454  |  Val Loss: 0.9064\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 395/1000] Train Loss: 0.7360  |  Val Loss: 0.8923\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 396/1000] Train Loss: 0.7514  |  Val Loss: 0.9318\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 397/1000] Train Loss: 0.7773  |  Val Loss: 0.9228\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 398/1000] Train Loss: 0.7955  |  Val Loss: 1.0337\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 399/1000] Train Loss: 0.7644  |  Val Loss: 0.9765\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 400/1000] Train Loss: 0.7911  |  Val Loss: 0.9041\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 401/1000] Train Loss: 0.8212  |  Val Loss: 0.8806\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 402/1000] Train Loss: 0.7598  |  Val Loss: 0.8768\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 403/1000] Train Loss: 0.7587  |  Val Loss: 1.0159\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 404/1000] Train Loss: 0.7913  |  Val Loss: 1.0132\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 405/1000] Train Loss: 0.7750  |  Val Loss: 0.9542\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 406/1000] Train Loss: 0.7481  |  Val Loss: 0.9138\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 407/1000] Train Loss: 0.7301  |  Val Loss: 1.0484\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 408/1000] Train Loss: 0.8197  |  Val Loss: 1.3783\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 409/1000] Train Loss: 0.8910  |  Val Loss: 1.1038\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 410/1000] Train Loss: 0.8197  |  Val Loss: 0.9553\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 411/1000] Train Loss: 0.7665  |  Val Loss: 0.8657\n",
      "Validation loss improved from 0.8742 to 0.8657.\n",
      "[Epoch 412/1000] Train Loss: 0.7934  |  Val Loss: 0.8964\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 413/1000] Train Loss: 0.7985  |  Val Loss: 0.8977\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 414/1000] Train Loss: 0.7472  |  Val Loss: 0.8968\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 415/1000] Train Loss: 0.7219  |  Val Loss: 1.1029\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 416/1000] Train Loss: 0.8551  |  Val Loss: 0.8836\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 417/1000] Train Loss: 0.7635  |  Val Loss: 0.9010\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 418/1000] Train Loss: 0.7149  |  Val Loss: 0.8478\n",
      "Validation loss improved from 0.8657 to 0.8478.\n",
      "[Epoch 419/1000] Train Loss: 0.7220  |  Val Loss: 0.8597\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 420/1000] Train Loss: 0.7208  |  Val Loss: 0.8705\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 421/1000] Train Loss: 0.7354  |  Val Loss: 0.9736\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 422/1000] Train Loss: 0.7119  |  Val Loss: 0.8774\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 423/1000] Train Loss: 0.7322  |  Val Loss: 0.8790\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 424/1000] Train Loss: 0.7821  |  Val Loss: 0.8568\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 425/1000] Train Loss: 0.7339  |  Val Loss: 0.8587\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 426/1000] Train Loss: 0.7347  |  Val Loss: 1.0031\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 427/1000] Train Loss: 0.7520  |  Val Loss: 0.8645\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 428/1000] Train Loss: 0.7652  |  Val Loss: 0.9325\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 429/1000] Train Loss: 0.7464  |  Val Loss: 1.0136\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 430/1000] Train Loss: 0.7425  |  Val Loss: 0.9681\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 431/1000] Train Loss: 0.7087  |  Val Loss: 0.9369\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 432/1000] Train Loss: 0.6971  |  Val Loss: 0.9814\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 433/1000] Train Loss: 0.7142  |  Val Loss: 0.8913\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 434/1000] Train Loss: 0.7089  |  Val Loss: 0.8433\n",
      "Validation loss improved from 0.8478 to 0.8433.\n",
      "[Epoch 435/1000] Train Loss: 0.6953  |  Val Loss: 0.8892\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 436/1000] Train Loss: 0.6925  |  Val Loss: 0.9362\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 437/1000] Train Loss: 0.6982  |  Val Loss: 0.8710\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 438/1000] Train Loss: 0.6893  |  Val Loss: 0.9128\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 439/1000] Train Loss: 0.7026  |  Val Loss: 0.8500\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 440/1000] Train Loss: 0.6941  |  Val Loss: 0.8487\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 441/1000] Train Loss: 0.7238  |  Val Loss: 0.9081\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 442/1000] Train Loss: 0.7484  |  Val Loss: 1.1984\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 443/1000] Train Loss: 0.7876  |  Val Loss: 1.0141\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 444/1000] Train Loss: 0.7458  |  Val Loss: 0.8423\n",
      "Validation loss improved from 0.8433 to 0.8423.\n",
      "[Epoch 445/1000] Train Loss: 0.6804  |  Val Loss: 0.9040\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 446/1000] Train Loss: 0.7350  |  Val Loss: 0.8767\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 447/1000] Train Loss: 0.6913  |  Val Loss: 0.8377\n",
      "Validation loss improved from 0.8423 to 0.8377.\n",
      "[Epoch 448/1000] Train Loss: 0.7288  |  Val Loss: 0.8559\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 449/1000] Train Loss: 0.7211  |  Val Loss: 1.0328\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 450/1000] Train Loss: 0.7199  |  Val Loss: 0.9180\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 451/1000] Train Loss: 0.6629  |  Val Loss: 0.9824\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 452/1000] Train Loss: 0.6875  |  Val Loss: 0.8769\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 453/1000] Train Loss: 0.6787  |  Val Loss: 0.9336\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 454/1000] Train Loss: 0.7619  |  Val Loss: 0.9876\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 455/1000] Train Loss: 0.7593  |  Val Loss: 1.0652\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 456/1000] Train Loss: 0.6881  |  Val Loss: 0.9148\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 457/1000] Train Loss: 0.6729  |  Val Loss: 0.9190\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 458/1000] Train Loss: 0.6690  |  Val Loss: 0.9113\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 459/1000] Train Loss: 0.6646  |  Val Loss: 0.8293\n",
      "Validation loss improved from 0.8377 to 0.8293.\n",
      "[Epoch 460/1000] Train Loss: 0.6881  |  Val Loss: 0.8867\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 461/1000] Train Loss: 0.6790  |  Val Loss: 0.8757\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 462/1000] Train Loss: 0.6812  |  Val Loss: 0.8753\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 463/1000] Train Loss: 0.6797  |  Val Loss: 0.9172\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 464/1000] Train Loss: 0.6871  |  Val Loss: 0.8282\n",
      "Validation loss improved from 0.8293 to 0.8282.\n",
      "[Epoch 465/1000] Train Loss: 0.6615  |  Val Loss: 0.8847\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 466/1000] Train Loss: 0.6540  |  Val Loss: 0.8313\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 467/1000] Train Loss: 0.6747  |  Val Loss: 0.8230\n",
      "Validation loss improved from 0.8282 to 0.8230.\n",
      "[Epoch 468/1000] Train Loss: 0.6763  |  Val Loss: 0.8680\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 469/1000] Train Loss: 0.7800  |  Val Loss: 0.8340\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 470/1000] Train Loss: 0.7927  |  Val Loss: 1.0580\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 471/1000] Train Loss: 0.7058  |  Val Loss: 0.9242\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 472/1000] Train Loss: 0.6519  |  Val Loss: 0.8736\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 473/1000] Train Loss: 0.6618  |  Val Loss: 0.8741\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 474/1000] Train Loss: 0.6729  |  Val Loss: 0.8227\n",
      "Validation loss improved from 0.8230 to 0.8227.\n",
      "[Epoch 475/1000] Train Loss: 0.6875  |  Val Loss: 0.8728\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 476/1000] Train Loss: 0.6590  |  Val Loss: 0.9426\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 477/1000] Train Loss: 0.6453  |  Val Loss: 0.8213\n",
      "Validation loss improved from 0.8227 to 0.8213.\n",
      "[Epoch 478/1000] Train Loss: 0.6552  |  Val Loss: 0.9742\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 479/1000] Train Loss: 0.6652  |  Val Loss: 0.8759\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 480/1000] Train Loss: 0.6387  |  Val Loss: 0.8728\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 481/1000] Train Loss: 0.6422  |  Val Loss: 0.8697\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 482/1000] Train Loss: 0.6757  |  Val Loss: 0.8271\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 483/1000] Train Loss: 0.6588  |  Val Loss: 0.8284\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 484/1000] Train Loss: 0.6598  |  Val Loss: 0.8606\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 485/1000] Train Loss: 0.6471  |  Val Loss: 0.8931\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 486/1000] Train Loss: 0.6749  |  Val Loss: 0.8133\n",
      "Validation loss improved from 0.8213 to 0.8133.\n",
      "[Epoch 487/1000] Train Loss: 0.6767  |  Val Loss: 0.8424\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 488/1000] Train Loss: 0.6482  |  Val Loss: 0.8350\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 489/1000] Train Loss: 0.6436  |  Val Loss: 0.8161\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 490/1000] Train Loss: 0.6557  |  Val Loss: 0.8560\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 491/1000] Train Loss: 0.6875  |  Val Loss: 0.9056\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 492/1000] Train Loss: 0.7709  |  Val Loss: 1.2080\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 493/1000] Train Loss: 0.7141  |  Val Loss: 0.9315\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 494/1000] Train Loss: 0.6688  |  Val Loss: 0.8206\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 495/1000] Train Loss: 0.6798  |  Val Loss: 0.9109\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 496/1000] Train Loss: 0.7107  |  Val Loss: 0.8553\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 497/1000] Train Loss: 0.6712  |  Val Loss: 1.0076\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 498/1000] Train Loss: 0.6830  |  Val Loss: 0.8541\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 499/1000] Train Loss: 0.6401  |  Val Loss: 0.8382\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 500/1000] Train Loss: 0.6396  |  Val Loss: 0.8040\n",
      "Validation loss improved from 0.8133 to 0.8040.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 501/1000] Train Loss: 0.6485  |  Val Loss: 0.8920\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 502/1000] Train Loss: 0.6352  |  Val Loss: 0.8056\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 503/1000] Train Loss: 0.6117  |  Val Loss: 0.8298\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 504/1000] Train Loss: 0.6302  |  Val Loss: 0.8660\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 505/1000] Train Loss: 0.6572  |  Val Loss: 0.9492\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 506/1000] Train Loss: 0.7051  |  Val Loss: 0.8453\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 507/1000] Train Loss: 0.6734  |  Val Loss: 0.8071\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 508/1000] Train Loss: 0.6457  |  Val Loss: 0.8128\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 509/1000] Train Loss: 0.6132  |  Val Loss: 0.8231\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 510/1000] Train Loss: 0.6107  |  Val Loss: 0.8402\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 511/1000] Train Loss: 0.6330  |  Val Loss: 0.8306\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 512/1000] Train Loss: 0.6232  |  Val Loss: 0.8223\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 513/1000] Train Loss: 0.6182  |  Val Loss: 0.8188\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 514/1000] Train Loss: 0.6267  |  Val Loss: 0.8967\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 515/1000] Train Loss: 0.6167  |  Val Loss: 0.8293\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 516/1000] Train Loss: 0.5995  |  Val Loss: 0.8661\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 517/1000] Train Loss: 0.6247  |  Val Loss: 0.8546\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 518/1000] Train Loss: 0.6415  |  Val Loss: 0.8161\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 519/1000] Train Loss: 0.6661  |  Val Loss: 0.8465\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 520/1000] Train Loss: 0.6899  |  Val Loss: 0.9868\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 521/1000] Train Loss: 0.6659  |  Val Loss: 1.0317\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 522/1000] Train Loss: 0.6712  |  Val Loss: 0.9529\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 523/1000] Train Loss: 0.7206  |  Val Loss: 0.7936\n",
      "Validation loss improved from 0.8040 to 0.7936.\n",
      "[Epoch 524/1000] Train Loss: 0.7160  |  Val Loss: 0.8062\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 525/1000] Train Loss: 0.6652  |  Val Loss: 0.9123\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 526/1000] Train Loss: 0.6513  |  Val Loss: 0.8190\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 527/1000] Train Loss: 0.5957  |  Val Loss: 0.8988\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 528/1000] Train Loss: 0.6202  |  Val Loss: 0.8021\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 529/1000] Train Loss: 0.6182  |  Val Loss: 0.8083\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 530/1000] Train Loss: 0.6046  |  Val Loss: 0.7979\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 531/1000] Train Loss: 0.6133  |  Val Loss: 0.8091\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 532/1000] Train Loss: 0.5975  |  Val Loss: 0.8552\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 533/1000] Train Loss: 0.6090  |  Val Loss: 0.8721\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 534/1000] Train Loss: 0.6069  |  Val Loss: 0.8163\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 535/1000] Train Loss: 0.6009  |  Val Loss: 0.8138\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 536/1000] Train Loss: 0.5965  |  Val Loss: 0.8323\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 537/1000] Train Loss: 0.6002  |  Val Loss: 0.7945\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 538/1000] Train Loss: 0.5887  |  Val Loss: 0.8067\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 539/1000] Train Loss: 0.5884  |  Val Loss: 0.8925\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 540/1000] Train Loss: 0.5887  |  Val Loss: 0.8404\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 541/1000] Train Loss: 0.5876  |  Val Loss: 0.8356\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 542/1000] Train Loss: 0.6312  |  Val Loss: 1.1045\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 543/1000] Train Loss: 0.6255  |  Val Loss: 1.0064\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 544/1000] Train Loss: 0.6078  |  Val Loss: 0.9238\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 545/1000] Train Loss: 0.6501  |  Val Loss: 0.8840\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 546/1000] Train Loss: 0.5876  |  Val Loss: 0.7871\n",
      "Validation loss improved from 0.7936 to 0.7871.\n",
      "[Epoch 547/1000] Train Loss: 0.5875  |  Val Loss: 0.9124\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 548/1000] Train Loss: 0.5818  |  Val Loss: 0.8589\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 549/1000] Train Loss: 0.6139  |  Val Loss: 0.8106\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 550/1000] Train Loss: 0.5917  |  Val Loss: 0.9838\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 551/1000] Train Loss: 0.6948  |  Val Loss: 0.8989\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 552/1000] Train Loss: 0.6461  |  Val Loss: 0.8443\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 553/1000] Train Loss: 0.6020  |  Val Loss: 0.9509\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 554/1000] Train Loss: 0.5972  |  Val Loss: 0.8938\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 555/1000] Train Loss: 0.6248  |  Val Loss: 0.8182\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 556/1000] Train Loss: 0.6069  |  Val Loss: 0.8092\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 557/1000] Train Loss: 0.6109  |  Val Loss: 0.8150\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 558/1000] Train Loss: 0.5807  |  Val Loss: 0.8070\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 559/1000] Train Loss: 0.5715  |  Val Loss: 0.8203\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 560/1000] Train Loss: 0.5827  |  Val Loss: 0.8473\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 561/1000] Train Loss: 0.5692  |  Val Loss: 0.8340\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 562/1000] Train Loss: 0.5655  |  Val Loss: 0.8693\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 563/1000] Train Loss: 0.5972  |  Val Loss: 0.9459\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 564/1000] Train Loss: 0.6015  |  Val Loss: 0.8789\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 565/1000] Train Loss: 0.6012  |  Val Loss: 1.0408\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 566/1000] Train Loss: 0.6693  |  Val Loss: 0.8862\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 567/1000] Train Loss: 0.6463  |  Val Loss: 0.9139\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 568/1000] Train Loss: 0.6690  |  Val Loss: 0.8204\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 569/1000] Train Loss: 0.6345  |  Val Loss: 0.7892\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 570/1000] Train Loss: 0.6365  |  Val Loss: 0.7805\n",
      "Validation loss improved from 0.7871 to 0.7805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 571/1000] Train Loss: 0.5810  |  Val Loss: 0.8062\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 572/1000] Train Loss: 0.6116  |  Val Loss: 1.0107\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 573/1000] Train Loss: 0.6219  |  Val Loss: 0.9450\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 574/1000] Train Loss: 0.6756  |  Val Loss: 1.0747\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 575/1000] Train Loss: 0.6312  |  Val Loss: 0.8480\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 576/1000] Train Loss: 0.6061  |  Val Loss: 0.8179\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 577/1000] Train Loss: 0.6179  |  Val Loss: 0.8137\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 578/1000] Train Loss: 0.6045  |  Val Loss: 0.7771\n",
      "Validation loss improved from 0.7805 to 0.7771.\n",
      "[Epoch 579/1000] Train Loss: 0.6136  |  Val Loss: 0.8486\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 580/1000] Train Loss: 0.5757  |  Val Loss: 0.7807\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 581/1000] Train Loss: 0.5673  |  Val Loss: 0.8032\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 582/1000] Train Loss: 0.5808  |  Val Loss: 0.8140\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 583/1000] Train Loss: 0.5720  |  Val Loss: 0.8038\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 584/1000] Train Loss: 0.5789  |  Val Loss: 0.8386\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 585/1000] Train Loss: 0.5718  |  Val Loss: 0.9123\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 586/1000] Train Loss: 0.5871  |  Val Loss: 0.9061\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 587/1000] Train Loss: 0.5643  |  Val Loss: 0.8902\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 588/1000] Train Loss: 0.5844  |  Val Loss: 0.8288\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 589/1000] Train Loss: 0.5734  |  Val Loss: 0.8366\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 590/1000] Train Loss: 0.5621  |  Val Loss: 0.8252\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 591/1000] Train Loss: 0.5562  |  Val Loss: 0.7990\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 592/1000] Train Loss: 0.5550  |  Val Loss: 0.8010\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 593/1000] Train Loss: 0.5513  |  Val Loss: 0.8215\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 594/1000] Train Loss: 0.5887  |  Val Loss: 0.8031\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 595/1000] Train Loss: 0.5823  |  Val Loss: 0.8064\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 596/1000] Train Loss: 0.5745  |  Val Loss: 0.8518\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 597/1000] Train Loss: 0.5827  |  Val Loss: 0.9430\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 598/1000] Train Loss: 0.6056  |  Val Loss: 0.8212\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 599/1000] Train Loss: 0.5643  |  Val Loss: 0.7933\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 600/1000] Train Loss: 0.5631  |  Val Loss: 0.7888\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 601/1000] Train Loss: 0.5503  |  Val Loss: 0.8846\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 602/1000] Train Loss: 0.5720  |  Val Loss: 0.8373\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 603/1000] Train Loss: 0.5715  |  Val Loss: 0.7873\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 604/1000] Train Loss: 0.5654  |  Val Loss: 0.8103\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 605/1000] Train Loss: 0.5517  |  Val Loss: 0.8200\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 606/1000] Train Loss: 0.6088  |  Val Loss: 0.8012\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 607/1000] Train Loss: 0.6424  |  Val Loss: 0.9637\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 608/1000] Train Loss: 0.6520  |  Val Loss: 0.8250\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 609/1000] Train Loss: 0.6606  |  Val Loss: 0.8450\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 610/1000] Train Loss: 0.5889  |  Val Loss: 0.8154\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 611/1000] Train Loss: 0.5509  |  Val Loss: 0.9213\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 612/1000] Train Loss: 0.5827  |  Val Loss: 0.9076\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 613/1000] Train Loss: 0.5602  |  Val Loss: 0.9059\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 614/1000] Train Loss: 0.5867  |  Val Loss: 0.8379\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 615/1000] Train Loss: 0.5546  |  Val Loss: 0.8050\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 616/1000] Train Loss: 0.5504  |  Val Loss: 0.7988\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 617/1000] Train Loss: 0.5487  |  Val Loss: 0.8244\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 618/1000] Train Loss: 0.5616  |  Val Loss: 0.8230\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 619/1000] Train Loss: 0.5743  |  Val Loss: 0.8682\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 620/1000] Train Loss: 0.5387  |  Val Loss: 0.7868\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 621/1000] Train Loss: 0.5667  |  Val Loss: 0.9062\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 622/1000] Train Loss: 0.5519  |  Val Loss: 0.8438\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 623/1000] Train Loss: 0.5839  |  Val Loss: 0.8369\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 624/1000] Train Loss: 0.5436  |  Val Loss: 0.7951\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 625/1000] Train Loss: 0.5344  |  Val Loss: 0.7747\n",
      "Validation loss improved from 0.7771 to 0.7747.\n",
      "[Epoch 626/1000] Train Loss: 0.5900  |  Val Loss: 0.7700\n",
      "Validation loss improved from 0.7747 to 0.7700.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 627/1000] Train Loss: 0.5658  |  Val Loss: 0.8487\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 628/1000] Train Loss: 0.6349  |  Val Loss: 0.7733\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 629/1000] Train Loss: 0.5565  |  Val Loss: 0.7843\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 630/1000] Train Loss: 0.5659  |  Val Loss: 0.7904\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 631/1000] Train Loss: 0.5507  |  Val Loss: 0.8320\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 632/1000] Train Loss: 0.5707  |  Val Loss: 0.8335\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 633/1000] Train Loss: 0.5691  |  Val Loss: 0.8099\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 634/1000] Train Loss: 0.5546  |  Val Loss: 0.8250\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 635/1000] Train Loss: 0.5316  |  Val Loss: 0.7746\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 636/1000] Train Loss: 0.5406  |  Val Loss: 0.7830\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 637/1000] Train Loss: 0.5578  |  Val Loss: 0.9653\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 638/1000] Train Loss: 0.5527  |  Val Loss: 0.8269\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 639/1000] Train Loss: 0.5423  |  Val Loss: 0.9031\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 640/1000] Train Loss: 0.5850  |  Val Loss: 0.8457\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 641/1000] Train Loss: 0.6051  |  Val Loss: 0.7755\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 642/1000] Train Loss: 0.6321  |  Val Loss: 0.8263\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 643/1000] Train Loss: 0.6253  |  Val Loss: 0.8087\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 644/1000] Train Loss: 0.5222  |  Val Loss: 0.7874\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 645/1000] Train Loss: 0.5220  |  Val Loss: 0.7773\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 646/1000] Train Loss: 0.5444  |  Val Loss: 0.8275\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 647/1000] Train Loss: 0.5688  |  Val Loss: 0.8259\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 648/1000] Train Loss: 0.5643  |  Val Loss: 0.9712\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 649/1000] Train Loss: 0.6091  |  Val Loss: 0.9476\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 650/1000] Train Loss: 0.5545  |  Val Loss: 0.9674\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 651/1000] Train Loss: 0.5521  |  Val Loss: 0.8012\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 652/1000] Train Loss: 0.5460  |  Val Loss: 0.7791\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 653/1000] Train Loss: 0.5129  |  Val Loss: 0.7773\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 654/1000] Train Loss: 0.5175  |  Val Loss: 0.8112\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 655/1000] Train Loss: 0.5722  |  Val Loss: 0.7933\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 656/1000] Train Loss: 0.5115  |  Val Loss: 0.8205\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 657/1000] Train Loss: 0.5460  |  Val Loss: 0.7663\n",
      "Validation loss improved from 0.7700 to 0.7663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 658/1000] Train Loss: 0.5738  |  Val Loss: 0.7886\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 659/1000] Train Loss: 0.5246  |  Val Loss: 0.7740\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 660/1000] Train Loss: 0.5037  |  Val Loss: 0.7834\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 661/1000] Train Loss: 0.5257  |  Val Loss: 0.8118\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 662/1000] Train Loss: 0.5602  |  Val Loss: 0.8984\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 663/1000] Train Loss: 0.6000  |  Val Loss: 0.7910\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 664/1000] Train Loss: 0.5643  |  Val Loss: 0.7495\n",
      "Validation loss improved from 0.7663 to 0.7495.\n",
      "[Epoch 665/1000] Train Loss: 0.5850  |  Val Loss: 0.8035\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 666/1000] Train Loss: 0.5934  |  Val Loss: 0.8776\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 667/1000] Train Loss: 0.6841  |  Val Loss: 0.9809\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 668/1000] Train Loss: 0.5393  |  Val Loss: 0.8475\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 669/1000] Train Loss: 0.5597  |  Val Loss: 1.1025\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 670/1000] Train Loss: 0.5734  |  Val Loss: 0.8394\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 671/1000] Train Loss: 0.5366  |  Val Loss: 0.8009\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 672/1000] Train Loss: 0.5128  |  Val Loss: 0.8005\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 673/1000] Train Loss: 0.5320  |  Val Loss: 0.7514\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 674/1000] Train Loss: 0.4989  |  Val Loss: 0.8407\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 675/1000] Train Loss: 0.5759  |  Val Loss: 0.7795\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 676/1000] Train Loss: 0.5413  |  Val Loss: 0.7981\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 677/1000] Train Loss: 0.5645  |  Val Loss: 0.9036\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 678/1000] Train Loss: 0.5759  |  Val Loss: 1.3676\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 679/1000] Train Loss: 0.6796  |  Val Loss: 0.9441\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 680/1000] Train Loss: 0.5715  |  Val Loss: 0.7557\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 681/1000] Train Loss: 0.5373  |  Val Loss: 0.8268\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 682/1000] Train Loss: 0.5369  |  Val Loss: 0.7739\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 683/1000] Train Loss: 0.5053  |  Val Loss: 0.7740\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 684/1000] Train Loss: 0.5444  |  Val Loss: 0.7288\n",
      "Validation loss improved from 0.7495 to 0.7288.\n",
      "[Epoch 685/1000] Train Loss: 0.5239  |  Val Loss: 0.7565\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 686/1000] Train Loss: 0.5045  |  Val Loss: 0.7448\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 687/1000] Train Loss: 0.5162  |  Val Loss: 0.8866\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 688/1000] Train Loss: 0.5522  |  Val Loss: 0.7615\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 689/1000] Train Loss: 0.5860  |  Val Loss: 0.7482\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 690/1000] Train Loss: 0.6092  |  Val Loss: 0.7501\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 691/1000] Train Loss: 0.5546  |  Val Loss: 0.7384\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 692/1000] Train Loss: 0.5319  |  Val Loss: 0.7013\n",
      "Validation loss improved from 0.7288 to 0.7013.\n",
      "[Epoch 693/1000] Train Loss: 0.5340  |  Val Loss: 0.7471\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 694/1000] Train Loss: 0.5877  |  Val Loss: 0.7027\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 695/1000] Train Loss: 0.6082  |  Val Loss: 0.7711\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 696/1000] Train Loss: 0.5632  |  Val Loss: 0.9393\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 697/1000] Train Loss: 0.5333  |  Val Loss: 0.7404\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 698/1000] Train Loss: 0.5175  |  Val Loss: 0.7937\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 699/1000] Train Loss: 0.5079  |  Val Loss: 0.7139\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 700/1000] Train Loss: 0.5014  |  Val Loss: 0.7711\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 701/1000] Train Loss: 0.4864  |  Val Loss: 0.7670\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 702/1000] Train Loss: 0.4952  |  Val Loss: 0.7969\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 703/1000] Train Loss: 0.5282  |  Val Loss: 0.7526\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 704/1000] Train Loss: 0.5133  |  Val Loss: 0.7214\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 705/1000] Train Loss: 0.5077  |  Val Loss: 0.8626\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 706/1000] Train Loss: 0.5691  |  Val Loss: 0.7975\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 707/1000] Train Loss: 0.5754  |  Val Loss: 0.9824\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 708/1000] Train Loss: 0.5687  |  Val Loss: 0.8218\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 709/1000] Train Loss: 0.5043  |  Val Loss: 0.7897\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 710/1000] Train Loss: 0.4821  |  Val Loss: 0.7885\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 711/1000] Train Loss: 0.5238  |  Val Loss: 0.6948\n",
      "Validation loss improved from 0.7013 to 0.6948.\n",
      "[Epoch 712/1000] Train Loss: 0.4978  |  Val Loss: 0.7106\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 713/1000] Train Loss: 0.4819  |  Val Loss: 0.7062\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 714/1000] Train Loss: 0.4791  |  Val Loss: 0.7272\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 715/1000] Train Loss: 0.4759  |  Val Loss: 0.7078\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 716/1000] Train Loss: 0.4939  |  Val Loss: 0.6991\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 717/1000] Train Loss: 0.4860  |  Val Loss: 0.7685\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 718/1000] Train Loss: 0.5038  |  Val Loss: 0.7590\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 719/1000] Train Loss: 0.4989  |  Val Loss: 0.7709\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 720/1000] Train Loss: 0.5110  |  Val Loss: 0.7981\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 721/1000] Train Loss: 0.5243  |  Val Loss: 0.6984\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 722/1000] Train Loss: 0.5148  |  Val Loss: 0.7933\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 723/1000] Train Loss: 0.5424  |  Val Loss: 0.7145\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 724/1000] Train Loss: 0.5132  |  Val Loss: 0.7485\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 725/1000] Train Loss: 0.5047  |  Val Loss: 0.7649\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 726/1000] Train Loss: 0.5282  |  Val Loss: 0.7079\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 727/1000] Train Loss: 0.4962  |  Val Loss: 0.7419\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 728/1000] Train Loss: 0.5378  |  Val Loss: 0.7067\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 729/1000] Train Loss: 0.5121  |  Val Loss: 0.7054\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 730/1000] Train Loss: 0.4856  |  Val Loss: 0.7235\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 731/1000] Train Loss: 0.5064  |  Val Loss: 0.8389\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 732/1000] Train Loss: 0.4973  |  Val Loss: 0.7941\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 733/1000] Train Loss: 0.5295  |  Val Loss: 0.7846\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 734/1000] Train Loss: 0.5390  |  Val Loss: 0.8201\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 735/1000] Train Loss: 0.5009  |  Val Loss: 0.7790\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 736/1000] Train Loss: 0.5245  |  Val Loss: 0.9508\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 737/1000] Train Loss: 0.5529  |  Val Loss: 0.7622\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 738/1000] Train Loss: 0.4820  |  Val Loss: 0.8581\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 739/1000] Train Loss: 0.4850  |  Val Loss: 0.7496\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 740/1000] Train Loss: 0.4762  |  Val Loss: 0.7574\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 741/1000] Train Loss: 0.5039  |  Val Loss: 0.8102\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 742/1000] Train Loss: 0.5056  |  Val Loss: 0.7882\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 743/1000] Train Loss: 0.5083  |  Val Loss: 0.7738\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 744/1000] Train Loss: 0.4984  |  Val Loss: 0.7801\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 745/1000] Train Loss: 0.4853  |  Val Loss: 0.7050\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 746/1000] Train Loss: 0.5231  |  Val Loss: 0.7467\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 747/1000] Train Loss: 0.5158  |  Val Loss: 0.8406\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 748/1000] Train Loss: 0.5151  |  Val Loss: 0.7735\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 749/1000] Train Loss: 0.5233  |  Val Loss: 0.7724\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 750/1000] Train Loss: 0.4784  |  Val Loss: 0.7176\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 751/1000] Train Loss: 0.4768  |  Val Loss: 0.7606\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 752/1000] Train Loss: 0.4933  |  Val Loss: 0.7582\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 753/1000] Train Loss: 0.4746  |  Val Loss: 0.7555\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 754/1000] Train Loss: 0.5016  |  Val Loss: 0.8630\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 755/1000] Train Loss: 0.4725  |  Val Loss: 0.6693\n",
      "Validation loss improved from 0.6948 to 0.6693.\n",
      "[Epoch 756/1000] Train Loss: 0.4669  |  Val Loss: 0.6877\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 757/1000] Train Loss: 0.5111  |  Val Loss: 0.7541\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 758/1000] Train Loss: 0.4656  |  Val Loss: 0.6970\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 759/1000] Train Loss: 0.5036  |  Val Loss: 0.7499\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 760/1000] Train Loss: 0.4737  |  Val Loss: 0.7916\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 761/1000] Train Loss: 0.5168  |  Val Loss: 0.7503\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 762/1000] Train Loss: 0.5258  |  Val Loss: 0.7182\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 763/1000] Train Loss: 0.5167  |  Val Loss: 0.7330\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 764/1000] Train Loss: 0.4874  |  Val Loss: 0.7289\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 765/1000] Train Loss: 0.5205  |  Val Loss: 1.0054\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 766/1000] Train Loss: 0.5914  |  Val Loss: 0.8756\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 767/1000] Train Loss: 0.5653  |  Val Loss: 0.6696\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 768/1000] Train Loss: 0.5257  |  Val Loss: 0.6913\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 769/1000] Train Loss: 0.5302  |  Val Loss: 0.7077\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 770/1000] Train Loss: 0.5163  |  Val Loss: 0.7329\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 771/1000] Train Loss: 0.5116  |  Val Loss: 0.6759\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 772/1000] Train Loss: 0.5001  |  Val Loss: 0.7018\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 773/1000] Train Loss: 0.5309  |  Val Loss: 0.7715\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 774/1000] Train Loss: 0.4980  |  Val Loss: 0.6719\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 775/1000] Train Loss: 0.4831  |  Val Loss: 0.7624\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 776/1000] Train Loss: 0.4748  |  Val Loss: 0.7669\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 777/1000] Train Loss: 0.4968  |  Val Loss: 0.7673\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 778/1000] Train Loss: 0.4578  |  Val Loss: 0.6627\n",
      "Validation loss improved from 0.6693 to 0.6627.\n",
      "[Epoch 779/1000] Train Loss: 0.4516  |  Val Loss: 0.6990\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 780/1000] Train Loss: 0.4989  |  Val Loss: 0.7612\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 781/1000] Train Loss: 0.4836  |  Val Loss: 0.7059\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 782/1000] Train Loss: 0.4608  |  Val Loss: 0.7174\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 783/1000] Train Loss: 0.4635  |  Val Loss: 0.8108\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 784/1000] Train Loss: 0.5231  |  Val Loss: 0.8831\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 785/1000] Train Loss: 0.5218  |  Val Loss: 0.6731\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 786/1000] Train Loss: 0.4520  |  Val Loss: 0.7186\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 787/1000] Train Loss: 0.4765  |  Val Loss: 0.6742\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 788/1000] Train Loss: 0.4702  |  Val Loss: 0.7005\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 789/1000] Train Loss: 0.4528  |  Val Loss: 0.6744\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 790/1000] Train Loss: 0.4507  |  Val Loss: 0.6927\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 791/1000] Train Loss: 0.4641  |  Val Loss: 0.6930\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 792/1000] Train Loss: 0.4578  |  Val Loss: 0.7621\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 793/1000] Train Loss: 0.4584  |  Val Loss: 0.7550\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 794/1000] Train Loss: 0.5452  |  Val Loss: 0.8814\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 795/1000] Train Loss: 0.5140  |  Val Loss: 0.7412\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 796/1000] Train Loss: 0.4768  |  Val Loss: 0.6821\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 797/1000] Train Loss: 0.4742  |  Val Loss: 0.6904\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 798/1000] Train Loss: 0.4436  |  Val Loss: 0.7047\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 799/1000] Train Loss: 0.4481  |  Val Loss: 0.7431\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 800/1000] Train Loss: 0.4615  |  Val Loss: 0.7621\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 801/1000] Train Loss: 0.5437  |  Val Loss: 0.7331\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 802/1000] Train Loss: 0.4892  |  Val Loss: 0.7600\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 803/1000] Train Loss: 0.5037  |  Val Loss: 0.7360\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 804/1000] Train Loss: 0.4667  |  Val Loss: 0.7761\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 805/1000] Train Loss: 0.4859  |  Val Loss: 0.8086\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 806/1000] Train Loss: 0.5286  |  Val Loss: 0.9216\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 807/1000] Train Loss: 0.5733  |  Val Loss: 0.6970\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 808/1000] Train Loss: 0.4703  |  Val Loss: 0.6705\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 809/1000] Train Loss: 0.4475  |  Val Loss: 0.6536\n",
      "Validation loss improved from 0.6627 to 0.6536.\n",
      "[Epoch 810/1000] Train Loss: 0.4654  |  Val Loss: 0.6960\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 811/1000] Train Loss: 0.4769  |  Val Loss: 0.7762\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 812/1000] Train Loss: 0.4764  |  Val Loss: 0.6485\n",
      "Validation loss improved from 0.6536 to 0.6485.\n",
      "[Epoch 813/1000] Train Loss: 0.4707  |  Val Loss: 0.6723\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 814/1000] Train Loss: 0.4761  |  Val Loss: 0.6725\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 815/1000] Train Loss: 0.4433  |  Val Loss: 0.7078\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 816/1000] Train Loss: 0.4423  |  Val Loss: 0.7233\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 817/1000] Train Loss: 0.4686  |  Val Loss: 0.6519\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 818/1000] Train Loss: 0.4417  |  Val Loss: 0.6537\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 819/1000] Train Loss: 0.4492  |  Val Loss: 0.6866\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 820/1000] Train Loss: 0.4436  |  Val Loss: 0.7377\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 821/1000] Train Loss: 0.4302  |  Val Loss: 0.6635\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 822/1000] Train Loss: 0.4327  |  Val Loss: 0.6955\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 823/1000] Train Loss: 0.4478  |  Val Loss: 0.6613\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 824/1000] Train Loss: 0.4727  |  Val Loss: 0.7226\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 825/1000] Train Loss: 0.5397  |  Val Loss: 0.7343\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 826/1000] Train Loss: 0.5758  |  Val Loss: 0.7963\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 827/1000] Train Loss: 0.5328  |  Val Loss: 0.6790\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 828/1000] Train Loss: 0.5290  |  Val Loss: 0.7305\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 829/1000] Train Loss: 0.4684  |  Val Loss: 0.6633\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 830/1000] Train Loss: 0.4586  |  Val Loss: 0.6762\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 831/1000] Train Loss: 0.4445  |  Val Loss: 0.6559\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 832/1000] Train Loss: 0.4310  |  Val Loss: 0.6446\n",
      "Validation loss improved from 0.6485 to 0.6446.\n",
      "[Epoch 833/1000] Train Loss: 0.4325  |  Val Loss: 0.6595\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 834/1000] Train Loss: 0.4402  |  Val Loss: 0.7632\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 835/1000] Train Loss: 0.4717  |  Val Loss: 0.8522\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 836/1000] Train Loss: 0.5090  |  Val Loss: 0.7797\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 837/1000] Train Loss: 0.5115  |  Val Loss: 1.0311\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 838/1000] Train Loss: 0.5322  |  Val Loss: 0.7263\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 839/1000] Train Loss: 0.4545  |  Val Loss: 0.6550\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 840/1000] Train Loss: 0.4434  |  Val Loss: 0.7952\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 841/1000] Train Loss: 0.5073  |  Val Loss: 0.7372\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 842/1000] Train Loss: 0.5184  |  Val Loss: 0.7380\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 843/1000] Train Loss: 0.5112  |  Val Loss: 0.7512\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 844/1000] Train Loss: 0.4252  |  Val Loss: 0.7475\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 845/1000] Train Loss: 0.4456  |  Val Loss: 0.7423\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 846/1000] Train Loss: 0.4255  |  Val Loss: 0.6365\n",
      "Validation loss improved from 0.6446 to 0.6365.\n",
      "[Epoch 847/1000] Train Loss: 0.4147  |  Val Loss: 0.6404\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 848/1000] Train Loss: 0.4201  |  Val Loss: 0.6723\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 849/1000] Train Loss: 0.4332  |  Val Loss: 0.6604\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 850/1000] Train Loss: 0.4247  |  Val Loss: 0.7362\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 851/1000] Train Loss: 0.4484  |  Val Loss: 0.6503\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 852/1000] Train Loss: 0.4596  |  Val Loss: 0.6445\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 853/1000] Train Loss: 0.5341  |  Val Loss: 0.6813\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 854/1000] Train Loss: 0.4723  |  Val Loss: 0.7476\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 855/1000] Train Loss: 0.5347  |  Val Loss: 0.7489\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 856/1000] Train Loss: 0.4500  |  Val Loss: 0.6591\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 857/1000] Train Loss: 0.4320  |  Val Loss: 0.7940\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 858/1000] Train Loss: 0.4558  |  Val Loss: 0.7337\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 859/1000] Train Loss: 0.4375  |  Val Loss: 0.7616\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 860/1000] Train Loss: 0.4480  |  Val Loss: 0.6612\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 861/1000] Train Loss: 0.4339  |  Val Loss: 0.7182\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 862/1000] Train Loss: 0.4407  |  Val Loss: 0.7090\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 863/1000] Train Loss: 0.4870  |  Val Loss: 0.6669\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 864/1000] Train Loss: 0.4512  |  Val Loss: 0.6683\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 865/1000] Train Loss: 0.4576  |  Val Loss: 0.6679\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 866/1000] Train Loss: 0.4736  |  Val Loss: 0.6425\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 867/1000] Train Loss: 0.4246  |  Val Loss: 0.6792\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 868/1000] Train Loss: 0.4395  |  Val Loss: 0.9331\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 869/1000] Train Loss: 0.5350  |  Val Loss: 1.0144\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 870/1000] Train Loss: 0.5494  |  Val Loss: 0.8632\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 871/1000] Train Loss: 0.4562  |  Val Loss: 1.1220\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 872/1000] Train Loss: 0.5398  |  Val Loss: 1.0166\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 873/1000] Train Loss: 0.5562  |  Val Loss: 0.8228\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 874/1000] Train Loss: 0.4456  |  Val Loss: 0.7541\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 875/1000] Train Loss: 0.4814  |  Val Loss: 0.7333\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 876/1000] Train Loss: 0.4378  |  Val Loss: 0.6773\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 877/1000] Train Loss: 0.4091  |  Val Loss: 0.6917\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 878/1000] Train Loss: 0.4189  |  Val Loss: 0.6333\n",
      "Validation loss improved from 0.6365 to 0.6333.\n",
      "[Epoch 879/1000] Train Loss: 0.4262  |  Val Loss: 0.6659\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 880/1000] Train Loss: 0.4128  |  Val Loss: 0.7009\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 881/1000] Train Loss: 0.4101  |  Val Loss: 0.6692\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 882/1000] Train Loss: 0.4393  |  Val Loss: 0.8891\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 883/1000] Train Loss: 0.5135  |  Val Loss: 0.8094\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 884/1000] Train Loss: 0.5086  |  Val Loss: 0.6978\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 885/1000] Train Loss: 0.4433  |  Val Loss: 0.6502\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 886/1000] Train Loss: 0.4276  |  Val Loss: 0.7267\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 887/1000] Train Loss: 0.4141  |  Val Loss: 0.7560\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 888/1000] Train Loss: 0.4067  |  Val Loss: 0.7042\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 889/1000] Train Loss: 0.4218  |  Val Loss: 0.6754\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 890/1000] Train Loss: 0.4222  |  Val Loss: 0.7544\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 891/1000] Train Loss: 0.4457  |  Val Loss: 0.8148\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 892/1000] Train Loss: 0.4235  |  Val Loss: 0.7134\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 893/1000] Train Loss: 0.4177  |  Val Loss: 0.6236\n",
      "Validation loss improved from 0.6333 to 0.6236.\n",
      "[Epoch 894/1000] Train Loss: 0.4213  |  Val Loss: 0.6589\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 895/1000] Train Loss: 0.4822  |  Val Loss: 0.6488\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 896/1000] Train Loss: 0.4509  |  Val Loss: 0.8431\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 897/1000] Train Loss: 0.4657  |  Val Loss: 0.6575\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 898/1000] Train Loss: 0.4333  |  Val Loss: 0.7812\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 899/1000] Train Loss: 0.4684  |  Val Loss: 0.6333\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 900/1000] Train Loss: 0.4231  |  Val Loss: 0.6585\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 901/1000] Train Loss: 0.4065  |  Val Loss: 0.6748\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 902/1000] Train Loss: 0.3941  |  Val Loss: 0.6296\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 903/1000] Train Loss: 0.3978  |  Val Loss: 0.6775\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 904/1000] Train Loss: 0.3973  |  Val Loss: 0.6192\n",
      "Validation loss improved from 0.6236 to 0.6192.\n",
      "[Epoch 905/1000] Train Loss: 0.4143  |  Val Loss: 0.7050\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 906/1000] Train Loss: 0.3960  |  Val Loss: 0.8343\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 907/1000] Train Loss: 0.4742  |  Val Loss: 0.8448\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 908/1000] Train Loss: 0.4704  |  Val Loss: 0.9653\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 909/1000] Train Loss: 0.4235  |  Val Loss: 0.6334\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 910/1000] Train Loss: 0.4028  |  Val Loss: 0.6851\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 911/1000] Train Loss: 0.3946  |  Val Loss: 0.6583\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 912/1000] Train Loss: 0.4202  |  Val Loss: 0.6423\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 913/1000] Train Loss: 0.4085  |  Val Loss: 0.6267\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 914/1000] Train Loss: 0.4228  |  Val Loss: 0.6408\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 915/1000] Train Loss: 0.4475  |  Val Loss: 0.6460\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 916/1000] Train Loss: 0.4296  |  Val Loss: 0.6753\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 917/1000] Train Loss: 0.3973  |  Val Loss: 0.6609\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 918/1000] Train Loss: 0.3962  |  Val Loss: 0.6397\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 919/1000] Train Loss: 0.4026  |  Val Loss: 0.6306\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 920/1000] Train Loss: 0.4349  |  Val Loss: 0.6631\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 921/1000] Train Loss: 0.4153  |  Val Loss: 0.6638\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 922/1000] Train Loss: 0.4424  |  Val Loss: 0.6722\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 923/1000] Train Loss: 0.4377  |  Val Loss: 0.6384\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 924/1000] Train Loss: 0.4198  |  Val Loss: 0.6922\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 925/1000] Train Loss: 0.4029  |  Val Loss: 0.7450\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 926/1000] Train Loss: 0.4000  |  Val Loss: 0.6929\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 927/1000] Train Loss: 0.3988  |  Val Loss: 0.6205\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 928/1000] Train Loss: 0.4078  |  Val Loss: 0.6463\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 929/1000] Train Loss: 0.4037  |  Val Loss: 0.6482\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 930/1000] Train Loss: 0.3992  |  Val Loss: 0.6672\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 931/1000] Train Loss: 0.4046  |  Val Loss: 0.6424\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 932/1000] Train Loss: 0.4072  |  Val Loss: 0.6306\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 933/1000] Train Loss: 0.4433  |  Val Loss: 0.6311\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 934/1000] Train Loss: 0.4216  |  Val Loss: 0.6158\n",
      "Validation loss improved from 0.6192 to 0.6158.\n",
      "[Epoch 935/1000] Train Loss: 0.4177  |  Val Loss: 0.6405\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 936/1000] Train Loss: 0.4057  |  Val Loss: 0.6260\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 937/1000] Train Loss: 0.4348  |  Val Loss: 0.6996\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 938/1000] Train Loss: 0.4327  |  Val Loss: 0.6483\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 939/1000] Train Loss: 0.4393  |  Val Loss: 0.7592\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 940/1000] Train Loss: 0.4705  |  Val Loss: 0.9361\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 941/1000] Train Loss: 0.4795  |  Val Loss: 1.0642\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 942/1000] Train Loss: 0.4802  |  Val Loss: 0.7369\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 943/1000] Train Loss: 0.4419  |  Val Loss: 0.7792\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 944/1000] Train Loss: 0.4067  |  Val Loss: 0.7030\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 945/1000] Train Loss: 0.4233  |  Val Loss: 0.6897\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 946/1000] Train Loss: 0.4419  |  Val Loss: 0.9103\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 947/1000] Train Loss: 0.4548  |  Val Loss: 0.7896\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 948/1000] Train Loss: 0.4219  |  Val Loss: 0.6969\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 949/1000] Train Loss: 0.4096  |  Val Loss: 0.7435\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 950/1000] Train Loss: 0.4308  |  Val Loss: 0.6447\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 951/1000] Train Loss: 0.4740  |  Val Loss: 1.1259\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 952/1000] Train Loss: 0.6416  |  Val Loss: 1.2882\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 953/1000] Train Loss: 0.6500  |  Val Loss: 1.0351\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 954/1000] Train Loss: 0.4658  |  Val Loss: 0.6922\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 955/1000] Train Loss: 0.4130  |  Val Loss: 0.8796\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 956/1000] Train Loss: 0.4201  |  Val Loss: 0.6848\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 957/1000] Train Loss: 0.4191  |  Val Loss: 0.6240\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 958/1000] Train Loss: 0.3999  |  Val Loss: 0.6847\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 959/1000] Train Loss: 0.4000  |  Val Loss: 0.6993\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 960/1000] Train Loss: 0.4248  |  Val Loss: 0.6743\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 961/1000] Train Loss: 0.4129  |  Val Loss: 0.6746\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 962/1000] Train Loss: 0.4050  |  Val Loss: 0.6469\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 963/1000] Train Loss: 0.3874  |  Val Loss: 0.6112\n",
      "Validation loss improved from 0.6158 to 0.6112.\n",
      "[Epoch 964/1000] Train Loss: 0.3817  |  Val Loss: 0.6461\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 965/1000] Train Loss: 0.3781  |  Val Loss: 0.6234\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 966/1000] Train Loss: 0.3793  |  Val Loss: 0.6202\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 967/1000] Train Loss: 0.4132  |  Val Loss: 0.8936\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 968/1000] Train Loss: 0.4298  |  Val Loss: 0.7489\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 969/1000] Train Loss: 0.4221  |  Val Loss: 0.6403\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 970/1000] Train Loss: 0.4350  |  Val Loss: 0.7849\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 971/1000] Train Loss: 0.4611  |  Val Loss: 0.6433\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 972/1000] Train Loss: 0.4009  |  Val Loss: 0.6673\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 973/1000] Train Loss: 0.3856  |  Val Loss: 0.6185\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 974/1000] Train Loss: 0.4034  |  Val Loss: 0.7134\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 975/1000] Train Loss: 0.4172  |  Val Loss: 0.8160\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 976/1000] Train Loss: 0.5653  |  Val Loss: 1.1164\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 977/1000] Train Loss: 0.4722  |  Val Loss: 0.6798\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 978/1000] Train Loss: 0.3913  |  Val Loss: 0.6291\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 979/1000] Train Loss: 0.4014  |  Val Loss: 0.6783\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 980/1000] Train Loss: 0.4067  |  Val Loss: 0.8094\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 981/1000] Train Loss: 0.4530  |  Val Loss: 0.6754\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 982/1000] Train Loss: 0.3901  |  Val Loss: 0.6926\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 983/1000] Train Loss: 0.4022  |  Val Loss: 0.8106\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 984/1000] Train Loss: 0.4182  |  Val Loss: 0.7522\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 985/1000] Train Loss: 0.4330  |  Val Loss: 0.7469\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 986/1000] Train Loss: 0.4225  |  Val Loss: 0.8170\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 987/1000] Train Loss: 0.4246  |  Val Loss: 0.7173\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 988/1000] Train Loss: 0.3864  |  Val Loss: 0.6826\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 989/1000] Train Loss: 0.3876  |  Val Loss: 0.7136\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 990/1000] Train Loss: 0.4043  |  Val Loss: 0.7042\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 991/1000] Train Loss: 0.3938  |  Val Loss: 0.6251\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 992/1000] Train Loss: 0.3818  |  Val Loss: 0.6210\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 993/1000] Train Loss: 0.3838  |  Val Loss: 0.6218\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 994/1000] Train Loss: 0.3843  |  Val Loss: 0.6028\n",
      "Validation loss improved from 0.6112 to 0.6028.\n",
      "[Epoch 995/1000] Train Loss: 0.4174  |  Val Loss: 0.6188\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 996/1000] Train Loss: 0.4269  |  Val Loss: 0.6399\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 997/1000] Train Loss: 0.4128  |  Val Loss: 0.6277\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 998/1000] Train Loss: 0.3886  |  Val Loss: 0.7047\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 999/1000] Train Loss: 0.3987  |  Val Loss: 0.6167\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 1000/1000] Train Loss: 0.3974  |  Val Loss: 0.5952\n",
      "Validation loss improved from 0.6028 to 0.5952.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIhCAYAAAB5deq6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAD2Z0lEQVR4nOzdd3hTZfsH8G/SvUuBssvee4vIEmSqIDh+bnxxg4q4XnxVcLxu3HsAblFRXxRUVJYKMmS4EFBKWS2jpbvNPL8/Tk7ynJOT0TRp0ub7uS6uJifJydPQNs+d+37uxyBJkgQiIiIiIiLyyBjuARAREREREUU6Bk5EREREREQ+MHAiIiIiIiLygYETERERERGRDwyciIiIiIiIfGDgRERERERE5AMDJyIiIiIiIh8YOBEREREREfnAwImIiIiIiMgHBk5ERDVgMBj8+rdu3bpaPc/ChQthMBgCeuy6deuCMoZIN3PmTLRr187j7SdOnEB8fDz+7//+z+N9SktLkZycjHPPPdfv5126dCkMBgMOHDjg91hEBoMBCxcu9Pv5FEePHsXChQuxc+dOt9tq8/NSW+3atcPZZ58dlucmIqpLseEeABFRfbJp0ybV9QcffBBr167FmjVrVMd79OhRq+e5+uqrMXHixIAeO2DAAGzatKnWY6jvmjZtinPPPReff/45Tp06hUaNGrnd58MPP0RVVRVmzZpVq+e69957ccstt9TqHL4cPXoU999/P9q1a4d+/fqpbqvNzwsREfmHgRMRUQ2cdtppqutNmzaF0Wh0O65VWVmJ5ORkv5+ndevWaN26dUBjTE9P9zmeaDFr1iwsX74c7733HubMmeN2++LFi9GsWTNMmTKlVs/TsWPHWj2+tmrz80JERP5hqR4RUZCNHj0avXr1woYNG3D66acjOTkZ//rXvwAAy5Ytw/jx49GiRQskJSWhe/fu+Pe//42KigrVOfRKr5SSqK+//hoDBgxAUlISunXrhsWLF6vup1eqN3PmTKSmpuLvv//G5MmTkZqaijZt2uC2226DyWRSPf7w4cM4//zzkZaWhszMTFx66aXYunUrDAYDli5d6vV7P3HiBG688Ub06NEDqampyM7OxplnnokffvhBdb8DBw7AYDDgySefxFNPPYX27dsjNTUVw4YNw88//+x23qVLl6Jr165ISEhA9+7d8fbbb3sdh2LChAlo3bo1lixZ4nbb7t27sXnzZlxxxRWIjY3Ft99+i6lTp6J169ZITExEp06dcN111+HkyZM+n0evVK+0tBTXXHMNGjdujNTUVEycOBF79+51e+zff/+Nq666Cp07d0ZycjJatWqFc845B7/99pvzPuvWrcPgwYMBAFdddZWzJFQp+dP7ebHb7Xj88cfRrVs3JCQkIDs7G1dccQUOHz6sup/y87p161aMGDECycnJ6NChAx599FHY7Xaf37s/qqurMX/+fLRv3x7x8fFo1aoVZs+ejeLiYtX91qxZg9GjR6Nx48ZISkpCTk4OZsyYgcrKSud9Xn75ZfTt2xepqalIS0tDt27dcPfddwdlnERE3jDjREQUAvn5+bjssstw55134uGHH4bRKH9OtW/fPkyePBlz585FSkoK/vrrLzz22GPYsmWLW7mfnl27duG2227Dv//9bzRr1gxvvPEGZs2ahU6dOmHkyJFeH2uxWHDuuedi1qxZuO2227BhwwY8+OCDyMjIwH333QcAqKiowJgxY1BUVITHHnsMnTp1wtdff42LLrrIr++7qKgIALBgwQI0b94c5eXl+OyzzzB69Gh8//33GD16tOr+L774Irp164ZnnnkGgFzyNnnyZOTm5iIjIwOAHDRdddVVmDp1KhYtWoSSkhIsXLgQJpPJ+bp6YjQaMXPmTDz00EPYtWsX+vbt67xNCaaUoPaff/7BsGHDcPXVVyMjIwMHDhzAU089hTPOOAO//fYb4uLi/HoNAECSJEybNg0bN27Efffdh8GDB+Onn37CpEmT3O579OhRNG7cGI8++iiaNm2KoqIivPXWWxg6dCh27NiBrl27YsCAAViyZAmuuuoq3HPPPc4Mmbcs0w033IDXXnsNc+bMwdlnn40DBw7g3nvvxbp167B9+3Y0adLEed+CggJceumluO2227BgwQJ89tlnmD9/Plq2bIkrrrjC7+/b22vx/fffY/78+RgxYgR+/fVXLFiwAJs2bcKmTZuQkJCAAwcOYMqUKRgxYgQWL16MzMxMHDlyBF9//TXMZjOSk5Px4Ycf4sYbb8RNN92EJ598EkajEX///Tf+/PPPWo2RiMgvEhERBezKK6+UUlJSVMdGjRolAZC+//57r4+12+2SxWKR1q9fLwGQdu3a5bxtwYIFkvZPdNu2baXExEQpLy/PeayqqkrKysqSrrvuOuextWvXSgCktWvXqsYJQProo49U55w8ebLUtWtX5/UXX3xRAiB99dVXqvtdd911EgBpyZIlXr8nLavVKlksFmns2LHSeeed5zyem5srAZB69+4tWa1W5/EtW7ZIAKQPPvhAkiRJstlsUsuWLaUBAwZIdrvdeb8DBw5IcXFxUtu2bX2OYf/+/ZLBYJBuvvlm5zGLxSI1b95cGj58uO5jlP+bvLw8CYD0v//9z3nbkiVLJABSbm6u89iVV16pGstXX30lAZCeffZZ1Xn/+9//SgCkBQsWeByv1WqVzGaz1LlzZ+nWW291Ht+6davH/wPtz8vu3bslANKNN96out/mzZslANLdd9/tPKb8vG7evFl13x49ekgTJkzwOE5F27ZtpSlTpni8/euvv5YASI8//rjq+LJlyyQA0muvvSZJkiR98sknEgBp586dHs81Z84cKTMz0+eYiIhCgaV6REQh0KhRI5x55plux/fv349LLrkEzZs3R0xMDOLi4jBq1CgAcumYL/369UNOTo7zemJiIrp06YK8vDyfjzUYDDjnnHNUx/r06aN67Pr165GWlubWaODiiy/2eX7FK6+8ggEDBiAxMRGxsbGIi4vD999/r/v9TZkyBTExMarxAHCOac+ePTh69CguueQSVSla27Ztcfrpp/s1nvbt22PMmDF47733YDabAQBfffUVCgoKnNkmADh+/Diuv/56tGnTxjnutm3bAvDv/0a0du1aAMCll16qOn7JJZe43ddqteLhhx9Gjx49EB8fj9jYWMTHx2Pfvn01fl7t88+cOVN1fMiQIejevTu+//571fHmzZtjyJAhqmPan41AKZlU7VguuOACpKSkOMfSr18/xMfH49prr8Vbb72F/fv3u51ryJAhKC4uxsUXX4z//e9/fpVREhEFCwMnIqIQaNGihdux8vJyjBgxAps3b8ZDDz2EdevWYevWrfj0008BAFVVVT7P27hxY7djCQkJfj02OTkZiYmJbo+trq52Xi8sLESzZs3cHqt3TM9TTz2FG264AUOHDsXy5cvx888/Y+vWrZg4caLuGLXfT0JCAgDXa1FYWAhAnthr6R3zZNasWSgsLMSKFSsAyGV6qampuPDCCwHI64HGjx+PTz/9FHfeeSe+//57bNmyxbneyp/XV1RYWIjY2Fi3709vzPPmzcO9996LadOm4YsvvsDmzZuxdetW9O3bt8bPKz4/oP9z2LJlS+ftitr8XPkzltjYWDRt2lR13GAwoHnz5s6xdOzYEd999x2ys7Mxe/ZsdOzYER07dsSzzz7rfMzll1+OxYsXIy8vDzNmzEB2djaGDh2Kb7/9ttbjJCLyhWuciIhCQG9PnTVr1uDo0aNYt26dM8sEwG2BfDg1btwYW7ZscTteUFDg1+PfffddjB49Gi+//LLqeFlZWcDj8fT8/o4JAKZPn45GjRph8eLFGDVqFL788ktcccUVSE1NBQD8/vvv2LVrF5YuXYorr7zS+bi///474HFbrVYUFhaqghK9Mb/77ru44oor8PDDD6uOnzx5EpmZmQE/PyCvtdOugzp69KhqfVOoKa/FiRMnVMGTJEkoKChwNr0AgBEjRmDEiBGw2WzYtm0bnn/+ecydOxfNmjVz7sd11VVX4aqrrkJFRQU2bNiABQsW4Oyzz8bevXudGUIiolBgxomIqI4owZSSVVG8+uqr4RiOrlGjRqGsrAxfffWV6viHH37o1+MNBoPb9/frr7+67X/lr65du6JFixb44IMPIEmS83heXh42btzo93kSExNxySWXYPXq1XjsscdgsVhUZXrB/r8ZM2YMAOC9995THX///ffd7qv3mq1cuRJHjhxRHdNm47xRykTfffdd1fGtW7di9+7dGDt2rM9zBIvyXNqxLF++HBUVFbpjiYmJwdChQ/Hiiy8CALZv3+52n5SUFEyaNAn/+c9/YDab8ccff4Rg9ERELsw4ERHVkdNPPx2NGjXC9ddfjwULFiAuLg7vvfcedu3aFe6hOV155ZV4+umncdlll+Ghhx5Cp06d8NVXX+Gbb74BAJ9d7M4++2w8+OCDWLBgAUaNGoU9e/bggQceQPv27WG1Wms8HqPRiAcffBBXX301zjvvPFxzzTUoLi7GwoULa1SqB8jlei+++CKeeuopdOvWTbVGqlu3bujYsSP+/e9/Q5IkZGVl4Ysvvgi4BGz8+PEYOXIk7rzzTlRUVGDQoEH46aef8M4777jd9+yzz8bSpUvRrVs39OnTB7/88gueeOIJt0xRx44dkZSUhPfeew/du3dHamoqWrZsiZYtW7qds2vXrrj22mvx/PPPw2g0YtKkSc6uem3atMGtt94a0PflSUFBAT755BO34+3atcNZZ52FCRMm4K677kJpaSmGDx/u7KrXv39/XH755QDktXFr1qzBlClTkJOTg+rqamer/XHjxgEArrnmGiQlJWH48OFo0aIFCgoK8MgjjyAjI0OVuSIiCgUGTkREdaRx48ZYuXIlbrvtNlx22WVISUnB1KlTsWzZMgwYMCDcwwMgf4q/Zs0azJ07F3feeScMBgPGjx+Pl156CZMnT/ZZOvaf//wHlZWVePPNN/H444+jR48eeOWVV/DZZ5+p9pWqiVmzZgEAHnvsMUyfPh3t2rXD3XffjfXr19fonP3790f//v2xY8cOVbYJAOLi4vDFF1/glltuwXXXXYfY2FiMGzcO3333naoZh7+MRiNWrFiBefPm4fHHH4fZbMbw4cOxatUqdOvWTXXfZ599FnFxcXjkkUdQXl6OAQMG4NNPP8U999yjul9ycjIWL16M+++/H+PHj4fFYsGCBQucezlpvfzyy+jYsSPefPNNvPjii8jIyMDEiRPxyCOP6K5pqo1ffvkFF1xwgdvxK6+8EkuXLsXnn3+OhQsXYsmSJfjvf/+LJk2a4PLLL8fDDz/szKT169cPq1evxoIFC1BQUIDU1FT06tULK1aswPjx4wHIpXxLly7FRx99hFOnTqFJkyY444wz8Pbbb7utoSIiCjaDJNY+EBER6Xj44Ydxzz334ODBg173DiIiImqomHEiIiKVF154AYBcvmaxWLBmzRo899xzuOyyyxg0ERFR1GLgREREKsnJyXj66adx4MABmEwm5OTk4K677nIrHSMiIoomLNUjIiIiIiLyge3IiYiIiIiIfGDgRERERERE5AMDJyIiIiIiIh+irjmE3W7H0aNHkZaW5twpnoiIiIiIoo8kSSgrK0PLli19bvIedYHT0aNH0aZNm3APg4iIiIiIIsShQ4d8brkRdYFTWloaAPnFSU9PD/NoiIiIiIgoXEpLS9GmTRtnjOBN1AVOSnleeno6AyciIiIiIvJrCQ+bQxAREREREfnAwImIiIiIiMgHBk5EREREREQ+RN0aJyIiIiIibyRJgtVqhc1mC/dQKAji4uIQExNT6/MwcCIiIiIicjCbzcjPz0dlZWW4h0JBYjAY0Lp1a6SmptbqPAyciIiIiIgA2O125ObmIiYmBi1btkR8fLxf3dYockmShBMnTuDw4cPo3LlzrTJPDJyIiIiIiCBnm+x2O9q0aYPk5ORwD4eCpGnTpjhw4AAsFkutAic2hyAiIiIiEhiNnCI3JMHKGvKngoiIiIiIyAcGTkRERERERD4wcCIiIiIiIjejR4/G3Llzwz2MiMHmEERERERE9ZivNTxXXnklli5dWuPzfvrpp4iLiwtwVLKZM2eiuLgYn3/+ea3OEwkYOBERERER1WP5+fnOy8uWLcN9992HPXv2OI8lJSWp7m+xWPwKiLKysoI3yAaApXpERERERB5IkoRKszUs/yRJ8muMzZs3d/7LyMiAwWBwXq+urkZmZiY++ugjjB49GomJiXj33XdRWFiIiy++GK1bt0ZycjJ69+6NDz74QHVebaleu3bt8PDDD+Nf//oX0tLSkJOTg9dee61Wr+/69esxZMgQJCQkoEWLFvj3v/8Nq9XqvP2TTz5B7969kZSUhMaNG2PcuHGoqKgAAKxbtw5DhgxBSkoKMjMzMXz4cOTl5dVqPN4w40RERERE5EGVxYYe930Tluf+84EJSI4PznT9rrvuwqJFi7BkyRIkJCSguroaAwcOxF133YX09HSsXLkSl19+OTp06IChQ4d6PM+iRYvw4IMP4u6778Ynn3yCG264ASNHjkS3bt1qPKYjR45g8uTJmDlzJt5++2389ddfuOaaa5CYmIiFCxciPz8fF198MR5//HGcd955KCsrww8//ABJkmC1WjFt2jRcc801+OCDD2A2m7Fly5aQbljMwImIiIiIqIGbO3cupk+frjp2++23Oy/fdNNN+Prrr/Hxxx97DZwmT56MG2+8EYAcjD399NNYt25dQIHTSy+9hDZt2uCFF16AwWBAt27dcPToUdx111247777kJ+fD6vViunTp6Nt27YAgN69ewMAioqKUFJSgrPPPhsdO3YEAHTv3r3GY6gJBk5hdKioEn8cLUXTtHgMbMsaUiIiIqJIkxQXgz8fmBC25w6WQYMGqa7bbDY8+uijWLZsGY4cOQKTyQSTyYSUlBSv5+nTp4/zslISePz48YDGtHv3bgwbNkyVJRo+fDjKy8tx+PBh9O3bF2PHjkXv3r0xYcIEjB8/Hueffz4aNWqErKwszJw5ExMmTMBZZ52FcePG4cILL0SLFi0CGos/uMYpjL7bfQzXv/sLFv90INxDISIiIiIdBoMByfGxYfkXzLIzbUC0aNEiPP3007jzzjuxZs0a7Ny5ExMmTIDZbPZ6Hm1TCYPBALvdHtCYJEly+x6VdV0GgwExMTH49ttv8dVXX6FHjx54/vnn0bVrV+Tm5gIAlixZgk2bNuH000/HsmXL0KVLF/z8888BjcUfDJzCKDVBTviVV1t93JOIiIiIKHh++OEHTJ06FZdddhn69u2LDh06YN++fXU6hh49emDjxo2qJhgbN25EWloaWrVqBUAOoIYPH477778fO3bsQHx8PD777DPn/fv374/58+dj48aN6NWrF95///2QjZelemGUlihH7OUmBk5EREREVHc6deqE5cuXY+PGjWjUqBGeeuopFBQUhGSdUElJCXbu3Kk6lpWVhRtvvBHPPPMMbrrpJsyZMwd79uzBggULMG/ePBiNRmzevBnff/89xo8fj+zsbGzevBknTpxA9+7dkZubi9deew3nnnsuWrZsiT179mDv3r244oorgj5+BQOnMEpLZMaJiIiIiOrevffei9zcXEyYMAHJycm49tprMW3aNJSUlAT9udatW4f+/furjimb8q5atQp33HEH+vbti6ysLMyaNQv33HMPACA9PR0bNmzAM888g9LSUrRt2xaLFi3CpEmTcOzYMfz111946623UFhYiBYtWmDOnDm47rrrgj5+hUHyt0F8A1FaWoqMjAyUlJQgPT09rGPZdagYU1/8CS0zErFx/tiwjoWIiIgo2lVXVyM3Nxft27dHYmJiuIdDQeLt/7UmsQHXOIVRqiPjVMZSPSIiIiKiiMbAKYycpXom/3eGJiIiIiKiusfAKYzSEuTmEJIEVJptYR4NERERERF5wsApjBLjjIgxyr3r2VmPiIiIiChyMXAKI4PB4NzLqazaEubREBERERGRJwycwkxZ51TGluRERERERBGLgVM4VZ3CGONO9DP8zVI9IiIiIqIIxsApnH5+BQ9W3I8rY7/hJrhERERERBGMgVM45QwFAAw07MXJclOYB0NERERERJ4wcAqnVoNghxE5xhM4dDA33KMhIiIioig2evRozJ07N9zDiFgMnMIpMR1lGV0AAMbDW8I8GCIiIiKqj8455xyMGzdO97ZNmzbBYDBg+/bttX6epUuXIjMzs9bnqa8YOIWZsVV/AEBqyR5YbfYwj4aIiIiI6ptZs2ZhzZo1yMvLc7tt8eLF6NevHwYMGBCGkTUsDJzCLKV1bwBAR+kgdueXhXk0RERERKQiSYC5Ijz/JMmvIZ599tnIzs7G0qVLVccrKyuxbNkyzJo1C4WFhbj44ovRunVrJCcno3fv3vjggw+C+lIdPHgQU6dORWpqKtLT03HhhRfi2LFjztt37dqFMWPGIC0tDenp6Rg4cCC2bdsGAMjLy8M555yDRo0aISUlBT179sSqVauCOr7aig33AKKdsVl3AEAXw2GszS1E79YZYR4RERERETlZKoGHW4bnue8+CsSn+LxbbGwsrrjiCixduhT33XcfDAYDAODjjz+G2WzGpZdeisrKSgwcOBB33XUX0tPTsXLlSlx++eXo0KEDhg4dWuuhSpKEadOmISUlBevXr4fVasWNN96Iiy66COvWrQMAXHrppejfvz9efvllxMTEYOfOnYiLiwMAzJ49G2azGRs2bEBKSgr+/PNPpKam1npcwcTAKdyyewAA2hkKsOOffGBEhzAPiIiIiIjqm3/961944oknsG7dOowZMwaAXKY3ffp0NGrUCI0aNcLtt9/uvP9NN92Er7/+Gh9//HFQAqfvvvsOv/76K3Jzc9GmTRsAwDvvvIOePXti69atGDx4MA4ePIg77rgD3bp1AwB07tzZ+fiDBw9ixowZ6N1brsbq0CHy5sQMnMIttRnMiU0QX30S9qM7AAwP94iIiIiISBGXLGd+wvXcfurWrRtOP/10LF68GGPGjME///yDH374AatXrwYA2Gw2PProo1i2bBmOHDkCk8kEk8mElBTfGS1/7N69G23atHEGTQDQo0cPZGZmYvfu3Rg8eDDmzZuHq6++Gu+88w7GjRuHCy64AB07dgQA3HzzzbjhhhuwevVqjBs3DjNmzECfPn2CMrZg4RqncDMYgJzTAABtK35DpZkb4RIRERFFDINBLpcLxz9HyZ2/Zs2aheXLl6O0tBRLlixB27ZtMXbsWADAokWL8PTTT+POO+/EmjVrsHPnTkyYMAFmszkoL5MkSc4SQU/HFy5ciD/++ANTpkzBmjVr0KNHD3z22WcAgKuvvhr79+/H5Zdfjt9++w2DBg3C888/H5SxBQsDpwgQ317OMg0y7sE/xyvCPBoiIiIiqo8uvPBCxMTE4P3338dbb72Fq666yhm0/PDDD5g6dSouu+wy9O3bFx06dMC+ffuC9tw9evTAwYMHcejQIeexP//8EyUlJejevbvzWJcuXXDrrbdi9erVmD59OpYsWeK8rU2bNrj++uvx6aef4rbbbsPrr78etPEFA0v1IkHLfgDkBhG/nChjgwgiIiIiqrHU1FRcdNFFuPvuu1FSUoKZM2c6b+vUqROWL1+OjRs3olGjRnjqqadQUFCgCmr8YbPZsHPnTtWx+Ph4jBs3Dn369MGll16KZ555xtkcYtSoURg0aBCqqqpwxx134Pzzz0f79u1x+PBhbN26FTNmzAAAzJ07F5MmTUKXLl1w6tQprFmzpsZjCzUGTpEgS67tbGU4iU8KigG0DutwiIiIiKh+mjVrFt58802MHz8eOTk5zuP33nsvcnNzMWHCBCQnJ+Paa6/FtGnTUFJSUqPzl5eXo3///qpjbdu2xYEDB/D555/jpptuwsiRI2E0GjFx4kRnuV1MTAwKCwtxxRVX4NixY2jSpAmmT5+O+++/H4AckM2ePRuHDx9Geno6Jk6ciKeffrqWr0ZwGSTJzwbxDURpaSkyMjJQUlKC9PT0cA9HJkmwPNgCcfYqPNzhXdx9xTnhHhERERFR1KmurkZubi7at2+PxMTEcA+HgsTb/2tNYgOucYoEBgMqU+VPBKRT+8M8GCIiIiIi0mLgFCGkRu0BAMmleWEeCRERERERaTFwihDxTdoBAFJMBTBb7eEdDBERERERqTBwihBJWa0AANmGU8gvqQrzaIiIiIiISMTAKUIY0lsCAJqhGPkl1WEeDREREVH0irLeaQ1esP4/wxo4PfLIIxg8eDDS0tKQnZ2NadOmYc+ePV4fs27dOhgMBrd/f/31Vx2NOkTSmgOQM07HShk4EREREdW1uLg4AEBlZWWYR0LBZDabAcgt0WsjrPs4rV+/HrNnz8bgwYNhtVrxn//8B+PHj8eff/6JlJQUr4/ds2ePqmVg06ZNQz3c0EprAQBoZjiFNaWmMA+GiIiIKPrExMQgMzMTx48fBwAkJyfDYDCEeVRUG3a7HSdOnEBycjJiY2sX+oQ1cPr6669V15csWYLs7Gz88ssvGDlypNfHZmdnIzMzM4Sjq2OpzeQvhmoUFxcC6BDe8RARERFFoebN5SogJXii+s9oNCInJ6fWQXBYAyctZefirKwsn/ft378/qqur0aNHD9xzzz0YM2aM7v1MJhNMJlcGp7S0NDiDDbaEVJhjUhFvK0f1qfxwj4aIiIgoKhkMBrRo0QLZ2dmwWCzhHg4FQXx8PIzG2q9QipjASZIkzJs3D2eccQZ69erl8X4tWrTAa6+9hoEDB8JkMuGdd97B2LFjsW7dOt0s1SOPPIL7778/lEMPGlNSNuLLy2EvORruoRARERFFtZiYmFqviaGGxSBFSNuQ2bNnY+XKlfjxxx/RunXrGj32nHPOgcFgwIoVK9xu08s4tWnTBiUlJao1UpGg5JVJyCjYiIcS5uGe+QvCPRwiIiIiogattLQUGRkZfsUGEdGO/KabbsKKFSuwdu3aGgdNAHDaaadh3759urclJCQgPT1d9S9SxWTINbUJVcfZBpOIiIiIKIKENXCSJAlz5szBp59+ijVr1qB9+/YBnWfHjh1o0aJFkEdX9xIayZvgNrIXotxkDfNoiIiIiIhIEdY1TrNnz8b777+P//3vf0hLS0NBQQEAICMjA0lJSQCA+fPn48iRI3j77bcBAM888wzatWuHnj17wmw2491338Xy5cuxfPnysH0fwRKX4dgE13AKx0pNSEuMC/OIiIiIiIgICHPg9PLLLwMARo8erTq+ZMkSzJw5EwCQn5+PgwcPOm8zm824/fbbceTIESQlJaFnz55YuXIlJk+eXFfDDh3nJrjFOF5ajU7ZqWEeEBERERERARHUHKKu1GQBWJ3L2wQsmYgD9mbYcd4anNe/5uu9iIiIiIjIP/WuOQQ5ZMhrnFoYCnGspCrMgyEiIiIiIgUDp0iS3go2QwwSDFZUnjwc7tEQEREREZEDA6dIYoxBRaLcIMJQfCC8YyEiIiIiIicGThHGlNYGABBfetDHPYmIiIiIqK4wcIowUmY7AEBy5ZHwDoSIiIiIiJwYOEWY+MZtAQCZ5nxEWcNDIiIiIqKIxcApwqQ0agYASJPKUFptDfNoiIiIiIgIYOAUceLSmgIAGhnKcaKsOsyjISIiIiIigIFT5EnOAgA0QhmOlZrCPBgiIiIiIgIYOEWe5MYA5IxTYYU5zIMhIiIiIiKAgVPkSZIzThmoQGlFVZgHQ0REREREAAOnyJPUCABgNEioKi0K82CIiIiIiAhg4BR5YmJRFZMGALCWnQjzYIiIiIiICGDgFJFM8ZkAAFtFYXgHQkREREREABg4RSRrvFyuh0qW6hERERERRQIGThHI7ljnFFPNwImIiIiIKBIwcIpEjr2cYs2nwjwQIiIiIiICGDhFJGOKvJdTork4vAMhIiIiIiIADJwiUlxqEwBAorUEkiSFeTRERERERMTAKQIlZDQFAGRKZai22MM8GiIiIiIiYuAUgRLS5IxTpqEMJVWWMI+GiIiIiIgYOEUgQ7K8xikLZSiuMod5NERERERExMApEjkCp0xDOYormXEiIiIiIgo3Bk6RyNGOPBPlKK4whXkwRERERETEwCkSKRvgGiRUlXETXCIiIiKicGPgFIliE2AyJAIAqssKwzwYIiIiIiJi4BShTLFpAAAzM05ERERERGHHwClCmePSAQC2ylNhHgkRERERETFwilDW+EwAgFTFwImIiIiIKNwYOEUoKTEDAGCoKg7vQIiIiIiIiIFTxErKBAAYzSXhHQcRERERETFwilTGZLkleRwDJyIiIiKisGPgFKHiUuVNcBOspWEeCRERERERMXCKUAmpjQEAybZyWG32MI+GiIiIiCi6MXCKUIlpcsYpAxUorbaGeTRERERERNGNgVOEikmRM06ZhnIUV5rDPBoiIiIioujGwClSObrqZRgqUFJlCe9YiIiIiIiiHAOnSJWYCQBIRwWKGTgREREREYUVA6dI5cg4pRuqUFpeFd6xEBERERFFOQZOkcqRcQKAytLC8I2DiIiIiIgYOEWsmFhUG5MBAObyU2EeDBERERFRdGPgFMFMsekAAHNFUZhHQkREREQU3Rg4RTBLfAYAQGLgREREREQUVgycIpgtwRE4VRWHdyBERERERFGOgVMEkxwNIgymkvAOhIiIiIgoyjFwimAGR0vyGFNxWMdBRERERBTtGDhFsNiULABAgqU0zCMhIiIiIopuDJwiWFyqI3CylkKSpDCPhoiIiIgoejFwimCJaY0BAOmoQKXZFubREBERERFFLwZOEUzJOGUYKnCq0hzm0RARERERRS8GThFMaQ6RgXKUVVvDOxgiIiIioijGwCmSOdqRZxgqUFplCe9YiIiIiIiiGAOnSObMOFWglBknIiIiIqKwYeAUyZIaAQBSDCaUVVSEeTBERERERNGLgVMkS8iAHQYAgLmsKMyDISIiIiKKXgycIpnRCJMxBQBgrigO71iIiIiIiKIYA6cIZ41JAgCYqsrCPBIiIiIioujFwCnC2WLlwMlSVR7mkRARERERRS8GThHOFpsMALBWM3AiIiIiIgoXBk6RLl4OnOwmBk5EREREROHCwCnSxcnNIezmyjAPhIiIiIgoejFwinDGBDlwMpiZcSIiIiIiChcGThHOmJAqX7Aw40REREREFC4MnCJcXKIcOBmtVZAkKcyjISIiIiKKTgycIlxckhw4JUnVqDTbwjwaIiIiIqLoxMApwsUmymucklGNsmprmEdDRERERBSdGDhFOEO8I+NkMKG02hLm0RARERERRScGTpHOsY9TCkworWLgREREREQUDgycIl2cq1SPGSciIiIiovBg4BTpHBmnJIMJpVVc40REREREFA4MnCJdvJxxSoEJZcw4ERERERGFBQOnSBefBgBIRSVK2VWPiIiIiCgsGDhFuqRGAIBMQwWbQxARERERhQkDp0iXnAUASDdUoryqKsyDISIiIiKKTgycIl1ipvOitbw4bMMgIiIiIopmDJwiXUwszHHpAACpqjDMgyEiIiIiik4MnOoBa3wGAMBQfSrMIyEiIiIiik4MnOoBe6LcICK2uji8AyEiIiIiilIMnOoDR4OIOHNxeMdBRERERBSlGDjVA8aUxgCAREtJmEdCRERERBSdwho4PfLIIxg8eDDS0tKQnZ2NadOmYc+ePT4ft379egwcOBCJiYno0KEDXnnllToYbfjEpsgZpzSpFNUWW5hHQ0REREQUfcIaOK1fvx6zZ8/Gzz//jG+//RZWqxXjx49HRUWFx8fk5uZi8uTJGDFiBHbs2IG7774bN998M5YvX16HI69bccmZAIBUVKG0mpvgEhERERHVtdhwPvnXX3+tur5kyRJkZ2fjl19+wciRI3Uf88orryAnJwfPPPMMAKB79+7Ytm0bnnzyScyYMSPUQw4LQ6LcjjzVUIXSKiuy08I8ICIiIiKiKBNRa5xKSuQ1PFlZWR7vs2nTJowfP151bMKECdi2bRssFvdsjMlkQmlpqepfvZMgR0ppzDgREREREYVFxAROkiRh3rx5OOOMM9CrVy+P9ysoKECzZs1Ux5o1awar1YqTJ0+63f+RRx5BRkaG81+bNm2CPvaQcwROqahCaRUDJyIiIiKiuhYxgdOcOXPw66+/4oMPPvB5X4PBoLouSZLucQCYP38+SkpKnP8OHToUnAHXpQShVK/aGubBEBERERFFn7CucVLcdNNNWLFiBTZs2IDWrVt7vW/z5s1RUFCgOnb8+HHExsaicePGbvdPSEhAQkJCUMdb54SMUxlL9YiIiIiI6lxYM06SJGHOnDn49NNPsWbNGrRv397nY4YNG4Zvv/1WdWz16tUYNGgQ4uLiQjXU8FLWODmaQxARERERUd0Ka+A0e/ZsvPvuu3j//feRlpaGgoICFBQUoKqqynmf+fPn44orrnBev/7665GXl4d58+Zh9+7dWLx4Md58803cfvvt4fgW6kZCKgC2IyciIiIiCpewBk4vv/wySkpKMHr0aLRo0cL5b9myZc775Ofn4+DBg87r7du3x6pVq7Bu3Tr069cPDz74IJ577rkG24ocgHONU5LBjPLKKh93JiIiIiKiYAvrGielqYM3S5cudTs2atQobN++PQQjilDxqc6LpsqyMA6EiIiIiCg6RUxXPfIiNh42o9zgwlZVEubBEBERERFFHwZO9YQ1Ts46MXAiIiIiIqp7DJzqCbtSrlfNUj0iIiIiorrGwKmekJKyAADxpqIwj4SIiIiIKPowcKovUpsBAFIsJ8M8ECIiIiKi6MPAqZ6ISW8BAMi0n4LZag/zaIiIiIiIogsDp3oiLlMOnLJRjDJugktEREREVKcYONUTxjS5VC/bUIzSamuYR0NEREREFF0YONUXqc0BANmGUyitYsaJiIiIiKguMXCqLxwZp6aGEpSyVI+IiIiIqE4xcKovkpsAABqhDGUs1SMiIiIiqlMMnOqLBHkD3ASDFeUVlWEeDBERERFRdGHgVF/EpTgvVlaUhnEgRERERETRh4FTfREbD6shDgBgqigL82CIiIiIiKILA6d6xBKTBAAwVTHjRERERERUlxg41SPWWLlcz1LJjBMRERERUV1i4FSP2ByBk626PMwjISIiIiKKLgyc6hEpXg6cJBMzTkREREREdYmBUz1icAZOzDgREREREdUlBk71iMGxlxMsFeEdCBERERFRlGHgVI/EJKYBAIxmBk5ERERERHWJgVM9EpsoZ5xibVWw2uxhHg0RERERUfRg4FSPxCXJGadkQzXKTdYwj4aIiIiIKHowcKpHlFK9FFSjtIqBExERERFRXWHgVJ84uuqlGKpRWm0J82CIiIiIiKIHA6f6JCkLANAEJSitYuBERERERFRXGDjVJxmtAAAtDEUorWapHhERERFRXWHgVJ+ktwYAtDAU4lSFKcyDISIiIiKKHgyc6pP0lgCAVEM1ThWdDPNgiIiIiIiiBwOn+iQ+GVWxGQAAU+HBMA+GiIiIiCh6MHCqZ6qTWwAA7CWHwzwSIiIiIqLowcCpnrGnyoFTTHlBmEdCRERERBQ9GDjVM7EZzeWv1VzjRERERERUVxg41TMJmXLGKc1SiCqzLcyjISIiIiKKDgyc6pmETDnj1NRQgqJKc5hHQ0REREQUHRg41TOG1GwAQBNDCYoZOBERERER1QkGTvVNajMAQFMUo7jSEubBEBERERFFBwZO9Y0jcGpiKGXgRERERERURxg41TcpTQEAaYYqlJYWh3csRERERERRgoFTfZOQBhtiAACm8qIwD4aIiIiIKDowcKpvDAaYYlMBANVlp8I8GCIiIiKi6MDAqR6yOAInS2VxeAdCRERERBQlGDjVQ/b4NACAtbIkzCMhIiIiIooODJzqISVwkqpLwzwSIiIiIqLowMCpHjIkZsgXGDgREREREdUJBk71UExSuvzVUhbmkRARERERRQcGTvVQbHKm/NVSBkmSwjsYIiIiIqIowMCpHkpIyQQAJEtVKDdZwzsYIiIiIqIowMCpHopNltc4pRsqUVxpCfNoiIiIiIgaPgZO9VGivMYpDQyciIiIiIjqAgOn+ihBCZyqcKrSHObBEBERERE1fAyc6qPkxgCApoZiFFcx40REREREFGoMnOqjRm0BAK0NJ1BcYQrzYIiIiIiIGj4GTvVRemvYYUCiwYKqUwXhHg0RERERUYPHwKk+io1HRUI2AMBSmBvmwRARERERNXwMnOqp6pTWAABDycEwj4SIiIiIqOFj4FRPSZltAADxZYfDPBIiIiIiooaPgVM9lZDRDABgrD4FSZLCPBoiIiIiooaNgVM9lZLRFACQai/HKW6CS0REREQUUgyc6qnYlCwAQKahHEeLq8I8GiIiIiKiho2BU32V1AgAkGGowIky7uVERERERBRKDJzqKyVwQjmOl1WHeTBERERERA0bA6f6KikTAJBpqMDxUmaciIiIiIhCiYFTfeXIOGWiHMdZqkdEREREFFIMnOorR+CUZDDjVElJmAdDRERERNSwMXCqrxLSYTfEAAAqSwvDPBgiIiIiooYtoMDp0KFDOHz4sPP6li1bMHfuXLz22mtBGxj5YDDAlpABALCUMXAiIiIiIgqlgAKnSy65BGvXrgUAFBQU4KyzzsKWLVtw991344EHHgjqAMmLtBYAgLiKfFht9jAPhoiIiIio4QoocPr9998xZMgQAMBHH32EXr16YePGjXj//fexdOnSYI6PvIjNagsAaInjKChlS3IiIiIiolAJKHCyWCxISEgAAHz33Xc499xzAQDdunVDfn5+8EZHXhky5cCpteEkjpyqCvNoiIiIiIgaroACp549e+KVV17BDz/8gG+//RYTJ04EABw9ehSNGzcO6gDJi8wcAMD1sV/AsufbMA+GiIiIiKjhCihweuyxx/Dqq69i9OjRuPjii9G3b18AwIoVK5wlfFQHMlo7L3b+49kwDoSIiIiIqGGLDeRBo0ePxsmTJ1FaWopGjRo5j1977bVITk4O2uDIh+wezoulUiKahXEoREREREQNWUAZp6qqKphMJmfQlJeXh2eeeQZ79uxBdnZ2UAdIXjTphLw2UwEA1VYpzIMhIiIiImq4Agqcpk6dirfffhsAUFxcjKFDh2LRokWYNm0aXn755aAOkLyr7nQ2ACDGUh7mkRARERERNVwBBU7bt2/HiBEjAACffPIJmjVrhry8PLz99tt47rnngjpA8i7L0YwjwVYBu51ZJyIiIiKiUAgocKqsrERaWhoAYPXq1Zg+fTqMRiNOO+005OXlBXWA5F2jTDlwSkUljpeZwjwaIiIiIqKGKaDAqVOnTvj8889x6NAhfPPNNxg/fjwA4Pjx40hPTw/qAMm72OQMAEAqqnD4VGWYR0NERERE1DAFFDjdd999uP3229GuXTsMGTIEw4YNAyBnn/r37x/UAZIPCXKgmmIwIfdEaZgHQ0RERETUMAXUjvz888/HGWecgfz8fOceTgAwduxYnHfeeUEbHPkhIc158VDBcQDtwjYUIiIiIqKGKqCMEwA0b94c/fv3x9GjR3HkyBEAwJAhQ9CtWze/z7Fhwwacc845aNmyJQwGAz7//HOv91+3bh0MBoPbv7/++ivQb6P+i42H1ZgAACg4djzMgyEiIiIiapgCCpzsdjseeOABZGRkoG3btsjJyUFmZiYefPBB2O12v89TUVGBvn374oUXXqjR8+/Zswf5+fnOf507d67pt9Cg2ONTAQAnCk+EeSRERERERA1TQKV6//nPf/Dmm2/i0UcfxfDhwyFJEn766ScsXLgQ1dXV+O9//+vXeSZNmoRJkybV+Pmzs7ORmZlZ48c1VMbEdKC6EGUlp1BtsSExLibcQyIiIiIialACCpzeeustvPHGGzj33HOdx/r27YtWrVrhxhtv9DtwClT//v1RXV2NHj164J577sGYMWM83tdkMsFkcrXpLi1teA0UYpLSgWIgDZXYf6ICPVr66GxorgTik+tkbEREREREDUFApXpFRUW6a5m6deuGoqKiWg/KkxYtWuC1117D8uXL8emnn6Jr164YO3YsNmzY4PExjzzyCDIyMpz/2rRpE7LxhYshQ/6ecgzHse94mfc7/74ceLgF8PMrdTAyIiIiIqKGIaDAydO6pBdeeAF9+vSp9aA86dq1K6655hoMGDAAw4YNw0svvYQpU6bgySef9PiY+fPno6SkxPnv0KFDIRtf2DSR13h1NBzF38fLvd/3k3/JX7++K8SDIiIiIiJqOAIq1Xv88ccxZcoUfPfddxg2bBgMBgM2btyIQ4cOYdWqVcEeo1ennXYa3n33XY+3JyQkICEhoQ5HFAZNugCQA6dNvgInIiIiIiKqsYAyTqNGjcLevXtx3nnnobi4GEVFRZg+fTr++OMPLFmyJNhj9GrHjh1o0aJFnT5nxHEETsNj/kDBsfzQPlfuBmD3F6F9DiIiIiKiCBNQxgkAWrZs6dYEYteuXXjrrbewePFiv85RXl6Ov//+23k9NzcXO3fuRFZWFnJycjB//nwcOXIEb7/9NgDgmWeeQbt27dCzZ0+YzWa8++67WL58OZYvXx7ot9EwNO0Ke3wqjOZyXFX8Iiy2yYiLCXiLLu/eOkf+euufQEar0DwHEREREVGECThwCoZt27apOuLNmzcPAHDllVdi6dKlyM/Px8GDB523m81m3H777Thy5AiSkpLQs2dPrFy5EpMnT67zsUeUhDQYhs8F1j6EHMMx5BVWoFN2moc7GwBIgT2PJDyu4jgDJyIiIiKKGmENnEaPHg1J8jyJX7p0qer6nXfeiTvvvDPEo6qfDO1HAmuBLJTij2PlXgKnWpD839yYiIiIiKghCVE9F9W5lCYAgCxDGfafrAjNc9itoTkvEREREVGEq1HGafr06V5vLy4urs1YqDaSGwMAUg3VOHw8RHtpMXAiIiIioihVo8ApIyPD5+1XXHFFrQZEAUrMgN0QC6NkRfFJL531DAb1WqWasNsCexwRERERUT1Xo8CprluNUw0YDLAlNYax8hgqThWE5jmYcSIiIiKiKMU1Tg2IMTUbAPC65T/Y/NFjqLYEOUMkZpwkCTj4M1D4T3Cfg4iIiIgoAjFwakBiUuUGEQkGC4b++TDe+elvH4+oITHjdHIfsHgC8PyA4D4HEREREVEEYuDUkDRqp7pqytsa3PNLQsap4NfgnpuIiIiIKIIxcGpIup+jutrylF7gZAj8/GLGieudiIiIiCiKMHBqSNqPUmWdUqq8dNcLhLjGiYETEREREUURBk4NSUwsMOs7FPSdDQBItJwK7vlVGSe2JiciIiKi6MHAqaFJbYrYVv3li9ZiSIHu2aTHU8apNs+R+wPwbF/gnzWBnyPYdn0IfD4bsDGrRkREREQyBk4NUFrjFgCALJSgzKSZ/BuCtcbJpn+5pt46Gzh1AHjnvMDPEWyfXQfsfBf47aNwj4SIiIiIIgQDpwYoIaMZAKCxoQwny0zBO7Gn5hANdb1TZWG4R0BEREREEYKBU0OU3BgAkG6oxC//FATvvKoNcNkogoiIiIiiBwOnhigxEzZDLADg3TW/BO+8noIlBk5E9UvhP8BzA4BfloZ7JERERPUGA6eGyGiEMaUJAMBadgInyz2U6323sGbnDcUaJ3IpOSxPaIlC7as7gaJ/gC9uCfdIiOpeMJsmEVFUYeDUQBkatQUA9DDmYe+xMvEW18Ufn65Z0CMGTjaz/nEKTMlh4JnewPMDgO3vhHs01NBZqsM9AqLwWHYZ8PLpgM0S7pEQUT3EwKmhajscAHBH7Ee45vV1eHmdh0yGtQbNI8QAyVqtfzxQMfG1P0cwhOuTyFMHAMkuXz72R3jGQETU0O3+Ajj+J3Dw53CPhIjqIQZODVX7EQCAbEMx5sV+gse+/guFeiV71hp88my3C48LcsYpEgKnDy8FXh0ZnufmmjGqS7XZloCoIeDvABEFgIFTQ9X2DOfF7oY8JMCME39uUDd4AABLlf/nDGXGyRhb+3PU1l9fAgW/hue5tYFT1Sl5U2AxWCUiouDgOiciCgADp4YqNh648ksAQLv4Ejwc9ya6rTrfVQ6mqFHGSQycTPrHAxUTV/tz1Ea4AxRtq/c3zpI3Bf5lSfjGRERERERODJwasvSWAIDGUhFmxPygf59AAydbsAOnMJfq2cO8UFjbsbBwn3z5j8/CMx5q2FimREREVGMMnBqytBYAgAS7l3I8S7V/JQuWamDrG67rwcg4iVmWYJfqSRJQdsz/+4e7wxLXOFGdYuBEUUj1XsdSPSKqOQZODVl8MpCY4f0+70wDXh7uHjjYNJP3H54E8n5yXQ9G4GSpdF0OdqneynnAoi7Anyv8u3/YM04eNhcmIqLg0JaqExHVEAOnhi6tpffbTaXA8T+Aoztcxwr/AR5rB3z/gOvYvm/Vj1M1h3BM+tc+LHem83dvKLExhSHGv8f4a9ti+euaB/27vzZQrGs1CZx2vg8s6g7k7wrtmKjhYqkeRSNu1k5EtcTAqaFr0sm/+4klDN/fD5jLgB8WCbd7aSqhTPTXPyZ3psvd4N9zmivczxFs/nZOEjf0DQftGieF3gT38xuAsqPA5zeGflxERA0FM05EVEsMnBq6M+8D4tNgi0v1cUchwNB7c9EGINo1OeLtNjNQXeJ7bGKpXqhK5fx9owx7qZ6HwMnbWpRwr8uieowZJ4pCDJyIqJYYODV0TbsAszfDOHsTrPBSDqfK/ghvLqZy+au3Nxy7VV12t+wy4NEc4OTf3scmPiZUQYC/b5R6pXp1+SbrqTmEt5IqY5DLGyl6sFSPohEDJyKqJQZO0SCjFQyZObAnZ3u+z+/LAUsVKkxWlFYJjR8eaQVUFvkInGzqwEspe9v+lvdx1UXg5G/nJL2MU102aQikq56Bv75ERH4T38e4AS4RBSDIPaApksVnNAMq8/Vv3PkeEBOHq47+H647XIixYjIjd4PvjJO5XOcGH29Mqs584c446QVOdbiQ2GNzCC+ZgYYSOFWXAHHJ4d8EOaow40RRiBknIqqlBjLzIr+kesk4AcAvS7Eltwgx0Ly5fHwlcHKP58dtfAH2DYvcj/v6RE/YRFeymlFSGYLgye/mEGEOnCQxcPLzeRtC4FRxUi7rfGlYuEcSXViqR9GIgRMRUPAbsO5RwFzp+77kpgHMvMhvKT4CJwejNnDyJe9HGHe+437cV9AiZJwsFjPGPrUOUrDLJ2rTHCISSvV8rXHa+AKwZIq6VLI++Wet/LVwX3jHQUQNn+r9gKV6FKVeOQNY9wiw4Ylwj6ReYuAUTXxlnABMNf6IxobSID2hr4yTqwV4vMGGk+UmHCpyrHuSpODsrVSrUr0wBU6SvxmnGGD1f4C8H4FtS0IzrlDjJ8BhwowTRSGucSJyKfg13COolxg4RZPs7q7Lo/6te5dn419CT2NecJ6vBhknAIiBHbsOF8tXll8NPNXdv7bmXsdQi4yTvwFMMASyxknsqldfM04MnMKDpXoUjVSBEzfDpSjXEMr9w4CvWjTpNQMYci1w3mtAXGIdPKH/GScAiIMVvyqB0++fABXHgT8+r+UQ/F3jpJNdUoKZsoLQr3fyuI+TFw3hjx4DJyKqK8w4Ebk0hDlEGPBViybGGGDyE0Dfi4DYpNA/Xw0zTnGwYc8xbXc+xzlM5fJ6GHsNJ9q1XeOUtwlY1BX44P9q9rxapjL5XJ7GLwZOmoASdjvw5a3AL5r27uIfvfqaQWDgFCbCzwsnkBQtVIET//ZQlGPgFBC+atEqNiH0z+GrxbhNHThlGCpwuEjT5UWZ1K28DXhnGvCjTvc+b/xe42R2P2a3AZtfkS/vW12z59V6eyqwZCKw423928XAyVrtumwwAH9/B2xbDHxxszozVts/etsWA5tfq905aoufAIcfJ5AULcSf9brsmkoUiRg4BYSvWrRq1iv0z2Gp9n67VR2s/JhwCw6fqoLdpjOR+/VD+euah2o4iNqU6ln9f7wvR36Rv27X6T4IqN/Eta+bSWjWIQZV4hqnmrJUyVmsr+4AKgoDP09t8RPg8BAzlJxAUrTg3xsiFwZOAeGrFq1aD3I79Lx1WnCfY983wCf/kvfqAeRytS2vy2uGALeMEwBYbFYcLxa7+jkCl7hk4VANgplalerZ9J+rrAB4/yJg33f+j8Pb8yjPpRCDIxjU2cHqYuGmWvz6imWS1qrAz+PN/vXy5sneqD4BrsMuhlFPDJz4ulOUYOBE5MLAKSB81aKVwQBc9ZXqF6fvxQ8G9zkqC4HflwOvjQZeHQm8OR5YdTvw4aXy7Vb38rj/xr6JY/mHXAeUwCW7h+tYySF4JQYhtdkA11PXpRU3A3u/Bt6b4d+5PY1NdVyYvFo0gYz4x638mDC+Wrzx632/wVRdCrx9LvDWOW5r2VQYOIUfu4tRtLCzqx6RU22qVqIYA6do1vZ04N5CYMoi4LoNGNkzB1JMfPCfp+QQkL8LOP6nfP3INvmr1b2U75LYtWi86b+uA0qgIb7Jmcrl8y3qrl/6JgYFtd4AVyfwOrrddfmnZ4HD2/x7Du3Y3J5LZyx2qzqQKj/uuiyW9BX8Cqx92P+dwMVsXyiCKDHA8xo4Ca8vA6e6Y2DGiaIQM05ELsw4BSQ23AOgMDMagcFXO68a9JokhIpOqR4AZBbudF1RysjEIMFSBXy/ECg7CqyYAwy4XH0CMfCoTcbJblU/fvcXQGZboOKE69i398lfF/q535SnSaq342KAqQqchL2bdn8h/7NWA2c94HscYjATiv9zcV2Wt4k5F2uHH193ihZsRkPkwsApIAycKHx0SvUAwCAGVMoEXwweLJWA0cuPbiAZJ93ASTOhXHaZf+fyxmOA5KWEz2PGSWdt0qGt/o1DDJZCEThVFQvn95LRUmXamPmoMwxYKRrx557IhYFTQPiqUZ2rhGPzXQ8Zpxi7MJFXggNt4JTWQriuKfkTJ+p2C7D+CeD1M+XmFIqC34E9X6vvpxXIG+sfn3nftNdTcOCp3t4tcBJK4PTK8vwNgmqacSo+VLNPaCuLXJe9taUXn5uBU90Rf7b5ulO0YKkeRTvxbz8Dp4DwVSO1mStVpXuhUIYUAMAfh07o3m4UAyclYBKDB0slEJvoun4qV30C7WR87UNyO3BxA9lXhgMfXAQc+8PxGA/tyGsSLFSXAh/PBD6+EjBX6N+npqV6NovnwMmiFzh5WU8kstZgjdPO94FnegEr5/l3bgCoEgInb+e3adZzRbqGUt4jRVngZLc3nP87ChwDJ4p24nuuuNaV/MbAidTanSE3iwihGMmCaosNhcVlurfHSsIvtm7GqUodNBT+oz6BpwyHsu5GnECd3Of5MTWdUJrLhTF62MPKn+YQquM2dbtwVameXuDkOL+lSs58iSVzqvvplEN68r1jzdS2xd7vJ1JlnLy8jvUp42SpBl4cAnwyy/02uw1YPFEOnOsDVefJBl6yZDXJ/2/BKLWl+k1iVz2KcuJ7PzNOAeGrRvqmv+F+7LTZQTl1GipxcOtKNDUUAwAetKgnNEaxk521Wg50xMBp9b3Arg9c1wt+BTa96Mry7PtW/4mVoEJsXKDskaRXribZ4P8GuprMkBjsiNksj2uZPB23qIMwVbc6neBMCYK+u1/OfHmayIvry3xlnAL541opbKq7bbH8f6b3ib8qcIrwicyBH4CTe4HfP3G/rSgXOLhJLtX0lG2MJKFe6yFJQMFvvoPyupD3E1C4D/jry3CPhMJNDJaYcaJopHq/Z8YpEGwOQfr6XAD0Ph8oy5ffYEqPAm2GAINnAc8P0H3IW8kzcWXlUp+nTjBY0WX15c6w/aCUjT2xXdDVutf9zgW/uWdWKk+qr69/TP76zxrgvNeAr+7Uf2IloyFO6pVJo06pnt1mhTHGzyyIuUI9TjGIEj/h8baWydNx8bxixkmP8kdxh6NN+/61Hu5XkzVOAfxxFUv1fn5J/tppHNBhlGYcNSzVs1mBT66SN3AefkvNx1UbYkMSu13uSKmIiXNdLjkMNO1ad+MKhGqNUwgCp10fAJ/fALQfBVy5IvjnJwqE+OENAyeKRuL7PX8HAsKME3lmMADpLYGM1nLQBACNOwLnvep21wNDFmLqjY84r5dKSZhq8qMtNgAz4hBn8JDZOfY78PV8/8b793fu651ESoam8pTrWOkR4OgO3VK9k6UV+p3r9Fiq1JmG7x+Qsz12m/q4uRz49WNXYwe7TS6pKzmsf16bRVOm6COboQRE8Sn6t//2CfDFLerGEt4CJ7stsDposVRPUXzQ/VhNS/X2fg3sXuFqA18X/lwhZ82U7CSgzigC6rEX+9igORKEeo3Tltflr7nrg3/uGuOnquTArnoU7epTlUeEYsaJaq7necBn16kOtWveBEhNBrqdDfz1Jf7KuRi79nXCYWSjNbxnSfq1y0ZLczxw0sMdtr/l4QYd+9d5vk2ZzIvZECU71aSL+92rzUCKn6VGlkr1Gqfdjk/Zj+8GTvylvu+nVwNj7gFG3QFsfxv4cq7n89pt+muZPKk4AWxbAsSnAjjmfvtyx/qcgt9dxzwFTr9/Cvxvju9gTY9JZ/1atc5eVzUNnLTNLyRJzoZmtKrZ+GriI8c+YdNfdx0zV6qDU/ENqKQeBE6h7qoXqbXzksQF0dGM+zhRtKtvDZkiUIS+u1FEi00AJj8JNGrnOmaMkb9esBS46D30u/h+3DOlO5o2z3Hd59zndU9368TeSAzWT+Kx3z3fpgRMYqme4qR7maDVatFfR6THXKHfHlwbNCmUwGrPKu/n1a5x8seXc4FTB1zX9SYIR7a5LnsKnD65KrCgCdBf56MbOIl/xP349CtGzPqYgbX/BZ7uIWfSQs3T5sOA+g3IU/Ywkkghbg6h/D2INCxNiW5sDkHRrj41ZIpQDJwoMEOuAW7ZBZx5L9C4M9BhjHw8Jg7ofjbik9Nx9YgOSGgk7Lc04Ar9c8XGA43aBmVYliO/er7x+G45iNArI9NhtdQgcLJU1qwpQLNe8lcfn8xbLGb/xyASJwViMww9odgAVzdwKvb+3P78EY+JF56jHNjwhHx5uU6nu2AQgzlxrNrvTxU41beMUwgmkJGaceJEIbqxHTlFOwZOtRah725Ub4y8HbhpG5DeQv/27lPlr2KmQCvGkcHqMrHWw4kr/sfzjWX5wDvTgLKjfp1Lstsg+ZvtKT6kLtXzxayUsnkvGzKbzTUr1dNTckT+6qnDmTUIgdPG59XrjvRei2CU6omTHVOZ942Qg0Eck3hZm10Ub6v2EahGAtVajwZeqieW5rGmP7oxcKJoV9MqD3ITQe9u1CD1Ph+Y8SZw4ybP90lpIq9RuWQZ7G1OC+149q8Dtui0WtfR3XgQhhKdhgZ6Pr0a2OzeNENUENsSc803AgDsVY7JtY/1FrGw1iwgaNTe/djLw+QucCYPgV1tM042C7D6HuCnZ+W23IB+xkkv01fjrnpi1qccyO7uul56xL/x1oQ4JnGsb08F3rvQVQYZ6jVDwcaME0WjUP/cE0U6VVc9/g4EIkLf3ajBMBjk4KlxR/n6he/IDSTG3Q8kpAOTngBSs513N7YdFtDTlEpJXm+3xqYArQY6rvjZKa+mCvd5vbnKHocyyOO0VhbLB31M5IyS3f+MU0aOXEKpp/SI55I93T2sarBwWlz7I9nlAEPbxAGQG1covl0A/G+2+n41DZxMZepgxtt+VMd3A1vfrPlkSXV+4bktFcC+b4AqR4dGVZc6H/tiRYJQd9WL1AYMnChEN2acKNqxVK/WGDhR3epxLvB/7wFnzAXuygOGXqu+vd0I1+W4FOw+7Qm/TvulzXum6peMs4Bhc2o42OAqt8agTEoGANiqSuRJd1Wx18fEweK9xbrqzomObno6TuzR73QHuIKDyiK5jXTuD/rrkTwpK3BdtlZ7XuulBBk2K/DTM8COd4HjQvMMf4IaVeBU7jmw0XrpNGDlPGDne76fQ6Ra46QTEDkzTn5schxJojbjVA/+byh0uI8TRTsrA6faitB3N4oKRp0fv45nAi36ypcnPoLu46/2eopFlvPxqnUK1tn7eb3flmPAm7mNAhxocFQhDqWQW1gnlR0AHmsHHN4SvCeISwIS0tTHWvSTv570Fjg5sj4fXwmsuh14/0LPG+3adSYb5ULgZPESOClrrMzCOMR9svz5Iy6u0zKXqYMlf0oOD232fR+ROCa9Jh1KdslTSV+kEscbiixMJAVO9a2MkkKHGSeKdtzHqda4jxNFFoMBuPp74NAWedNdoxG4+ENg2eVAzmnAgR+A+DRg6HWwpLXC8582AwBc2qoAcHQZf8M6CevtfdHRcBQL494GAGyw9cEvGyvwr8QYGIIxUUzIkDcHPrHb74eYpDiU+SgprJVYncCp1QAgfyew5r/yZT3KRL9wv/zVUqluZ666rwkwar4HVcapykvg5AiSxLVW1hoGTmJQ4laq50fgZLfJ67BMZUCLPn7cXzi/3mbINp3AqT5MzkPeHCKC2pFz01NSMHCiaMdSvVpj4ESRJyYOaDfcdb3rJOCOfUBiJnB0B5CZA6Q0QRyAtzNPwGy1Y1yXRsBHq/HJ3xKesl6ASiTCbnSts9ib0AP2ajvK0zsircR9zyZPPrMNx3kxP7nf0PciYPITcjvsNQ/5dS4T4tCiWTNAp7mcT/FpsAGIMXvIGgFyxklbqtfcERxYKuSgU4/yh1Rcb1TsoSmGtVp+HkDO/lScUAdOlmrP3QWdGSfh9pp++iWO0VSufrynroEiuxV4rp98+ba9QFoz3/dX6K01c2ac6llWI5pK9erb/w2FDgMninbcALfWIujdjciLpEZyNqrVALkLn8PILk0xrkczeS+oS5Zh8OwluHF8HzRPT8SYiRfIbc6vWYsJvVoCAOacOA8A8Ju9nfMcl5nn4zd7OzxidG+scI/lX3jLepbbcZsE5J6sAM64DZizDcg53ee3cEzKQtsW2T7vp8dmMOKkycfnHHHJQIIQOBli5KyYz5M7gg+xjbanTVzF4OStc4GnewL7VruOleXLGS7dx1bLaww8dfer6RonsyZwUt4QvDW2EO/vz9oxcUx6pXr1NuMU6uYQEfTWEurNfqn+YPaRoh0zTrXGjBM1KG0bp2DOmZ0x58zOjiNyN7+JvY7ho22Hsd7eF2eZHse1Z49Aj4y9+DQvAT/+YMeP5t7o3TQDmDQRWHaFnKEBYIlNQfLoW2HfcxilRceRaZPrAX/eX4RLf1iHd2YNwfCOnYDkJj4/hdhg742BLTOBv3zcUUdVtRkpcAUEx6VMZBuK1XeKT1FnnOJT5YDTF6vJUfYmBEUeA6dq4OBmeZPXQz/Lx8RAaYWPBhxWE2DykHLza42T2ByiVLO2yAQc2Q68dz4w9j5g4Ez3x4tlhMY438/nK+NUXwOnqMo41bPGHRQ6zDiRL6fygMK/gU5jwz2S0GDgVGsMnCgqnNmtGdbcNgrLth5CUnxnnH96ZxgMPTCmnQlxG7+HxSahW/M0oNMZwH+OAjvegz29NXa1OQNJ8THA2E146vOduHPnRKQaqvFqvhyQvfFDLl5dvx/XHz6EM3yMYaO9Fy5uloYiKRVZBt+b5d5huRZPxL0GADDCjmKkIBVy1uNve0tkxxSrH5DZRr3GKcFD4NSkC3BSKFfc9QGw60P1fTwFTp/8Czjyi8+xe3RwE/DuDP3batqOvPKUe3OIFTcBlYXAF7foB07iJrx6zUncns/HGqf62hwi1FmYSGpHzlI9Uqh+7hk4kY5nHeXtV34JtB/h/b71UbA+NCs5Ahz7A+h8VmT9va8DDJwoanRomor5k7urjjVJTcD380bjr4JSDO3Q2HVD/0thBOBsg2AwoFebJhi9+Wl0NBzFZkk+z/q98t5Ed8SXeCx8fcJyIQ5IzRGTnIHmGYmYY7kZPQx5uCfO0Ro7rSVQdtTtcd/aBgKOpEgM7HjOOh0zYjbgP5ZZuCZmpfsTZeaoA6fMtvqBU8/pwPpHNQc15W2eNpOtTdAEyHs3eVLTwOnQZs0aJ7PvBhFiOaJeh0BvY/LaHMJLs4WSI/Lr1u1s/4K1uuBtvMFgFJpD2G3q63WN5VmkUGWc+LNAXuRtbJiBU7AaAz3dQ/564TvyNjNRJELexYnCJ6dxMsb3bI6MJO+lWzMGtEaXjh2cQZPoSeuFsEgxOCmlO4/dEXc3RpsW4UXbNKy0n4YmqQlokpqAjfZeeMM2xfXgbPfzAUAxXGV3J5CBD21n4gLzQuyV2uAoGrs/ILMtEJvgut6kE5CYofMND8VDlku9fq8oOeT99kBVnPR8m7kCWPcokP+r5/uIgVHhPtfeUMptRp3PgsQgQWzJrrdJr9tjhcmV36V6mgnZ8wOBjy4HftVk9cKpLtc4hTsDF2lllOYKoDhEv1/knWofpxps8k3Rx58urfVRsDuq5m6o/TnqGQZORH6KMRrwzqyh2HnfWfjzgQnO43dN7IbNxn7oZXoTI03P4E3rJFxuvx8fl/XCAamF835NUuPRKDneeV0JsqRe0/F+8qX40nYaDnSeCaRko2jcUwAMmGm+A3vsrTHbfLNqLPmSe+BUldpafSC7p9yhUKvVQLxhm4J55utr/iLUlrdgZf1jwLpHgFc9fMpnNQN5m7yc26zfBtumWRclHvc1efLVjlyvVM+uCRSUluv/rPH+XHVJr3yt4Hc5yPvjs9qfXwyctK9HXbOHuCyxpp4fCDzTCyj8J9wjabgqi4Alk4Ff3lIf5xon8hcDJ/KApXpENRBjNCDTEfw8NqM3Tpabcf2oDjirRzZsdiAh1ohbljXHrkPFbo9t3yQFMUKL9KmmBzHAuA/XNZ2ChaWNYbbasWrMCKDlszBUmIEvv8U6e3+sM/dXnadXq3Qczm/qdv6rP89H/3Z23D70euDgz0D/y/S/CUcWygw/miPURuNO8iJbf4lBjZ6V84Bjv3m+3WZ2LwmzmuROfwqxFbqpDHhxiJzxu/Bt/XP6bA5hdb+fpzcjvWxYuIgBhPI9LL9a/v/6eCbQ87zanT+SMk5SkGr6g0X5edz7DTDsxvCOpaHa8CSQ95P8b+CVruMs2yR/hfvvVqgE+3cgkhoB1ZEIeicnql8uGpzjvNwp27W2aNEFfTH+6fWwS0CXZqnYe0yerF95ejsAwEPTemHbgSJs2p+AL0qb4osXNgIAOjRNQZdmcnlecoLnNSGdmqbiiyM9sMQ6AWbEYqjxL/xq74CfcsvwU24ZLpt/P5pPStR/8JxfIDmyLAWSHx33aqPdiJoFTr7seMf77b8vV3f4s1QBLw8Hijx8sr9vtdwkQ2yUoaUKnBztyPtdBhzeCpzc4/pUUtUcwlPgFEGbwopvmMr3YPKyR1hNiZm8cH9yG2mleopwvy4NWbWHzp3MOJG/wp0pD5VgZ5yirDEEwMCJKOg6Zafi6Yv64Z8TFbh2ZAe8vekAMpLi0K25XJp32WltcdlpbTH7ve1Y+Zv86XNaQiwWXdAXsTHypzcJsepJ9vMX98dNH+wAACTFx6JZRgruL7kSerYcKEJOVjL6tclUHc8ztkbbJp1QaZL/WG6TumJvfA90Mf8ZtO/dqc//AamB7VkFQN5Ud+ubcme8jFb+PUbbuKKq2HPQBKj3k5Ik/TcAMQhSygxjYoHkLPlyTTbAjdiMkx9rvWoqkroMhrr1eqAYONU9NocgfzXU38+gl+pFX+AUfTk2ojowtV8rzDurC1ITYnHj6E64dGhbt/s8MLUnxnXPxpTeLbDt3nHon6POAHVsmuK8fE5f10a2aYmx6N7C1YTiokFtVI+7+YMdmPbiT3h9w35IkoTDkrxh8DoMAQAUVShvCAbck/EIcPnnwIRH5EONO6kHGZeCGrthIzD9Vf/2SfJk2eXAhsflsjE9/gQhlV4aUQDqPZ08vYHoHTfGup6/Jvs46a2/CgdtN0FrCCYIkk5GK1witabfGoKAlbxTrXdjxom88FQ5UN+J1QDMOAWEgRNRmDROTcAbVw7Gi5cOcMswAcDwTk1U1/97Xi8MyMnE9aM6omtzV2ng+YNaax8q33/Vbjz3/d8437QA/7ZcjRclef8kV+AEHK+UgI5j5LUWt/4BjFuoPknrgTX/xpIc2ZiYWmRYDm9Rf9U2cfBnY99Ted5vF9c7Wav17+MpcIpxNPnQDZyEDIs4UYuUUj3tJ+0hyThF0N5JkdYcQhHsgLK6BHhnuvuebNHI01yOpXrkr3B/4BMqQV/nx8CJiCLEbeO7Ymy3bDx9UV8AwKVD2+LTG4cjKyUeLTOdO0yhX5tMPHF+H91zvLB2HwrQGB/azkSJJQZl1RZMffEn5+0HCisx6dkf8PuREiCjtbwuSWGIAdqPrPnAlTI2DxmnTbYeeMByuf/n+/kVYFE39TG/AqcD3m8X1/Q83UsdaG18HnhlBFB+zP1xxlhXt0K9rnqS3ZXVERtKREqpnvbN0llKF8T2zHprqPRYTaFvC+2tVXw4BXtituFJ4J/vgc+uC+55GxLVpJGBE3nBwMk/zDgRUaTISIrDmzMH47z+7hml6QNaYVz3bCw4pwfiYoy4YFAbPD7DFTwNaZeFTtmpsNhck1KT1Y6xi9a7nWt3finuWu7YOykp01VS1v0coMOZ3gc59SVg8DVAl4muY8peUnqt0AHkIwtViNe9TdfXdwHlBepj/gROJ/7yfntVsetydTGw+h7X9dX3AAW/AptfcX+cMca9VE/76bUyWTeLnfiC9AZjt9Vu3ZA26xKKkjFVqZ6HsZYfBx5rJ3fzC6VQ71kVqGBPzCpOBPd89ZmnWJwZJ/JXuNdm1sbRHcCLp8mdO7UitXS5HmHgRFQPJcfH4o0rB+Oq4e2dxwa0dQUT6UlxGNG5idvjjpfpT5KV4yVVFlRf9gXQ9xJgyiK5VO+CpfI6KD09pgJTntTfxNdDhqVAykK15Aqc/jB00T83AMR66A6YmOn5MYpDm73fXlmovq60Q1dtkqkzufJVqideFzNOwZgoS5KcCXtxaOA1+G4ZJ5Pr3MHiT3OI7W/Lr8/vn/g+X+4G4L0LfJdf6o4lSppDRNL3Fql8/W5TdBOzkPW5q977FwEndgPvX+h+W7A/SGLGiYjqq07ZqbhuZAcAckZKbDbRJDXB7f7pia7AJjHOiJIqC8Y9tR7nrrBCmvYSfi+Ow9VvbcPvmWfK66Cu2wBcuw6YfwRoOQAYPhdIkNuno/UQ9wF5yjhJWcgyuMrktkudPX9TcUn6x+OTPT9G4a3NOABYKtTXlQl+1SnheVLdHyeW6v2+XC6R0gYHeoGTp3VUNVFdAhz/Q+4WWHoksHO4rXEKwQTBn1K9mjzvW+fI7eM/D2Dfo0habyVO3IPdlCOS1m9FKnbVI28iqRtobVR4aYyk+sBACkLJavQFThFSdE9EwfDvSd0w64z2aJqWgMOnqpzHLzstB7sOFWPtHrmc5/Hz++DLX/OxYa983QADvvmjACfKTDhRZkJJlQXPr9mH73Yfw3e7j+GvBycisUVf1xNdu1b9xF0nARe8BbQQ1lp56CJXIGWhEq5ArsKQ4rm0RgxiQk150xQDEr03T2Osa/3W4S3yv5zT9c9lDnLGSSzHCnTjQbeuekoWMkRrnDx9chvI61EcQMYpkjbAFSctwW7KEe6gsD5gqR5501ACJ28fCuiVlRtrUDqvxYwTEdVnBoMB2emJMBgMaJOVjIXn9MDCc3rg5jM7Y1LvFgAAowEYkJOJnCxXNudYaTXW7TnuvL7veDkOFbkCr52Hin09MdBzGpDVwXnIHCNki9JaOC/usHfGT/ZeeCDtXmDub7AH0qY7xj2DBgDI6gjc4WXvJm9sFuCb/wCvnOE6prcprDHGvWNgxXH1dWfGSchqBWMtkdisItBATBvIhGIRtD9rnAJ53kACn0jqqheMiVn+r8DK29w/VQ53UBhRPHwIIP7/M3AiLU/dURsST+txAxZ9gRMzTkQN2ExhDdSFg9pgQE4mTFY7OmWn4eaxnbE9rxh/5pfCZLXjmz9ck/ILXtmkOs+xUu9lZhUmKwwGee0VAGw/eApzPo/DHbGTcO5F1yJm//fAphcgpbXAyeoMAMDPsUOBzBxUGmq4V1TL/kCfC4BfddouZ7UHUprIJXZiu3F/2C3AphfUx0wl7vcT1zgptNkfmwWwVAFvTxWOBSFAKRcCNF+BmM0qd1lrM1Ru+uHpcc5xBfEN0FOAUHIYSG8lB9qBBA6BBD6hag7hadNkb8TnDzSQftXR+bKsAPi/94TxMBDwKeitmKlBUf3daqhd9TQfKtT2byIzTkTUkHXKTkPPlnLgkp2WiFW3jEBOlrxeyGb3XKp1y4c7sTu/VPe2aosN57zwIwY8+C2++1MOvh5euRtHK424tfxy5GYMxr1FE/Frj9thuuZH5+OUZ9sd09X/b2DsAnmdVXJj/dsTHPtb+dM8QkvVAc9BN+MU695qXfsma7cCR7arjwUj4ySW6vl6Y9/4nLw4+N0Z3scR6lI9ZZw73gWe7gl8dafjuDAOfxtTBPImH4p25FteB57oBBT8FvhYajsx0z43S/V8Y6le/ffTs8BrY+T1nsEm/kyEYmPwSMCMU60xcCKKcreN99LVTjDp2R/cjr2/+SCuWLwF+09UoNpix5Or92DZ1oPYludam/T8mr/xzq5SnLt9ACpj0p3H7Y5A7Z+Y9m7n9UhZQxXnIUuV4Di/mGHxV/lx92N6kyuDTqletSaotFvd35CCUqonjNHXxFvZCPXINvVx7dqaUJfqKa/Dt/fJX7e85nheIePkb/YpkMmuPQTtd1fdDlSeBL6eX8Ox+FHCGChmUAQeJnOqwCnE+4dRaHx7H3B0O7D5teCfW5URrvJ8v/pM+zc0kL+p4u8OM05EFG3O7dsSWSnui0P1/h5KkgRJkvD17/lYt+c47v7sN2zJLXLe/ldBGe5arv4kfJewPqq0yjVZrLTIb1LlFgO+s/UHAJQMuBFSTAIsKc31B6t07/PUVU/ZfDegjJNOdkmPMca9VE+bmbJbXe3NFf42A7CagYpC/dsqalCqF6dp5W6zAOYK909SlcApqO3IdTJO2rVsYsDm72sTSAeoUDaHqOmkQ3z+YHRZVI2FgZNP7KrXcAT79wdQB06WEJw/ErhlnGq5bpQZp7q1YcMGnHPOOWjZsiUMBgM+//xzn49Zv349Bg4ciMTERHTo0AGvvKKzQSUR+c1gMGDFnOG4eEgOLh2aAwDITkvAhjvG4KFpvVT3ffb7fbjvf3/g+ne3Y+aSrX6d/0ChqwQu96SrWUKFyYYjxVUoq7ZgjuVmDK9+Frn970LXitfQtfBJFF6xRn2i2/YAiY6MkqfAqIdjTVEgGSd/6ZXqaRcS263upSRKoLPvO6Bov+fzr5gDPNkZOPanfP3EXiB/lxzYiA0BfGWKtHtgvX8h8HgHYOd76uM1LUk59qe8aW2hlyYceoGTdl8vMfDzO+MUyJu8MBkK9mTZ0z5j/ozFEsRPtO02ef0YOQgfAtg9ZJlYqkciUzmwZJLrejB/PyOJW8aplutGmXGqWxUVFejbty9eeOEF33cGkJubi8mTJ2PEiBHYsWMH7r77btx8881Yvnx5iEdK1LC1bpSMR6b3xoJzeuKxGb3x2ezhaJOVjFaN1PsoPfPdPrzzs3tL6Ocv7q/aFwoA2jV2zwr9fdzVsKGowozhj66ByWpHNRJwBE2x71gZzIiDHUbsldoBp82W75zZFkhzZaFOmOPwu70dAOCI1FQu3esySW4cAYQ+cNKW6mnZLO7lezYzcOQX4L0ZwHP99R9nKgd+XSa/Mf32kRw0vTgYeHUksO1NdWarpoHTP2vkT2m3vakZVw1LCN+dDvz2MfDe+Z7vo1rL47hs1GScxImJv2WMtf101G4FTv4td0/UK83063zCxMPTPmOeiBOOWk/MhCDg02uAwr9reb4GylMnvWgKnOx2+ee+IZUnBnvCvuU1oPig63qDbQ7BjFNthbWr3qRJkzBp0iTfd3R45ZVXkJOTg2eeeQYA0L17d2zbtg1PPvkkZsyY4f3BRORTfKwRFw3OcV5vlOx7f4dLh+bgnL4t8cKav1FaLU/se7ZMx4fXnoZL39iMXw+7Mi9i4KRn4z+uErWyagtw5j1Ao3ZA14mq+xVVmHGx+R7cELsCq6Uh+PjuqxEXK2SB9NZAXb0G+PMzuVxt22Kf35dHel31tOw2V6les97Asd/koOX4btd9bFb3AOwfIctmjAX2r3NdP7FHHWD4CjbEwMnbhMnfCcLe1cDPLwFl+fJ1b1kzSa9UT/MGK3Y99Dd4q3VXPRvwxliguhg4/idw+Wc1P191setyTQMnVcapwvP9aup3fnjokd3m2rA6WrvqfXUnsPV1YPxDwOk3hXs0QRLkCXtVkfp6tLQjZ8apxurVGqdNmzZh/PjxqmMTJkzAtm3bYLHo/5CbTCaUlpaq/hGRf/q2zsDsMR3x5AV9MX9SN937NEuXJ+gtMl0T9fP6t0JaYhxGdm6quu8/J7wHTj/sc3WNO1lultcyDb0WyMxR3a+owowyJONx6/9hp60Djpbb1UGIOEE9+xlg5iqg9UB54tBmqNcx+KRXqqclluqlOl4DqxlIzHDdR28zV7FTWulROUOlsFSqFyz7Km+LFfa60usOqDTScJbq+fg0+v0LgP1rvd9HobcBrnaNkypw8nOSEoyMkxL4HNxc83MB6s6GNW34IY5Fr4tjTXj77wpkLVhD5amrYjRlnLa+Ln/97v7wjiOYgj1h1/4NslsbVoZOEZSMk9hkh4FTRCsoKECzZs1Ux5o1awar1YqTJ0/qPuaRRx5BRkaG81+bNm3qYqhEDYLBYMAdE7rh/IGtcd2ojnj8/D7ISIrDx9cPc94nOV6eELfKdH36rlzOTldvVCt229NzstwsXFZPSkurLVj1Wz6qLTacqlRnSfIKNZNQ8Q/7oKuAdsNd12N8BD2+6G2Aq2UXSvVSHIGTzaQuz9JbIyQ2fyg5rAmcqtULlmtSYqf9NBWQ97qq6Xn8pdc9TluqZxICJ38DkIDWOAW5OYRY4lfjvcLE5hBVoct6sDW5i2qNW5SW6ikaahYlGPQy7/X990hvc/lgdNUTP5jR7mEYBerdd2zQfMogOT4R0B5XzJ8/HyUlJc5/hw4dCvkYiRqqCwe1wa4F4zG4XRYemd4bZ3bLxsVD5GzQ5cPaOu/Xpbm8n1J2mn+L5/XWQ50oU0+mb/5gB258bzue/GaPTuCkKXuK89B1D/BcZtdzul9j9T/jVCxfThEyTmZhnHprUsRJeelRdc29papmpXpi1ym99TzKnldKYCN5WFAfCN1SPeFN3G7XZJxCuJ5AtcYlCIGKmHEy17DcTjsREx+fv0vd/MMXbx/0RvsEWfWzXAdrnKKp7C9ihDjj5OlYfaL3IaHbBri1LNUL5v5/9US9CpyaN2+OgoIC1bHjx48jNjYWjRvrb4iZkJCA9PR01T8iqr2Lh+Rg8czBSEmQsy/dmqfjx7vG4MNrT0PHpnI2Q5tx0nNe/1a4Y4J7GaA247Rujzxh/WDLQZyq8JFxOmMu0LQbMP6/7k+omjAJb77TXgJ6nudzvHLgpPNJnui3T4C/vpQvp2bLX63Vcrmd4tQB98eJAc6pXHU2yFpVs1I9MbtVfsz9dqVDoV4A5u8nra+Nkdc+eXu8XsbpjTPVXQdDGThpS/VqSxy3qaYZJw+BU/4uuQHIIv1yWF1eS/Xq+SfltbF3NbDrfdf1UGec9n0HPNJa/p2nuhPqUj2g/n8AofcBnzZQCijj5OF3KkrUq8Bp2LBh+Pbbb1XHVq9ejUGDBiEurpblN0RUa60bJeO0Dq4PMbLT3AOnUV2aYmJPV4e8/0zpjpaZ7pkpbeCkSE6IRVGF/IaW4igTPKANnNKaA7M3A6fPcT+BGFBkCKW7cUlA+1G6z6lijAVKjni/z453XJdTHIGT3aLOMFTq7NUkBk7aya824+SrxE7MOJUVuN+uZJzsFvcMkzJh+HMFcOwPz89xdLu89klLr1RPzDgd3aEOlgLdHHj3F8CvH3u/j6c1LoESx+rv3l8KbcZL+XnIdWwuHayJWkPJgASyxkT78+ipq16wXqP3ZsgfiCyfFZzzkZ+CHDjp/e7V94yT3gd8wWgOEa1rBR3CGjiVl5dj586d2LlzJwC53fjOnTtx8KBcnjJ//nxcccUVzvtff/31yMvLw7x587B7924sXrwYb775Jm6//fZwDJ+IfGiqEzg1S09AfKzrT09mUhyaZ7gHTrknK2Czu0+cUuJjUOwo1euXkwlAp1TPm+7nAF0mAlOeAjo4AqVkJdjzY6JmjJH3i4pNAhIyfN8/WciGi4GRNnCSJPUaJy1LlaaFt48sjbgeSq8ETAmcAP19qA7+DHx0OfDy6d6fR49ecwhvWbpAJih2G7DsMuDTq723FldNloUgKtBPrMWAtcaletrAyZGx8tWlUZe3Ton1fMIHyN/DS8OAxROBvI2Bl4+qPh3nPk7kgV7Wu77/HumW6gWhOYSnDyOiRFgDp23btqF///7o31/e02TevHno378/7rvvPgBAfn6+M4gCgPbt22PVqlVYt24d+vXrhwcffBDPPfccW5ETRaiEWPfJckJsDGJjXJPW2BgjmglroZLiYpCeGIuT5WZsPSA3NagwuSY/SfGxKHIETv3bNAIAHCyqhF0nyNIVnwJcsgwYPAuY8DBw1gPANY424MLE6hd7Z/3HG2OB7G7AXQeAc5/z/lxJWUCncZBSHU1tjm533aYNnExlriyRXjt1c7k6wPFV3iaW9VX6CJysJqgm4jarusNfTemtcfIaOAWQcRIzP1Vemo4EuzmEGLAGq1RPnOAEo5NXKEr1tr4BbH41uOf89j7g5TP0A9DCf4ATu4GDm+SNSXevCOw52Byi4RB/N+p7qd7PL8v7+QV742rxAwa9Ur1gZ5waSna7BsIaOI0ePRqSJLn9W7p0KQBg6dKlWLduneoxo0aNwvbt22EymZCbm4vrr7++7gdORH7bcMcYfHajK2vRt00m4ozqPz1GowHfzB2Jvq0zcP+5PXFWD7mUb+0eOZOQX+IKAo6VVuOXA/JEeVC7RogxGmCy2nGsrBo1lpgODL9F3isKUL2pzDB7aN1rdHTUi0v03oQCAGa8ATsM+KWqpXxd7JKnDZyUrEl8KpDewv1cVcXq676CDVXG6YT77fFC4GQzB3ctkN4GuN66LwWyxkl8jLfxqibOQXiTt2nKJWvyqbRbxkkJnISMk7fXQpUx8RJgBXvCZ64AVt4m7wdUqdOhMVA/PSvvcbbrQ/fbtD8ve74K7DlUZUVBbhRCdSuUG6/WdXOIr/8t74W3Rmcdbm2If5/0ur+6ZZwCWePEjBMRUcjkNE5G/5xGWH7DMNw5sSum92+FMd3kTnMJQsle1+Zp+N+cM3Dh4Dbo2VJuXHC4SA6YxOYPRRVmlJms6NM6AyM7N0UzRzlgQUkAgZNWZ3mfuIN2eXxFCa3c7yNuLOtrA9SkTBRWmLHNpHOeykL15FdpGZ6cpd7vSck+abMqvkr1xIxThc56qrhEVxBoNWnWAmkmDDXNgth1Mk7eAidf34seMcDwGmz4GRBKkn+TCO16rJq0JHfLOCmlesInw0d+UXdTVD3ez8l+sD8FFl9fSy33n9I9v96kVfM6N+0a2LnrY8ap8B/vG0xHq1A2PbHqvH/URZOVYAfw4vdh9CNwqu0GuJH8exQiDJyIqE4MbJuFG0d3gtFowISezfHq5QPx/W36zRhaOvaBOlIsT/5X/prvdp+54zrDaDSgqWMD3uNl3jMwT327F2/84GMy0qgtSm/4DWeZnwAAvN3jDeDCd4CRdzpubwe07Oe6f6ZmXzilEYQiMRMSJOyx6+wfZ60GFnUFdrwnX1cySomZ6sBJ6cqnfYPzlaURM056jShiE+V1WspYxMmr3aouhdGbVHgiSfqlet4mITXJOClBnGoy72V8/paVvH8R8NJpvoM47VhrspGtp1I9cfKxZBLwTG/9x+eud132VqoU7AmfzUPwESx659T+P8T67tCpy2M78ghto2ypAp4fIJdx1fc1NsEWykBGr1y0Ll5/X1tb1JT4wY7eh1VB2QBX/J2K0N+jEPKxiyMRUfAZDHLw5ImygW5eYQVe2/APPt2h7mLXOCUeo7rIAYWScTpe6nnyfPhUJZ77fh8A4LLT2iIxzrXexmaXcLLchGaOAKw4tglMkEunipCO460HwJR1Otq0GiB33RPX6jRqB1y3QX4zKs0H9qxSd9RLagSLWcJRqYn+wMqPAf+7UW5d3vFMx2My5eBJkdpMbk2uJX4iX5ovf7qY6tgzSpJ8r3GKiQfik+XOcOYK/fI6hdiUwo1mAu/2xuw4l7fgyFvZoVvHP6u8x9VbZwvj8xK8+BM4SRKw7xv58tHtQM5pns+nzTjVJOjzVKqndw6rSR0sVJcC7wp7jYkTlpgETQlhABM+SZKbgSQ1As59Xn2bKrsXgsmkXuCk/ZkItGW9p4xTTSaMp/Lk38M4vX3pDAjqXjZiKaSlEojxowFNtFA1dwnyufUCp7poR17bDdm1xL9Pej/j2kAnoDVOQS5/rmeYcSKiiKO0Jz9VacHDq/4CAPRq5dqDrV+bTMQY5XfOZn5knIorXW+AhZo9oO74ZBeGPvw9th+US+FKqlz3Lau2YsjD32PEM5tRkjNODjS0WvQFWvYHuk0Gcoapb0vMgNlqx3Fkev+G96wCVt3ufIxuxklLmcCaK4GnugFPdnK9Udos6kmiXle92AS5UQYgT9DESYLdop4ge+seF5sIFPwOfHmr3PZc+2atTHi9Tbi9ZXm0b8zWauB/s903B/bn8Z4+sRYf762kEHCfwNckkHBrR17u+RzaNW3aUk3x/1c75kA+mT+5V27vvv1t98A5GK3jvdIJPNwCVD9eZ71Pvz1lnPx9jfJ3Ac/2AV45Q//2YDcpEF+LKCyD8iqUa5z0Sm61vwehEMrASS+oYVe9WmPgREQRJyvFvT3zbeNdaxwGtctyXlb2itp/sgIXvboJcz/cgb+Pq/fXEfeEOqkJsD7dLmezXlr7DwB14LT3mOs8frU8bysETgYjYIyRAycp0/djFW6les3076e8QZYJZYzK5qw/Pq25s2MyJjaEiE1wrZ+qLlXf3W5VZ3FMmv2KEoSNxK3V8qRy22I5eNJOSJUJr7eJr9dslOZxVjNQnKc+5i1w8tQcQKQKDH1MyNwm9DUIJDyV6ukGTto1bZqMql5zDGWvrEACJ1VWyUvQEkgHRF90M07aANWPjJPefTxmnPwMeH9fLn8t3Off/WtLHCNL9dRUv79BLhHTLdUL4cbcimCX6om/n3prNoPSVa+erBUMEQZORBRxDAYD2jeRJ/X9czKx7Z5xGNM1G9eN7ID+OZm4fFhb532VjNPKX/OxObcIn+88inFPbcDGv11ZlpPlrjfAwgrXG0u1xfWmkZogTzrFwOmPo66AQsxaedSoveuy4w3FbLWjAkkok4RGEjPeBM68V/8cSZnyP0VyY+hO5vN+AnYtUwc4SmZp3cP6587MEa4YXBk0JeBS2CzqdUPVxerbG3cCbtjouCLBOYnJ36WzFquWgZM2CNCuxwK8l+rprbfSEj9t9rWeqzYlZB4DJ51zaF9zbetz5TWQJFcQoDQrCSRwEgNMb+WIgTTy8PV8epmiQEoi9X4OJA/P429Q4nMNRwi7uwUrcPKVRQ2VYK9/CfZm1iK9TGqdlOoFecWM+HviV8YpkK56Ifx/qAcYOBFRRHpgak/MHtMR7199Gpqkylml+ZO747MbhyM1wfVmk52uv2j8C0dDicOnKp1leABwssz1xrL/hOtTRotjHygxcBKd8NF8AoBctnPmPY6B9QQAmG3yG8sJScgiZfcARt7uyiyJAZc245TSRL/tecUJ4LNrgX/WuI5pO/VppQnZq+oS13m1k3S7TT0J1ZaNJaYDTbu5nz8mTifjpDSH0HldkxyZw5+ec70B2+1AUa7r+9ALnLSTHK9rnITHe2oiIX7a7Ctw0gYOtWlHrmTy9IIC7Wtu1mT9nK+rcM7aBE7i9+0tu1VVJG9Mu+qOmj+Hp3P6lXHy43XW+//1NMnz+/+tjhe/q5q0BGnirtddLdS2vA480Uku4w2WUE7Y9X5nQlWqJ/6NDnrGSfz58SNwCiRjxFI9IqLIM6JzU9wxoRuS4r1snApgcLssNEl1L+3bd6wMh4oqceai9Xh/s2s9zAmhbO/vE65P8Vf+mo/FP+Z6DJzEcr9tB4qcm/O6D/x24LzXgPMXAwBMVvmNpYOxwHWfRo6M2azvgHELgWkvuW5LynQGXWjaDeh9gYdF6Q75v7ouVxaqF5f3Ol99X7GVenWxa42TNuNkt6jL37RlYwlpcpOMWM24Th0ATv7tfi5APzhQNuE1l8lrawDguwXAc/3kDVcB9wlN1amaZZzET1S136dCDJx8tdvWBhWlR4CjO70/xjkWzUSm/BiQt1F/DZr2NddmnKxVwP516sm10iVRLyiwmoGDmz1/wuwteBTPl7sBOP4nsOU1z6+nP8RzBqtUT+//rraler6yJsHO5qg2uQ7SxD0cgdOq2+WmNCvnBe+coWpKoO0E6ny+EGWcxJ/9GPf3rqCd25+MU203wGXgRERUv6QkxOL9a07D+QNb4/vbRmGNo8X5trxTGPH4Wpit6j/sT3yzB1ct2YJqiw25J9R17Q98+SeKK/UnaCfKTNh/ohz/nCjH+a9swgWvbMKhIp2JmsEA9L0IyJYzMhabPPH6n82xCXC3s10BS9MuwBm3qkvoEtKBnKHA3N+A63+UA6lYocxP6+Re1+VPrgJeGCRfTsoCztJs4iu+SbfsL2SctIGTVT151makEhwZMb1M2Jvj1Ne9leq1G+G6vPE59dfV9+o/rrLIfULjb3OIQz8LNwglVmKpnrfW5oD7BP6TfwGvjVIHsJ44J36O5/7ne7n9+OaX3e+rfc31Fq+/PVX9+igBtt4nzVvfABaPBz6+Un9sYtChfQ08bTa88wP385Qf995MRO88QSvV0/k58DTJC1ZQEuzmEP7uT1YT4QicQsHfrQVqc15RqNaYiR1PQ1mqp3xf/5sNvHGW/DMflHbkPn53GzgGTkRU73VploYnL+iLjk1T0b5Jim4GSrR2zwl880cBDuoEPtque4o9x8pw5qL1GLvItZfO25sOqO5js0tugZcSuP3Xcim+bneXMxOlIjaAUN6UMnNcHZfEjXYbd1YHLMf+EAZgdm2km9bcldFRxCYAN20Hpr8BdJ/qWuNk0jSHKMr1XaoHuAJAb479Dmx/xzUJ6Sa0ET/jVuBSx+L7ov3qbIhybm3GqbLQfULptTmEHxPkGmWcPJRsinsseaIEcek6GyJruWWcyvTvJ35/3kr1lHbru1cAJ/a43y7uR+WtVE8Msr++Czj+l+t6xUngyc7AUz30x+rpnGsfUp9Hezvg3yTW1yamqsCpDhb+ByIkpXpC1r4uOsWpnjuIgYGqVC+I34enc4Uq46Taa8l7RUWN6WVyd7wLHN4C5P0YpA1wxeYQXONERFSvGQwG9GmdqTpmFD4UToiV/+x9uOUQDp3SCZzK9SfGP/3tXk61JVcOUmx2CRe9ugkd716F/g9+i5/3uzacVQKn42iEHzPP0d/IU2xJq91EF5CDIEV2N+CWXfKeUoDnNy5jrNxFL0Z4vtgEoHFHoM8FgNHo6qr3y1L1Y7+4WR0suWWcHAGZXsZJz4o5romqGASmNAbanu66LgYt3gIn7Zu/t2BHW+KmEM/rrUyt7JjcMVA5j6cJ9+p7gL3feB6H+JwZ/gROxerrehknQFP24/i/1pvwpTR1Xf77e/fbLeJr4CXbox3XSSEIO7xV/qr9edGjDYReH6O+7m/GyWoCProC+OUtD6V6HtrRB6tUL+jNIcSMUwhK9ULRFdHrcwcxMPAUBAfzvKJQBZni35hgl7qptpXQadQT9A1wWapHRFTvDevQ2Hn5ifP74LeFE7Du9tH48a4x+PbWUTAYgE37C52Bz7JrXRueHiiUJ1+vXj4Qn1w/DK9ePhAAYNeZPxU4Nt09WlyFzY5zSRLwwBd/Ou+jNIcAgAqTlzepiz8ERv0b6DTW/TaxEUPjzvLeToOu8nwuADjxlxwcNensOiYEUcfLqrG7yMt4xH2StJNlpR253r5WnigBnvhGm5DhCKQck08xgFGCM7c1Tjpry5SMkyQBn88GvrrLdb2y0P3+gDxBPfAj8O0CdXZHO/l+d7rcZv2b+fJ1ZUKvt6j7/Qv1nwsANr0EfOconUzN9v1Js681Tgrl9THGuQJwvYmg+Pi8n9xvF7N2/macAHUre/FDgZqWPGpfd3+7F25/G/jzf3Kwr1uqJzYHEW6X7H52FKvr5hBiqVUImkOEZB8ub88dxOYHoWoO4enDJ73X36LT1bOmfO21VBvaslox8LfrlOp5C3xsVmDJZGDlbZrHRHfg1EAKX4mIXGYOb4fSagtGdWnq3PMpRejEN7JzU6zfe8J5vWN2KtITY1FabUXuSXny3iQ1HgPbZjmv6zlRZoLNLqHCrJ6oFgnlfuIaq3KTl08wu06S/+nJ7u663GqA/DW9tedzAXKTCgBo2lUulwNUE9sLX9mEicXF6K7MazLaACWHXI8vPeq6rM0gOEv1Uj0/f2yih9Ip4U3XaHSdx1wmdwlUnMpzbKirk3HSUibdJ/cBO9+VL5/1gDzB8fQJu2QDlk6RL6cKGT3thF957f74H3Du867zJaS6Bzee2O2uwAuQ15qlZqv34NLSlk96yjgpr3FMnGuCrPdJuVjqd2iz++2qUj2TXAKa3kpeYydOFN3apAvnFSfo1SXem5r4KrVSuhcqP0eeJqviz4OvwEn782i3AEbH78Txv+R1YCNvV2d4fTaHCHbGSRhvKMoJaxI4SVLtv7+glur5sSdbbc8r0ttD7qnu8u/+3N8Cfz7x5zSQduDeaJtDqBqi2GqWccr7Uf6QJe8nYMoi4TEhyvzVE8w4EVGDExdjxG3ju6o2yhX93+A2zsvJ8TFonBLvbHmuyEqRr7fMTHSbO6y+dSSMBjkLVVhuQnm1ehJYUFqN42XyJM1sc028KrwFTt407ui63NIRODXvrW5brug6Bbj8M+CMufJ1MVslNIc4UFiJSgjf8+Qn1ecRFzArJVgKJWBKauR5zGJpmEhvwqOU5e1f5zpmLgMWdXWfvOh1oFMmIuXHXMdM5Z6zTVrlQsdDT2V/yriVCb12/Zg3Vs2E3hjreWNjhTbD5CnjpGSAjLGuSapeUCK2M6846T5hE0v18ncBL58uNxsBvGecxADP6uV+Wr6CAuV25WfN0/3FiZuv5hDa28Vzvj4G2Po68Ok12ifQP5eT8MchGAvlVaV6Qco4eQsePakuBZ7pA/xvjvttkiSXpv7ylu/zxIQq41QHa5y0r/+pXDnjXXywdpm7kGacNKV6qus6Gac9Kz1/L56ColA16agnGDgRUdQZ272Zs4HENSM6wGAwID1J/QaflSLfnhAbg2Zprk/Obz6zE7o0S0PTNDnoKCit1s0kHSuR34z8zjh503qwnBFqcxqQ3lI+FpcI9NYpDTOXAR3PdGWXmvdx3aZZb1AlBk6N2roHT847ajIryjqllCaex+wpcNL7hNVbkwntpOavL/XHJ0nqLJm5BoGTyFOjCWUSoWSc4n0ETuIkWttlzhCjH/SKtPs2aa8rlMDFV+Ckai4h6WS0hIDxxG7HV8f6JW9rnMTzqjox+gqcfAQFynMmKIGTh/uLkzttgAp4LtXTnlMJmI9s15zfx6a54qcqwQh0PHUwrA3V/lV+ZrF+XQaUHAR2vON+28GfgY3Py+WRvoRqjVNQu+r52RxCLEX1p3OkJ+LvSbADD9X/r6T+HvQCp91fAN8t1D+XWE7saV0TM05ERA1ffKwRr14+CA9M7Ymbx8prgMqq1W+S6YmuEpM2Wa6GBk0cAVPzdDmYOveFn/DIKrkj2JD2WejdSp4QH3OsfwpK4BSfAty8E5i5Uj1RG3sf0P8yoPu5rmPZmo5mnc+Ss1CAOogCEAPhTS+jDTDkGtd9vVEyV8k1DZwMcic9AOg1w3XYW+B0/E/PtykOb5XXIYmlhuZy155WvsoaRZ4+kVcm0FbNhF5PRSHwdE9gxU2OsWgmWcYY3x0JvWWcLnrPlYlRApQYcY2TzgReez5tYCNmnJRAWdlQWQwItMGJch6rWd7jydP5tfSCDDFIsWoCVE8TfnFCp5eVEz/R145db8LsljUSM056gZEYOAWhtE58XYKWcRJfAz8zTt4CA711hp6EqqtenTSH0Lz+4nN66nLpj7rKOAHqLLBYqieuPdM2B1KoujF6COgZOBERRYeBbRvhimHtEONouXfD6E6q2w1CgNK6kasJQmNHCV92uisLteeY/CaamhCLZuny7cfL3DNOAZfqAfJ+H9o9PxLTgakvAhe9A9y4GRg2BzjzHvV9jDHA/70H3L4P6HGu6qYsCFkHJRBI1pTf9ZzuPhZl49vkxu63KfQCp5g4oM1g4I79ckt0hbhWqmV/9WOU4CMjBx4ZjMAvS9Rd7cwVroyTP13sFJ5K9axV8iezzoyTl8Bp43PyxrjKpr5ugVOsurugHu2aJiVDdNG7QPez3ffgMsa5Jjp6n2JrJ3rawEbMOCkBp7VaHrteQKB0ZFTGtep2YMurwvmL3R8j0l14LwQ24loywL9SPb0Mo78ZJ9cJNVe9ZJzKj6sDzqAETgHs42S3A/+sVW9+LRIn5/5msbwFWOJroleeKK7Tqg/NIfzNOInPWauMk7jGKciBk3bMquyWkHHyp4TSU1MRdtUjIqLzB7bGvv9OwpwxnfDKZQNVt43r7lqP0jxDDoz6tcl0O0dKQqwzoHJmnPztqldb2d2ACf/VX3tjMMjNCDRW2h3dBFsPcR0U1y1l9wS6n+N+vqwO8lexVG/yk0CrQa7rqXqBkyNTldLY1RgCUGdfxt7n/jhAnuif/Yz78a5TgGa95MuHt7iOm8pcE2mlvNEf3rrB/fi0a5LlbY2TuLeWJOlnnHwFTtpAp9TRSCKthfxVebzS1S4m1jVJ1U4EbVbXZE1pd++WcfKwb5fevlkAkNZMPc7tmvUugaxxEoMt5ZNy5WfDY6me8DtVccL9dn/XODnPpw2cxMX1mtf1yc7q68EInMSJ79Y3/Jug73wXeGca8PqZHs4pNpzwM3DytjcafJQvipP1UDWHCOoaJ0/NIbS/R8L36qlZiz9UGadgN4fQ7n8mPJe1Wj/j5IlB+BstnjfKu+oxcCIicoiLMeL2CV0xsVdz1fEpfVrghUv646YzO6F/GzmwuPL0dshMVr/5pCbEIjtNyTjJkweL0Byi3GSFXa+veR1TxpAnNcdFaW8BV60CALz7cx7e+EWY8PaaDjTr6brepAtw1VdAumPyLmacstrLwZtCL+PkcRIlvCaeyupMJUCyTrMPya7faEHMOHlab6XH1wa4Cm+Bk7i3kaVKnZUAHBknH63cLZWuCZ3d5urApwSB8ZqMj1HsqqeZzIqTPCX7ps0ImXVK9QCg8qT+5NgZgJW63wb4ETjpTHzFgM2Z2VMCJ0/7OAnHy4+73+4t46Q7+db8ftprUDoX7FK9vJ88rz8R/faJ/PVUrv7tqoDDz/I/f0v69LpWqgKnIK5xEjPKQe2qJ/wcnHajq1zZLeMk7v1Wm8AplGucND/TYpBmNbk+GNBWL+hRlXiKGSeW6hERkQ9n92mJ28Z3hdFR2peaEIuvbxmpuk9qQgyaOTJOx0vdS/UAoNIS/i5E4hhOGRs5yzbu+fx3nCoX3tR7TZeDpaE3AH0uAi79RL1hrZhxSm4CJGYKt+kEK+keSubECae38r8kT4GTzqbB5nJXl72aBE7ipMbbRNlT4CRJ8qa5iqpTHkr1/NgDS5mcbXlNnigaYlxBorNUT8k4xambQ+z+AvhklrzuR8kKxSS4XgtvGSexEUVlkX5AoLzm2iYTCuX8m16U99bSNgXRO6cYsDkzTj7WOIlBqW7GyTHJs9uFSb6jDNfXOivtfXwFHcFuDgEAe77y/Rhf2RdVxsnPMXrLOKnWoun8v6j2ywrS37u8TcC2N13XQ1Gql9ocmPiI/CEQ4P5aif//nrpc+kO1AW4om0NAEzjVMOOk+rnRrJVSMHAiIiJ/Nc9IROtGrpKrFGGNU36J/OZo0gROtVrnFCRi+3SrTT1R/F1yTBpgkEvyDAZg0qPA9NfkznsiMZBJbuwKqgxGuV26lpiREomfknrbVFcvqJLs+oHRV3cBJ/fKl8WMVKuBQJ//8/wcylqfov2esykweA58TKXqT+GrTqnXDwHy6+NP4GQqBwp+B77+t3w9panrE3xnqZ7QjlzZN8lcASy7DPj9E3m9lRKAJaS5uvlpAydPHQgrTuq3K07VlOppKUHQN3fLpWQHNqhv1wtCxCyYv131zL4CJ5sc/OWudx1TNnDWDYS0gZO45kj8pF1vbU8tMk7K+bTn0NtHKf9X9f+ft8DJboe6wUUAa5y036sqC+cj4xSsAEcsww3meQFhE2nHBw+eNpL2d42TzQp8fiOwXacjIaD+exDSrnrQyTjprXHysFeX5CHjpN0bKsowcCIiqgWlbTkgZ6FysuTSorzCCkiS5JZx0nbWC0fpXrnJIlxWj2e9vQ+ebnwvMM+PbnZiwJKaDXSbAtz6BzB7q3rTXkWGhzI8cSIWm6h/H0C/VA+SfqmeqdS10au4oWlskjprplVZKGdrnusPfHmL/n3SWqhbE4uKD6qvV51yL+uxVOmvccpo45rUA/LjxLI/cb8ppYRNDJyU11ccQ8kRV3CTkOoKnL5doM4W6O2PBTjWOOkEGMprXl2q32J+9xfq0jttgKV3TvE+/u7jJE5ClVK9QbNc47NbgFdHyWuAFMoGzn5lnMRP2n2U7QW6t8+fK4AnOsr7mLmdVzOpzd0AvDoCeFXIdnubvGozGoFknNw6tZn0L/vz2EAZNCV/odgAV1l3qWRjtGP3d43TH58BO98DVujsgQUA+9e6Lgc74+S2vlH8v6oSMk5+lFCqMk5sDqFg4EREVAuNkrWBUzJijAZUmG04VmqC2aYJnIRsz6vr/0Hf+1fjlzzP7X235BZh4jMb8PP+APYk8qBMGIN7i3QDNicM96+hQmw8cNte4LY9rkAiozXQxNGh8Jo1wBUr5CYTgOdMjzg51fuEXVGTUj2RGFgZDEDrQe73UQKW8mNyEwhAnvzrycxRbSasog2cPr4S+OY/6mMpTfUDp2kvAXf8IwdQgBxIFAnrVsTyGuXxJqFUL9ORESzOU59XCYqSGrkCLrvF1QXPUuV5IuipOYSyVspSoQ7oFFVF6j23JAn4Yi7wWDtgy+v6E2oxw6dMyH111RM/+VcCm25TgN4XOM5ZIu9HpIiJd/3f+dNVz1N7cL1MS6BBwkeXy6/z21Pdz6H9ffjzf/LXUwdcx7xmnLRZkwDWOGnPoSpn1fl/8bQepja0E/26yDhpvzd/1zh5a9decVK90Xe4Mk5+leoJ713ajXQVDJyIiKgmxIxTSkIs4mONyMmSy7D2nyjHjoPqzWP3HS/H7vxSLNt6EI989RfKTFbMeHkTjhRXYeehYrfzX/jqJvxVUIa5H+4M2pjFYKnSbINNk/XSSyB4lNZMndERtRoIdBgFzPxSbpferIf+/TytfRJNWSQHalqeSvVUYxTGZzC6AhNRi77ybZLNtfGrJ+ktvAROh9TXKwtdHe3aDgeGXCfvvaW3j1NMvPw9KlkWU5lcMqi4SCj9UdqBK+VtxjhXKeUpMXCS5NbogPw6i+Vmuz6Uv3rKNgGO5hB6a5yaucb5x2f6jz25z3X51AG5ZXzVKbl1+Z5V7vf/6g7gnzVyVkUpzXJmnDxM+LWNNwA5CFb+z8s0QV1ckmti/OElvrNEntY46a3tCXY7cgBuGSe9BiteAyfNxNzfQEbMGrm1uNasm9FStdsOVuCk+b5D0RxCeQ5PG0kHY41TWX5oN5B1C5yq1ZeVnwexVM/Th1Xi9+9p7ym9ktUGjoETEVEtiBmnNMemue2byJPaJ1bvweFT6kXWt3+8C5Oe/QF3Lf9NdXz4o2sw7cWf8Nth/W5kpyrlN8QtuUX4cZ+Xia5GWbUF172zDSt/zXceE7NegHvWyVqjyMkPyVme1zcBwOQngI5jgUuXy9cHzXIFBoDc6nzw1fqPlexy57/4VDnwSdHJPomBlcHoKtUSNenseqzep8lKBgOQywk97YOizTiJWg0AJj8uZ2v0Mk7KOZUsi7ncFTjNeBPoOsl1X2UtmNiOPLOdfFnMAEl2deA0eJarpfmx3+WubW9P9TzmksPADp21GnHJrtLAb+7Wf6wY9BX+rb5NzEaJ3jkP+EsIqpTMpzIhLCsAVt4OHJc3ndZda5KQ6voetYFTrBA4VRW59tpSeCvVE4NO3YxTEAKnTS+or2sntTUOnHRa0/tDlVXyknHSbQ7hJVsVqEADQL/Orc04echIBmMfJ+3rVedd9Wqwj5NfpXoext+AAyoGTkREtTC8U2PExxpxVo9mGNJeLiXr0kzuBLbjYHGNz/fNH66J3sly15tVy8wkWGx2XPjqJlz25mYUlvu3nuLZ7/bhmz+OYfb7253HyjSBUmmVeoKgzUCFXEZr4PJPgc7j5OtnPwXcfQQ46wEguwfQQ5jYD5sjtyxXmk8Mvkbu7nfr73KZW4dR7uc3xsjldQDQc5r+GJp0VWemmvdxXc4ZBswQNuwVy720tGVyIjEY9NYcQunYt/wa4OAmx/g0ewYpmRilqYMxTg5QlS50ivLjrtLDjFZA447AbX+5snw/Pg0U/eN5LP+sEZ5TOLe1yvOaNaWlvBg4iZdFOacDp81WHytxZO1yhrn2GLNb5VTop9cAW1+XAyzAvfEGIL9+zoxTvvq2uCR1mZLSedHJz656epkqX5v+eqJdv6O6TTNNE0vWnO3qa5Jx8rNUT68EUiF+77rNIUKQcdJmFoP54Y5zjZOm8Yp2awLVGifNmr0j24E1D/nY/wruGbq67KpnqXIFNP6U6qmaQ9Sgq94PT8l7nBV6+btSjwVxZzIiougztnsz7HlwIgzCJ8MjOzfBK+sDe9PIK3K9Wf+V73pzrjLbVIHU4VNVaJzqoUGB4K8C965nVWb1m3VJlQVi8ZotEj4tNBiA4bfI/0QT/guMf0iexBTnuQIKZeNeJdOg6DJR/nrNWuDoDjmzpadpF1fjBAAYOFN+7PpHgZ6OSXqXScDer4Ah18rZGj1KJiWzrXsQJZbn6WWclOYIbU6TAxZlAhqb6NrkV6EELUp2LCZOfs16TlNniP753nVZLIls3NGViVIkZnqf/I9/APjyVsfjO6tLHhPSXeutMnOA0sPqiZOnSVSjdu7r6ZRgrf/l6vLML+fKZXwAUHZU/qqXHYz3knESS/UA94m914yTRf+4Qlum6a+EVM/7XhX+Dbw7AzjzHqBlf3XGyVQq/9x7C04CbQ4hNupwW+PkqzmEny39a0IbkISkOYTjtVXWO2pb7avWOGkCudfHyF9j4tXbMmhpA6dgZ5y0Qa6tNhknYWyqjJPwHJId+PVjuaOlZJf/3ii/v2seBC5YWqPh1wcMnIiIasmgKacZ1C4LiXFGVFvkN6l/T+qGCpMVz6/5W+/hKltyC2GzS4gxGnC02DVZOFFucrY4B4D8kir0bZPp83xKiZ+oUhM4FVdqM04+TxteBoM8odZmYQBgxDy5BKvPRfIeVEpAldIE6HyW53M27abem6n3BXJJ37nPu45d9I68Hii9hbrb3fBbgI0vqCdzQ6+X13998i/XMbHVuph9UrToK38dOBPY8LhrotZqkPvieKURhEKZ9I26U7+0DlAHKI07uYIQRZuhwL5v4FF1CTBvt5zlymyjzji16Asc+EG+nOZoxiFmHpRARysmzn1PLOWT/uTG6sze9rc096vSD/TiU12vhzawik1UB0c2iyZY8pZx8rDmQ1ESaOCU7n3D4L+/A/avB+47qR5DtRI4eZl8u63T8TMDJL5u3rrq6QWQ4mODFRi4bV4cwjVOSimvthOkt8BJcewPeS2jQpLU5Zba1yvoGScf69GczSH82QBX/HkXxq1a/2YDPvVURh0BH8CFAAMnIqIgi4814pHpvbFuzwlcOKgNhndqAkmScOGgNli35zhW7DqKrQdO6T72WKkJ6/ceh8lix45DrvvY7BJ257s+AdWundJTYbKqgiJJkmAwGFBlVk+ePtp2CD/+7Vo3FY4W6UGT1AiY+qLv+w2a5dpQM7unnKE441a5ecGZ9+qvg4qJk4MmQD2hb9ReLoMT1zd1PksO7A785HqepkKLdjHjNHurHNg5s2bNgJmrgL1fAwd+lPfR0lJKDxVKq3ZvjTayOrouN+7kfnv/y4CDPwMmD5P4qlNy8KUEYOJeXVkdXIGTt02Mh80BfvvEtQ5LL3BSaAMnLbGznCIuWV7vFZMqlxZqS6riktWZBJvFe4MIvYzTsT/l7KWWp4yT1QT8+AzQZQLQsp/77UrZpTfKp/xiaaIysa9JqZ6/GSDVXkPe1jjpvHalQpDsb2mg8/6O5izZ3dUBhzZQsVvl9TwxQZjGagMn5edRu4+b+Dp4KsnT/rzaLOqsaagzTgHt4+SBp4yTWMLo7f/Xn+CsHuIaJyKiEDivf2s8+3/9MbxTEwByVqpNVjIuH9YOC87p6bxffIz7n+F/Ld2GG97bjg+2qCdivx9xTWiPOLJRpyrM+CXPPQj76e+T6LXwG+f9AGD7wVMoKKlGhSbjtGLXUVVpYdCbQ9TSoaJKPPXt3uBuHjzhYeCi94A79gPX/+BqU37VKqDtMN+PFzMEXSYCZz/tup7Z1pUNE++Xc5rrsrJZLQAkZbrvUZUzFBi3ALj6W/3NhLXrixo7nk9vf5b2I4GrvnJlggC57AuQ1zr0u0xuzNHjXCCrvfvjAblUcPA16mOdx7vG1kkogfQWODXu6FrLpjx/gk6QCsiviTFGv2tifJr+uikl+AT0/x8TUtWT1+oS/XU6CnEi+tHl8mT65WHAFze739dTxumHRcC6h4HXRgGr73X/JN7fzmp2m3rCrgSAeoFT3kY5wAsk42S3qV+TmmacxNehpmucvv63/Pr++LT6uDZQObodeLSNvBmwP/74DFgyGSjNd7/NLXDykHESXwe9boKAHDiJAZ+39WFACLrqecs4ifs41bQ5hIeMk8XD6wAwcCIiouDo0NRVpmW22fH57OG4cFBrPD6jj5dHqZtNHHFknM5+/kfMeHmj215QN32ww21+NuPlTRj5+Fq3Uj2tYCScdhw8hXs//x0llbVf4zDi8bV47vt9eDXAdWO64hKB7mcDKY392wxSq+UA+Wt6azkL1WkccN8pubTvcqE997DZ8gL/0Xern0ecuHjLqngSn6wOKPQySIpe57tv+pszDJj1nbzR8bQXXcGMXpA29Abghp/k8jyRwQD86xt5r67u57qOJ2Z6bn6Rkq0OrGLi9LN7gCuYzNZpY28uk9uJa4l7fZ33qvvtzXqqJ3tVRTqdzrzsX/PDIvdzTnEcO/Y78Pun7rfvFcofNz4H5P2kvt3TJFyrKFfdJEHJiGgny8WHgCWT5AAkkOYQ2qYINc04lRx2Xa7pGqctr8lf1zzkfUzKsVW3+3fej2fKr/vXd7nfpm0OoWScvK1xUnUOFF7jmDj3UlCR9vUKesbJyxonS7WHjJOHduRiGWFlketDIPH/wtvPLgMnIiIKhuT4WDRPlzMO8bFG9GuTicfP74spfVro3j/d0eZcbPSQV1iJg4WVzozSD5oW5UUV+q2RzTY7/jkhr0GINeq/YZqt6k9BX1izD+/87KVbnI7zXtqId37Ow+Pf/FWjx2mVVbsmAof8KE+sM816ADdsAm740XXMaAQGXCFnVRStBgD/OSavPRIlZbou6zWK8IfY+U9vvZdzrD3djxkMQJvB7psHj/mPXAYoBmVdxns+d3yK3MlQ/JQ9u5t7MwtAzhLlnKYObryV6iVkuI/f155d4usqNvtQtBqoXntVdco942TzklHRNgVpOQAYcKXr+q4P3J9T29lP6YSo8Ddw2vyKes8tZ8ZJs6+O2PpdW3bpTztybadCt6yJ2PxBJ3ASSxYDDQyUDbUVeoGTt+OelBxxP+apVM9arekmJ675EX6GxKxyTDxU6+S2vK4OxN0yTiEu1asqFp5bzDj58WGR+H+39r/Aozny+MWMk7e27MEoo4xADJyIiMJg2XWnYWj7LLx0yQDnsZSEWPTTafhwescmbsf2HCvDyCfWOq/HCBPXaov3N+MtuXJ2qmWm/oS9UlgDdbCwEk+u3ot7P/8d1gC6RvxxtNT3nbz4eb8rk9Y8I9HLPcOgWQ91aZgnsfHu+/EkpAFXfgHMXOk+SfTXgCtcl7XNIkRNu/p/zvQWwJxtwC275K8XvQd0PNO/x16zFjj3BaDDGKCFTvZ05O3qtVyAvLZMXOMjduozOqYoYsZJzGwpOglNP8Rz600OWw5QT14Pb3UvN1IFBpqJqLbUKzZBDv5mONax6bVH17Y815ZnKc+nXbemtfV11zoywDVhV5VUWdSTWe14A8k4aYMt8TXRy6CI3RqVsW18Hvhrpe/nVrgFTh4+NNF7vb3RC1I9leoBnrsLij8zYoMSu0V9v7UPAb997Pn5Q91VT1lfCTjakQdYqqcoP64p1YugD7PqCAMnIqIwaNs4BcuuG4ZxPZqpjj82ow/uP1edIRjeyVXa1CRVv6zreJkJG/aewJe/HsXfx/3b1b5Riv65qoTAq1TI+JwKoOzO06b0/iqqcE3MtG3U/fXyun+wYpeHrm7h1H4k0O6MwB/f/Vxg7AJg+uvqT3fHLXRdnvqS54yOJ7EJciapSWe5nNFfrQYAAy6X/9Ob6wROff9P/iqW5vW5UH192svy107COqhOY4FUx75MSudB0aCrXJe1a8VEQ66VA0PtZO+7BerrVi/re47/ob6ulFkqwZ9YSidJ+g0jtJNlZRI+cyUw6XHP49dadbscJIkTXLsFqDjuuq7Ndonfz6aXgK/nu6+5qk2pXlmBOotitwCHtgCr79EvrfQkxt+MUw0n7nr3d9sAN9ZVaqptJKLwlHEyV7r/zOTvFM7heL2Urpqh7qonMle6/q9r2hxCpCrV8/L6e1v/VI81zDwaEVE91bV5Gro2T8OR4iq8tmE/7j+3J9pkudaLXDeyI1bsOorfHI0ierVKx+9HSvHOz3nOcrp/T+rm13NZrPoZpGqLHXa7BKPRgBJhc9zCChOWbz+Mwe0aYWBbzxNUi5CZ8hQ3SY43cG0rdy0xWAqkOcSfR0vx2NdyueC5fVv6uHc9YzTK7de1Tr9Fzvo06xW+cpnu56gbKJx2o2tT2q5T5GxZp7Nc5XQz3pTXgrUfAcz9TZ05Sm8JzP0VOLlX/p7E805/XZ2l8pYBnPyE/FX7qfyhLerrSmAgSb7L6JTMiNJqXpyY71sNvH+h+2MObZYDjNNuAGBwTaZjk4Ch18lZpd1feH9eRcFv7hmn8hOu69q9upT7ShLwzXz58tGdcpfAHlOB6a/6LtUTv0cl+yRJ8kRb6ZYoPl8gbdq1GSdlTGPvA75/QBhLEDNO4mbDCenyucXAyWPGSQicLJXur5d4XiXQjEuSg+xgN+LRa9bhHFuFsPZQ+Lvr6W+wXsbJbvU/WK3p/009wcCJiCgCzTurC87t2xK9WmXgwEnXp9hT+7fE0ZIq/HakBM3SE3DV6e1x28e7VI/96vcC7el0XTioNRZ+8afubZUWG1ITYlVrpZ5f8zdW/ip/gn3g0Skezytu1Gvz0Glizvs7sOtwMZ66sB+GtPcchFVZXBOLSh8liHrEwK/aYkNiXACNIOobo1G/7XVdSs4CbtoO/L5czvSIa49i49X7YwFA7/Ndl/VK1mITXI0rlI2Ir/xSDrTKhFI4vXVNvogZGsA1KbZU+c4IKBknZUIqBh2e9tNSGiA0aqfuRqh0WjTo/Ixe9inw7nT344snqK/brerSQLdSPcdkWMwUHdwof/3zc7m8cd9q9WPEUr0//yeXNyqU83x4CbBnlWtdmsEol4XZrOrHa/c18iRWU5arTNbjtXt+1TDjVHpEbg1/xlzXMe0GuICcpS0vULckV61xEhuMFAvjqfS+jkx5XHwyUIm6zThJdv/X0wH6gZPN7H1dk6iBlvExcCIiikCJcTHo1UqehLRrkoKF5/RAVmoCstMSccvYzujTOgPjujfD3mNlbo/ddagYAHBO35bo1DQVx8uq8d7mg27369kqAz/PH4stB4pw8wfqfWmKK81ITYhVbaCrBE2AHJBkJOmXexwrdU3KCj00qVj5m3yu697Zhh33eW4+IK7Xqgwg4yT2vyitskRH4BQpGnd0b4oRDBcslTu3NXF0EkwR1gAGo73zsd/lBhfarmoKY5wrq6BkRpTASfyUPcPHmqXyAvXkUgkWxi2Us2DKpsGxSe4t21Obu2d3AGD948AfQmc/bcZJmVhrW20D8qR653vux8UMyqb/b++8w6MouzZ+b0s2vfdGAqGEUAOS0JtIF2yISLEjgqifih0sKK+94yuv2BVFUFGxgPTeIfQakpBGet8ku/P9MTszz8zOltCSwPldV67sPtOe3UyS595zzn0UPdLMdby4OLbSel5r9MUvmu9rZmmQH29psJ8mxqaGsb2PAOl9Vaadmk38a3Il9Uxg9VyFcFKk6gHqTXBZIcGZebfEv54Consy86xRiTgxf4QEswkhVe9yu+opEV+DC9apar9LSnMIR1ylwolqnAiCIFoA0/rEi6lm/p5uGN8tGj5GA0K8pU9mr1fUS43qFI7ZQxPx5A3t8dj1bfH86CR4uUnCwcOgQ7ifUXT4Yymp4v8B23PnS8+20yQVQEG59Knm+QqTmJYnwEah2IiQGjLhdAE1Tmy9lrNrES0Eg1ESTYDcBEL5ab9a6t7w//DfU2eon3/ZPcDp9cCJVerb2WieTpmqxwgnofmuPWt2QIoAaHTS4j8wHvi/I9I+USl8/ykWPzuNjnf8l3cKFGCb0QLSot6eKFSDFQxCuqVAgwnIlUe8AfA2/cL17EVqlLBzslfjpFavNz9C3SYeAApP8PVVjlATTsJ9w0YjlaLku9v4XmIHfpDP00a8sMLJ+voFJ81LHXFyVHPUWOxFnK7xVD0STgRBEC2YCH8jYgM9kRjqjdEKO/OkCD5i5edpwMNDEnFP33jEMz2kPK0iKtDL9tPaIqspQ4kd4fTt9rM2gkggjxFOpgYLymvl/4BZ1z5nPaMuVjixx5SScLp68bHe+0rr9DuWAgHxwO2MTXjqdODxk8Dg5+2f76uxwIqZ6ttYlz+9IlWvvlqqWxGiFUMU5hMCB36UzBuUqWmAlJo4YoHceRDg674EBjsQBsr6IkFYNkY4sUJAuWg2m/hmtEoEYWcxK0wVHNTgsLVCrKDgOEY4Kd4HgBdn/74E7P/Bdtv3E3lHP0eIwokR4CHWOtH8w7b7OaKu2nY/tRont0ZGnLZ8CHyQYiuElVyIIYO916U2twaT64KIIk4EQRBEc8Og02LVY/3x5+x+6B4r/3Q9JtDWbrxTlFQD4unGf8KqZkteUl2H4qo65JSp/yP+82CeXavxUwpXv9wy+T9QpQBS9o1iqZEJp8an6rGGEpeiGS/RTHlwCzB9ExDZTT4e0xOYvQ9oP1I+7h0iRYkEet5nX+SwsM5+gq0zG1USogpCfYy9Br9Z24GvxluPVxFOU1bwRhnhnWwjLYEJ0uPgdvZNMZRmARYHqXr2YBfWwnFCelqDSS4uBITojaXBccPUjE3A2ld5QccKJ7YGiz1GWePEsn6BdY6VwJkN/MK/1DZF2QbRopuJOAmiNS9dGnNFONXX2L7nrHASXfWs94urEad/nuX7c61bYH8fjruwiJO99D6111tX6XjOOnfJrIUiTgRBEERzxF2vg16nRUygJ/w9+YVcz1YBqo51SZGScPKwRpwEAcWSnl2O/q+vxarD8h400we0RrdYfwDAmUL1IuFT5+Xjw9/diN8PSJ+UKt3xHLnl1TLmEBdiR04Rp2sEz0BpsXshBLTiXff6PaZuec4S2kF6XGPtM8Y2MRYWjILIUNYnsQg1QXqVnmqegZJRhjLi5M2kzHmHutaXB+AXyf++BKx+0bX9hWPE+VpfkxDhM1VItViy+YVKx5qYD1KUwumLUcD6/wAHlshNFgoO8z2DALnhhlqqnvDeVFkbC39/O/DlGL4eyxWxo5aqJ9xL+QclC2+XhFOVrRCR1TgxrnpA41316hy0mlBawzuCzRaw1Nta0gPqr5f9GakR1hG4wxr5o4gTQRAE0dz5aXoaRnWKwIKbVfroAEiOlBZxnm72jRIWbz6DSoWg8XbXY1SnCMRa7dFzStX/Mar1kZr53V489O0ecBxnE3FSXoeFjThVXYBwqmKiVFTjRNjFP1Za4Aa0km9rcz1w+3fSc0/GjEJY3Gt1UrpdXjrwywzgPG+D71IfLWdNkFlbeb2HPMLkHSq5+znj/FG+HujcLtf2B+QLaCGKJgi6mlLeWp2l8wSgx93SsawLm7C4Vy7Ui08DZ7fIx95M5L8LQlTnbmsC0e//gDuXWc9t/XskNAne+T/70RGZcFARTsFt+e+mcqCqkH/szHgBsJpDKP6esdcSXfUusI+TnfRo/tzM3+O7/7G/nxpqaXlq5hBss1819EZJFF6lwolc9QiCIK4i2oT64KNJ3e1u7xrjjzt6xcLHXQ+DTvrsTKNx/D957eMDEeXvATe9Vkzty1VJ46s0NYg1TgkhXjjNRJ/+SM9F61Ve6N0mWHZMRa2jiJP0D/2CIk4mxhyi2kF9RSPhOA4/7MxC52h/JEU6iCgQzZsBT/E1MMOZFCgfea0gtHp5Kh5rrc6KBoMHvzD+epz8eFeEk0El4mQPN0+565xXqPN+Xd5hvE150UnXryNQXSg9NimEU22Z9B5M+AaI68NHyqqtkThwUlQN4FPV9nwFrJoLTFwijevcgEM/q19fWIAbPOTiBgD6PykJM3OdXAA4ss1uMEnpkWo1TjoDb61uKuPFgneIixGnavvpkQDjqme9n1ypcXJFsAFSfZNGC8Rcx6ee7lzk2rGWett76EIiTgajvN7PVfv5FgRFnAiCIK4hNBoNXh3fCU+P7CAbf9pJ09z4YC+46fl/GZF+/ILjUE4Ztp0ukplEZBbxnw4HeBoQHWDrJvb+mpP455A8/c9RxIkVTnVmi6y5ritcrojTrrMleGp5Oka+vxGnzjtInyGaN4OeBp7K5FOMBJTCyWySRwaM/kBsGv+Y7T9l8IIqrvSWUrrVOcLgKU/xcvd2nKoX3RMYak3Nc2Xxr+Tfl4Dzx/hFsJCqJ9SxVORIYip+AC+aALkIYRfbDSZgxSw+xZF1u9NopQgdi7meT38D+NetNIfQuyvSJJkoh6M6rjcTpf5fan2cAEkgC/N39b0zKf4esIYYF+Kqx7okOtpfiDjpPXixomakIZ1I/lRNnKm93sZEnDgzf99cZZBwIgiCIHBv3wQsn9Eb793e1em+EX78P8adGSW4/dNt+HjdKXFbZjEvnGKDvOBjVP8U/ESBfEFTabIvaGoUTW8b66zHRpxyymox56cDWHuswMERrnGuRFqgLd+TfdHnI5oQ5SftrGMdYI1OMKJI78ZHS27/Huj7mDSuNJsQcCXiFNXDtbkCvIBoOwzwCuGbAQPqfYxGvQUEtgbG/9d5nyNHlukAsG2hNYJg/X0SU/Wsi3qDl/x1skKONX2oOi89ZiMR1UXq160tZ5rfetqaQ2g0ckdCVjiZVWp+hObCpnLg72f4x2qpegAjnErk+zmjVtGqgZ3HhbjqscJJeW4WIeIkRNKUdXGOUHttanNzFnHSG/nrCoYYH/cCdi12fR4tABJOBEEQBLRaDbrHBmBUpwg8cUM7/PFwXyyawi/mXlfUSyld+N74+xjKaurBcRzWWUVJTIAHfO0IJ2WKn+NUPXmEqbHpemzEadXhfPywKwt3fb7TZr96swVzfz1oY4ZhD7YxcGHFpUsBJJoByohTQy0QmwqkTANueI0f8/DnnfrYlDllipaAUjipOfdFN0I4uXnyUaxHDwETrTbrykU/APS8F3h4D9+IWG07i2ew7Vjb4fLnQgRHo7UVlz7hciHEXo+NUpzZKD1moxxldj58MJVLNU4GD/WURK1WEk/OXOXYWrIT1jogu8LJWkcmCBdXU+aUVu9sxMnGVc+FCLqY9qh4rISNOAGuCXZxXmoRJ5W/tcLPUs0+XxjX6uTmJb8/Ks8DNzcAa17hHRVbIFTjRBAEQYjodVo8NIhvLtox0g9HXx4Od738M7a2YbafZC7acBonCyrx1yG+3iE20BMNdpo0KU0lHJpDKIRSRW09wv3s/NNWwdUI1c97zuHLrWfx5dazyFgwyun+bH+rkktYO0U0A9gaJoAXUhoNMOY9x8eVZKiPs4tMr1Cg76NA3gGppsfd1zXhFN6JN57oOsl6XkYEOIsoOdvuFQSUMdbdbUfI34fdn0vphO4+tumHyoa8rAipYaIk55nGvuz7JQgnrxB5VMrERJwcRcX0Rl7gOutjxIpbUwW/oHdFOGVuBw7/4vjcAjYRJ+aawvzcGlHjxEac2Mcs9TXALw/xj4WIkyPhpCxoPbuJT6vr/6QkTtXSAoWIk5uXejNj4Z70i5K7LRadkppW7/kS2PAG/zXPQQStmUIRJ4IgCMIuRoPOxtZcr9PK+kEBwIdrT4qiCQCCvd2hVRznZXXxs3HVcxBxMjXI922spbi93k8WhajLZ5r2KrepUXSJhdOhnDJM+t827MsqvehzERdJSHsg1Frz1OZ6YMR/Gn8OwenNM5gXXUJEJ74///zWL4C5pcD0zcD96+z3YWKZsgKY9JPkWMeirHFSpmk5jTgFSY9veBW47UtbAbDOGm1z9+WjCqzNelwfxfW0UrpWDRMlKT4jPWbHc/fx371C5eepLZfsyB0ZaAjbHNl1A4qUNI6PoKiZQwB8LRsAnFkP/DjF8XlZHKXqCfVa7ta/ny7VOLkQcdrxqSRKhYhTuLqzqio/3c3bwu/7RhpzVONkLw1Q+Dkoo7Zs1LHwuOvzaoaQcCIIgiAazceTumNw+1A8N6qDqmnSdfGBsCg+1YwLUi+erzQ14GheOd5ZdRw1dWacPl+JDcf5T52FiFOgF58SVVpdjzVH87H7rJ1PXhXYizixwgeAaHwBAAUV9vuhnCyoxMA31uLb7dKn8yWXoLHu/V/txuaTRbjp480XfS7iItEZ+Ga6c0uBO38C/KJdO67XdP77Tf8D2gzlhc7U3/ixe1cBg54FRr0p7a/RAOHJfCqdK3gGAonX2y7whTkLuPvy12ZxJpxY4RbRhY8c2KtnEQwg3Jjf59aDbfcT0rVYMVOW5WQe/vLnslQ9O+YbgLRgF6zDXaWygDGHULyvwntybCVQybgn2jPiEMSQo1Q9welPiAa50nuJFUv1VerHlDLvqxBxYg1PfBX3cECc+rVY10VHrnr2ollCdFUZ4WSNOlxJT2zGkHAiCIIgGk1MoCcWT+uJe/sl4Pv7UtEvkf9EvU2oN36e0RvJUX4wM5GbfonBmJKm/s86t6wWD327B+/9ewKpr/2LwW+tx5TFO3CyoAK1Dfw/2XBf/h/yttNFuPuLXbh54RaZm5897NVPPfdLuux41nEvq8R+x/v5fxxGRpF8e0nVxUeczlnTF10IdhEO+HlvNm78cJPdHmMA0OCKM6NW23gb5WHzgYd2Ap1v5Z8nDADCkvjHgQnAgCddiyxdCOxcp28ColPk252aQzDRHCFaYM9BbaRV/FXkSmORKi0QXBWELMoUQFOF3I4ckCJZLEKUpaqRxi+V+c5T9ZSwDohsGqZ3iPr+QsTJYpbS24zWaF1tKe9a6Ahlep6aWyDbx0uYk0YDpM7gH499HxgwR9qn98NAj3tsz1PB1Hg6qnFysyNiBbGmPJa1hifhRBAEQVzLpCYE4et7emHr04Pxy0N90C2WX3D4eUiLta/v6YVQX3mTz2Bv/p/99jNFOGXt98QKmO1nikXxFWGta/rjgLRYYyNDB8+ViYvlHWeKsXDdKVTU1ttdQP99KB/7s6WUmmJG/GQ7EE5q0ajSmnqX0vsc4agZsStwHIddGcWXRMS1ZB79YT/2Z5dh/sojqtvPV5jQc/5qPPtz+qW/uE4PhLS99Od1hSLJ2VK0CmdhoyRq0Scz8wGDYPygVk/j7sv3CAKAKKs4S7lL3bThQoQTm/4HAPu+Y+zIreJIp9IsWIw4nbfd5ojKAvvCyV7anxBxA4CAeGY8yHZfgBd+xaeBX2dKY2zEZuNb0uOybLl4AeSpeoAd4cT8fFkRfcOrwBOngTZD5DVxbt7A6Lcld0SBk6ul+ic14SRE/+wJJ+HeaHuDfJx9L9kPvFz48Ku5QcKJIAiCuCRE+HnA211afEzr0wq9Wwdh/vhkAHIhBQDzx3eCXqtBVrG6uHn254MAAJ1WIxpC5DG1SGetkZ+zRVUY/cEm9F6wBltOFuK2/27Ff/46iv9tPANTg8Vu4IAVGWzqXrad+QCQRdHYMUfOgK7g6ea6V1N1XQOKq+pQytRWrT9+Hrd8shWjP2iZTlWXGnt1c19vzUBJdb0s1fKqoPyc9FirsrRjozTtR9tuZ0WSIELUrK9DmH5v4z7ho08j37TdD+Ct0BsLZwaSxknPz6wHDizlHwuLddbJUECY8+p5jbteZb70OpV1O/Ys4tkeWhFMHZE9MZG1HXi/G7D/O/65RmdrdGEx8/P48Drgg+6SkD2wFNj9hXxfNeHE/pFjDTI0Gt74A5ALTmF/ZYSvphj4+1nrnBz8TfOyE10TRHvn24GbP+PTPgGFcGLeP1dSFZsZJJwIgiCIy4Kv0YDv7kvFpF58ip6fh7Tg+WBiN9zQMRxpreWf0p5+dSSeGSlvxntP33iE+Nh+yny2qAp/H8rDnwel+oM/0qWI1HprnVSYj7oL3/lK6Z82G3Gyl6rHcRyyS9RF1cUaRHi5ux5xGvfRZnR/eRW6vrQKP+zkBcCf6fx7cM5Bitq1hEHXyDS7qwU2AsLC2nSPeRe47gFgMNOAVi26NPpd+fPQjsD4T6TnIW2B6+5TjzYBQFAbV2Ysp66KN85IulEaK7Q2UXUl4tRY/n4GOLWGf+yrMDRoM1Q+DwEjExXrMJZPeRv+H+e9sATcvGzrqcqygYIjfHStrpI3yyg8ASy/1/b46kJg2X3Anq+kMTYVrt5OxFyvJpz8bffL2MB/d2Rc4RksTw909+WFknBerZZvDh1qTVU12RFO9ubajCHhRBAEQVwRfD2kBVaXaH8AwBu3dBHH+rQJglarQXyw9MmvVgM8OrQtAjxtP2Ve8OdRPPD1biz486g4xkYSBIe66AAPLLipE9qH++Cn6Wni9kI7wsmeOMorr5VZpw/tEIrYQH6xlFN2cYKFjTg5qsHhOA7H86VFyJxlfMqZ7goIhaziarz+11GUXQIzjMuNTqv+frS8xCAXuf17vs7ojh/Vt8f15Rf5w17ha3dGvg70fwKY/DPwyEEpHY6lywTgiVO8ZfS8MmDGlsal30V2Ux+/9Qv7x5gq+MW3mq24IEx0KhEne32FGoOPojeVVstHTlhi04D+j0vP3X34lLfU6a6LNzcvqRGvQPEpucHDrs+BD+1EvLZ+BKT/CKyYJY2xUag6lZ8loP4esRGnPo9Y53JGbtOuhpunPDVx0k+8ULLZz9t2TqyNuTMXxGYICSeCIAjiihDs5Y4uMf7oHuuP6AB+kRHuZ8SGJwbh5u7ReHQoXx/SIULK/7dwgIebDv6eUpqf4LCndMazR1SAB26/LhZ/PdIfPVoFYvoAfvF3vqJxEaeTBfw/eS83Hd64pTM+mtQd3WL9AQBbTha5NBd7GA3Sv2NHLn019eqfAusZoVBrZ5+Lpd/ra/HxulNYtPH0ZTn/pUSvlq6GFllS4RrtRwL3r7VfY6XTAxO+BnrPko+3Hgz4xwAj3uAX1sMXyLd7qTTGdRVlBEeg7Qj584SB0mOhR9WQF2yPcyVVT42gROlxx5v4730fBe5bK99Pbb6sy1+rfsDdf8kjae5Mep+rESedwTbiVHhS3teKtQUXr2WNdOXslcYElztWONXb+RBHVTj5S48jOvMpnXWVfK2Yox5TBg/Ag6n1slffJfzMWIHERp/qKOJEEARBEKpotRr8/GBvLHuwN7TMQj82yBNv3dYFPVrx/4ijAzzFJrt92/ALN7YJ74tjGZtdF2ilsEEXTCkOnSvH2qMFqKitl5lS5JbWqkZ9BOHUp00wbu0RA3e9Dv0T+Vx/IS3QVTYcP485Px1AlTWCVc9cr9iBIFTWUgnvC1t75aqgbAxHciWL5YuNrl0J7EWcWFxxZbxmiEsDns4GUh+8tOdVmj0Akl22wJRf+Wvf/TfQeQI/Fp4MPJMjN7UQ6mU6jue/s2mJMuGk+NlP+pGPHN2zChj3MW8RP+hZIKo7ENDK8VxZYSHY0nuyYpK5lqvCydxgG3HK3mG/gbKAv9WVtJr5kKbwBP/dJeEkpep9uSUDizedkUecvEIl2/Li006Ek6dcNLKGGSzCPqxwqmPnaic61owh4UQQBEFcMbRajU1DXTW+vTcV9/SNx4s38iIpLSEYrYI8MTk1DiOSw1WPuTM1VnV8cHt5U02hXmpHRjHu+mInvtp6FgDg72mAQadBg4WTmVAICMKpTai0YEiJ4x0ETxSoFGw7YMriHfhhVxb+u4GP3tQw/aaKKu0XTCuFk0bDCwBW+BU66EN1oXy5JUN87MMYgDQnWCGkd0E4mRpati3yJceZZfmFcM8/QJc7gNje8vH2o3kBMm4h/9zdB4hNlRtbuHnJe2hF9+S/D5jDG1Pc/Ze0Tc8IJzaVDuCt4G/6L+/4ZvDgmxALr5U1hFD7u8RGnHyjrMcwAol1pXNTCKcJ39qeDwAs9bYRp4zNUgNbFlbMKR3wAKmZLCtMwjupX5eJOM1dcQgv/X4YtQbG3c/oBwRaxejiG4DMLernAWwjfGq1UoD0/prsRZxannBqnn/9CIIgiGuaEB93PD86SXzu52nAuicGic8nXheLJTszZalX47pGoaK2Ad7ueui0Gny19Syi/D3QOVruHBXsLS8uf+sfvvg8IdgLxVV1yCiqRnZJDaID5AuhEyrCKcCaNlhbb0FtvRlGQ+NsxQW79Np6aRHvKGJUUStP46uttyCjqBqlTHpfUdWlFU51DRb8sk9ybaswOah9aEJYIeRKxMlUb2n0z4toJKEdgPELgcrzwKZ3gO6T+fEJ1lQ0Zx+iXP8i8OMUvj5LiJjo3YGuE+X7scYHfjHAmPeB3x7ma5IcEdkNyD9ofzsrCFgRNfsAL1bYVEZWTPSeBYS0Uz+nud62F1VFDv+l1fP5pIIxQ0g7IHsn/1gtlTD/IO+6d243/zy4LS8S1QhPthmq1/tAlFMe/uriTA1ldM1OaqxNjdPRlUDOHml7C0zVI+FEEARBtDjmjU3CjIGt8cWWDHy26QxaBXmia4y/mO7XYLYgMcwHnaP8bCJcbcN84GHQifVCQpZbq2AveLnrkVFUjVWH87H7bAnu7RcPd70ODWYLDp7jbYs7RkpCzMddD62GP0d5Tb3ThXhZdb3Mgc/NmmrH1iW5EnFqF+aDjKIqmBosGPTmOiRHSZ9MF1Ze2lS9/PJambCzZ/WtRqWpAbcs3IKB7ULx1Ij2dvfjOA5/HsxDz1aBqg6KrlDNRO3sCad6xkq6tsEMP1yGKAthi3cIMPxV6bmrzYWTbuRT7IITHe/HipaYXkBoe160qfW0Yrn+Jd4Su9sk5+dl7cYDVJp5s5/iDJhjv6eUUjj5REjNhHs/DJTnAAeW8M/bj5aEExt9SpsJbP0Q2Pax/Nw3LZJH6Vh8I4HpmzH7l1NABj/UoGV+14x+UlSNJaAVn0boGw2UZ/NjrhphKFP1ligEbwtM1SPhRBAEQbQ43PU6xAR64uHBiegc7YehHcKg10mLEb1Oi8mpKosb8NGsjXMG4XheBe7433ZxPD7IS6wZ+mzTGQDAqYJKpLYOQusQb1TXmeFr1CORiThptRr4eRhQUl2P0pp6hPo6dve676td2JEhNbR0s86ZNX0oqqpDvdkCg872U1zB1c/Pw4CkSF/szSzlj2HE0vlLnKqntDivbETEadnubBzNq8DRvAqHwmnN0QLM+HYPPAw6pM8bJvtZukp1nTSvBjsNiWsZccWmRxLNGKGpqiM63gSc3QL0vJcXTa4e5xkI3LzI/nZW4MX0cnwuwagB4FMPzXZMXsx1cqOG9qOBndY5JN3IR2cE4dRhDC9c/GOAY0xqYuqDwK7FtnbebGNdNcKTkYsKAPzfIFnjbjcfqfkxy6i3+TTK6mLgXWvUSu/hmtOKGyOcLCqpsS0wVY9qnAiCIIgWi5+nATd2jYJXI+tugr3d0bsNXzclkBjmY5Oet3zvOTz50wHc/QX/qW/3uACZsQUA+Fut0tcdK5AvRFRgRRMANFgs4DhOFnH6YM1JJL3wF9KzbRuQCql6PkY9vrs3VRzPLWMbA1/axUhu2YULJ1cd/nZm8H2EaurNWMn05WoMrBCqt2PpzkbOahtIOF01hLQFpq4AksZe+nPP3AVMWQGEOTGlUfbC8gwE7lkNPLhFnjJoqecNMh7YCEzfJHcVDO8MxPUGuk8Bkm/mDTA6jgOiUoCqAmk/v2ig32O2c1AzuFBQx/xumFnxo9WqR5x0Bj7axjrncWapD1iPu+1fTBBOufuBFTNVJtPyUvVIOBEEQRDXLFEBUspJ1xjJJl2JYL7QOcrPZpufB5/u9erKo5j2xU674klNRJTXNKC6zgzlIfVmDk/8tN9mfyFVz9uoh4ebTtWo4cdd2Xhv9QmnIs5Vckp5URZnFZmNSdVjp+DIxa6AMePItmMH7ww2Va/OjvEDG9ljRRRB2CU4EUgY4Hw/wZFQcP0DgJievOCatlIaE8RERGfeyKH9KOCG14Cpv/PiRaMBxn4A3LJYXjvkFSK/Xv8n5K6D/R7nUyKdwH6oUNJqBC+I2o/mB9QiTkLfLNb8or6af08eP8lHpOwR0UVy6ttnNcvQGoCQDtbzUMSJIAiCIFoM7AI73M9oE3FS0ppJ0xNge0xtOH4eCc+sxO8HclCuMHIoVKldKq+tx7iPNqte62heBfZkyj/FFoSTj5EXTH7MtX2Nkoh6Z/VxJDyzElnFF/+JrmBgkRjKpwE1xhyCY1rOOnKxO8NEyQRBw3EcTuRX2I0eKWm8cLIVsmYLh/TsMtGO3mLh7J6LIGREdAaePAPcvNh2m1YL3LEU8IsF7vhBvk2jAdJmAPH9HJ8/bSbf52ryL9JY9yn896A2wJDnXZom+/tUp/cDHjsimXWwwim+Py8C2UbGrYfwboith/DPvUMc16u5eQLTfpOPdb0DaGM9vqrQpTk3J0g4EQRBENcs9/ZLAAAMsVqWJ0X4wsuNN3gY3y0K+18YhkHtpE9xW4fYCie1WqSZ3+1F2qv/Yu0xKb1GzbShsNIkuvWpMffXQ7LnYsTJnRdMrGh7ZKht89N/j+TbPbeSSlMD5v9xGAeyS2XjgnASems1JuJkNkvCqcqB4MooZIUTL2h+2XcO17+zAY/9aBt5U6OmXjp/nd1UPcfCaeG6kxjz4Sa8YXVavOWTLRj05rrL1lSYuMrwDLTvMNd2GPBoOtCq74Wd28Of70PVWnIXxfDXgKEvApN+cvk09czvZJ3ZwjsSCuKH7es0biFw6xdyx8I7lwGPHQaMzlMCRQITgFFvSc/j+kiOgwWHXT9PM4GEE0EQBHHNckPHcPz6UB+8N5H/VNXDTYcNTw7C86OT8MQN7eDnaUDbcKngOj7Yy+YcJXbsw6vqzLjr85146Ls92J9Vqtpf6Vie4/5P6eekOqdDOWVYvJk3rRAiTv4ebuL2LjF+MuMKAKhuxIL/9b+OYtHGMxj7oTwCVmy1Om9lfe019WbVBsFqsNevMqnPpaSqDiWMnbpQq/TBmpMAgN/25zi8Rl5ZLV7/6yhOn5fEl73oljPh9OY/fF+c/64/jYLyWuzJLMW50hqxhxdBNCv07kDfR6T+Sy7ARlBtfo81Gr4ma9pKdXc+jUYupFwlvIv0OK63VC+Wf0h9/2YMCSeCIAjimqZLjD+8mVqhIG933NM3HpH+fL1T79ZSrxY1Ewo2Be/uPrYLmD8O5OKFXw+K/ZUGtw/F77P4T53ZT39ZPN0kW/OymnrUmy2478td4li7MB/rfKT9ogM88fU9vfDdfZL7V0G56w5764+r2yeXWe3To/2l+i97IkgJ23fKnqnEoZxy2XNB0JhdrNF66Ls9+HjdKbzyh9RA1F56ncwcwkmNEzsvZdplS4PjOJffT+Lqhk3VU3WfDOsItOpzaS8a2RVIHAZ0mcg7BIZ0AKDhLdsrC5wd3awg4UQQBEEQDhjQNgTv3d4VK2aqLyYevZ5PkbszNRYvjEnCff3iMbBdCP6c3U/s07Q/uwxzlqUDAIK83ERDCSVL7k9FqyBPvDi2I4K9+WhSVnE1zpXUIMfqnPfzjN4Y0oFPLaxhFv8h3u4I9zOid+tgvDiW/0Q3nzFdKK+tR2aRbc3Td9szsf10EYrtRM4EY4xgH3fx9VSY6lFaXefQYW/76SJ8sy1TfM7ahbMczJG7B9Y0UjjtPltiM3YhNU7s9fw8DDicKwmnokvcG+tKM3vJPvRZsEb8WRLXLrIaJxcjxxeNzgBMWgqM/4R/7uYJBLXmHztqQNwMoT5OBEEQBOGEG7uq2PRaGdslEp2j/RFjdeR7dlSSuO3Qizdg6uId2HKqSBwL8zXKapMEHhzYGqkJQVj3BF/D8O32TBRW1uHb7WfF2qrWIV7oFhsgHsNGdFib9DBrP6m88lrU1pthNOgwdfEO7M0sRZtQb8wfl4xeCUE4kluOZ35Ot5mL2cJBp9XAYuHExba/hwG+Rj0KK+vw/r8n8OOubET5e2DTnEGyJsNbThViZXquTDQB9iNOQmPhuCBPnC2qbnTESY0LqXFijTR8PfQ4yqRROmpK3BJYYU13XL4nG3epREWJawc2yt1gJ+J9RRjyAqBzl5tPtABIOBEEQRDERaDRaFRrnwDeOGLBTZ3xw65MVJnMqDQ14I5esfAxGvDk8HZ4/S/ehGDW4Db4v2HtZMfGBHpiX1Ypvt+RJY4pXf+87fSvCvPl6xD2Zpai/fN/ybadLKjEhE+3IWPBKJxViUABQFGVCaE+RlTWNYiW4r4eBoT4GFFYWYcfd2UD4JvjllTXI9BLqrW6Y9F2tVPaTe8T5tApys8qnHjRw6YR2WsIbA+lE9/5ChP0Wo1cOCmiUlmMDXp5TYOsJq3ITjQO4FM1g7zcZOKxOcHawOc3InWzKeA4DtklNYgO8Gi272dLh/1QwdVaxctC0o1Nd+2LgFL1CIIgCOIyEhvkiSduaI95YzvizVu7iLVTMwa2wZL7UzGqUwQm9YqzOS4l1t9mLErRZ2rumI5IivDFR3d0l40LESdHnDpfiYKKWtVtx/Iq8PG6k1i+mxdI7notjAadKMhYzpXUYOOJ8xj85jrVtDmBqroGHMktR1m1PF3svFWgxAbyolBIp2PFT7k16vXt9rPYcqoQc346gBd+PWjTG0pIgTxbVI0Hvt6F7BI+gtVz/mp0e3kVyhlHQLZhLgDklsrTGtnURTUreQD4cksGeryyGh+tPWn3dTc1bC3XeRWDksvFf9efwiu/N8417d3VJ9Dv9bX4Znum852JRsNxXNOk6l1FUMSJIAiCIJqI1IQgpCYEqW67KSUa836TLzyVDXrbhHpj5Wzb/i/hLginFfty0GCRFk5ebjrUNlhgtnB46bfDMpt0IbUwzMf2vOdKqzH9mz0AgJsXbrF7vSd/OgAA8HHXY/mM3kgM8wHHcaJphiic6sx4+59jKGUEVmlNPTKKqvDsz/J6iPusdvICUf4eYmrh34fy0WDmMM9a7wXIa5+UNVe5ZZJw4jggk0ndU7OSL6mqw9wVvCvYm/8cxy0pMQj3c/6+X2kqTNL7yNa8XU4azBa89udRAMAdvWKRoGLjr8Z7/54AADz/y0FMTrX9MIG4OMwWDuxnDReaqldRW4/M4mp0jLRtCH61QxEngiAIgmiG+BoN+OKunkhjhFWMkwa9AlqtBi/fyAsGLzcdXhidhN6t5QLtt/05olh44oZ22D93GPq24R0Elb2lfIxW4aQiDA4rXPGcUWFqwA87+fRD3jGQX7wJaYi1DWa8v0YewSmtrpfZjQscyZVfOzFMvkA/X2my24NJmbaWV14je84aSahFnI7ny63klf2vmgts362MItv38HLARussXOMX5zotpeldDpQueq42l1Yy8v2NGPX+Jmw51fIa2F4sFHEiCIIgiGbKwHahGNguFCv252Dj8fOim54r3Jkah7ggLyRH+SHQyw13psbhvq92IcjLDX8ezMPpwiqctjaeDfc1Qq/TYlTnCFVb8mxr/Y/g9Mfy7QWkVW06WYj5fxwWDSR8jXr4evBLEjZlTqCo0gS19feRXEm8JEX44oH+rfHrPqnvk6/RYGNKMSI5HH8ezENumVwo5ahcVyC/zHab0qGuohGNgZ0hmHNcCtjXX1BuAsdxl71+iI3Q2eup5YimFE4lVXV4d/VxTOgZi6TIRjR6bQEoU/PqL9CAJauY/935/UCurF3DtQBFnAiCIAiimTO2SyTeuLULPN1c/7xTo9Ggf9sQ0bjBTa/Fl3dfh7cndMX/DWsr21eoibqtRwz6JdouhNR6Hglrb0fGCQAwb0ySzdjRvAos2nhGjOoE+7jDw8D3pBLGovw9MKBtCADgpd8Pq7ryCRGnge1CsHJ2P4T4yGuw8strbUwpBrbjz5mrEEN5KuJIILe81sbivFwhlC5Vr6cT+RXoPO9vvLPq+CU5HxtxqjNbZCmQlws2QuesX5aAhVnEG5pAOFWZGvD7gRzc8+VOfLn1LO77apfzg1oY9Yp7+GLNIcxN6crXRJBwIgiCIIhrjHv6xuOtW7vAXa+FXqtBm1ApxW1CzxgAfF3Te7d3BQA8bhVaPVsFAgC0GmDXs0MR6aSmx9tdjzt6xeHdCV3FsSh/D5v9SqrqYDToZGOJYd64u288vN31yC6pwWt/HrE57kgeL5yEmi43hfNeXnmtjeBKS+CFYX55LU6dr8RXWzNQb7YgxxqBasuk+wV4GmA0aMFxvIMgS/kFRJzKa+ud2qzP++0QqurMYr3PxVKheP0FF2kQwXEc3lt9Ar/uOycb33qqSLR0lwsn15olF1ZJxzSFo97D3+/FzO/2Yk9mKQDbn/fVgLLh9oWm6onHW649cwlK1SMIgiCIawyNRoObU6IxoF0ISqrqZKYGoztHQqvRoG2YD9qEeqNXfJCYotchwhfLHkxDhJ8Hgrzd8eP0NHy09hS83XVYtPEMAOCm7lFYvodfVNeZLXDTazGuWxTig73g4abD638dtVmUWjjYCKe2YT4Y0DYEL4/riEd/2G+z6AMkK3MhYiY06BWoqG2wqU+K9DdCq+EXkUPeWg+AjzYJwmdgu1Acz+drvAK83BCs0eBEQSWyiqtltvPKCJNSSCnJL6/FwDfWoXfrIHw2rSeqTA04mleO7rEB0Gg0qKkz47sdmUjPLnN4nsZSWasUTrVoF+5zwec7lFOOd1bz0bCxXSKh0WiQnl2GiYu2AQAyFoySvedK90J75JdJx1SaGlDXYLH5eV5O/j1aIHuu5iDZ0lEKJbXfqcbQpH2gmgiKOBEEQRDENUqwtzsSw2wX0SM7RYhRqHA/vv5JICUuULRUjw7wxGs3dZI1/R2ZHCE+ZtPbusT4o22Yj+x647tFoW2YN966tQs83OTCSbh+52h/p69DEH7uKgvtPw/mio+nD2gNvU5rY9f+yfpTAHjHv+6MDby/hwExVrc/ts8TwPd6YnEWcVq+5xxq6s3492gBOI7DrO/34uaFW7HMKjIf/HY3Xv79sE0K4MWijLgVWE0xOI67oCbDbARJMIHYrzDGKGJqnGobXBNOSmv8oir1yNip85U29WlqZJdU46XfDuOBr3fh881nHO6rlqbpqhFLS8KmxuliU/Uuokl1S4WEE0EQBEEQF83396Xi2ZEdMKRDqOjoN6pzhM1+bKre86OT8M+jAzA0KQxGhehJtAqnSD/b1D4lQnRAq9Xg+/tS8fU916G9Naqy+WSROJenRrQHIKUjCgjrvwh/I9oywi7czyjapJ8q4I00zBYO/9t4GrvOFlvnx4swZzVO7CL1k/WnscYa4fjv+lOorTdj3TFbU46LwWLhUFFbbyOc/m/pfuSV1WLyZzsw+K11LqfSCbBRiuwSXsAYdFJqXYPZgvMXEHFSCs+vtp612Se/vBZD3lqP/q+vdXq++7/ajcWbz+DvQ/l48TfH/aROFFTYjF2NPY6UQuliI0YXK7xaIpSqRxAEQRDERZPWOghpVsvzyWmt0C7cV1Y7JTC2ayT+OpiHoR1CReMKALKoFgAxMuXhpkOgl5vM4loJG0ES5tAmNAtH86QFcTBzrdlDEvHhmpM29szhfh6ID/bChB4xqDNb8PgN7bAroxhfbAF2ZvBC6afdWXjlD6neKirAAzlltfjzYB7u/XIn5o/vZBPRWnu0AG8zZg//+euo+LjS1CCbJ4vSAe+XvedQXluPYG93HM2rwKNDE+3WA7342yF8uz0TnaJte+18vyMTm07yVtL7skpteolxHIdP1p9GvdmCaX1awddqRw8ANfWSwDlXWoMuMf7Qa6WfXXltg8xVr9ZFV70KhfD8cWcW5gxvLxvbdIKfc72Zc+o8eFhhVe9ofzVx11hB2RKob1DUOF1kjZLy9+dagIQTQRAEQRCXnOviA1XHfY0GfHNvL9Vt7notTA0W+Br18HaXliiR/kaHwkmICrEkhvoAkNL0vJjzaTQauOm1aFAsmCP9jNBoNPjPLZ3FMV08LyoO5ZShvLZerH8SiA7wxM6MEgDA6iMF0GkP4r+Te8j2ueuLnXbnXlHbgHMl6qlntfUWMYXR1GDGIz/sk20f3D4UXWP8bY7LL6/Fl9aIzV6r2UG/xGBstAqP73dIFvJKW3WAFx2CuKuqa8DTIzqI26qZ90ywqWctx0ur61DEmkO4GHESUhT7tw3BhuPnUVJdZyMczzJNifPLa/HKH4cxtEMYbuoe7fT81XUNYj8yJTUqIslVN8CWhE2qXkPjhQ/H9AW4FiNOTZ6q9/HHHyM+Ph5GoxEpKSnYuHGj3X3XrVsHjUZj83X06FG7xxAEQRAE0TJYeGd3TOgRgw/v6C4bN+jsL1dCfdxVF8ShiuJ+VjjZO2e4iktguJ8R8cFesHDAmiMFNhbOSpfAg+fkkY6Ccvs25wAfccpW1E8JVJgkUVNQblvzU8g45HEch1/3ncPx/Ar8czjfZt9hSWFY838D+HMxx+WouMexESPldasZe3ehn091nRSFKq2pl5tDuBi5EVIKowP499PC2dZn7c0sER8vXHcKK9Pz8NiP+12qeap2IODUIk5q884qrsbI9zbiyy0ZTq/XHLFJ1buAiBMrvsgc4grzww8/4JFHHsGzzz6LvXv3ol+/fhgxYgQyMx030zt27Bhyc3PFr8TExCs0Y4IgCIIgLheD24fhP7d0Rn9r/yaBIe3ljX8TQiR3O72d9CtlPyqtIqVNTTgpU9YExnWNAgB8ve2sjSNgVIBcOLG1ThzH4ReFbbcar/2p/gFwRW0DNhw/j3Efbcak/2232c4aKGw4UYjZS/Zh2DsbkGFtbMwS6e+BhBBvjOsaKRtXE05sFEpZe8SKJKEXFtsrq7DCJDeHcFE4Cal6wd7uopsea5Txz6E8MWIGAMv2ZIuPf9krNT22R5VKHzABNVGlNu81RwtwOLccc1ccwr6sUqfXbG5cClc99hgyh7jCvP3227jnnntw7733okOHDnj33XcRExODhQsXOjwuNDQU4eHh4pdOp3O4P0EQBEEQLZcHBrTGyof7Yf/cYXhuVAd8d2+quC1SpS8UwKfQbXhikPhcmZIm1EKxCH2qlNx+XQzcdFrsPluC1Uck22oPgw6douQ1RKzQeOHXQ3h1JS+KnrihHfa9cL29l6jKZ5vOYMriHdiXVYpMa5paSlwAbk3hU9MKK+tQVl2P2Uv24n2m79Nnm2xd5IT36ZlRHWTjrBAsqKhFXlmtQjjJ37cqRmTkW6NprJi6/+vdstoXVyNOwvvma9SLNVWsxfu643LzDFbslNY4bsKs3F+J2hxNKql6rJjafbbEZntzx1Y4XUDEiUnLpD5OV5C6ujrs3r0bTz31lGx82LBh2LJli8Nju3XrhtraWiQlJeG5557DoEGD7O5rMplgMkmfyJSXl9vdlyAIgiCI5odBp0VSpC8A4N5+CQCAT+7sjndXn5DVIymJDZJqnzwVducvju2IIC83jOocgS82Z2Bkpwi75gFhvkbc2y8eH687JY4tn9EbcYGe8PWwTROsNDUgs6gaX2+TnOGGdgiDv6cb3p/YDQ9/v9eFVw2sU/QWAvhmv0HefBpidkkNHv9pP1appOYpEYRTqI88HfFsUTXu/2oXWgV7YemuLJRU1+PBga1lr4WFTWvLswqnqjr70RzXI078OXyMevh66FFYaZIJuHwVy3ABNn3Q7j4OhJPaHOvMFhtDCTZqpRSULYE6RU2TMu3UtXNIx7jqmHg10WTCqbCwEGazGWFhYbLxsLAw5OXlqR4TERGBTz/9FCkpKTCZTPj6668xZMgQrFu3Dv3791c95rXXXsOLL754yedPEARBEETTMTw5AsOTbe3OlbwzoQt+25+LaX1aycYDvdwwbyxvm24v0sQytmukTDi1DfMRDSw0GoCpmcef6bl44qcD4vNJvWLRNox3GBzbJRKmerNsu8BvM/viTFEVPt98BnszS5FjFQsTesTgh11ZAIAQH3exITFr8qCG0aAVTQ58jdKSb8MTg/DO6uP4ee85HMopx6Ec+YfKqxkhphROrEgqrDShwWxxKFxcNVkQhIiP0QA/D9uIU56DWjFHokhAKe5q681i02V7x5sazPB0k963Cua9UPbxagkoa5ouLFWPEU5XofOgM5rcHEJpo6l0UGFp164d7rvvPnTv3h1paWn4+OOPMWrUKLz55pt2z//000+jrKxM/MrKyrqk8ycIgiAIovkyvls0Fk/rKbPUvhDaMf2dEoK9ZK5/QYzVOQC8v+aE7Pn88Z1ka5tbUqLxy0N9cFsPyQ3u5PwR6BTth7FdIm2iY7cxfaeKq+oQ5C2/nj06RPiKj9nrxwZ54u3buiBCxQwDAE4USM6BlbX2I04cB5yvNDmMODW2j5MPk6onizhZTSoCPG1/jtUOri/uw4i7NUfzkTz3b3y3nRee9gRAlUIQuhJxqjQ1iCmMzY1LkarHOigq359rgSYTTsHBwdDpdDbRpYKCApsolCNSU1Nx4sQJu9vd3d3h6+sr+yIIgiAIgmgMGo0GMwa2hqebDu/e3lW2jRUogOQ2BwBPDm+neq6uMf6Y1jseAG9kwfax8nKTJwS1CfUWDTJuvy4GQV5yx0B7vDA6CZ2i/PCiNbKmnINanZeSoqo6mWBQRmfyymqd1g9lFVfjaF456hossNgxFJCEExNxso7Vmy2iEUZCiG1vMOX11QQBK+5mfbcXDRYOz/yczs/RzvwHv7VOls7GCgWlaYbAiPc2oNer/zaZeDpTWIXJn23HHYu22dT1Ke3HL6QPkzxVr+VF3S6WJhNObm5uSElJwapVq2Tjq1atQu/evV0+z969exER4TxUTxAEQRAEcTE8Obw90ufdgM7R/rLxV8d3QrdYf7wyLlkWxXl5XDKm928NeyRF+mLDE4OwaIq879OtPWJkz/08DPhoUnf8/Uh/9G4dbDdSpKR9uC9+m9UXU3u3Ut1+swv9jwBeQAiLcGV056O1J0VhNb5blDieEhcAADhdWImhb6/H8Hc3ou1zf2L4extU3dikVD2+xgmQIk7nK0zgOMCg0yAmwNYMRDknNQc9Vhyx0bd5Kw5hy6lCm/35OTWIzoGAPFWPtYpnEUTzeoWZhbS9GjO+3Y21x2zr1y4Fb/1zDBtPFGLLqSKsVdTI2fRxupAaJ+aY6nqzrK/TtUCTpuo99thj+N///ofFixfjyJEjePTRR5GZmYnp06cD4NPspkyZIu7/7rvv4pdffsGJEydw6NAhPP3001i2bBlmzpzZVC+BIAiCIIhrCDUDiZhAT/w8ow/uTI3Db7P6Ykj7ULQK8sSYzhHQ2jGcEIgN8hRrbQSuTwrDnuevR4+4ADwylG+5YjTo0C6cTxdsE+qN50Z1EMWJPTzcHLsO924dhN4uRJ3yy034wOraJ0R3hnbgI2CrjxSIjn8JwZJNvFA3llVcI0vvOp5fiTf/OYa5vx4Uo0/1ZotYS+WrUuMk1DeF+hjhzdRqCVb0yoiTsi4LkEecDDrpZ/LFlgwxDVCNkmrJsU+eqmd7DdZk4mhuBd5edRxfbc2Q7fNHei5Wpufhrs934mRBhd3rXgiFlSb8eVDK5FLWhQniUbiHL0Q4scdw3NXZKNgRTWYOAQATJkxAUVERXnrpJeTm5iI5ORkrV65EXFwcACA3N1fW06murg6PP/44zp07Bw8PD3Ts2BF//PEHRo4c2VQvgSAIgiAIQiTY2x2fTet50ecJ9HLDTw+qZ+BoNBrc2y8B9/ZLQFl1PXZmFOPer3bJ9ln1qLpplvI8i6f1xKzv9zp15lu2JxvbzhSJDX4n9IzFgewyFFSYxIa5bBrdgLYh+GS9ZKYR4WcUozcLrSYbw5MjkNY6CJnF1bBwvPNhsLeb6PyXfq4MAHCuhI/iRPobZY2Mw3yNOFdaYyOc1Gpv2BonRw2VlbDNfNl6r/Ia24gT28Nr8WbJEv6O62LFVMzSammfPWdL0SZUqp27WI7lVciieXkKJ0LhtYRb3zc27c4RHMdh3bHz6Bjla3NMdV2DU4F+NdHk5hAzZsxARkYGTCYTdu/eLXPH++KLL7Bu3Trx+ZNPPomTJ0+ipqYGxcXF2LhxI4kmgiAIgiCuWfw8DRiaFIaPJ3XHTd2j0C3WH8se7I3EMNcW5EaDDu3Dne9bUl0viiaAFzlxjN07ALQL98bTI9rj9Zs7o0uMvL/V8hm90Ste7l4o1AGdtJpRtA7xhkajwYjkcOi1Guw+W4Lj+RVir6noAE94M/Vf4daURWVqnpDiFxPogRlWa/XdZ0tw0CrE7NnOq1FYIUWcKp1EnOw57ZUwYomNShVVOe8/1RiyS6plz4X3N7+8FtV1DThfKdSJ8ZFBtcicGiv25+CuL3bitk+2qgina8sgosmFE0EQBEEQBHFxjOwUgbdv64qfZ/RxmsKnpDUTKRrVKQJjukRi6fQ0u/u76bRICPFCTIAknPw8DIgP9sYDA1rjtp4xMhtvAIjw80CUoj5p7bECcByHU+cF4cQv6EN9jRjYLgQAsOpwvigIovw9ZBGncF9eOCnNHTad4OuL2oX5iA6FW08XYfQHm1BUaZJFfZxRWCVFnNh0PzXhpDRjEChizsGKleIq+ymCF4IQmRPs6vPKa3HqfCX6v74WD3+/T4wMtgnlf94lLr4PS3dlAwAyiqpt6qRyy2ox9sNNsuji1QwJJ4IgCIIgiGuYUZ0j4GUVGLf1jMEHE7uhZ6tA0S2wU5QUPXrtpk7YNGcQIvw8EM0Iof5tQ5xGcqL85cLp1305ePG3wzhVUAVALuAGtuNrqNYfOy8KgugAD7ERMgAEePG1UBWmBmw7XSSO/34gFwAwpkukTGgBQMorq+3ajz8/OgnPjeogGxMiThzHyVL16swWMXqUnl2Gt1cdx/kKdSFUVClFllgjC3Z80YbTuGXhFpRWux6FqjQ1wNQgvZZs6/vUPZYXzvlltVh7tACmBgt2ZhSj0Dq/RGt6YGl1nUvmDmxkTBlx+nDtSRzILsOCP4+6PO+WTJPWOBEEQRAEQRBNi0GnxeanBmNPZgn6JwaL40vuS8Xpwkp0ivLDr/tyYNBrMbZLpLg9mok43cQ46gn85+ZOmLMsHR/d0R0AEOlv64j3xZYM8XF7xtZ9QFs+4rQ7swQh3u7i9dhmxRpIQu32T7fhzGsjUWFqwOlCXogNbBeKA9mldl/3e7d3xeNL94uNYPslBqNtmA/e+/eEGFES6oJMDRYb++6ymnoYDTqM+XATAHmvLxZZnZRJPVVv/sojAIBPN5zGk8PbAwBe+PUgNp0sxGdTeyKeMd4AeAHW//W1CPM1YuXDfaHRaETh1KNVAP45nI+CCpMoKMtq6sX6p0RrM+Z6M4eqOrOsJ5kaRcz8lcIpp7RGuftVDUWcCIIgCIIgrnH8Pd0wuH2YzKrbz9OAbrEB0Ou0uDklWiaaAGBoUhh6xQdi3pgkDLL2mWK5rUcM0ucNw6jOfNuYfonBiAm0FU8AoNUA1zE1UDGBnkgI8YLZwonucHFBntBpNXh3Qld0ifHHjEFyq/dzpTX4cWcWAD6Nz8/DYGMdL9AqyBM3do2SNUYW0vp+n9UX11kFmiB6BOMHjQaiiNmXVSqL2BzL513ybugo70fKRpaqZKl6/Dibvne2uBr1Zgve+ucYvtp6FqfPV2Hip9ts5n8ktwLFVXU4kluOnLJazP31IHZkFAPgreA1Gr5P04YTktW6cJ2YAE+46QWzCucRrmJG4FUronVseiLHcTh4ruyC3PpaCiScCIIgCIIgiEYT6OWGHx5Iw7Q+8arbNRoNfBhhEh3giQ1PDMKxV4Zjz/PX45VxyeK25Cg/0YZcQIg6AUCfNkGICeQjXOO6ReHXh/ogwk8uwt5bfQKv/MFHboSoivKcAndZ58xGfYRUwrggLzw2rC0AXoxxHCemC4b7GtHPGpXbfLJQNFxgUV6TrXFSE06nrTVe/OMq/Lz3HD5Yc1IcyyuvlYkXAChhnv93/Sl8ufUsAKB9uA+6RPsj2BqlU3POC/J2Q4AnP0dH9V7FVXWY/Nl2WaStSPF6WeG0dFc2Rn+wCa/8flj1fGYLZzedsaVAwokgCIIgCIK4Img0GrjrdQj0csPw5HD4GvUw6DR4cIBto+Dx3aKg12oQ7mvEc6OSnJ576e5s8bG7Xlrivjq+ExJDvbFpziB8fldPPDuyA+5MjVOdm0CsVaSdLapGr1f/xU0Lt4jjfdvwwmnTyUKbJrMAL5w+nZwiPpdFnNgaJ6ugOsUIp+P5FbLnAnszS2TPc5keTSvTpd5Nb97aBXqdVjTOUBLi4w6DTgt/D95AosRa5/TqyiN4+59jsn0/WHMCG5mIFSBPOwTkwmzuikMAgC+3nsVLv9mKp5d/P4ye81djy0n1hsMtAapxIgiCIAiCIK44wd7u+POR/jBoNQhVWeh3jvbHvrnDYNRrxT5IStISgrCVMYYQuCUlRnx8R69Y3NErFgAf9RrUTkorvL1nDJbszMK8MXJhFu5rhJtei7oGCwqYKElsoCdSWwdBq+GjQ3OWpdtc29dowLCO4Xjtpk54enm6aKcOyHtM1dZb8PD3e7Fif444ZrZwyCqW24oDwJ7MEgzpIKUA5jM9mgQxM3NQGyRbjTzCfI1iHyydViPWNwnW8/7WiNPkz3bgrj6t8PnmDAB8NE/ox7X7rFysAXJ7diWs6cbizWcwa3AbBHhZBVpVnVjP9sGak+jdJljtFM0eijgRBEEQBEEQTUKUv4eqaBLwdtfbFU0A8PldPfHv/w0Qn+u1GqyY2cemzsgec8d0xNLpaZjau5VsXKvVwMNg29g1NtATvkYDusT4y8Y7R/OCxU2vxeAOvDBLjuTH9mWVwmLh8NHak2LKnRDcYkWTwI4ztoJlz9lS2fNcRXNbYW4C4X7u4uNbukeLj5OsBhxsVEsQTQDw50E+elVvtuBEPr9P2zBvRFh7ZmWV2Io6e+RXSHNcfURqsJxRVOWSm19zhIQTQRAEQRAE0SIxGnRoHeKNidfFwsOgw9f39ELnaH9Z2p0jPNx06NkqUHV/tb5Msdamv4OZqNUDAxLw4wNpeGF0En6anoaOVsHUIYLvI1VR24DDueV4428pFY51BxRItPZXYtPhnh/NR8L2Z5diV0Yx/u/H/ThbVIXDuXwzYtbJL4YVTlYx6qbT4v+s9VqA5Gx4c4okpliW7MxEvdmCjMIq1NTzjnt/ze4virJDOfx1fY3qSWv9EoPFqFZ+uUkUSJlMFC23rFZ0AGxpkHAiCIIgCIIgWjSvjk/G3heuR1rroEt2zpfHJUOn1eD9id1wS0o02oZ5o3drPsVsSlorcb/+iSEwGnS4u2+8zMVPr9OKPZUWbzojO3fPVvImxX3aBNlEsX6f1Rd39W4FH3c9quvMuOWTrVi2JxsD3liHI1bh9PCQRHH/uCBP5jHv/Nc9zh+hvkZMSYtDdICH6HA4Y2AbfHJnCrrFyq+ZVVyDvw7miemF0QEe0Go18FUYXgxPDld9z9JaByHMKtqmLt6BPgvWoLiqTpauCAAnCipUj2/uUI0TQRAEQRAE0aLRaDQwqqTWXQyTU+MwoUcM3BT9qwDeqn35jN44lleB3g7E2sB2Idh0shDL956TjV8XH4SP1p4CwKf5LZrSA/9df1rc7qbTIi7IE1qtBgPahYhNfVlmDW6DUZ0jkF+ehNoGs6xP1ojkcMwdkyQ2En7pxmS8dCMzfw8DhieHY8eZYuzNLAUAhPq4i72fhKiZcE7BhQ/gI2PxwVKzYpa0hCBkWPtoAUBOWS2W7sqy6fd09xe70DXGH8+N6oAeKtG35gpFnAiCIAiCIAhCBTe9/aVy99gATLwu1mFa4LAk9chMX8YcoUu0Pzzd9EiKlBoA39c/XrRynz++E25NiYa/pwG3pEQjJS4A0we0xmPX8yl4d/eNx4yBbWTn1+u0uKtPvE3jXCV39IpFWkIQhiWF4Ykb2gEA9maWIreMFzqR/nz0SDCdAPg+UfZsxbtE+4sRJ4F/jxQgp5Svd0pNkETSvqxSeNtJ+WuutKzZEgRBEARBEEQLITbIE3f3iUdGURXu7hOP4uo6RPkbodNqsOzB3li86QxmDuZFz7CkMHx3Xy9kl9Tgpm5R4jn8PAx449Yul2V+bUK98f39qQCAPKvhxNG8coT58uYSQq+stAQpqtYx0hdxQV5YvPkM2of7oG2YD1bsz0HHSF9oVRwShca8AC+6tp3mn790Y0dZjVZLgIQTQRAEQRAEQVwmXhij3oMqJS4AKXFSrZNGoxFrqJqCcD8jkiJ8cTi3HGuPnQcgRZzahHrDoNOg3swhrXUwWod44ccH0pAc5YsqkxkdInwxKZW3fO9mrdXSazWy5rluOi3u798aR3MrMLhDKCb1su2l1dzRcC3VD/ACKS8vh5+fH8rKyuDr6+v8AIIgCIIgCIK4Bjh4rgw3LdwiNrZd9mBvUdxlFlWjuLoOXRUmFmqcK62Bl5sO288U48FvdqNbbAAm9YrFTd3V3fyaksZoAxJOBEEQBEEQBEEAALadLsKnG04jNSEQ9/ZNgFbrmrW7PSwW7qLPcTlpjDagVD2CIAiCIAiCIAAAqQlBSE24dLbuzVk0NRZy1SMIgiAIgiAIgnACCSeCIAiCIAiCIAgnkHAiCIIgCIIgCIJwAgkngiAIgiAIgiAIJ5BwIgiCIAiCIAiCcAIJJ4IgCIIgCIIgCCeQcCIIgiAIgiAIgnACCSeCIAiCIAiCIAgnkHAiCIIgCIIgCIJwAgkngiAIgiAIgiAIJ5BwIgiCIAiCIAiCcAIJJ4IgCIIgCIIgCCeQcCIIgiAIgiAIgnACCSeCIAiCIAiCIAgnkHAiCIIgCIIgCIJwAgkngiAIgiAIgiAIJ5BwIgiCIAiCIAiCcAIJJ4IgCIIgCIIgCCfom3oCVxqO4wAA5eXlTTwTgiAIgiAIgiCaEkETCBrBEdeccKqoqAAAxMTENPFMCIIgCIIgCIJoDlRUVMDPz8/hPhrOFXl1FWGxWJCTkwMfHx9oNJqmng7Ky8sRExODrKws+Pr6NvV0iBYA3TNEY6F7hmgsdM8QjYXuGaKxNJd7huM4VFRUIDIyElqt4yqmay7ipNVqER0d3dTTsMHX15f+0BCNgu4ZorHQPUM0FrpniMZC9wzRWJrDPeMs0iRA5hAEQRAEQRAEQRBOIOFEEARBEARBEAThBBJOTYy7uzvmzp0Ld3f3pp4K0UKge4ZoLHTPEI2F7hmisdA9QzSWlnjPXHPmEARBEARBEARBEI2FIk4EQRAEQRAEQRBOIOFEEARBEARBEAThBBJOBEEQBEEQBEEQTiDhRBAEQRAEQRAE4QQSTk3Ixx9/jPj4eBiNRqSkpGDjxo1NPSWiCXjttdfQs2dP+Pj4IDQ0FOPGjcOxY8dk+3Ach3nz5iEyMhIeHh4YOHAgDh06JNvHZDJh1qxZCA4OhpeXF8aOHYvs7Owr+VKIJuK1116DRqPBI488Io7RPUMoOXfuHO68804EBQXB09MTXbt2xe7du8XtdM8QShoaGvDcc88hPj4eHh4eSEhIwEsvvQSLxSLuQ/fNtc2GDRswZswYREZGQqPR4JdffpFtv1T3R0lJCSZPngw/Pz/4+flh8uTJKC0tvcyvTgWOaBKWLFnCGQwGbtGiRdzhw4e52bNnc15eXtzZs2ebemrEFeaGG27gPv/8c+7gwYPcvn37uFGjRnGxsbFcZWWluM+CBQs4Hx8fbtmyZVx6ejo3YcIELiIigisvLxf3mT59OhcVFcWtWrWK27NnDzdo0CCuS5cuXENDQ1O8LOIKsWPHDq5Vq1Zc586dudmzZ4vjdM8QLMXFxVxcXBw3bdo0bvv27dyZM2e41atXcydPnhT3oXuGUPLKK69wQUFB3O+//86dOXOGW7p0Keft7c29++674j5031zbrFy5knv22We5ZcuWcQC4n3/+Wbb9Ut0fw4cP55KTk7ktW7ZwW7Zs4ZKTk7nRo0dfqZcpQsKpibjuuuu46dOny8bat2/PPfXUU000I6K5UFBQwAHg1q9fz3Ecx1ksFi48PJxbsGCBuE9tbS3n5+fHffLJJxzHcVxpaSlnMBi4JUuWiPucO3eO02q13F9//XVlXwBxxaioqOASExO5VatWcQMGDBCFE90zhJI5c+Zwffv2tbud7hlCjVGjRnF33323bOymm27i7rzzTo7j6L4h5CiF06W6Pw4fPswB4LZt2ybus3XrVg4Ad/To0cv8quRQql4TUFdXh927d2PYsGGy8WHDhmHLli1NNCuiuVBWVgYACAwMBACcOXMGeXl5svvF3d0dAwYMEO+X3bt3o76+XrZPZGQkkpOT6Z66innooYcwatQoDB06VDZO9wyhZMWKFejRowduvfVWhIaGolu3bli0aJG4ne4ZQo2+ffvi33//xfHjxwEA+/fvx6ZNmzBy5EgAdN8QjrlU98fWrVvh5+eHXr16ifukpqbCz8/vit9D+it6NQIAUFhYCLPZjLCwMNl4WFgY8vLymmhWRHOA4zg89thj6Nu3L5KTkwFAvCfU7pezZ8+K+7i5uSEgIMBmH7qnrk6WLFmCPXv2YOfOnTbb6J4hlJw+fRoLFy7EY489hmeeeQY7duzAww8/DHd3d0yZMoXuGUKVOXPmoKysDO3bt4dOp4PZbMb8+fMxceJEAPS3hnDMpbo/8vLyEBoaanP+0NDQK34PkXBqQjQajew5x3E2Y8S1xcyZM3HgwAFs2rTJZtuF3C90T12dZGVlYfbs2fjnn39gNBrt7kf3DCFgsVjQo0cPvPrqqwCAbt264dChQ1i4cCGmTJki7kf3DMHyww8/4JtvvsF3332Hjh07Yt++fXjkkUcQGRmJqVOnivvRfUM44lLcH2r7N8U9RKl6TUBwcDB0Op2NSi4oKLBR5cS1w6xZs7BixQqsXbsW0dHR4nh4eDgAOLxfwsPDUVdXh5KSErv7EFcPu3fvRkFBAVJSUqDX66HX67F+/Xq8//770Ov14s+c7hlCICIiAklJSbKxDh06IDMzEwD9nSHUeeKJJ/DUU0/h9ttvR6dOnTB58mQ8+uijeO211wDQfUM45lLdH+Hh4cjPz7c5//nz56/4PUTCqQlwc3NDSkoKVq1aJRtftWoVevfu3USzIpoKjuMwc+ZMLF++HGvWrEF8fLxse3x8PMLDw2X3S11dHdavXy/eLykpKTAYDLJ9cnNzcfDgQbqnrkKGDBmC9PR07Nu3T/zq0aMHJk2ahH379iEhIYHuGUJGnz59bNocHD9+HHFxcQDo7wyhTnV1NbRa+VJRp9OJduR03xCOuFT3R1paGsrKyrBjxw5xn+3bt6OsrOzK30NX1IqCEBHsyD/77DPu8OHD3COPPMJ5eXlxGRkZTT014grz4IMPcn5+fty6deu43Nxc8au6ulrcZ8GCBZyfnx+3fPlyLj09nZs4caKqnWd0dDS3evVqbs+ePdzgwYPJ7vUagnXV4zi6Zwg5O3bs4PR6PTd//nzuxIkT3Lfffst5enpy33zzjbgP3TOEkqlTp3JRUVGiHfny5cu54OBg7sknnxT3ofvm2qaiooLbu3cvt3fvXg4A9/bbb3N79+4V2+tcqvtj+PDhXOfOnbmtW7dyW7du5Tp16kR25NcaH330ERcXF8e5ublx3bt3F+2niWsLAKpfn3/+ubiPxWLh5s6dy4WHh3Pu7u5c//79ufT0dNl5ampquJkzZ3KBgYGch4cHN3r0aC4zM/MKvxqiqVAKJ7pnCCW//fYbl5yczLm7u3Pt27fnPv30U9l2umcIJeXl5dzs2bO52NhYzmg0cgkJCdyzzz7LmUwmcR+6b65t1q5dq7qGmTp1Ksdxl+7+KCoq4iZNmsT5+PhwPj4+3KRJk7iSkpIr9ColNBzHcVc2xkUQBEEQBEEQBNGyoBongiAIgiAIgiAIJ5BwIgiCIAiCIAiCcAIJJ4IgCIIgCIIgCCeQcCIIgiAIgiAIgnACCSeCIAiCIAiCIAgnkHAiCIIgCIIgCIJwAgkngiAIgiAIgiAIJ5BwIgiCIAiCIAiCcAIJJ4IgCIJoBBqNBr/88ktTT4MgCIK4wpBwIgiCIFoM06ZNg0ajsfkaPnx4U0+NIAiCuMrRN/UECIIgCKIxDB8+HJ9//rlszN3dvYlmQxAEQVwrUMSJIAiCaFG4u7sjPDxc9hUQEACAT6NbuHAhRowYAQ8PD8THx2Pp0qWy49PT0zF48GB4eHggKCgI999/PyorK2X7LF68GB07doS7uzsiIiIwc+ZM2fbCwkKMHz8enp6eSExMxIoVKy7viyYIgiCaHBJOBEEQxFXF888/j5tvvhn79+/HnXfeiYkTJ+LIkSMAgOrqagwfPhwBAQHYuXMnli5ditWrV8uE0cKFC/HQQw/h/vvvR3p6OlasWIE2bdrIrvHiiy/itttuw4EDBzBy5EhMmjQJxcXFV/R1EgRBEFcWDcdxXFNPgiAIgiBcYdq0afjmm29gNBpl43PmzMHzzz8PjUaD6dOnY+HCheK21NRUdO/eHR9//DEWLVqEOXPmICsrC15eXgCAlStXYsyYMcjJyUFYWBiioqJw11134ZVXXlGdg0ajwXPPPYeXX34ZAFBVVQUfHx+sXLmSaq0IgiCuYqjGiSAIgmhRDBo0SCaMACAwMFB8nJaWJtuWlpaGffv2AQCOHDmCLl26iKIJAPr06QOLxYJjx45Bo9EgJycHQ4YMcTiHzp07i4+9vLzg4+ODgoKCC31JBEEQRAuAhBNBEATRovDy8rJJnXOGRqMBAHAcJz5W28fDw8Ol8xkMBptjLRZLo+ZEEARBtCyoxokgCIK4qti2bZvN8/bt2wMAkpKSsG/fPlRVVYnbN2/eDK1Wi7Zt28LHxwetWrXCv//+e0XnTBAEQTR/KOJEEARBtChMJhPy8vJkY3q9HsHBwQCApUuXokePHujbty++/fZb7NixA5999hkAYNKkSZg7dy6mTp2KefPm4fz585g1axYmT56MsLAwAMC8efMwffp0hIaGYsSIEaioqMDmzZsxa9asK/tCCYIgiGYFCSeCIAiiRfHXX38hIiJCNtauXTscPXoUAO94t2TJEsyYMQPh4eH49ttvkZSUBADw9PTE33//jdmzZ6Nnz57w9PTEzTffjLfffls819SpU1FbW4t33nkHjz/+OIKDg3HLLbdcuRdIEARBNEvIVY8gCIK4atBoNPj5558xbty4pp4KQRAEcZVBNU4EQRAEQRAEQRBOIOFEEARBEARBEAThBKpxIgiCIK4aKPucIAiCuFxQxIkgCIIgCIIgCMIJJJwIgiAIgiAIgiCcQMKJIAiCIAiCIAjCCSScCIIgCIIgCIIgnEDCiSAIgiAIgiAIwgkknAiCIAiCIAiCIJxAwokgCIIgCIIgCMIJJJwIgiAIgiAIgiCc8P9NY1E4HmeuEAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cae_mlp_input_dim = cae_mlp_train_reps.shape[1]\n",
    "cae_mlp_num_classes = len(torch.unique(cae_mlp_train_labels_torch))\n",
    "cae_mlp_model = MLPClassifier(cae_mlp_input_dim, cae_mlp_num_classes).to(device)\n",
    "\n",
    "cae_mlp_criterion = nn.CrossEntropyLoss()\n",
    "cae_mlp_optimizer = optim.Adam(cae_mlp_model.parameters(), lr=1e-3)\n",
    "\n",
    "cae_mlp_num_epochs = 1000\n",
    "cae_mlp_patience = 100\n",
    "\n",
    "cae_mlp_train_losses = []\n",
    "cae_mlp_val_losses = []\n",
    "\n",
    "cae_mlp_best_val_loss = float('inf')\n",
    "cae_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for cae_mlp_epoch in range(cae_mlp_num_epochs):\n",
    "    # Training\n",
    "    cae_mlp_model.train()\n",
    "    cae_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for cae_mlp_embeddings_batch, cae_mlp_labels_batch in cae_mlp_train_loader:\n",
    "        cae_mlp_embeddings_batch = cae_mlp_embeddings_batch.to(device)\n",
    "        cae_mlp_labels_batch = cae_mlp_labels_batch.to(device)\n",
    "        \n",
    "        cae_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        cae_mlp_outputs = cae_mlp_model(cae_mlp_embeddings_batch)\n",
    "        cae_mlp_loss = cae_mlp_criterion(cae_mlp_outputs, cae_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        cae_mlp_loss.backward()\n",
    "        cae_mlp_optimizer.step()\n",
    "        \n",
    "        cae_mlp_train_running_loss += cae_mlp_loss.item() * cae_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    cae_mlp_epoch_train_loss = cae_mlp_train_running_loss / len(cae_mlp_train_loader.dataset)\n",
    "    cae_mlp_train_losses.append(cae_mlp_epoch_train_loss)\n",
    "\n",
    "\n",
    "    # Validation\n",
    "\n",
    "    cae_mlp_model.eval()\n",
    "    cae_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for cae_mlp_val_embeddings_batch, cae_mlp_val_labels_batch in cae_mlp_val_loader:\n",
    "            cae_mlp_val_embeddings_batch = cae_mlp_val_embeddings_batch.to(device)\n",
    "            cae_mlp_val_labels_batch = cae_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            cae_mlp_val_outputs = cae_mlp_model(cae_mlp_val_embeddings_batch)\n",
    "            cae_mlp_val_loss = cae_mlp_criterion(cae_mlp_val_outputs, cae_mlp_val_labels_batch)\n",
    "\n",
    "            cae_mlp_val_running_loss += cae_mlp_val_loss.item() * cae_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    cae_mlp_epoch_val_loss = cae_mlp_val_running_loss / len(cae_mlp_val_loader.dataset)\n",
    "    cae_mlp_val_losses.append(cae_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {cae_mlp_epoch+1}/{cae_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {cae_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {cae_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "\n",
    "    if cae_mlp_epoch_val_loss < cae_mlp_best_val_loss:\n",
    "        # improvement, reset patience\n",
    "        print(f\"Validation loss improved from {cae_mlp_best_val_loss:.4f} to {cae_mlp_epoch_val_loss:.4f}.\")\n",
    "        cae_mlp_best_val_loss = cae_mlp_epoch_val_loss\n",
    "        cae_mlp_epochs_without_improvement = 0\n",
    "\n",
    "    else:\n",
    "        # no improvement\n",
    "        cae_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {cae_mlp_epochs_without_improvement}/{cae_mlp_patience}\")\n",
    "        \n",
    "        if cae_mlp_epochs_without_improvement >= cae_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {cae_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {cae_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(cae_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(cae_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:43:43.544505Z",
     "iopub.status.busy": "2025-05-08T19:43:43.544505Z",
     "iopub.status.idle": "2025-05-08T19:43:43.694822Z",
     "shell.execute_reply": "2025-05-08T19:43:43.694822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CAE+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.6718 | Test Accuracy: 77.04%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cae_mlp_model.eval()\n",
    "\n",
    "cae_mlp_test_running_loss = 0.0\n",
    "cae_mlp_test_correct = 0\n",
    "cae_mlp_all_predictions = []\n",
    "cae_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for cae_mlp_test_embeddings_batch, cae_mlp_test_labels_batch in cae_mlp_test_loader:\n",
    "        cae_mlp_test_embeddings_batch = cae_mlp_test_embeddings_batch.to(device)\n",
    "        cae_mlp_test_labels_batch = cae_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        cae_mlp_test_outputs = cae_mlp_model(cae_mlp_test_embeddings_batch)\n",
    "        \n",
    "        cae_mlp_test_loss_batch = cae_mlp_criterion(cae_mlp_test_outputs, cae_mlp_test_labels_batch)\n",
    "        cae_mlp_test_running_loss += cae_mlp_test_loss_batch.item() * cae_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, cae_mlp_test_predicted = torch.max(cae_mlp_test_outputs, dim=1)\n",
    "        cae_mlp_test_correct += (cae_mlp_test_predicted == cae_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        #saving predictions for conf matrix\n",
    "        cae_mlp_all_predictions.extend(cae_mlp_test_predicted.cpu().numpy())\n",
    "        cae_mlp_all_true_labels.extend(cae_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'cae_mlp_predictions.npy'), np.array(cae_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'cae_mlp_true_labels.npy'), np.array(cae_mlp_all_true_labels))\n",
    "print(f\"Saved CAE+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "cae_mlp_epoch_test_loss = cae_mlp_test_running_loss / len(cae_mlp_test_loader.dataset)\n",
    "cae_mlp_test_accuracy = cae_mlp_test_correct / len(cae_mlp_test_loader.dataset)\n",
    "\n",
    "cae_mlp_test_accuracy_pct = cae_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {cae_mlp_epoch_test_loss:.4f} | Test Accuracy: {cae_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "cae_mlp_num_epochs_run = len(cae_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         cae_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         cae_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         [cae_mlp_epoch_test_loss]*cae_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical SCL with Cosine Similarity (Supervised Contrastive Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:43:43.697830Z",
     "iopub.status.busy": "2025-05-08T19:43:43.697830Z",
     "iopub.status.idle": "2025-05-08T19:43:43.706564Z",
     "shell.execute_reply": "2025-05-08T19:43:43.706564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 560 samples with 64 features each\n",
      "LOG: Labels shape: (560,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2618 samples with 64 features each\n",
      "LOG: Labels shape: (2618,)\n",
      "\n",
      "\n",
      "Train embeddings shape: (560, 64), \n",
      "Train labels shape: (560,)\n",
      "\n",
      "\n",
      "Val embeddings shape: (70, 64), \n",
      "Val labels shape: (70,)\n",
      "\n",
      "\n",
      "Test embeddings shape: (2618, 64), \n",
      "Test labels shape: (2618,)\n"
     ]
    }
   ],
   "source": [
    "tscl_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "tscl_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "tscl_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "tscl_train_embeddings, tscl_train_labels = load_encoded_data(tscl_encoded_train_dir)\n",
    "tscl_val_embeddings, tscl_val_labels = load_encoded_data(tscl_encoded_val_dir)\n",
    "tscl_test_embeddings, tscl_test_labels = load_encoded_data(tscl_encoded_test_dir)\n",
    "\n",
    "#shape verification\n",
    "print(f\"\\n\\nTrain embeddings shape: {tscl_train_embeddings.shape}, \\nTrain labels shape: {tscl_train_labels.shape}\")\n",
    "print(f\"\\n\\nVal embeddings shape: {tscl_val_embeddings.shape}, \\nVal labels shape: {tscl_val_labels.shape}\")\n",
    "print(f\"\\n\\nTest embeddings shape: {tscl_test_embeddings.shape}, \\nTest labels shape: {tscl_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:43:43.709571Z",
     "iopub.status.busy": "2025-05-08T19:43:43.709571Z",
     "iopub.status.idle": "2025-05-08T19:43:43.722184Z",
     "shell.execute_reply": "2025-05-08T19:43:43.722184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20, 9: 20, 10: 20, 11: 20, 12: 20, 13: 20}\n",
      "Training batch size: 280\n"
     ]
    }
   ],
   "source": [
    "#flattening embeddings to (num_samples, 64)\n",
    "tscl_train_embeddings = tscl_train_embeddings.reshape(tscl_train_embeddings.shape[0], -1)\n",
    "tscl_val_embeddings = tscl_val_embeddings.reshape(tscl_val_embeddings.shape[0], -1)\n",
    "tscl_test_embeddings = tscl_test_embeddings.reshape(tscl_test_embeddings.shape[0], -1)\n",
    "\n",
    "#compute mean and std from training set\n",
    "tscl_train_mean = np.mean(tscl_train_embeddings, axis=0)\n",
    "tscl_train_std = np.std(tscl_train_embeddings, axis=0)\n",
    "\n",
    "#normalize all datasets from above training mean and std\n",
    "tscl_train_embeddings = (tscl_train_embeddings - tscl_train_mean) / tscl_train_std\n",
    "tscl_val_embeddings = (tscl_val_embeddings - tscl_train_mean) / tscl_train_std\n",
    "tscl_test_embeddings = (tscl_test_embeddings - tscl_train_mean) / tscl_train_std\n",
    "\n",
    "tscl_train_dataset = TensorDataset(torch.tensor(tscl_train_embeddings, dtype=torch.float32), torch.tensor(tscl_train_labels, dtype=torch.long))\n",
    "tscl_val_dataset = TensorDataset(torch.tensor(tscl_val_embeddings, dtype=torch.float32), torch.tensor(tscl_val_labels, dtype=torch.long))\n",
    "tscl_test_dataset = TensorDataset(torch.tensor(tscl_test_embeddings, dtype=torch.float32), torch.tensor(tscl_test_labels, dtype=torch.long))\n",
    "\n",
    "tscl_m = 20\n",
    "tscl_num_classes = len(np.unique(tscl_train_labels))\n",
    "\n",
    "# Calculate theoretical required batch size\n",
    "tscl_required_batch_size = tscl_m * tscl_num_classes\n",
    "\n",
    "# Ensure batch size doesn't exceed training set size\n",
    "if tscl_required_batch_size > len(tscl_train_dataset):\n",
    "    #case 1: Not enough samples - reduce m proportionally\n",
    "    tscl_max_possible_m = len(tscl_train_dataset) // tscl_num_classes\n",
    "    tscl_m = max(1, tscl_max_possible_m)  # Ensure m >= 1\n",
    "    tscl_batch_size_train = tscl_m * tscl_num_classes\n",
    "else:\n",
    "    #case 2: Use full batch size\n",
    "    tscl_batch_size_train = tscl_required_batch_size\n",
    "\n",
    "tscl_sampler = MPerClassSampler(labels = tscl_train_labels, m = tscl_m, batch_size = tscl_batch_size_train, length_before_new_iter=len(tscl_train_dataset))\n",
    "tscl_train_loader = DataLoader(tscl_train_dataset, batch_size=tscl_batch_size_train, sampler=tscl_sampler)\n",
    "\n",
    "#creating dataloaders for scl\n",
    "tscl_dataloader_bs = 256\n",
    "tscl_val_loader = DataLoader(tscl_val_dataset, batch_size=tscl_dataloader_bs, shuffle=False)\n",
    "tscl_test_loader = DataLoader(tscl_test_dataset, batch_size=tscl_dataloader_bs, shuffle=False)\n",
    "\n",
    "for tscl_X_batch, tscl_y_batch in tscl_train_loader:\n",
    "    tscl_unique, tscl_counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(\"Class distribution in batch:\", dict(zip(tscl_unique, tscl_counts)))\n",
    "    print(f\"Training batch size: {tscl_batch_size_train}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:43:43.725190Z",
     "iopub.status.busy": "2025-05-08T19:43:43.725190Z",
     "iopub.status.idle": "2025-05-08T19:43:43.730693Z",
     "shell.execute_reply": "2025-05-08T19:43:43.730693Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature = 0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        #normalize feat vectors\n",
    "        features = F.normalize(features, p=2, dim = 1)\n",
    "\n",
    "        #compute cosine simi matrix\n",
    "        similarity_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "\n",
    "        #create a mask for +ve pairs - i.e. same class\n",
    "        labels = labels.unsqueeze(1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(features.device)\n",
    "\n",
    "        #loss computation\n",
    "        exp_sim = torch.exp(similarity_matrix)\n",
    "        log_prob = similarity_matrix - torch.log(exp_sim.sum(dim = 1, keepdim=True))\n",
    "\n",
    "        #mask out diagonal - i.e. self similarity\n",
    "        mask_self = torch.eye(mask.shape[0], dtype = torch.bool).to(features.device)\n",
    "        mask = mask * (~mask_self)\n",
    "\n",
    "        #handling edge cases when there is no +ve pair\n",
    "        mask_pos_pairs = mask.sum(dim=1)\n",
    "        mask_pos_pairs = torch.where(mask_pos_pairs < 1e-6, 1, mask_pos_pairs)\n",
    "\n",
    "        loss = -(mask * log_prob).sum(dim=1) / mask_pos_pairs\n",
    "\n",
    "        return loss.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:43:43.733698Z",
     "iopub.status.busy": "2025-05-08T19:43:43.732698Z",
     "iopub.status.idle": "2025-05-08T19:43:43.737111Z",
     "shell.execute_reply": "2025-05-08T19:43:43.737111Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SupConNet, self).__init__()\n",
    "\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(64, 128), #expects input of shape (batch_size, 64)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #flattening input tensor\n",
    "        #x = x.view(x.size(0), -1)  #reshaping -> (batch_size, channels * height * width)\n",
    "        projections = self.projection_head(x)\n",
    "        return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:43:43.740619Z",
     "iopub.status.busy": "2025-05-08T19:43:43.740619Z",
     "iopub.status.idle": "2025-05-08T19:44:01.367532Z",
     "shell.execute_reply": "2025-05-08T19:44:01.367029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 8.4745\n",
      "    Batch [2/2], Train Loss: 8.3522\n",
      "Epoch [1/2000], Avg Train Loss: 8.4133\n",
      "Epoch [1/2000], Avg Val Loss: 3.4843\n",
      "Validation loss improved from inf to 3.4843. Saving model...\n",
      "\n",
      "LOG: Epoch [2/2000] - Training\n",
      "    Batch [1/2], Train Loss: 8.1099\n",
      "    Batch [2/2], Train Loss: 8.2444\n",
      "Epoch [2/2000], Avg Train Loss: 8.1772\n",
      "Epoch [2/2000], Avg Val Loss: 3.4462\n",
      "Validation loss improved from 3.4843 to 3.4462. Saving model...\n",
      "\n",
      "LOG: Epoch [3/2000] - Training\n",
      "    Batch [1/2], Train Loss: 8.1143\n",
      "    Batch [2/2], Train Loss: 7.9725\n",
      "Epoch [3/2000], Avg Train Loss: 8.0434\n",
      "Epoch [3/2000], Avg Val Loss: 3.4116\n",
      "Validation loss improved from 3.4462 to 3.4116. Saving model...\n",
      "\n",
      "LOG: Epoch [4/2000] - Training\n",
      "    Batch [1/2], Train Loss: 8.0499\n",
      "    Batch [2/2], Train Loss: 7.7521\n",
      "Epoch [4/2000], Avg Train Loss: 7.9010\n",
      "Epoch [4/2000], Avg Val Loss: 3.3800\n",
      "Validation loss improved from 3.4116 to 3.3800. Saving model...\n",
      "\n",
      "LOG: Epoch [5/2000] - Training\n",
      "    Batch [1/2], Train Loss: 7.5328\n",
      "    Batch [2/2], Train Loss: 7.6393\n",
      "Epoch [5/2000], Avg Train Loss: 7.5861\n",
      "Epoch [5/2000], Avg Val Loss: 3.3513\n",
      "Validation loss improved from 3.3800 to 3.3513. Saving model...\n",
      "\n",
      "LOG: Epoch [6/2000] - Training\n",
      "    Batch [1/2], Train Loss: 7.5474\n",
      "    Batch [2/2], Train Loss: 7.6636\n",
      "Epoch [6/2000], Avg Train Loss: 7.6055\n",
      "Epoch [6/2000], Avg Val Loss: 3.3251\n",
      "Validation loss improved from 3.3513 to 3.3251. Saving model...\n",
      "\n",
      "LOG: Epoch [7/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 7.4971\n",
      "    Batch [2/2], Train Loss: 7.6057\n",
      "Epoch [7/2000], Avg Train Loss: 7.5514\n",
      "Epoch [7/2000], Avg Val Loss: 3.3011\n",
      "Validation loss improved from 3.3251 to 3.3011. Saving model...\n",
      "\n",
      "LOG: Epoch [8/2000] - Training\n",
      "    Batch [1/2], Train Loss: 7.3929\n",
      "    Batch [2/2], Train Loss: 7.3826\n",
      "Epoch [8/2000], Avg Train Loss: 7.3878\n",
      "Epoch [8/2000], Avg Val Loss: 3.2795\n",
      "Validation loss improved from 3.3011 to 3.2795. Saving model...\n",
      "\n",
      "LOG: Epoch [9/2000] - Training\n",
      "    Batch [1/2], Train Loss: 7.2370\n",
      "    Batch [2/2], Train Loss: 7.3393\n",
      "Epoch [9/2000], Avg Train Loss: 7.2881\n",
      "Epoch [9/2000], Avg Val Loss: 3.2599\n",
      "Validation loss improved from 3.2795 to 3.2599. Saving model...\n",
      "\n",
      "LOG: Epoch [10/2000] - Training\n",
      "    Batch [1/2], Train Loss: 7.3342\n",
      "    Batch [2/2], Train Loss: 7.1076\n",
      "Epoch [10/2000], Avg Train Loss: 7.2209\n",
      "Epoch [10/2000], Avg Val Loss: 3.2421\n",
      "Validation loss improved from 3.2599 to 3.2421. Saving model...\n",
      "\n",
      "LOG: Epoch [11/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 6.8608\n",
      "    Batch [2/2], Train Loss: 6.8528\n",
      "Epoch [11/2000], Avg Train Loss: 6.8568\n",
      "Epoch [11/2000], Avg Val Loss: 3.2260\n",
      "Validation loss improved from 3.2421 to 3.2260. Saving model...\n",
      "\n",
      "LOG: Epoch [12/2000] - Training\n",
      "    Batch [1/2], Train Loss: 6.9929\n",
      "    Batch [2/2], Train Loss: 6.8843\n",
      "Epoch [12/2000], Avg Train Loss: 6.9386\n",
      "Epoch [12/2000], Avg Val Loss: 3.2117\n",
      "Validation loss improved from 3.2260 to 3.2117. Saving model...\n",
      "\n",
      "LOG: Epoch [13/2000] - Training\n",
      "    Batch [1/2], Train Loss: 6.7797\n",
      "    Batch [2/2], Train Loss: 6.6943\n",
      "Epoch [13/2000], Avg Train Loss: 6.7370\n",
      "Epoch [13/2000], Avg Val Loss: 3.1988\n",
      "Validation loss improved from 3.2117 to 3.1988. Saving model...\n",
      "\n",
      "LOG: Epoch [14/2000] - Training\n",
      "    Batch [1/2], Train Loss: 6.6747\n",
      "    Batch [2/2], Train Loss: 6.5914\n",
      "Epoch [14/2000], Avg Train Loss: 6.6330\n",
      "Epoch [14/2000], Avg Val Loss: 3.1875\n",
      "Validation loss improved from 3.1988 to 3.1875. Saving model...\n",
      "\n",
      "LOG: Epoch [15/2000] - Training\n",
      "    Batch [1/2], Train Loss: 6.6329\n",
      "    Batch [2/2], Train Loss: 6.5679\n",
      "Epoch [15/2000], Avg Train Loss: 6.6004\n",
      "Epoch [15/2000], Avg Val Loss: 3.1772\n",
      "Validation loss improved from 3.1875 to 3.1772. Saving model...\n",
      "\n",
      "LOG: Epoch [16/2000] - Training\n",
      "    Batch [1/2], Train Loss: 6.4983\n",
      "    Batch [2/2], Train Loss: 6.4258\n",
      "Epoch [16/2000], Avg Train Loss: 6.4621\n",
      "Epoch [16/2000], Avg Val Loss: 3.1682\n",
      "Validation loss improved from 3.1772 to 3.1682. Saving model...\n",
      "\n",
      "LOG: Epoch [17/2000] - Training\n",
      "    Batch [1/2], Train Loss: 6.4321\n",
      "    Batch [2/2], Train Loss: 6.4110\n",
      "Epoch [17/2000], Avg Train Loss: 6.4215\n",
      "Epoch [17/2000], Avg Val Loss: 3.1600\n",
      "Validation loss improved from 3.1682 to 3.1600. Saving model...\n",
      "\n",
      "LOG: Epoch [18/2000] - Training\n",
      "    Batch [1/2], Train Loss: 6.3394\n",
      "    Batch [2/2], Train Loss: 6.3351\n",
      "Epoch [18/2000], Avg Train Loss: 6.3372\n",
      "Epoch [18/2000], Avg Val Loss: 3.1528\n",
      "Validation loss improved from 3.1600 to 3.1528. Saving model...\n",
      "\n",
      "LOG: Epoch [19/2000] - Training\n",
      "    Batch [1/2], Train Loss: 6.2619\n",
      "    Batch [2/2], Train Loss: 6.2171\n",
      "Epoch [19/2000], Avg Train Loss: 6.2395\n",
      "Epoch [19/2000], Avg Val Loss: 3.1462\n",
      "Validation loss improved from 3.1528 to 3.1462. Saving model...\n",
      "\n",
      "LOG: Epoch [20/2000] - Training\n",
      "    Batch [1/2], Train Loss: 6.2538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 6.1394\n",
      "Epoch [20/2000], Avg Train Loss: 6.1966\n",
      "Epoch [20/2000], Avg Val Loss: 3.1404\n",
      "Validation loss improved from 3.1462 to 3.1404. Saving model...\n",
      "\n",
      "LOG: Epoch [21/2000] - Training\n",
      "    Batch [1/2], Train Loss: 6.0496\n",
      "    Batch [2/2], Train Loss: 6.0703\n",
      "Epoch [21/2000], Avg Train Loss: 6.0600\n",
      "Epoch [21/2000], Avg Val Loss: 3.1354\n",
      "Validation loss improved from 3.1404 to 3.1354. Saving model...\n",
      "\n",
      "LOG: Epoch [22/2000] - Training\n",
      "    Batch [1/2], Train Loss: 6.0735\n",
      "    Batch [2/2], Train Loss: 6.0901\n",
      "Epoch [22/2000], Avg Train Loss: 6.0818\n",
      "Epoch [22/2000], Avg Val Loss: 3.1311\n",
      "Validation loss improved from 3.1354 to 3.1311. Saving model...\n",
      "\n",
      "LOG: Epoch [23/2000] - Training\n",
      "    Batch [1/2], Train Loss: 6.0608\n",
      "    Batch [2/2], Train Loss: 5.9707\n",
      "Epoch [23/2000], Avg Train Loss: 6.0157\n",
      "Epoch [23/2000], Avg Val Loss: 3.1272\n",
      "Validation loss improved from 3.1311 to 3.1272. Saving model...\n",
      "\n",
      "LOG: Epoch [24/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.9444\n",
      "    Batch [2/2], Train Loss: 5.8996\n",
      "Epoch [24/2000], Avg Train Loss: 5.9220\n",
      "Epoch [24/2000], Avg Val Loss: 3.1236\n",
      "Validation loss improved from 3.1272 to 3.1236. Saving model...\n",
      "\n",
      "LOG: Epoch [25/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.8461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 5.8630\n",
      "Epoch [25/2000], Avg Train Loss: 5.8546\n",
      "Epoch [25/2000], Avg Val Loss: 3.1203\n",
      "Validation loss improved from 3.1236 to 3.1203. Saving model...\n",
      "\n",
      "LOG: Epoch [26/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.7777\n",
      "    Batch [2/2], Train Loss: 5.7191\n",
      "Epoch [26/2000], Avg Train Loss: 5.7484\n",
      "Epoch [26/2000], Avg Val Loss: 3.1172\n",
      "Validation loss improved from 3.1203 to 3.1172. Saving model...\n",
      "\n",
      "LOG: Epoch [27/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.7379\n",
      "    Batch [2/2], Train Loss: 5.7255\n",
      "Epoch [27/2000], Avg Train Loss: 5.7317\n",
      "Epoch [27/2000], Avg Val Loss: 3.1143\n",
      "Validation loss improved from 3.1172 to 3.1143. Saving model...\n",
      "\n",
      "LOG: Epoch [28/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 5.7916\n",
      "    Batch [2/2], Train Loss: 5.6162\n",
      "Epoch [28/2000], Avg Train Loss: 5.7039\n",
      "Epoch [28/2000], Avg Val Loss: 3.1116\n",
      "Validation loss improved from 3.1143 to 3.1116. Saving model...\n",
      "\n",
      "LOG: Epoch [29/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.7190\n",
      "    Batch [2/2], Train Loss: 5.6670\n",
      "Epoch [29/2000], Avg Train Loss: 5.6930\n",
      "Epoch [29/2000], Avg Val Loss: 3.1092\n",
      "Validation loss improved from 3.1116 to 3.1092. Saving model...\n",
      "\n",
      "LOG: Epoch [30/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.6394\n",
      "    Batch [2/2], Train Loss: 5.6170\n",
      "Epoch [30/2000], Avg Train Loss: 5.6282\n",
      "Epoch [30/2000], Avg Val Loss: 3.1070\n",
      "Validation loss improved from 3.1092 to 3.1070. Saving model...\n",
      "\n",
      "LOG: Epoch [31/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.6397\n",
      "    Batch [2/2], Train Loss: 5.7007\n",
      "Epoch [31/2000], Avg Train Loss: 5.6702\n",
      "Epoch [31/2000], Avg Val Loss: 3.1049\n",
      "Validation loss improved from 3.1070 to 3.1049. Saving model...\n",
      "\n",
      "LOG: Epoch [32/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.5925\n",
      "    Batch [2/2], Train Loss: 5.5397\n",
      "Epoch [32/2000], Avg Train Loss: 5.5661\n",
      "Epoch [32/2000], Avg Val Loss: 3.1029\n",
      "Validation loss improved from 3.1049 to 3.1029. Saving model...\n",
      "\n",
      "LOG: Epoch [33/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.5229\n",
      "    Batch [2/2], Train Loss: 5.5745\n",
      "Epoch [33/2000], Avg Train Loss: 5.5487\n",
      "Epoch [33/2000], Avg Val Loss: 3.1011\n",
      "Validation loss improved from 3.1029 to 3.1011. Saving model...\n",
      "\n",
      "LOG: Epoch [34/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.4598\n",
      "    Batch [2/2], Train Loss: 5.4973\n",
      "Epoch [34/2000], Avg Train Loss: 5.4785\n",
      "Epoch [34/2000], Avg Val Loss: 3.0995\n",
      "Validation loss improved from 3.1011 to 3.0995. Saving model...\n",
      "\n",
      "LOG: Epoch [35/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.5291\n",
      "    Batch [2/2], Train Loss: 5.4943\n",
      "Epoch [35/2000], Avg Train Loss: 5.5117\n",
      "Epoch [35/2000], Avg Val Loss: 3.0979\n",
      "Validation loss improved from 3.0995 to 3.0979. Saving model...\n",
      "\n",
      "LOG: Epoch [36/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.4963\n",
      "    Batch [2/2], Train Loss: 5.4428\n",
      "Epoch [36/2000], Avg Train Loss: 5.4695\n",
      "Epoch [36/2000], Avg Val Loss: 3.0964\n",
      "Validation loss improved from 3.0979 to 3.0964. Saving model...\n",
      "\n",
      "LOG: Epoch [37/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.3806\n",
      "    Batch [2/2], Train Loss: 5.4589\n",
      "Epoch [37/2000], Avg Train Loss: 5.4197\n",
      "Epoch [37/2000], Avg Val Loss: 3.0948\n",
      "Validation loss improved from 3.0964 to 3.0948. Saving model...\n",
      "\n",
      "LOG: Epoch [38/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.3857\n",
      "    Batch [2/2], Train Loss: 5.3154\n",
      "Epoch [38/2000], Avg Train Loss: 5.3506\n",
      "Epoch [38/2000], Avg Val Loss: 3.0933\n",
      "Validation loss improved from 3.0948 to 3.0933. Saving model...\n",
      "\n",
      "LOG: Epoch [39/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 5.4354\n",
      "    Batch [2/2], Train Loss: 5.3952\n",
      "Epoch [39/2000], Avg Train Loss: 5.4153\n",
      "Epoch [39/2000], Avg Val Loss: 3.0917\n",
      "Validation loss improved from 3.0933 to 3.0917. Saving model...\n",
      "\n",
      "LOG: Epoch [40/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.3837\n",
      "    Batch [2/2], Train Loss: 5.3606\n",
      "Epoch [40/2000], Avg Train Loss: 5.3721\n",
      "Epoch [40/2000], Avg Val Loss: 3.0902\n",
      "Validation loss improved from 3.0917 to 3.0902. Saving model...\n",
      "\n",
      "LOG: Epoch [41/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.3617\n",
      "    Batch [2/2], Train Loss: 5.3661\n",
      "Epoch [41/2000], Avg Train Loss: 5.3639\n",
      "Epoch [41/2000], Avg Val Loss: 3.0887\n",
      "Validation loss improved from 3.0902 to 3.0887. Saving model...\n",
      "\n",
      "LOG: Epoch [42/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.2832\n",
      "    Batch [2/2], Train Loss: 5.2881\n",
      "Epoch [42/2000], Avg Train Loss: 5.2856\n",
      "Epoch [42/2000], Avg Val Loss: 3.0871\n",
      "Validation loss improved from 3.0887 to 3.0871. Saving model...\n",
      "\n",
      "LOG: Epoch [43/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.3821\n",
      "    Batch [2/2], Train Loss: 5.2261\n",
      "Epoch [43/2000], Avg Train Loss: 5.3041\n",
      "Epoch [43/2000], Avg Val Loss: 3.0855\n",
      "Validation loss improved from 3.0871 to 3.0855. Saving model...\n",
      "\n",
      "LOG: Epoch [44/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 5.2783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 5.3116\n",
      "Epoch [44/2000], Avg Train Loss: 5.2949\n",
      "Epoch [44/2000], Avg Val Loss: 3.0838\n",
      "Validation loss improved from 3.0855 to 3.0838. Saving model...\n",
      "\n",
      "LOG: Epoch [45/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.2262\n",
      "    Batch [2/2], Train Loss: 5.2725\n",
      "Epoch [45/2000], Avg Train Loss: 5.2494\n",
      "Epoch [45/2000], Avg Val Loss: 3.0820\n",
      "Validation loss improved from 3.0838 to 3.0820. Saving model...\n",
      "\n",
      "LOG: Epoch [46/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.2644\n",
      "    Batch [2/2], Train Loss: 5.2473\n",
      "Epoch [46/2000], Avg Train Loss: 5.2559\n",
      "Epoch [46/2000], Avg Val Loss: 3.0802\n",
      "Validation loss improved from 3.0820 to 3.0802. Saving model...\n",
      "\n",
      "LOG: Epoch [47/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.2250\n",
      "    Batch [2/2], Train Loss: 5.2992\n",
      "Epoch [47/2000], Avg Train Loss: 5.2621\n",
      "Epoch [47/2000], Avg Val Loss: 3.0783\n",
      "Validation loss improved from 3.0802 to 3.0783. Saving model...\n",
      "\n",
      "LOG: Epoch [48/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.2258\n",
      "    Batch [2/2], Train Loss: 5.2024\n",
      "Epoch [48/2000], Avg Train Loss: 5.2141\n",
      "Epoch [48/2000], Avg Val Loss: 3.0765\n",
      "Validation loss improved from 3.0783 to 3.0765. Saving model...\n",
      "\n",
      "LOG: Epoch [49/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.2056\n",
      "    Batch [2/2], Train Loss: 5.2746\n",
      "Epoch [49/2000], Avg Train Loss: 5.2401\n",
      "Epoch [49/2000], Avg Val Loss: 3.0747\n",
      "Validation loss improved from 3.0765 to 3.0747. Saving model...\n",
      "\n",
      "LOG: Epoch [50/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.1809\n",
      "    Batch [2/2], Train Loss: 5.1540\n",
      "Epoch [50/2000], Avg Train Loss: 5.1674\n",
      "Epoch [50/2000], Avg Val Loss: 3.0728\n",
      "Validation loss improved from 3.0747 to 3.0728. Saving model...\n",
      "\n",
      "LOG: Epoch [51/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.1936\n",
      "    Batch [2/2], Train Loss: 5.1738\n",
      "Epoch [51/2000], Avg Train Loss: 5.1837\n",
      "Epoch [51/2000], Avg Val Loss: 3.0709\n",
      "Validation loss improved from 3.0728 to 3.0709. Saving model...\n",
      "\n",
      "LOG: Epoch [52/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.2089\n",
      "    Batch [2/2], Train Loss: 5.1378\n",
      "Epoch [52/2000], Avg Train Loss: 5.1734\n",
      "Epoch [52/2000], Avg Val Loss: 3.0691\n",
      "Validation loss improved from 3.0709 to 3.0691. Saving model...\n",
      "\n",
      "LOG: Epoch [53/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.1977\n",
      "    Batch [2/2], Train Loss: 5.0874\n",
      "Epoch [53/2000], Avg Train Loss: 5.1426\n",
      "Epoch [53/2000], Avg Val Loss: 3.0671\n",
      "Validation loss improved from 3.0691 to 3.0671. Saving model...\n",
      "\n",
      "LOG: Epoch [54/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.1521\n",
      "    Batch [2/2], Train Loss: 5.1749\n",
      "Epoch [54/2000], Avg Train Loss: 5.1635\n",
      "Epoch [54/2000], Avg Val Loss: 3.0651\n",
      "Validation loss improved from 3.0671 to 3.0651. Saving model...\n",
      "\n",
      "LOG: Epoch [55/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.1102\n",
      "    Batch [2/2], Train Loss: 5.1079\n",
      "Epoch [55/2000], Avg Train Loss: 5.1091\n",
      "Epoch [55/2000], Avg Val Loss: 3.0630\n",
      "Validation loss improved from 3.0651 to 3.0630. Saving model...\n",
      "\n",
      "LOG: Epoch [56/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.1193\n",
      "    Batch [2/2], Train Loss: 5.1977\n",
      "Epoch [56/2000], Avg Train Loss: 5.1585\n",
      "Epoch [56/2000], Avg Val Loss: 3.0608\n",
      "Validation loss improved from 3.0630 to 3.0608. Saving model...\n",
      "\n",
      "LOG: Epoch [57/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 5.0880\n",
      "    Batch [2/2], Train Loss: 5.1047\n",
      "Epoch [57/2000], Avg Train Loss: 5.0964\n",
      "Epoch [57/2000], Avg Val Loss: 3.0586\n",
      "Validation loss improved from 3.0608 to 3.0586. Saving model...\n",
      "\n",
      "LOG: Epoch [58/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.0591\n",
      "    Batch [2/2], Train Loss: 5.0567\n",
      "Epoch [58/2000], Avg Train Loss: 5.0579\n",
      "Epoch [58/2000], Avg Val Loss: 3.0563\n",
      "Validation loss improved from 3.0586 to 3.0563. Saving model...\n",
      "\n",
      "LOG: Epoch [59/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.1269\n",
      "    Batch [2/2], Train Loss: 4.9998\n",
      "Epoch [59/2000], Avg Train Loss: 5.0633\n",
      "Epoch [59/2000], Avg Val Loss: 3.0540\n",
      "Validation loss improved from 3.0563 to 3.0540. Saving model...\n",
      "\n",
      "LOG: Epoch [60/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.0901\n",
      "    Batch [2/2], Train Loss: 5.0834\n",
      "Epoch [60/2000], Avg Train Loss: 5.0867\n",
      "Epoch [60/2000], Avg Val Loss: 3.0516\n",
      "Validation loss improved from 3.0540 to 3.0516. Saving model...\n",
      "\n",
      "LOG: Epoch [61/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.0359\n",
      "    Batch [2/2], Train Loss: 5.0497\n",
      "Epoch [61/2000], Avg Train Loss: 5.0428\n",
      "Epoch [61/2000], Avg Val Loss: 3.0492\n",
      "Validation loss improved from 3.0516 to 3.0492. Saving model...\n",
      "\n",
      "LOG: Epoch [62/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.0714\n",
      "    Batch [2/2], Train Loss: 4.9584\n",
      "Epoch [62/2000], Avg Train Loss: 5.0149\n",
      "Epoch [62/2000], Avg Val Loss: 3.0467\n",
      "Validation loss improved from 3.0492 to 3.0467. Saving model...\n",
      "\n",
      "LOG: Epoch [63/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.0354\n",
      "    Batch [2/2], Train Loss: 5.0458\n",
      "Epoch [63/2000], Avg Train Loss: 5.0406\n",
      "Epoch [63/2000], Avg Val Loss: 3.0441\n",
      "Validation loss improved from 3.0467 to 3.0441. Saving model...\n",
      "\n",
      "LOG: Epoch [64/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 5.0549\n",
      "    Batch [2/2], Train Loss: 5.0329\n",
      "Epoch [64/2000], Avg Train Loss: 5.0439\n",
      "Epoch [64/2000], Avg Val Loss: 3.0414\n",
      "Validation loss improved from 3.0441 to 3.0414. Saving model...\n",
      "\n",
      "LOG: Epoch [65/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.0346\n",
      "    Batch [2/2], Train Loss: 5.0525\n",
      "Epoch [65/2000], Avg Train Loss: 5.0436\n",
      "Epoch [65/2000], Avg Val Loss: 3.0387\n",
      "Validation loss improved from 3.0414 to 3.0387. Saving model...\n",
      "\n",
      "LOG: Epoch [66/2000] - Training\n",
      "    Batch [1/2], Train Loss: 5.0382\n",
      "    Batch [2/2], Train Loss: 4.9673\n",
      "Epoch [66/2000], Avg Train Loss: 5.0027\n",
      "Epoch [66/2000], Avg Val Loss: 3.0361\n",
      "Validation loss improved from 3.0387 to 3.0361. Saving model...\n",
      "\n",
      "LOG: Epoch [67/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.9717\n",
      "    Batch [2/2], Train Loss: 5.0397\n",
      "Epoch [67/2000], Avg Train Loss: 5.0057\n",
      "Epoch [67/2000], Avg Val Loss: 3.0333\n",
      "Validation loss improved from 3.0361 to 3.0333. Saving model...\n",
      "\n",
      "LOG: Epoch [68/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.9406\n",
      "    Batch [2/2], Train Loss: 4.9612\n",
      "Epoch [68/2000], Avg Train Loss: 4.9509\n",
      "Epoch [68/2000], Avg Val Loss: 3.0306\n",
      "Validation loss improved from 3.0333 to 3.0306. Saving model...\n",
      "\n",
      "LOG: Epoch [69/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.9595\n",
      "    Batch [2/2], Train Loss: 5.0491\n",
      "Epoch [69/2000], Avg Train Loss: 5.0043\n",
      "Epoch [69/2000], Avg Val Loss: 3.0279\n",
      "Validation loss improved from 3.0306 to 3.0279. Saving model...\n",
      "\n",
      "LOG: Epoch [70/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.9507\n",
      "    Batch [2/2], Train Loss: 5.0048\n",
      "Epoch [70/2000], Avg Train Loss: 4.9778\n",
      "Epoch [70/2000], Avg Val Loss: 3.0252\n",
      "Validation loss improved from 3.0279 to 3.0252. Saving model...\n",
      "\n",
      "LOG: Epoch [71/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.9802\n",
      "    Batch [2/2], Train Loss: 4.9379\n",
      "Epoch [71/2000], Avg Train Loss: 4.9590\n",
      "Epoch [71/2000], Avg Val Loss: 3.0225\n",
      "Validation loss improved from 3.0252 to 3.0225. Saving model...\n",
      "\n",
      "LOG: Epoch [72/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.9400\n",
      "    Batch [2/2], Train Loss: 4.9832\n",
      "Epoch [72/2000], Avg Train Loss: 4.9616\n",
      "Epoch [72/2000], Avg Val Loss: 3.0198\n",
      "Validation loss improved from 3.0225 to 3.0198. Saving model...\n",
      "\n",
      "LOG: Epoch [73/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.9874\n",
      "    Batch [2/2], Train Loss: 4.9693\n",
      "Epoch [73/2000], Avg Train Loss: 4.9783\n",
      "Epoch [73/2000], Avg Val Loss: 3.0170\n",
      "Validation loss improved from 3.0198 to 3.0170. Saving model...\n",
      "\n",
      "LOG: Epoch [74/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.9894\n",
      "    Batch [2/2], Train Loss: 4.9576\n",
      "Epoch [74/2000], Avg Train Loss: 4.9735\n",
      "Epoch [74/2000], Avg Val Loss: 3.0143\n",
      "Validation loss improved from 3.0170 to 3.0143. Saving model...\n",
      "\n",
      "LOG: Epoch [75/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.9469\n",
      "    Batch [2/2], Train Loss: 4.9787\n",
      "Epoch [75/2000], Avg Train Loss: 4.9628\n",
      "Epoch [75/2000], Avg Val Loss: 3.0115\n",
      "Validation loss improved from 3.0143 to 3.0115. Saving model...\n",
      "\n",
      "LOG: Epoch [76/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 4.9638\n",
      "    Batch [2/2], Train Loss: 4.8918\n",
      "Epoch [76/2000], Avg Train Loss: 4.9278\n",
      "Epoch [76/2000], Avg Val Loss: 3.0087\n",
      "Validation loss improved from 3.0115 to 3.0087. Saving model...\n",
      "\n",
      "LOG: Epoch [77/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.9888\n",
      "    Batch [2/2], Train Loss: 4.9469\n",
      "Epoch [77/2000], Avg Train Loss: 4.9678\n",
      "Epoch [77/2000], Avg Val Loss: 3.0060\n",
      "Validation loss improved from 3.0087 to 3.0060. Saving model...\n",
      "\n",
      "LOG: Epoch [78/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.9064\n",
      "    Batch [2/2], Train Loss: 4.9421\n",
      "Epoch [78/2000], Avg Train Loss: 4.9242\n",
      "Epoch [78/2000], Avg Val Loss: 3.0031\n",
      "Validation loss improved from 3.0060 to 3.0031. Saving model...\n",
      "\n",
      "LOG: Epoch [79/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.9443\n",
      "    Batch [2/2], Train Loss: 4.9040\n",
      "Epoch [79/2000], Avg Train Loss: 4.9241\n",
      "Epoch [79/2000], Avg Val Loss: 3.0003\n",
      "Validation loss improved from 3.0031 to 3.0003. Saving model...\n",
      "\n",
      "LOG: Epoch [80/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8952\n",
      "    Batch [2/2], Train Loss: 4.9357\n",
      "Epoch [80/2000], Avg Train Loss: 4.9155\n",
      "Epoch [80/2000], Avg Val Loss: 2.9975\n",
      "Validation loss improved from 3.0003 to 2.9975. Saving model...\n",
      "\n",
      "LOG: Epoch [81/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.9064\n",
      "    Batch [2/2], Train Loss: 4.8730\n",
      "Epoch [81/2000], Avg Train Loss: 4.8897\n",
      "Epoch [81/2000], Avg Val Loss: 2.9945\n",
      "Validation loss improved from 2.9975 to 2.9945. Saving model...\n",
      "\n",
      "LOG: Epoch [82/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8881\n",
      "    Batch [2/2], Train Loss: 4.8522\n",
      "Epoch [82/2000], Avg Train Loss: 4.8701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/2000], Avg Val Loss: 2.9915\n",
      "Validation loss improved from 2.9945 to 2.9915. Saving model...\n",
      "\n",
      "LOG: Epoch [83/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.9273\n",
      "    Batch [2/2], Train Loss: 4.9200\n",
      "Epoch [83/2000], Avg Train Loss: 4.9237\n",
      "Epoch [83/2000], Avg Val Loss: 2.9886\n",
      "Validation loss improved from 2.9915 to 2.9886. Saving model...\n",
      "\n",
      "LOG: Epoch [84/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8762\n",
      "    Batch [2/2], Train Loss: 4.9334\n",
      "Epoch [84/2000], Avg Train Loss: 4.9048\n",
      "Epoch [84/2000], Avg Val Loss: 2.9856\n",
      "Validation loss improved from 2.9886 to 2.9856. Saving model...\n",
      "\n",
      "LOG: Epoch [85/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.9346\n",
      "    Batch [2/2], Train Loss: 4.9264\n",
      "Epoch [85/2000], Avg Train Loss: 4.9305\n",
      "Epoch [85/2000], Avg Val Loss: 2.9828\n",
      "Validation loss improved from 2.9856 to 2.9828. Saving model...\n",
      "\n",
      "LOG: Epoch [86/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8582\n",
      "    Batch [2/2], Train Loss: 4.8277\n",
      "Epoch [86/2000], Avg Train Loss: 4.8429\n",
      "Epoch [86/2000], Avg Val Loss: 2.9799\n",
      "Validation loss improved from 2.9828 to 2.9799. Saving model...\n",
      "\n",
      "LOG: Epoch [87/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8669\n",
      "    Batch [2/2], Train Loss: 4.8685\n",
      "Epoch [87/2000], Avg Train Loss: 4.8677\n",
      "Epoch [87/2000], Avg Val Loss: 2.9770\n",
      "Validation loss improved from 2.9799 to 2.9770. Saving model...\n",
      "\n",
      "LOG: Epoch [88/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.9137\n",
      "    Batch [2/2], Train Loss: 4.8184\n",
      "Epoch [88/2000], Avg Train Loss: 4.8661\n",
      "Epoch [88/2000], Avg Val Loss: 2.9740\n",
      "Validation loss improved from 2.9770 to 2.9740. Saving model...\n",
      "\n",
      "LOG: Epoch [89/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8717\n",
      "    Batch [2/2], Train Loss: 4.9113\n",
      "Epoch [89/2000], Avg Train Loss: 4.8915\n",
      "Epoch [89/2000], Avg Val Loss: 2.9710\n",
      "Validation loss improved from 2.9740 to 2.9710. Saving model...\n",
      "\n",
      "LOG: Epoch [90/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8554\n",
      "    Batch [2/2], Train Loss: 4.8650\n",
      "Epoch [90/2000], Avg Train Loss: 4.8602\n",
      "Epoch [90/2000], Avg Val Loss: 2.9681\n",
      "Validation loss improved from 2.9710 to 2.9681. Saving model...\n",
      "\n",
      "LOG: Epoch [91/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8859\n",
      "    Batch [2/2], Train Loss: 4.8635\n",
      "Epoch [91/2000], Avg Train Loss: 4.8747\n",
      "Epoch [91/2000], Avg Val Loss: 2.9653\n",
      "Validation loss improved from 2.9681 to 2.9653. Saving model...\n",
      "\n",
      "LOG: Epoch [92/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8865\n",
      "    Batch [2/2], Train Loss: 4.8616\n",
      "Epoch [92/2000], Avg Train Loss: 4.8741\n",
      "Epoch [92/2000], Avg Val Loss: 2.9624\n",
      "Validation loss improved from 2.9653 to 2.9624. Saving model...\n",
      "\n",
      "LOG: Epoch [93/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8370\n",
      "    Batch [2/2], Train Loss: 4.8192\n",
      "Epoch [93/2000], Avg Train Loss: 4.8281\n",
      "Epoch [93/2000], Avg Val Loss: 2.9596\n",
      "Validation loss improved from 2.9624 to 2.9596. Saving model...\n",
      "\n",
      "LOG: Epoch [94/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 4.8494\n",
      "Epoch [94/2000], Avg Train Loss: 4.8492\n",
      "Epoch [94/2000], Avg Val Loss: 2.9567\n",
      "Validation loss improved from 2.9596 to 2.9567. Saving model...\n",
      "\n",
      "LOG: Epoch [95/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8232\n",
      "    Batch [2/2], Train Loss: 4.8438\n",
      "Epoch [95/2000], Avg Train Loss: 4.8335\n",
      "Epoch [95/2000], Avg Val Loss: 2.9540\n",
      "Validation loss improved from 2.9567 to 2.9540. Saving model...\n",
      "\n",
      "LOG: Epoch [96/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8482\n",
      "    Batch [2/2], Train Loss: 4.8060\n",
      "Epoch [96/2000], Avg Train Loss: 4.8271\n",
      "Epoch [96/2000], Avg Val Loss: 2.9512\n",
      "Validation loss improved from 2.9540 to 2.9512. Saving model...\n",
      "\n",
      "LOG: Epoch [97/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8537\n",
      "    Batch [2/2], Train Loss: 4.8478\n",
      "Epoch [97/2000], Avg Train Loss: 4.8508\n",
      "Epoch [97/2000], Avg Val Loss: 2.9484\n",
      "Validation loss improved from 2.9512 to 2.9484. Saving model...\n",
      "\n",
      "LOG: Epoch [98/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8110\n",
      "    Batch [2/2], Train Loss: 4.8006\n",
      "Epoch [98/2000], Avg Train Loss: 4.8058\n",
      "Epoch [98/2000], Avg Val Loss: 2.9457\n",
      "Validation loss improved from 2.9484 to 2.9457. Saving model...\n",
      "\n",
      "LOG: Epoch [99/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8058\n",
      "    Batch [2/2], Train Loss: 4.8118\n",
      "Epoch [99/2000], Avg Train Loss: 4.8088\n",
      "Epoch [99/2000], Avg Val Loss: 2.9429\n",
      "Validation loss improved from 2.9457 to 2.9429. Saving model...\n",
      "\n",
      "LOG: Epoch [100/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 4.7617\n",
      "Epoch [100/2000], Avg Train Loss: 4.7936\n",
      "Epoch [100/2000], Avg Val Loss: 2.9401\n",
      "Validation loss improved from 2.9429 to 2.9401. Saving model...\n",
      "\n",
      "LOG: Epoch [101/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8147\n",
      "    Batch [2/2], Train Loss: 4.7988\n",
      "Epoch [101/2000], Avg Train Loss: 4.8067\n",
      "Epoch [101/2000], Avg Val Loss: 2.9374\n",
      "Validation loss improved from 2.9401 to 2.9374. Saving model...\n",
      "\n",
      "LOG: Epoch [102/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8008\n",
      "    Batch [2/2], Train Loss: 4.8176\n",
      "Epoch [102/2000], Avg Train Loss: 4.8092\n",
      "Epoch [102/2000], Avg Val Loss: 2.9347\n",
      "Validation loss improved from 2.9374 to 2.9347. Saving model...\n",
      "\n",
      "LOG: Epoch [103/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.8189\n",
      "    Batch [2/2], Train Loss: 4.7549\n",
      "Epoch [103/2000], Avg Train Loss: 4.7869\n",
      "Epoch [103/2000], Avg Val Loss: 2.9320\n",
      "Validation loss improved from 2.9347 to 2.9320. Saving model...\n",
      "\n",
      "LOG: Epoch [104/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.7616\n",
      "    Batch [2/2], Train Loss: 4.7413\n",
      "Epoch [104/2000], Avg Train Loss: 4.7515\n",
      "Epoch [104/2000], Avg Val Loss: 2.9292\n",
      "Validation loss improved from 2.9320 to 2.9292. Saving model...\n",
      "\n",
      "LOG: Epoch [105/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.7795\n",
      "    Batch [2/2], Train Loss: 4.7057\n",
      "Epoch [105/2000], Avg Train Loss: 4.7426\n",
      "Epoch [105/2000], Avg Val Loss: 2.9264\n",
      "Validation loss improved from 2.9292 to 2.9264. Saving model...\n",
      "\n",
      "LOG: Epoch [106/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.7516\n",
      "    Batch [2/2], Train Loss: 4.7751\n",
      "Epoch [106/2000], Avg Train Loss: 4.7634\n",
      "Epoch [106/2000], Avg Val Loss: 2.9235\n",
      "Validation loss improved from 2.9264 to 2.9235. Saving model...\n",
      "\n",
      "LOG: Epoch [107/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.7771\n",
      "    Batch [2/2], Train Loss: 4.7815\n",
      "Epoch [107/2000], Avg Train Loss: 4.7793\n",
      "Epoch [107/2000], Avg Val Loss: 2.9207\n",
      "Validation loss improved from 2.9235 to 2.9207. Saving model...\n",
      "\n",
      "LOG: Epoch [108/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.7421\n",
      "    Batch [2/2], Train Loss: 4.7826\n",
      "Epoch [108/2000], Avg Train Loss: 4.7624\n",
      "Epoch [108/2000], Avg Val Loss: 2.9179\n",
      "Validation loss improved from 2.9207 to 2.9179. Saving model...\n",
      "\n",
      "LOG: Epoch [109/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.7696\n",
      "    Batch [2/2], Train Loss: 4.7044\n",
      "Epoch [109/2000], Avg Train Loss: 4.7370\n",
      "Epoch [109/2000], Avg Val Loss: 2.9152\n",
      "Validation loss improved from 2.9179 to 2.9152. Saving model...\n",
      "\n",
      "LOG: Epoch [110/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.7625\n",
      "    Batch [2/2], Train Loss: 4.7759\n",
      "Epoch [110/2000], Avg Train Loss: 4.7692\n",
      "Epoch [110/2000], Avg Val Loss: 2.9124\n",
      "Validation loss improved from 2.9152 to 2.9124. Saving model...\n",
      "\n",
      "LOG: Epoch [111/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.7252\n",
      "    Batch [2/2], Train Loss: 4.7135\n",
      "Epoch [111/2000], Avg Train Loss: 4.7193\n",
      "Epoch [111/2000], Avg Val Loss: 2.9096\n",
      "Validation loss improved from 2.9124 to 2.9096. Saving model...\n",
      "\n",
      "LOG: Epoch [112/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 4.7315\n",
      "    Batch [2/2], Train Loss: 4.7166\n",
      "Epoch [112/2000], Avg Train Loss: 4.7241\n",
      "Epoch [112/2000], Avg Val Loss: 2.9068\n",
      "Validation loss improved from 2.9096 to 2.9068. Saving model...\n",
      "\n",
      "LOG: Epoch [113/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6847\n",
      "    Batch [2/2], Train Loss: 4.7018\n",
      "Epoch [113/2000], Avg Train Loss: 4.6932\n",
      "Epoch [113/2000], Avg Val Loss: 2.9039\n",
      "Validation loss improved from 2.9068 to 2.9039. Saving model...\n",
      "\n",
      "LOG: Epoch [114/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.7017\n",
      "    Batch [2/2], Train Loss: 4.7545\n",
      "Epoch [114/2000], Avg Train Loss: 4.7281\n",
      "Epoch [114/2000], Avg Val Loss: 2.9010\n",
      "Validation loss improved from 2.9039 to 2.9010. Saving model...\n",
      "\n",
      "LOG: Epoch [115/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6933\n",
      "    Batch [2/2], Train Loss: 4.7193\n",
      "Epoch [115/2000], Avg Train Loss: 4.7063\n",
      "Epoch [115/2000], Avg Val Loss: 2.8981\n",
      "Validation loss improved from 2.9010 to 2.8981. Saving model...\n",
      "\n",
      "LOG: Epoch [116/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6895\n",
      "    Batch [2/2], Train Loss: 4.7211\n",
      "Epoch [116/2000], Avg Train Loss: 4.7053\n",
      "Epoch [116/2000], Avg Val Loss: 2.8952\n",
      "Validation loss improved from 2.8981 to 2.8952. Saving model...\n",
      "\n",
      "LOG: Epoch [117/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.7057\n",
      "    Batch [2/2], Train Loss: 4.7322\n",
      "Epoch [117/2000], Avg Train Loss: 4.7190\n",
      "Epoch [117/2000], Avg Val Loss: 2.8923\n",
      "Validation loss improved from 2.8952 to 2.8923. Saving model...\n",
      "\n",
      "LOG: Epoch [118/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 4.7375\n",
      "    Batch [2/2], Train Loss: 4.7092\n",
      "Epoch [118/2000], Avg Train Loss: 4.7234\n",
      "Epoch [118/2000], Avg Val Loss: 2.8895\n",
      "Validation loss improved from 2.8923 to 2.8895. Saving model...\n",
      "\n",
      "LOG: Epoch [119/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6152\n",
      "    Batch [2/2], Train Loss: 4.6800\n",
      "Epoch [119/2000], Avg Train Loss: 4.6476\n",
      "Epoch [119/2000], Avg Val Loss: 2.8866\n",
      "Validation loss improved from 2.8895 to 2.8866. Saving model...\n",
      "\n",
      "LOG: Epoch [120/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6921\n",
      "    Batch [2/2], Train Loss: 4.6981\n",
      "Epoch [120/2000], Avg Train Loss: 4.6951\n",
      "Epoch [120/2000], Avg Val Loss: 2.8838\n",
      "Validation loss improved from 2.8866 to 2.8838. Saving model...\n",
      "\n",
      "LOG: Epoch [121/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6725\n",
      "    Batch [2/2], Train Loss: 4.7111\n",
      "Epoch [121/2000], Avg Train Loss: 4.6918\n",
      "Epoch [121/2000], Avg Val Loss: 2.8809\n",
      "Validation loss improved from 2.8838 to 2.8809. Saving model...\n",
      "\n",
      "LOG: Epoch [122/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6819\n",
      "    Batch [2/2], Train Loss: 4.7147\n",
      "Epoch [122/2000], Avg Train Loss: 4.6983\n",
      "Epoch [122/2000], Avg Val Loss: 2.8781\n",
      "Validation loss improved from 2.8809 to 2.8781. Saving model...\n",
      "\n",
      "LOG: Epoch [123/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6469\n",
      "    Batch [2/2], Train Loss: 4.6695\n",
      "Epoch [123/2000], Avg Train Loss: 4.6582\n",
      "Epoch [123/2000], Avg Val Loss: 2.8754\n",
      "Validation loss improved from 2.8781 to 2.8754. Saving model...\n",
      "\n",
      "LOG: Epoch [124/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.7012\n",
      "    Batch [2/2], Train Loss: 4.6507\n",
      "Epoch [124/2000], Avg Train Loss: 4.6760\n",
      "Epoch [124/2000], Avg Val Loss: 2.8727\n",
      "Validation loss improved from 2.8754 to 2.8727. Saving model...\n",
      "\n",
      "LOG: Epoch [125/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6129\n",
      "    Batch [2/2], Train Loss: 4.6671\n",
      "Epoch [125/2000], Avg Train Loss: 4.6400\n",
      "Epoch [125/2000], Avg Val Loss: 2.8700\n",
      "Validation loss improved from 2.8727 to 2.8700. Saving model...\n",
      "\n",
      "LOG: Epoch [126/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6596\n",
      "    Batch [2/2], Train Loss: 4.6484\n",
      "Epoch [126/2000], Avg Train Loss: 4.6540\n",
      "Epoch [126/2000], Avg Val Loss: 2.8671\n",
      "Validation loss improved from 2.8700 to 2.8671. Saving model...\n",
      "\n",
      "LOG: Epoch [127/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6705\n",
      "    Batch [2/2], Train Loss: 4.6296\n",
      "Epoch [127/2000], Avg Train Loss: 4.6501\n",
      "Epoch [127/2000], Avg Val Loss: 2.8643\n",
      "Validation loss improved from 2.8671 to 2.8643. Saving model...\n",
      "\n",
      "LOG: Epoch [128/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6741\n",
      "    Batch [2/2], Train Loss: 4.6484\n",
      "Epoch [128/2000], Avg Train Loss: 4.6613\n",
      "Epoch [128/2000], Avg Val Loss: 2.8615\n",
      "Validation loss improved from 2.8643 to 2.8615. Saving model...\n",
      "\n",
      "LOG: Epoch [129/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.7489\n",
      "    Batch [2/2], Train Loss: 4.6215\n",
      "Epoch [129/2000], Avg Train Loss: 4.6852\n",
      "Epoch [129/2000], Avg Val Loss: 2.8588\n",
      "Validation loss improved from 2.8615 to 2.8588. Saving model...\n",
      "\n",
      "LOG: Epoch [130/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 4.6727\n",
      "    Batch [2/2], Train Loss: 4.6416\n",
      "Epoch [130/2000], Avg Train Loss: 4.6572\n",
      "Epoch [130/2000], Avg Val Loss: 2.8561\n",
      "Validation loss improved from 2.8588 to 2.8561. Saving model...\n",
      "\n",
      "LOG: Epoch [131/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6492\n",
      "    Batch [2/2], Train Loss: 4.6797\n",
      "Epoch [131/2000], Avg Train Loss: 4.6645\n",
      "Epoch [131/2000], Avg Val Loss: 2.8534\n",
      "Validation loss improved from 2.8561 to 2.8534. Saving model...\n",
      "\n",
      "LOG: Epoch [132/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6725\n",
      "    Batch [2/2], Train Loss: 4.6522\n",
      "Epoch [132/2000], Avg Train Loss: 4.6623\n",
      "Epoch [132/2000], Avg Val Loss: 2.8507\n",
      "Validation loss improved from 2.8534 to 2.8507. Saving model...\n",
      "\n",
      "LOG: Epoch [133/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6425\n",
      "    Batch [2/2], Train Loss: 4.6526\n",
      "Epoch [133/2000], Avg Train Loss: 4.6476\n",
      "Epoch [133/2000], Avg Val Loss: 2.8480\n",
      "Validation loss improved from 2.8507 to 2.8480. Saving model...\n",
      "\n",
      "LOG: Epoch [134/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6603\n",
      "    Batch [2/2], Train Loss: 4.6948\n",
      "Epoch [134/2000], Avg Train Loss: 4.6775\n",
      "Epoch [134/2000], Avg Val Loss: 2.8454\n",
      "Validation loss improved from 2.8480 to 2.8454. Saving model...\n",
      "\n",
      "LOG: Epoch [135/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6100\n",
      "    Batch [2/2], Train Loss: 4.6430\n",
      "Epoch [135/2000], Avg Train Loss: 4.6265\n",
      "Epoch [135/2000], Avg Val Loss: 2.8428\n",
      "Validation loss improved from 2.8454 to 2.8428. Saving model...\n",
      "\n",
      "LOG: Epoch [136/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 4.6278\n",
      "Epoch [136/2000], Avg Train Loss: 4.6200\n",
      "Epoch [136/2000], Avg Val Loss: 2.8402\n",
      "Validation loss improved from 2.8428 to 2.8402. Saving model...\n",
      "\n",
      "LOG: Epoch [137/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6504\n",
      "    Batch [2/2], Train Loss: 4.5871\n",
      "Epoch [137/2000], Avg Train Loss: 4.6188\n",
      "Epoch [137/2000], Avg Val Loss: 2.8376\n",
      "Validation loss improved from 2.8402 to 2.8376. Saving model...\n",
      "\n",
      "LOG: Epoch [138/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6215\n",
      "    Batch [2/2], Train Loss: 4.6729\n",
      "Epoch [138/2000], Avg Train Loss: 4.6472\n",
      "Epoch [138/2000], Avg Val Loss: 2.8351\n",
      "Validation loss improved from 2.8376 to 2.8351. Saving model...\n",
      "\n",
      "LOG: Epoch [139/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5896\n",
      "    Batch [2/2], Train Loss: 4.6249\n",
      "Epoch [139/2000], Avg Train Loss: 4.6073\n",
      "Epoch [139/2000], Avg Val Loss: 2.8325\n",
      "Validation loss improved from 2.8351 to 2.8325. Saving model...\n",
      "\n",
      "LOG: Epoch [140/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6431\n",
      "    Batch [2/2], Train Loss: 4.6113\n",
      "Epoch [140/2000], Avg Train Loss: 4.6272\n",
      "Epoch [140/2000], Avg Val Loss: 2.8300\n",
      "Validation loss improved from 2.8325 to 2.8300. Saving model...\n",
      "\n",
      "LOG: Epoch [141/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6729\n",
      "    Batch [2/2], Train Loss: 4.5605\n",
      "Epoch [141/2000], Avg Train Loss: 4.6167\n",
      "Epoch [141/2000], Avg Val Loss: 2.8276\n",
      "Validation loss improved from 2.8300 to 2.8276. Saving model...\n",
      "\n",
      "LOG: Epoch [142/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6143\n",
      "    Batch [2/2], Train Loss: 4.6410\n",
      "Epoch [142/2000], Avg Train Loss: 4.6277\n",
      "Epoch [142/2000], Avg Val Loss: 2.8252\n",
      "Validation loss improved from 2.8276 to 2.8252. Saving model...\n",
      "\n",
      "LOG: Epoch [143/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6110\n",
      "    Batch [2/2], Train Loss: 4.5441\n",
      "Epoch [143/2000], Avg Train Loss: 4.5775\n",
      "Epoch [143/2000], Avg Val Loss: 2.8227\n",
      "Validation loss improved from 2.8252 to 2.8227. Saving model...\n",
      "\n",
      "LOG: Epoch [144/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6176\n",
      "    Batch [2/2], Train Loss: 4.5629\n",
      "Epoch [144/2000], Avg Train Loss: 4.5903\n",
      "Epoch [144/2000], Avg Val Loss: 2.8202\n",
      "Validation loss improved from 2.8227 to 2.8202. Saving model...\n",
      "\n",
      "LOG: Epoch [145/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6112\n",
      "    Batch [2/2], Train Loss: 4.6114\n",
      "Epoch [145/2000], Avg Train Loss: 4.6113\n",
      "Epoch [145/2000], Avg Val Loss: 2.8177\n",
      "Validation loss improved from 2.8202 to 2.8177. Saving model...\n",
      "\n",
      "LOG: Epoch [146/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5874\n",
      "    Batch [2/2], Train Loss: 4.6211\n",
      "Epoch [146/2000], Avg Train Loss: 4.6043\n",
      "Epoch [146/2000], Avg Val Loss: 2.8152\n",
      "Validation loss improved from 2.8177 to 2.8152. Saving model...\n",
      "\n",
      "LOG: Epoch [147/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6144\n",
      "    Batch [2/2], Train Loss: 4.5781\n",
      "Epoch [147/2000], Avg Train Loss: 4.5963\n",
      "Epoch [147/2000], Avg Val Loss: 2.8128\n",
      "Validation loss improved from 2.8152 to 2.8128. Saving model...\n",
      "\n",
      "LOG: Epoch [148/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6860\n",
      "    Batch [2/2], Train Loss: 4.5924\n",
      "Epoch [148/2000], Avg Train Loss: 4.6392\n",
      "Epoch [148/2000], Avg Val Loss: 2.8104\n",
      "Validation loss improved from 2.8128 to 2.8104. Saving model...\n",
      "\n",
      "LOG: Epoch [149/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5981\n",
      "    Batch [2/2], Train Loss: 4.6101\n",
      "Epoch [149/2000], Avg Train Loss: 4.6041\n",
      "Epoch [149/2000], Avg Val Loss: 2.8082\n",
      "Validation loss improved from 2.8104 to 2.8082. Saving model...\n",
      "\n",
      "LOG: Epoch [150/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 4.5776\n",
      "    Batch [2/2], Train Loss: 4.5816\n",
      "Epoch [150/2000], Avg Train Loss: 4.5796\n",
      "Epoch [150/2000], Avg Val Loss: 2.8059\n",
      "Validation loss improved from 2.8082 to 2.8059. Saving model...\n",
      "\n",
      "LOG: Epoch [151/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6279\n",
      "    Batch [2/2], Train Loss: 4.5296\n",
      "Epoch [151/2000], Avg Train Loss: 4.5788\n",
      "Epoch [151/2000], Avg Val Loss: 2.8036\n",
      "Validation loss improved from 2.8059 to 2.8036. Saving model...\n",
      "\n",
      "LOG: Epoch [152/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5871\n",
      "    Batch [2/2], Train Loss: 4.5674\n",
      "Epoch [152/2000], Avg Train Loss: 4.5772\n",
      "Epoch [152/2000], Avg Val Loss: 2.8013\n",
      "Validation loss improved from 2.8036 to 2.8013. Saving model...\n",
      "\n",
      "LOG: Epoch [153/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5990\n",
      "    Batch [2/2], Train Loss: 4.6032\n",
      "Epoch [153/2000], Avg Train Loss: 4.6011\n",
      "Epoch [153/2000], Avg Val Loss: 2.7990\n",
      "Validation loss improved from 2.8013 to 2.7990. Saving model...\n",
      "\n",
      "LOG: Epoch [154/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5258\n",
      "    Batch [2/2], Train Loss: 4.5905\n",
      "Epoch [154/2000], Avg Train Loss: 4.5582\n",
      "Epoch [154/2000], Avg Val Loss: 2.7968\n",
      "Validation loss improved from 2.7990 to 2.7968. Saving model...\n",
      "\n",
      "LOG: Epoch [155/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 4.5649\n",
      "    Batch [2/2], Train Loss: 4.5926\n",
      "Epoch [155/2000], Avg Train Loss: 4.5787\n",
      "Epoch [155/2000], Avg Val Loss: 2.7945\n",
      "Validation loss improved from 2.7968 to 2.7945. Saving model...\n",
      "\n",
      "LOG: Epoch [156/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5625\n",
      "    Batch [2/2], Train Loss: 4.5284\n",
      "Epoch [156/2000], Avg Train Loss: 4.5454\n",
      "Epoch [156/2000], Avg Val Loss: 2.7921\n",
      "Validation loss improved from 2.7945 to 2.7921. Saving model...\n",
      "\n",
      "LOG: Epoch [157/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5190\n",
      "    Batch [2/2], Train Loss: 4.5575\n",
      "Epoch [157/2000], Avg Train Loss: 4.5383\n",
      "Epoch [157/2000], Avg Val Loss: 2.7898\n",
      "Validation loss improved from 2.7921 to 2.7898. Saving model...\n",
      "\n",
      "LOG: Epoch [158/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5456\n",
      "    Batch [2/2], Train Loss: 4.5813\n",
      "Epoch [158/2000], Avg Train Loss: 4.5635\n",
      "Epoch [158/2000], Avg Val Loss: 2.7874\n",
      "Validation loss improved from 2.7898 to 2.7874. Saving model...\n",
      "\n",
      "LOG: Epoch [159/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5359\n",
      "    Batch [2/2], Train Loss: 4.5397\n",
      "Epoch [159/2000], Avg Train Loss: 4.5378\n",
      "Epoch [159/2000], Avg Val Loss: 2.7851\n",
      "Validation loss improved from 2.7874 to 2.7851. Saving model...\n",
      "\n",
      "LOG: Epoch [160/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5619\n",
      "    Batch [2/2], Train Loss: 4.5212\n",
      "Epoch [160/2000], Avg Train Loss: 4.5415\n",
      "Epoch [160/2000], Avg Val Loss: 2.7827\n",
      "Validation loss improved from 2.7851 to 2.7827. Saving model...\n",
      "\n",
      "LOG: Epoch [161/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5210\n",
      "    Batch [2/2], Train Loss: 4.5265\n",
      "Epoch [161/2000], Avg Train Loss: 4.5238\n",
      "Epoch [161/2000], Avg Val Loss: 2.7802\n",
      "Validation loss improved from 2.7827 to 2.7802. Saving model...\n",
      "\n",
      "LOG: Epoch [162/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.6121\n",
      "    Batch [2/2], Train Loss: 4.5438\n",
      "Epoch [162/2000], Avg Train Loss: 4.5779\n",
      "Epoch [162/2000], Avg Val Loss: 2.7779\n",
      "Validation loss improved from 2.7802 to 2.7779. Saving model...\n",
      "\n",
      "LOG: Epoch [163/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5333\n",
      "    Batch [2/2], Train Loss: 4.5258\n",
      "Epoch [163/2000], Avg Train Loss: 4.5296\n",
      "Epoch [163/2000], Avg Val Loss: 2.7755\n",
      "Validation loss improved from 2.7779 to 2.7755. Saving model...\n",
      "\n",
      "LOG: Epoch [164/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5563\n",
      "    Batch [2/2], Train Loss: 4.5140\n",
      "Epoch [164/2000], Avg Train Loss: 4.5351\n",
      "Epoch [164/2000], Avg Val Loss: 2.7731\n",
      "Validation loss improved from 2.7755 to 2.7731. Saving model...\n",
      "\n",
      "LOG: Epoch [165/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5255\n",
      "    Batch [2/2], Train Loss: 4.5498\n",
      "Epoch [165/2000], Avg Train Loss: 4.5376\n",
      "Epoch [165/2000], Avg Val Loss: 2.7707\n",
      "Validation loss improved from 2.7731 to 2.7707. Saving model...\n",
      "\n",
      "LOG: Epoch [166/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5481\n",
      "    Batch [2/2], Train Loss: 4.5387\n",
      "Epoch [166/2000], Avg Train Loss: 4.5434\n",
      "Epoch [166/2000], Avg Val Loss: 2.7683\n",
      "Validation loss improved from 2.7707 to 2.7683. Saving model...\n",
      "\n",
      "LOG: Epoch [167/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5187\n",
      "    Batch [2/2], Train Loss: 4.5517\n",
      "Epoch [167/2000], Avg Train Loss: 4.5352\n",
      "Epoch [167/2000], Avg Val Loss: 2.7661\n",
      "Validation loss improved from 2.7683 to 2.7661. Saving model...\n",
      "\n",
      "LOG: Epoch [168/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 4.5533\n",
      "    Batch [2/2], Train Loss: 4.5105\n",
      "Epoch [168/2000], Avg Train Loss: 4.5319\n",
      "Epoch [168/2000], Avg Val Loss: 2.7639\n",
      "Validation loss improved from 2.7661 to 2.7639. Saving model...\n",
      "\n",
      "LOG: Epoch [169/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5387\n",
      "    Batch [2/2], Train Loss: 4.4935\n",
      "Epoch [169/2000], Avg Train Loss: 4.5161\n",
      "Epoch [169/2000], Avg Val Loss: 2.7617\n",
      "Validation loss improved from 2.7639 to 2.7617. Saving model...\n",
      "\n",
      "LOG: Epoch [170/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4995\n",
      "    Batch [2/2], Train Loss: 4.4941\n",
      "Epoch [170/2000], Avg Train Loss: 4.4968\n",
      "Epoch [170/2000], Avg Val Loss: 2.7594\n",
      "Validation loss improved from 2.7617 to 2.7594. Saving model...\n",
      "\n",
      "LOG: Epoch [171/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4997\n",
      "    Batch [2/2], Train Loss: 4.5028\n",
      "Epoch [171/2000], Avg Train Loss: 4.5013\n",
      "Epoch [171/2000], Avg Val Loss: 2.7571\n",
      "Validation loss improved from 2.7594 to 2.7571. Saving model...\n",
      "\n",
      "LOG: Epoch [172/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4906\n",
      "    Batch [2/2], Train Loss: 4.4788\n",
      "Epoch [172/2000], Avg Train Loss: 4.4847\n",
      "Epoch [172/2000], Avg Val Loss: 2.7548\n",
      "Validation loss improved from 2.7571 to 2.7548. Saving model...\n",
      "\n",
      "LOG: Epoch [173/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 4.5374\n",
      "Epoch [173/2000], Avg Train Loss: 4.5247\n",
      "Epoch [173/2000], Avg Val Loss: 2.7525\n",
      "Validation loss improved from 2.7548 to 2.7525. Saving model...\n",
      "\n",
      "LOG: Epoch [174/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4903\n",
      "    Batch [2/2], Train Loss: 4.4946\n",
      "Epoch [174/2000], Avg Train Loss: 4.4925\n",
      "Epoch [174/2000], Avg Val Loss: 2.7502\n",
      "Validation loss improved from 2.7525 to 2.7502. Saving model...\n",
      "\n",
      "LOG: Epoch [175/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5041\n",
      "    Batch [2/2], Train Loss: 4.4996\n",
      "Epoch [175/2000], Avg Train Loss: 4.5019\n",
      "Epoch [175/2000], Avg Val Loss: 2.7480\n",
      "Validation loss improved from 2.7502 to 2.7480. Saving model...\n",
      "\n",
      "LOG: Epoch [176/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5457\n",
      "    Batch [2/2], Train Loss: 4.4836\n",
      "Epoch [176/2000], Avg Train Loss: 4.5147\n",
      "Epoch [176/2000], Avg Val Loss: 2.7457\n",
      "Validation loss improved from 2.7480 to 2.7457. Saving model...\n",
      "\n",
      "LOG: Epoch [177/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4499\n",
      "    Batch [2/2], Train Loss: 4.5307\n",
      "Epoch [177/2000], Avg Train Loss: 4.4903\n",
      "Epoch [177/2000], Avg Val Loss: 2.7434\n",
      "Validation loss improved from 2.7457 to 2.7434. Saving model...\n",
      "\n",
      "LOG: Epoch [178/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4708\n",
      "    Batch [2/2], Train Loss: 4.4918\n",
      "Epoch [178/2000], Avg Train Loss: 4.4813\n",
      "Epoch [178/2000], Avg Val Loss: 2.7412\n",
      "Validation loss improved from 2.7434 to 2.7412. Saving model...\n",
      "\n",
      "LOG: Epoch [179/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4454\n",
      "    Batch [2/2], Train Loss: 4.4810\n",
      "Epoch [179/2000], Avg Train Loss: 4.4632\n",
      "Epoch [179/2000], Avg Val Loss: 2.7388\n",
      "Validation loss improved from 2.7412 to 2.7388. Saving model...\n",
      "\n",
      "LOG: Epoch [180/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4918\n",
      "    Batch [2/2], Train Loss: 4.4514\n",
      "Epoch [180/2000], Avg Train Loss: 4.4716\n",
      "Epoch [180/2000], Avg Val Loss: 2.7364\n",
      "Validation loss improved from 2.7388 to 2.7364. Saving model...\n",
      "\n",
      "LOG: Epoch [181/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4634\n",
      "    Batch [2/2], Train Loss: 4.5023\n",
      "Epoch [181/2000], Avg Train Loss: 4.4828\n",
      "Epoch [181/2000], Avg Val Loss: 2.7341\n",
      "Validation loss improved from 2.7364 to 2.7341. Saving model...\n",
      "\n",
      "LOG: Epoch [182/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5045\n",
      "    Batch [2/2], Train Loss: 4.4611\n",
      "Epoch [182/2000], Avg Train Loss: 4.4828\n",
      "Epoch [182/2000], Avg Val Loss: 2.7318\n",
      "Validation loss improved from 2.7341 to 2.7318. Saving model...\n",
      "\n",
      "LOG: Epoch [183/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4580\n",
      "    Batch [2/2], Train Loss: 4.4869\n",
      "Epoch [183/2000], Avg Train Loss: 4.4725\n",
      "Epoch [183/2000], Avg Val Loss: 2.7296\n",
      "Validation loss improved from 2.7318 to 2.7296. Saving model...\n",
      "\n",
      "LOG: Epoch [184/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.5090\n",
      "    Batch [2/2], Train Loss: 4.4846\n",
      "Epoch [184/2000], Avg Train Loss: 4.4968\n",
      "Epoch [184/2000], Avg Val Loss: 2.7276\n",
      "Validation loss improved from 2.7296 to 2.7276. Saving model...\n",
      "\n",
      "LOG: Epoch [185/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4628\n",
      "    Batch [2/2], Train Loss: 4.4451\n",
      "Epoch [185/2000], Avg Train Loss: 4.4539\n",
      "Epoch [185/2000], Avg Val Loss: 2.7256\n",
      "Validation loss improved from 2.7276 to 2.7256. Saving model...\n",
      "\n",
      "LOG: Epoch [186/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4618\n",
      "    Batch [2/2], Train Loss: 4.4369\n",
      "Epoch [186/2000], Avg Train Loss: 4.4494\n",
      "Epoch [186/2000], Avg Val Loss: 2.7235\n",
      "Validation loss improved from 2.7256 to 2.7235. Saving model...\n",
      "\n",
      "LOG: Epoch [187/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 4.4978\n",
      "    Batch [2/2], Train Loss: 4.4256\n",
      "Epoch [187/2000], Avg Train Loss: 4.4617\n",
      "Epoch [187/2000], Avg Val Loss: 2.7215\n",
      "Validation loss improved from 2.7235 to 2.7215. Saving model...\n",
      "\n",
      "LOG: Epoch [188/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4446\n",
      "    Batch [2/2], Train Loss: 4.4627\n",
      "Epoch [188/2000], Avg Train Loss: 4.4536\n",
      "Epoch [188/2000], Avg Val Loss: 2.7195\n",
      "Validation loss improved from 2.7215 to 2.7195. Saving model...\n",
      "\n",
      "LOG: Epoch [189/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4627\n",
      "    Batch [2/2], Train Loss: 4.5219\n",
      "Epoch [189/2000], Avg Train Loss: 4.4923\n",
      "Epoch [189/2000], Avg Val Loss: 2.7175\n",
      "Validation loss improved from 2.7195 to 2.7175. Saving model...\n",
      "\n",
      "LOG: Epoch [190/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4350\n",
      "    Batch [2/2], Train Loss: 4.4423\n",
      "Epoch [190/2000], Avg Train Loss: 4.4387\n",
      "Epoch [190/2000], Avg Val Loss: 2.7154\n",
      "Validation loss improved from 2.7175 to 2.7154. Saving model...\n",
      "\n",
      "LOG: Epoch [191/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 4.4943\n",
      "Epoch [191/2000], Avg Train Loss: 4.4824\n",
      "Epoch [191/2000], Avg Val Loss: 2.7134\n",
      "Validation loss improved from 2.7154 to 2.7134. Saving model...\n",
      "\n",
      "LOG: Epoch [192/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4191\n",
      "    Batch [2/2], Train Loss: 4.4571\n",
      "Epoch [192/2000], Avg Train Loss: 4.4381\n",
      "Epoch [192/2000], Avg Val Loss: 2.7114\n",
      "Validation loss improved from 2.7134 to 2.7114. Saving model...\n",
      "\n",
      "LOG: Epoch [193/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3978\n",
      "    Batch [2/2], Train Loss: 4.4264\n",
      "Epoch [193/2000], Avg Train Loss: 4.4121\n",
      "Epoch [193/2000], Avg Val Loss: 2.7094\n",
      "Validation loss improved from 2.7114 to 2.7094. Saving model...\n",
      "\n",
      "LOG: Epoch [194/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4791\n",
      "    Batch [2/2], Train Loss: 4.4367\n",
      "Epoch [194/2000], Avg Train Loss: 4.4579\n",
      "Epoch [194/2000], Avg Val Loss: 2.7074\n",
      "Validation loss improved from 2.7094 to 2.7074. Saving model...\n",
      "\n",
      "LOG: Epoch [195/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4320\n",
      "    Batch [2/2], Train Loss: 4.4156\n",
      "Epoch [195/2000], Avg Train Loss: 4.4238\n",
      "Epoch [195/2000], Avg Val Loss: 2.7055\n",
      "Validation loss improved from 2.7074 to 2.7055. Saving model...\n",
      "\n",
      "LOG: Epoch [196/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4066\n",
      "    Batch [2/2], Train Loss: 4.4577\n",
      "Epoch [196/2000], Avg Train Loss: 4.4321\n",
      "Epoch [196/2000], Avg Val Loss: 2.7035\n",
      "Validation loss improved from 2.7055 to 2.7035. Saving model...\n",
      "\n",
      "LOG: Epoch [197/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4244\n",
      "    Batch [2/2], Train Loss: 4.4094\n",
      "Epoch [197/2000], Avg Train Loss: 4.4169\n",
      "Epoch [197/2000], Avg Val Loss: 2.7015\n",
      "Validation loss improved from 2.7035 to 2.7015. Saving model...\n",
      "\n",
      "LOG: Epoch [198/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3890\n",
      "    Batch [2/2], Train Loss: 4.4314\n",
      "Epoch [198/2000], Avg Train Loss: 4.4102\n",
      "Epoch [198/2000], Avg Val Loss: 2.6995\n",
      "Validation loss improved from 2.7015 to 2.6995. Saving model...\n",
      "\n",
      "LOG: Epoch [199/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4339\n",
      "    Batch [2/2], Train Loss: 4.4661\n",
      "Epoch [199/2000], Avg Train Loss: 4.4500\n",
      "Epoch [199/2000], Avg Val Loss: 2.6975\n",
      "Validation loss improved from 2.6995 to 2.6975. Saving model...\n",
      "\n",
      "LOG: Epoch [200/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3948\n",
      "    Batch [2/2], Train Loss: 4.4695\n",
      "Epoch [200/2000], Avg Train Loss: 4.4322\n",
      "Epoch [200/2000], Avg Val Loss: 2.6956\n",
      "Validation loss improved from 2.6975 to 2.6956. Saving model...\n",
      "\n",
      "LOG: Epoch [201/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3613\n",
      "    Batch [2/2], Train Loss: 4.4266\n",
      "Epoch [201/2000], Avg Train Loss: 4.3940\n",
      "Epoch [201/2000], Avg Val Loss: 2.6937\n",
      "Validation loss improved from 2.6956 to 2.6937. Saving model...\n",
      "\n",
      "LOG: Epoch [202/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4499\n",
      "    Batch [2/2], Train Loss: 4.4027\n",
      "Epoch [202/2000], Avg Train Loss: 4.4263\n",
      "Epoch [202/2000], Avg Val Loss: 2.6917\n",
      "Validation loss improved from 2.6937 to 2.6917. Saving model...\n",
      "\n",
      "LOG: Epoch [203/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4104\n",
      "    Batch [2/2], Train Loss: 4.4397\n",
      "Epoch [203/2000], Avg Train Loss: 4.4250\n",
      "Epoch [203/2000], Avg Val Loss: 2.6898\n",
      "Validation loss improved from 2.6917 to 2.6898. Saving model...\n",
      "\n",
      "LOG: Epoch [204/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 4.3849\n",
      "Epoch [204/2000], Avg Train Loss: 4.4258\n",
      "Epoch [204/2000], Avg Val Loss: 2.6879\n",
      "Validation loss improved from 2.6898 to 2.6879. Saving model...\n",
      "\n",
      "LOG: Epoch [205/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3968\n",
      "    Batch [2/2], Train Loss: 4.4216\n",
      "Epoch [205/2000], Avg Train Loss: 4.4092\n",
      "Epoch [205/2000], Avg Val Loss: 2.6859\n",
      "Validation loss improved from 2.6879 to 2.6859. Saving model...\n",
      "\n",
      "LOG: Epoch [206/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3769\n",
      "    Batch [2/2], Train Loss: 4.4058\n",
      "Epoch [206/2000], Avg Train Loss: 4.3914\n",
      "Epoch [206/2000], Avg Val Loss: 2.6839\n",
      "Validation loss improved from 2.6859 to 2.6839. Saving model...\n",
      "\n",
      "LOG: Epoch [207/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3464\n",
      "    Batch [2/2], Train Loss: 4.4209\n",
      "Epoch [207/2000], Avg Train Loss: 4.3837\n",
      "Epoch [207/2000], Avg Val Loss: 2.6820\n",
      "Validation loss improved from 2.6839 to 2.6820. Saving model...\n",
      "\n",
      "LOG: Epoch [208/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4051\n",
      "    Batch [2/2], Train Loss: 4.4222\n",
      "Epoch [208/2000], Avg Train Loss: 4.4136\n",
      "Epoch [208/2000], Avg Val Loss: 2.6800\n",
      "Validation loss improved from 2.6820 to 2.6800. Saving model...\n",
      "\n",
      "LOG: Epoch [209/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 4.4085\n",
      "    Batch [2/2], Train Loss: 4.4083\n",
      "Epoch [209/2000], Avg Train Loss: 4.4084\n",
      "Epoch [209/2000], Avg Val Loss: 2.6781\n",
      "Validation loss improved from 2.6800 to 2.6781. Saving model...\n",
      "\n",
      "LOG: Epoch [210/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4255\n",
      "    Batch [2/2], Train Loss: 4.3582\n",
      "Epoch [210/2000], Avg Train Loss: 4.3918\n",
      "Epoch [210/2000], Avg Val Loss: 2.6761\n",
      "Validation loss improved from 2.6781 to 2.6761. Saving model...\n",
      "\n",
      "LOG: Epoch [211/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3723\n",
      "    Batch [2/2], Train Loss: 4.3793\n",
      "Epoch [211/2000], Avg Train Loss: 4.3758\n",
      "Epoch [211/2000], Avg Val Loss: 2.6742\n",
      "Validation loss improved from 2.6761 to 2.6742. Saving model...\n",
      "\n",
      "LOG: Epoch [212/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3626\n",
      "    Batch [2/2], Train Loss: 4.3826\n",
      "Epoch [212/2000], Avg Train Loss: 4.3726\n",
      "Epoch [212/2000], Avg Val Loss: 2.6724\n",
      "Validation loss improved from 2.6742 to 2.6724. Saving model...\n",
      "\n",
      "LOG: Epoch [213/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3843\n",
      "    Batch [2/2], Train Loss: 4.4051\n",
      "Epoch [213/2000], Avg Train Loss: 4.3947\n",
      "Epoch [213/2000], Avg Val Loss: 2.6705\n",
      "Validation loss improved from 2.6724 to 2.6705. Saving model...\n",
      "\n",
      "LOG: Epoch [214/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3978\n",
      "    Batch [2/2], Train Loss: 4.4008\n",
      "Epoch [214/2000], Avg Train Loss: 4.3993\n",
      "Epoch [214/2000], Avg Val Loss: 2.6687\n",
      "Validation loss improved from 2.6705 to 2.6687. Saving model...\n",
      "\n",
      "LOG: Epoch [215/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3917\n",
      "    Batch [2/2], Train Loss: 4.4067\n",
      "Epoch [215/2000], Avg Train Loss: 4.3992\n",
      "Epoch [215/2000], Avg Val Loss: 2.6668\n",
      "Validation loss improved from 2.6687 to 2.6668. Saving model...\n",
      "\n",
      "LOG: Epoch [216/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3576\n",
      "    Batch [2/2], Train Loss: 4.3766\n",
      "Epoch [216/2000], Avg Train Loss: 4.3671\n",
      "Epoch [216/2000], Avg Val Loss: 2.6650\n",
      "Validation loss improved from 2.6668 to 2.6650. Saving model...\n",
      "\n",
      "LOG: Epoch [217/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4299\n",
      "    Batch [2/2], Train Loss: 4.4067\n",
      "Epoch [217/2000], Avg Train Loss: 4.4183\n",
      "Epoch [217/2000], Avg Val Loss: 2.6633\n",
      "Validation loss improved from 2.6650 to 2.6633. Saving model...\n",
      "\n",
      "LOG: Epoch [218/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3671\n",
      "    Batch [2/2], Train Loss: 4.3662\n",
      "Epoch [218/2000], Avg Train Loss: 4.3666\n",
      "Epoch [218/2000], Avg Val Loss: 2.6616\n",
      "Validation loss improved from 2.6633 to 2.6616. Saving model...\n",
      "\n",
      "LOG: Epoch [219/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3558\n",
      "    Batch [2/2], Train Loss: 4.4252\n",
      "Epoch [219/2000], Avg Train Loss: 4.3905\n",
      "Epoch [219/2000], Avg Val Loss: 2.6599\n",
      "Validation loss improved from 2.6616 to 2.6599. Saving model...\n",
      "\n",
      "LOG: Epoch [220/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3312\n",
      "    Batch [2/2], Train Loss: 4.3431\n",
      "Epoch [220/2000], Avg Train Loss: 4.3371\n",
      "Epoch [220/2000], Avg Val Loss: 2.6582\n",
      "Validation loss improved from 2.6599 to 2.6582. Saving model...\n",
      "\n",
      "LOG: Epoch [221/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3525\n",
      "    Batch [2/2], Train Loss: 4.3777\n",
      "Epoch [221/2000], Avg Train Loss: 4.3651\n",
      "Epoch [221/2000], Avg Val Loss: 2.6565\n",
      "Validation loss improved from 2.6582 to 2.6565. Saving model...\n",
      "\n",
      "LOG: Epoch [222/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4002\n",
      "    Batch [2/2], Train Loss: 4.3392\n",
      "Epoch [222/2000], Avg Train Loss: 4.3697\n",
      "Epoch [222/2000], Avg Val Loss: 2.6548\n",
      "Validation loss improved from 2.6565 to 2.6548. Saving model...\n",
      "\n",
      "LOG: Epoch [223/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3380\n",
      "    Batch [2/2], Train Loss: 4.3737\n",
      "Epoch [223/2000], Avg Train Loss: 4.3558\n",
      "Epoch [223/2000], Avg Val Loss: 2.6531\n",
      "Validation loss improved from 2.6548 to 2.6531. Saving model...\n",
      "\n",
      "LOG: Epoch [224/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 4.3345\n",
      "    Batch [2/2], Train Loss: 4.3198\n",
      "Epoch [224/2000], Avg Train Loss: 4.3271\n",
      "Epoch [224/2000], Avg Val Loss: 2.6514\n",
      "Validation loss improved from 2.6531 to 2.6514. Saving model...\n",
      "\n",
      "LOG: Epoch [225/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3849\n",
      "    Batch [2/2], Train Loss: 4.3554\n",
      "Epoch [225/2000], Avg Train Loss: 4.3701\n",
      "Epoch [225/2000], Avg Val Loss: 2.6496\n",
      "Validation loss improved from 2.6514 to 2.6496. Saving model...\n",
      "\n",
      "LOG: Epoch [226/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4136\n",
      "    Batch [2/2], Train Loss: 4.3537\n",
      "Epoch [226/2000], Avg Train Loss: 4.3837\n",
      "Epoch [226/2000], Avg Val Loss: 2.6479\n",
      "Validation loss improved from 2.6496 to 2.6479. Saving model...\n",
      "\n",
      "LOG: Epoch [227/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3098\n",
      "    Batch [2/2], Train Loss: 4.3558\n",
      "Epoch [227/2000], Avg Train Loss: 4.3328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [227/2000], Avg Val Loss: 2.6462\n",
      "Validation loss improved from 2.6479 to 2.6462. Saving model...\n",
      "\n",
      "LOG: Epoch [228/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3255\n",
      "    Batch [2/2], Train Loss: 4.3502\n",
      "Epoch [228/2000], Avg Train Loss: 4.3379\n",
      "Epoch [228/2000], Avg Val Loss: 2.6444\n",
      "Validation loss improved from 2.6462 to 2.6444. Saving model...\n",
      "\n",
      "LOG: Epoch [229/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3591\n",
      "    Batch [2/2], Train Loss: 4.3922\n",
      "Epoch [229/2000], Avg Train Loss: 4.3756\n",
      "Epoch [229/2000], Avg Val Loss: 2.6427\n",
      "Validation loss improved from 2.6444 to 2.6427. Saving model...\n",
      "\n",
      "LOG: Epoch [230/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3895\n",
      "    Batch [2/2], Train Loss: 4.3457\n",
      "Epoch [230/2000], Avg Train Loss: 4.3676\n",
      "Epoch [230/2000], Avg Val Loss: 2.6411\n",
      "Validation loss improved from 2.6427 to 2.6411. Saving model...\n",
      "\n",
      "LOG: Epoch [231/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3867\n",
      "    Batch [2/2], Train Loss: 4.3392\n",
      "Epoch [231/2000], Avg Train Loss: 4.3630\n",
      "Epoch [231/2000], Avg Val Loss: 2.6395\n",
      "Validation loss improved from 2.6411 to 2.6395. Saving model...\n",
      "\n",
      "LOG: Epoch [232/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3337\n",
      "    Batch [2/2], Train Loss: 4.3235\n",
      "Epoch [232/2000], Avg Train Loss: 4.3286\n",
      "Epoch [232/2000], Avg Val Loss: 2.6378\n",
      "Validation loss improved from 2.6395 to 2.6378. Saving model...\n",
      "\n",
      "LOG: Epoch [233/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3485\n",
      "    Batch [2/2], Train Loss: 4.3112\n",
      "Epoch [233/2000], Avg Train Loss: 4.3299\n",
      "Epoch [233/2000], Avg Val Loss: 2.6362\n",
      "Validation loss improved from 2.6378 to 2.6362. Saving model...\n",
      "\n",
      "LOG: Epoch [234/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3578\n",
      "    Batch [2/2], Train Loss: 4.3719\n",
      "Epoch [234/2000], Avg Train Loss: 4.3648\n",
      "Epoch [234/2000], Avg Val Loss: 2.6346\n",
      "Validation loss improved from 2.6362 to 2.6346. Saving model...\n",
      "\n",
      "LOG: Epoch [235/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2753\n",
      "    Batch [2/2], Train Loss: 4.3124\n",
      "Epoch [235/2000], Avg Train Loss: 4.2939\n",
      "Epoch [235/2000], Avg Val Loss: 2.6329\n",
      "Validation loss improved from 2.6346 to 2.6329. Saving model...\n",
      "\n",
      "LOG: Epoch [236/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3236\n",
      "    Batch [2/2], Train Loss: 4.3477\n",
      "Epoch [236/2000], Avg Train Loss: 4.3357\n",
      "Epoch [236/2000], Avg Val Loss: 2.6313\n",
      "Validation loss improved from 2.6329 to 2.6313. Saving model...\n",
      "\n",
      "LOG: Epoch [237/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3219\n",
      "    Batch [2/2], Train Loss: 4.3025\n",
      "Epoch [237/2000], Avg Train Loss: 4.3122\n",
      "Epoch [237/2000], Avg Val Loss: 2.6297\n",
      "Validation loss improved from 2.6313 to 2.6297. Saving model...\n",
      "\n",
      "LOG: Epoch [238/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3538\n",
      "    Batch [2/2], Train Loss: 4.3718\n",
      "Epoch [238/2000], Avg Train Loss: 4.3628\n",
      "Epoch [238/2000], Avg Val Loss: 2.6281\n",
      "Validation loss improved from 2.6297 to 2.6281. Saving model...\n",
      "\n",
      "LOG: Epoch [239/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3540\n",
      "    Batch [2/2], Train Loss: 4.3116\n",
      "Epoch [239/2000], Avg Train Loss: 4.3328\n",
      "Epoch [239/2000], Avg Val Loss: 2.6266\n",
      "Validation loss improved from 2.6281 to 2.6266. Saving model...\n",
      "\n",
      "LOG: Epoch [240/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.4039\n",
      "    Batch [2/2], Train Loss: 4.3257\n",
      "Epoch [240/2000], Avg Train Loss: 4.3648\n",
      "Epoch [240/2000], Avg Val Loss: 2.6252\n",
      "Validation loss improved from 2.6266 to 2.6252. Saving model...\n",
      "\n",
      "LOG: Epoch [241/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3096\n",
      "    Batch [2/2], Train Loss: 4.3337\n",
      "Epoch [241/2000], Avg Train Loss: 4.3216\n",
      "Epoch [241/2000], Avg Val Loss: 2.6237\n",
      "Validation loss improved from 2.6252 to 2.6237. Saving model...\n",
      "\n",
      "LOG: Epoch [242/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 4.2229\n",
      "Epoch [242/2000], Avg Train Loss: 4.2785\n",
      "Epoch [242/2000], Avg Val Loss: 2.6222\n",
      "Validation loss improved from 2.6237 to 2.6222. Saving model...\n",
      "\n",
      "LOG: Epoch [243/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3291\n",
      "    Batch [2/2], Train Loss: 4.2974\n",
      "Epoch [243/2000], Avg Train Loss: 4.3133\n",
      "Epoch [243/2000], Avg Val Loss: 2.6207\n",
      "Validation loss improved from 2.6222 to 2.6207. Saving model...\n",
      "\n",
      "LOG: Epoch [244/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3319\n",
      "    Batch [2/2], Train Loss: 4.2962\n",
      "Epoch [244/2000], Avg Train Loss: 4.3141\n",
      "Epoch [244/2000], Avg Val Loss: 2.6192\n",
      "Validation loss improved from 2.6207 to 2.6192. Saving model...\n",
      "\n",
      "LOG: Epoch [245/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2974\n",
      "    Batch [2/2], Train Loss: 4.3056\n",
      "Epoch [245/2000], Avg Train Loss: 4.3015\n",
      "Epoch [245/2000], Avg Val Loss: 2.6176\n",
      "Validation loss improved from 2.6192 to 2.6176. Saving model...\n",
      "\n",
      "LOG: Epoch [246/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 4.3130\n",
      "Epoch [246/2000], Avg Train Loss: 4.3000\n",
      "Epoch [246/2000], Avg Val Loss: 2.6160\n",
      "Validation loss improved from 2.6176 to 2.6160. Saving model...\n",
      "\n",
      "LOG: Epoch [247/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3173\n",
      "    Batch [2/2], Train Loss: 4.3234\n",
      "Epoch [247/2000], Avg Train Loss: 4.3203\n",
      "Epoch [247/2000], Avg Val Loss: 2.6144\n",
      "Validation loss improved from 2.6160 to 2.6144. Saving model...\n",
      "\n",
      "LOG: Epoch [248/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3052\n",
      "    Batch [2/2], Train Loss: 4.2923\n",
      "Epoch [248/2000], Avg Train Loss: 4.2988\n",
      "Epoch [248/2000], Avg Val Loss: 2.6127\n",
      "Validation loss improved from 2.6144 to 2.6127. Saving model...\n",
      "\n",
      "LOG: Epoch [249/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3477\n",
      "    Batch [2/2], Train Loss: 4.3064\n",
      "Epoch [249/2000], Avg Train Loss: 4.3270\n",
      "Epoch [249/2000], Avg Val Loss: 2.6112\n",
      "Validation loss improved from 2.6127 to 2.6112. Saving model...\n",
      "\n",
      "LOG: Epoch [250/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3061\n",
      "    Batch [2/2], Train Loss: 4.3723\n",
      "Epoch [250/2000], Avg Train Loss: 4.3392\n",
      "Epoch [250/2000], Avg Val Loss: 2.6096\n",
      "Validation loss improved from 2.6112 to 2.6096. Saving model...\n",
      "\n",
      "LOG: Epoch [251/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3081\n",
      "    Batch [2/2], Train Loss: 4.3428\n",
      "Epoch [251/2000], Avg Train Loss: 4.3254\n",
      "Epoch [251/2000], Avg Val Loss: 2.6081\n",
      "Validation loss improved from 2.6096 to 2.6081. Saving model...\n",
      "\n",
      "LOG: Epoch [252/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3236\n",
      "    Batch [2/2], Train Loss: 4.2936\n",
      "Epoch [252/2000], Avg Train Loss: 4.3086\n",
      "Epoch [252/2000], Avg Val Loss: 2.6066\n",
      "Validation loss improved from 2.6081 to 2.6066. Saving model...\n",
      "\n",
      "LOG: Epoch [253/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2773\n",
      "    Batch [2/2], Train Loss: 4.2864\n",
      "Epoch [253/2000], Avg Train Loss: 4.2819\n",
      "Epoch [253/2000], Avg Val Loss: 2.6051\n",
      "Validation loss improved from 2.6066 to 2.6051. Saving model...\n",
      "\n",
      "LOG: Epoch [254/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2729\n",
      "    Batch [2/2], Train Loss: 4.3232\n",
      "Epoch [254/2000], Avg Train Loss: 4.2981\n",
      "Epoch [254/2000], Avg Val Loss: 2.6036\n",
      "Validation loss improved from 2.6051 to 2.6036. Saving model...\n",
      "\n",
      "LOG: Epoch [255/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2949\n",
      "    Batch [2/2], Train Loss: 4.3135\n",
      "Epoch [255/2000], Avg Train Loss: 4.3042\n",
      "Epoch [255/2000], Avg Val Loss: 2.6022\n",
      "Validation loss improved from 2.6036 to 2.6022. Saving model...\n",
      "\n",
      "LOG: Epoch [256/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.3093\n",
      "    Batch [2/2], Train Loss: 4.2930\n",
      "Epoch [256/2000], Avg Train Loss: 4.3011\n",
      "Epoch [256/2000], Avg Val Loss: 2.6008\n",
      "Validation loss improved from 2.6022 to 2.6008. Saving model...\n",
      "\n",
      "LOG: Epoch [257/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2567\n",
      "    Batch [2/2], Train Loss: 4.3170\n",
      "Epoch [257/2000], Avg Train Loss: 4.2868\n",
      "Epoch [257/2000], Avg Val Loss: 2.5993\n",
      "Validation loss improved from 2.6008 to 2.5993. Saving model...\n",
      "\n",
      "LOG: Epoch [258/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2706\n",
      "    Batch [2/2], Train Loss: 4.2608\n",
      "Epoch [258/2000], Avg Train Loss: 4.2657\n",
      "Epoch [258/2000], Avg Val Loss: 2.5979\n",
      "Validation loss improved from 2.5993 to 2.5979. Saving model...\n",
      "\n",
      "LOG: Epoch [259/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2698\n",
      "    Batch [2/2], Train Loss: 4.3084\n",
      "Epoch [259/2000], Avg Train Loss: 4.2891\n",
      "Epoch [259/2000], Avg Val Loss: 2.5964\n",
      "Validation loss improved from 2.5979 to 2.5964. Saving model...\n",
      "\n",
      "LOG: Epoch [260/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2582\n",
      "    Batch [2/2], Train Loss: 4.2339\n",
      "Epoch [260/2000], Avg Train Loss: 4.2460\n",
      "Epoch [260/2000], Avg Val Loss: 2.5949\n",
      "Validation loss improved from 2.5964 to 2.5949. Saving model...\n",
      "\n",
      "LOG: Epoch [261/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 4.3147\n",
      "    Batch [2/2], Train Loss: 4.2788\n",
      "Epoch [261/2000], Avg Train Loss: 4.2967\n",
      "Epoch [261/2000], Avg Val Loss: 2.5934\n",
      "Validation loss improved from 2.5949 to 2.5934. Saving model...\n",
      "\n",
      "LOG: Epoch [262/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2618\n",
      "    Batch [2/2], Train Loss: 4.2643\n",
      "Epoch [262/2000], Avg Train Loss: 4.2631\n",
      "Epoch [262/2000], Avg Val Loss: 2.5919\n",
      "Validation loss improved from 2.5934 to 2.5919. Saving model...\n",
      "\n",
      "LOG: Epoch [263/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2564\n",
      "    Batch [2/2], Train Loss: 4.2829\n",
      "Epoch [263/2000], Avg Train Loss: 4.2697\n",
      "Epoch [263/2000], Avg Val Loss: 2.5904\n",
      "Validation loss improved from 2.5919 to 2.5904. Saving model...\n",
      "\n",
      "LOG: Epoch [264/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2920\n",
      "    Batch [2/2], Train Loss: 4.2782\n",
      "Epoch [264/2000], Avg Train Loss: 4.2851\n",
      "Epoch [264/2000], Avg Val Loss: 2.5889\n",
      "Validation loss improved from 2.5904 to 2.5889. Saving model...\n",
      "\n",
      "LOG: Epoch [265/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 4.2969\n",
      "    Batch [2/2], Train Loss: 4.2483\n",
      "Epoch [265/2000], Avg Train Loss: 4.2726\n",
      "Epoch [265/2000], Avg Val Loss: 2.5875\n",
      "Validation loss improved from 2.5889 to 2.5875. Saving model...\n",
      "\n",
      "LOG: Epoch [266/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2839\n",
      "    Batch [2/2], Train Loss: 4.2342\n",
      "Epoch [266/2000], Avg Train Loss: 4.2590\n",
      "Epoch [266/2000], Avg Val Loss: 2.5860\n",
      "Validation loss improved from 2.5875 to 2.5860. Saving model...\n",
      "\n",
      "LOG: Epoch [267/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2183\n",
      "    Batch [2/2], Train Loss: 4.2349\n",
      "Epoch [267/2000], Avg Train Loss: 4.2266\n",
      "Epoch [267/2000], Avg Val Loss: 2.5846\n",
      "Validation loss improved from 2.5860 to 2.5846. Saving model...\n",
      "\n",
      "LOG: Epoch [268/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1935\n",
      "    Batch [2/2], Train Loss: 4.2541\n",
      "Epoch [268/2000], Avg Train Loss: 4.2238\n",
      "Epoch [268/2000], Avg Val Loss: 2.5830\n",
      "Validation loss improved from 2.5846 to 2.5830. Saving model...\n",
      "\n",
      "LOG: Epoch [269/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2490\n",
      "    Batch [2/2], Train Loss: 4.2177\n",
      "Epoch [269/2000], Avg Train Loss: 4.2333\n",
      "Epoch [269/2000], Avg Val Loss: 2.5814\n",
      "Validation loss improved from 2.5830 to 2.5814. Saving model...\n",
      "\n",
      "LOG: Epoch [270/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2242\n",
      "    Batch [2/2], Train Loss: 4.2490\n",
      "Epoch [270/2000], Avg Train Loss: 4.2366\n",
      "Epoch [270/2000], Avg Val Loss: 2.5797\n",
      "Validation loss improved from 2.5814 to 2.5797. Saving model...\n",
      "\n",
      "LOG: Epoch [271/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2533\n",
      "    Batch [2/2], Train Loss: 4.2752\n",
      "Epoch [271/2000], Avg Train Loss: 4.2643\n",
      "Epoch [271/2000], Avg Val Loss: 2.5782\n",
      "Validation loss improved from 2.5797 to 2.5782. Saving model...\n",
      "\n",
      "LOG: Epoch [272/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1948\n",
      "    Batch [2/2], Train Loss: 4.2754\n",
      "Epoch [272/2000], Avg Train Loss: 4.2351\n",
      "Epoch [272/2000], Avg Val Loss: 2.5766\n",
      "Validation loss improved from 2.5782 to 2.5766. Saving model...\n",
      "\n",
      "LOG: Epoch [273/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2415\n",
      "    Batch [2/2], Train Loss: 4.2809\n",
      "Epoch [273/2000], Avg Train Loss: 4.2612\n",
      "Epoch [273/2000], Avg Val Loss: 2.5751\n",
      "Validation loss improved from 2.5766 to 2.5751. Saving model...\n",
      "\n",
      "LOG: Epoch [274/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2804\n",
      "    Batch [2/2], Train Loss: 4.2918\n",
      "Epoch [274/2000], Avg Train Loss: 4.2861\n",
      "Epoch [274/2000], Avg Val Loss: 2.5738\n",
      "Validation loss improved from 2.5751 to 2.5738. Saving model...\n",
      "\n",
      "LOG: Epoch [275/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2399\n",
      "    Batch [2/2], Train Loss: 4.2654\n",
      "Epoch [275/2000], Avg Train Loss: 4.2526\n",
      "Epoch [275/2000], Avg Val Loss: 2.5724\n",
      "Validation loss improved from 2.5738 to 2.5724. Saving model...\n",
      "\n",
      "LOG: Epoch [276/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2312\n",
      "    Batch [2/2], Train Loss: 4.1956\n",
      "Epoch [276/2000], Avg Train Loss: 4.2134\n",
      "Epoch [276/2000], Avg Val Loss: 2.5710\n",
      "Validation loss improved from 2.5724 to 2.5710. Saving model...\n",
      "\n",
      "LOG: Epoch [277/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2462\n",
      "    Batch [2/2], Train Loss: 4.1951\n",
      "Epoch [277/2000], Avg Train Loss: 4.2207\n",
      "Epoch [277/2000], Avg Val Loss: 2.5696\n",
      "Validation loss improved from 2.5710 to 2.5696. Saving model...\n",
      "\n",
      "LOG: Epoch [278/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2519\n",
      "    Batch [2/2], Train Loss: 4.2548\n",
      "Epoch [278/2000], Avg Train Loss: 4.2534\n",
      "Epoch [278/2000], Avg Val Loss: 2.5682\n",
      "Validation loss improved from 2.5696 to 2.5682. Saving model...\n",
      "\n",
      "LOG: Epoch [279/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 4.2226\n",
      "    Batch [2/2], Train Loss: 4.2296\n",
      "Epoch [279/2000], Avg Train Loss: 4.2261\n",
      "Epoch [279/2000], Avg Val Loss: 2.5668\n",
      "Validation loss improved from 2.5682 to 2.5668. Saving model...\n",
      "\n",
      "LOG: Epoch [280/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2400\n",
      "    Batch [2/2], Train Loss: 4.2186\n",
      "Epoch [280/2000], Avg Train Loss: 4.2293\n",
      "Epoch [280/2000], Avg Val Loss: 2.5653\n",
      "Validation loss improved from 2.5668 to 2.5653. Saving model...\n",
      "\n",
      "LOG: Epoch [281/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2255\n",
      "    Batch [2/2], Train Loss: 4.2184\n",
      "Epoch [281/2000], Avg Train Loss: 4.2219\n",
      "Epoch [281/2000], Avg Val Loss: 2.5639\n",
      "Validation loss improved from 2.5653 to 2.5639. Saving model...\n",
      "\n",
      "LOG: Epoch [282/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1918\n",
      "    Batch [2/2], Train Loss: 4.3149\n",
      "Epoch [282/2000], Avg Train Loss: 4.2534\n",
      "Epoch [282/2000], Avg Val Loss: 2.5625\n",
      "Validation loss improved from 2.5639 to 2.5625. Saving model...\n",
      "\n",
      "LOG: Epoch [283/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 4.2293\n",
      "Epoch [283/2000], Avg Train Loss: 4.2227\n",
      "Epoch [283/2000], Avg Val Loss: 2.5612\n",
      "Validation loss improved from 2.5625 to 2.5612. Saving model...\n",
      "\n",
      "LOG: Epoch [284/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1932\n",
      "    Batch [2/2], Train Loss: 4.2282\n",
      "Epoch [284/2000], Avg Train Loss: 4.2107\n",
      "Epoch [284/2000], Avg Val Loss: 2.5599\n",
      "Validation loss improved from 2.5612 to 2.5599. Saving model...\n",
      "\n",
      "LOG: Epoch [285/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2078\n",
      "    Batch [2/2], Train Loss: 4.2808\n",
      "Epoch [285/2000], Avg Train Loss: 4.2443\n",
      "Epoch [285/2000], Avg Val Loss: 2.5586\n",
      "Validation loss improved from 2.5599 to 2.5586. Saving model...\n",
      "\n",
      "LOG: Epoch [286/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2280\n",
      "    Batch [2/2], Train Loss: 4.2073\n",
      "Epoch [286/2000], Avg Train Loss: 4.2177\n",
      "Epoch [286/2000], Avg Val Loss: 2.5572\n",
      "Validation loss improved from 2.5586 to 2.5572. Saving model...\n",
      "\n",
      "LOG: Epoch [287/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2346\n",
      "    Batch [2/2], Train Loss: 4.1686\n",
      "Epoch [287/2000], Avg Train Loss: 4.2016\n",
      "Epoch [287/2000], Avg Val Loss: 2.5559\n",
      "Validation loss improved from 2.5572 to 2.5559. Saving model...\n",
      "\n",
      "LOG: Epoch [288/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1977\n",
      "    Batch [2/2], Train Loss: 4.2383\n",
      "Epoch [288/2000], Avg Train Loss: 4.2180\n",
      "Epoch [288/2000], Avg Val Loss: 2.5546\n",
      "Validation loss improved from 2.5559 to 2.5546. Saving model...\n",
      "\n",
      "LOG: Epoch [289/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1809\n",
      "    Batch [2/2], Train Loss: 4.2444\n",
      "Epoch [289/2000], Avg Train Loss: 4.2127\n",
      "Epoch [289/2000], Avg Val Loss: 2.5533\n",
      "Validation loss improved from 2.5546 to 2.5533. Saving model...\n",
      "\n",
      "LOG: Epoch [290/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1922\n",
      "    Batch [2/2], Train Loss: 4.2133\n",
      "Epoch [290/2000], Avg Train Loss: 4.2028\n",
      "Epoch [290/2000], Avg Val Loss: 2.5520\n",
      "Validation loss improved from 2.5533 to 2.5520. Saving model...\n",
      "\n",
      "LOG: Epoch [291/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1832\n",
      "    Batch [2/2], Train Loss: 4.2179\n",
      "Epoch [291/2000], Avg Train Loss: 4.2005\n",
      "Epoch [291/2000], Avg Val Loss: 2.5505\n",
      "Validation loss improved from 2.5520 to 2.5505. Saving model...\n",
      "\n",
      "LOG: Epoch [292/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1990\n",
      "    Batch [2/2], Train Loss: 4.2380\n",
      "Epoch [292/2000], Avg Train Loss: 4.2185\n",
      "Epoch [292/2000], Avg Val Loss: 2.5491\n",
      "Validation loss improved from 2.5505 to 2.5491. Saving model...\n",
      "\n",
      "LOG: Epoch [293/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1864\n",
      "    Batch [2/2], Train Loss: 4.2447\n",
      "Epoch [293/2000], Avg Train Loss: 4.2155\n",
      "Epoch [293/2000], Avg Val Loss: 2.5477\n",
      "Validation loss improved from 2.5491 to 2.5477. Saving model...\n",
      "\n",
      "LOG: Epoch [294/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2168\n",
      "    Batch [2/2], Train Loss: 4.2124\n",
      "Epoch [294/2000], Avg Train Loss: 4.2146\n",
      "Epoch [294/2000], Avg Val Loss: 2.5463\n",
      "Validation loss improved from 2.5477 to 2.5463. Saving model...\n",
      "\n",
      "LOG: Epoch [295/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2586\n",
      "    Batch [2/2], Train Loss: 4.1780\n",
      "Epoch [295/2000], Avg Train Loss: 4.2183\n",
      "Epoch [295/2000], Avg Val Loss: 2.5450\n",
      "Validation loss improved from 2.5463 to 2.5450. Saving model...\n",
      "\n",
      "LOG: Epoch [296/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2209\n",
      "    Batch [2/2], Train Loss: 4.1907\n",
      "Epoch [296/2000], Avg Train Loss: 4.2058\n",
      "Epoch [296/2000], Avg Val Loss: 2.5435\n",
      "Validation loss improved from 2.5450 to 2.5435. Saving model...\n",
      "\n",
      "LOG: Epoch [297/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1858\n",
      "    Batch [2/2], Train Loss: 4.2083\n",
      "Epoch [297/2000], Avg Train Loss: 4.1971\n",
      "Epoch [297/2000], Avg Val Loss: 2.5420\n",
      "Validation loss improved from 2.5435 to 2.5420. Saving model...\n",
      "\n",
      "LOG: Epoch [298/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1597\n",
      "    Batch [2/2], Train Loss: 4.2103\n",
      "Epoch [298/2000], Avg Train Loss: 4.1850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [298/2000], Avg Val Loss: 2.5405\n",
      "Validation loss improved from 2.5420 to 2.5405. Saving model...\n",
      "\n",
      "LOG: Epoch [299/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2404\n",
      "    Batch [2/2], Train Loss: 4.1534\n",
      "Epoch [299/2000], Avg Train Loss: 4.1969\n",
      "Epoch [299/2000], Avg Val Loss: 2.5390\n",
      "Validation loss improved from 2.5405 to 2.5390. Saving model...\n",
      "\n",
      "LOG: Epoch [300/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2086\n",
      "    Batch [2/2], Train Loss: 4.1951\n",
      "Epoch [300/2000], Avg Train Loss: 4.2019\n",
      "Epoch [300/2000], Avg Val Loss: 2.5375\n",
      "Validation loss improved from 2.5390 to 2.5375. Saving model...\n",
      "\n",
      "LOG: Epoch [301/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 4.1155\n",
      "Epoch [301/2000], Avg Train Loss: 4.1455\n",
      "Epoch [301/2000], Avg Val Loss: 2.5360\n",
      "Validation loss improved from 2.5375 to 2.5360. Saving model...\n",
      "\n",
      "LOG: Epoch [302/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1572\n",
      "    Batch [2/2], Train Loss: 4.1451\n",
      "Epoch [302/2000], Avg Train Loss: 4.1512\n",
      "Epoch [302/2000], Avg Val Loss: 2.5344\n",
      "Validation loss improved from 2.5360 to 2.5344. Saving model...\n",
      "\n",
      "LOG: Epoch [303/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1569\n",
      "    Batch [2/2], Train Loss: 4.2155\n",
      "Epoch [303/2000], Avg Train Loss: 4.1862\n",
      "Epoch [303/2000], Avg Val Loss: 2.5329\n",
      "Validation loss improved from 2.5344 to 2.5329. Saving model...\n",
      "\n",
      "LOG: Epoch [304/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1948\n",
      "    Batch [2/2], Train Loss: 4.1906\n",
      "Epoch [304/2000], Avg Train Loss: 4.1927\n",
      "Epoch [304/2000], Avg Val Loss: 2.5314\n",
      "Validation loss improved from 2.5329 to 2.5314. Saving model...\n",
      "\n",
      "LOG: Epoch [305/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1632\n",
      "    Batch [2/2], Train Loss: 4.2039\n",
      "Epoch [305/2000], Avg Train Loss: 4.1836\n",
      "Epoch [305/2000], Avg Val Loss: 2.5300\n",
      "Validation loss improved from 2.5314 to 2.5300. Saving model...\n",
      "\n",
      "LOG: Epoch [306/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1495\n",
      "    Batch [2/2], Train Loss: 4.2091\n",
      "Epoch [306/2000], Avg Train Loss: 4.1793\n",
      "Epoch [306/2000], Avg Val Loss: 2.5286\n",
      "Validation loss improved from 2.5300 to 2.5286. Saving model...\n",
      "\n",
      "LOG: Epoch [307/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1436\n",
      "    Batch [2/2], Train Loss: 4.2366\n",
      "Epoch [307/2000], Avg Train Loss: 4.1901\n",
      "Epoch [307/2000], Avg Val Loss: 2.5272\n",
      "Validation loss improved from 2.5286 to 2.5272. Saving model...\n",
      "\n",
      "LOG: Epoch [308/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1888\n",
      "    Batch [2/2], Train Loss: 4.1124\n",
      "Epoch [308/2000], Avg Train Loss: 4.1506\n",
      "Epoch [308/2000], Avg Val Loss: 2.5259\n",
      "Validation loss improved from 2.5272 to 2.5259. Saving model...\n",
      "\n",
      "LOG: Epoch [309/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2034\n",
      "    Batch [2/2], Train Loss: 4.1700\n",
      "Epoch [309/2000], Avg Train Loss: 4.1867\n",
      "Epoch [309/2000], Avg Val Loss: 2.5245\n",
      "Validation loss improved from 2.5259 to 2.5245. Saving model...\n",
      "\n",
      "LOG: Epoch [310/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2191\n",
      "    Batch [2/2], Train Loss: 4.2094\n",
      "Epoch [310/2000], Avg Train Loss: 4.2143\n",
      "Epoch [310/2000], Avg Val Loss: 2.5233\n",
      "Validation loss improved from 2.5245 to 2.5233. Saving model...\n",
      "\n",
      "LOG: Epoch [311/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1542\n",
      "    Batch [2/2], Train Loss: 4.1256\n",
      "Epoch [311/2000], Avg Train Loss: 4.1399\n",
      "Epoch [311/2000], Avg Val Loss: 2.5221\n",
      "Validation loss improved from 2.5233 to 2.5221. Saving model...\n",
      "\n",
      "LOG: Epoch [312/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1970\n",
      "    Batch [2/2], Train Loss: 4.1504\n",
      "Epoch [312/2000], Avg Train Loss: 4.1737\n",
      "Epoch [312/2000], Avg Val Loss: 2.5209\n",
      "Validation loss improved from 2.5221 to 2.5209. Saving model...\n",
      "\n",
      "LOG: Epoch [313/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1839\n",
      "    Batch [2/2], Train Loss: 4.1692\n",
      "Epoch [313/2000], Avg Train Loss: 4.1765\n",
      "Epoch [313/2000], Avg Val Loss: 2.5196\n",
      "Validation loss improved from 2.5209 to 2.5196. Saving model...\n",
      "\n",
      "LOG: Epoch [314/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1427\n",
      "    Batch [2/2], Train Loss: 4.1756\n",
      "Epoch [314/2000], Avg Train Loss: 4.1591\n",
      "Epoch [314/2000], Avg Val Loss: 2.5184\n",
      "Validation loss improved from 2.5196 to 2.5184. Saving model...\n",
      "\n",
      "LOG: Epoch [315/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1622\n",
      "    Batch [2/2], Train Loss: 4.1666\n",
      "Epoch [315/2000], Avg Train Loss: 4.1644\n",
      "Epoch [315/2000], Avg Val Loss: 2.5171\n",
      "Validation loss improved from 2.5184 to 2.5171. Saving model...\n",
      "\n",
      "LOG: Epoch [316/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 4.1322\n",
      "Epoch [316/2000], Avg Train Loss: 4.1577\n",
      "Epoch [316/2000], Avg Val Loss: 2.5158\n",
      "Validation loss improved from 2.5171 to 2.5158. Saving model...\n",
      "\n",
      "LOG: Epoch [317/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1749\n",
      "    Batch [2/2], Train Loss: 4.1002\n",
      "Epoch [317/2000], Avg Train Loss: 4.1376\n",
      "Epoch [317/2000], Avg Val Loss: 2.5145\n",
      "Validation loss improved from 2.5158 to 2.5145. Saving model...\n",
      "\n",
      "LOG: Epoch [318/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1650\n",
      "    Batch [2/2], Train Loss: 4.1825\n",
      "Epoch [318/2000], Avg Train Loss: 4.1738\n",
      "Epoch [318/2000], Avg Val Loss: 2.5132\n",
      "Validation loss improved from 2.5145 to 2.5132. Saving model...\n",
      "\n",
      "LOG: Epoch [319/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1527\n",
      "    Batch [2/2], Train Loss: 4.1625\n",
      "Epoch [319/2000], Avg Train Loss: 4.1576\n",
      "Epoch [319/2000], Avg Val Loss: 2.5119\n",
      "Validation loss improved from 2.5132 to 2.5119. Saving model...\n",
      "\n",
      "LOG: Epoch [320/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1189\n",
      "    Batch [2/2], Train Loss: 4.1311\n",
      "Epoch [320/2000], Avg Train Loss: 4.1250\n",
      "Epoch [320/2000], Avg Val Loss: 2.5105\n",
      "Validation loss improved from 2.5119 to 2.5105. Saving model...\n",
      "\n",
      "LOG: Epoch [321/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.2182\n",
      "    Batch [2/2], Train Loss: 4.1201\n",
      "Epoch [321/2000], Avg Train Loss: 4.1692\n",
      "Epoch [321/2000], Avg Val Loss: 2.5092\n",
      "Validation loss improved from 2.5105 to 2.5092. Saving model...\n",
      "\n",
      "LOG: Epoch [322/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1727\n",
      "    Batch [2/2], Train Loss: 4.1452\n",
      "Epoch [322/2000], Avg Train Loss: 4.1590\n",
      "Epoch [322/2000], Avg Val Loss: 2.5078\n",
      "Validation loss improved from 2.5092 to 2.5078. Saving model...\n",
      "\n",
      "LOG: Epoch [323/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1544\n",
      "    Batch [2/2], Train Loss: 4.0996\n",
      "Epoch [323/2000], Avg Train Loss: 4.1270\n",
      "Epoch [323/2000], Avg Val Loss: 2.5065\n",
      "Validation loss improved from 2.5078 to 2.5065. Saving model...\n",
      "\n",
      "LOG: Epoch [324/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0997\n",
      "    Batch [2/2], Train Loss: 4.1269\n",
      "Epoch [324/2000], Avg Train Loss: 4.1133\n",
      "Epoch [324/2000], Avg Val Loss: 2.5050\n",
      "Validation loss improved from 2.5065 to 2.5050. Saving model...\n",
      "\n",
      "LOG: Epoch [325/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1185\n",
      "    Batch [2/2], Train Loss: 4.1427\n",
      "Epoch [325/2000], Avg Train Loss: 4.1306\n",
      "Epoch [325/2000], Avg Val Loss: 2.5036\n",
      "Validation loss improved from 2.5050 to 2.5036. Saving model...\n",
      "\n",
      "LOG: Epoch [326/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1539\n",
      "    Batch [2/2], Train Loss: 4.1446\n",
      "Epoch [326/2000], Avg Train Loss: 4.1492\n",
      "Epoch [326/2000], Avg Val Loss: 2.5022\n",
      "Validation loss improved from 2.5036 to 2.5022. Saving model...\n",
      "\n",
      "LOG: Epoch [327/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1763\n",
      "    Batch [2/2], Train Loss: 4.1319\n",
      "Epoch [327/2000], Avg Train Loss: 4.1541\n",
      "Epoch [327/2000], Avg Val Loss: 2.5009\n",
      "Validation loss improved from 2.5022 to 2.5009. Saving model...\n",
      "\n",
      "LOG: Epoch [328/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0867\n",
      "    Batch [2/2], Train Loss: 4.1495\n",
      "Epoch [328/2000], Avg Train Loss: 4.1181\n",
      "Epoch [328/2000], Avg Val Loss: 2.4997\n",
      "Validation loss improved from 2.5009 to 2.4997. Saving model...\n",
      "\n",
      "LOG: Epoch [329/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1290\n",
      "    Batch [2/2], Train Loss: 4.1204\n",
      "Epoch [329/2000], Avg Train Loss: 4.1247\n",
      "Epoch [329/2000], Avg Val Loss: 2.4984\n",
      "Validation loss improved from 2.4997 to 2.4984. Saving model...\n",
      "\n",
      "LOG: Epoch [330/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1001\n",
      "    Batch [2/2], Train Loss: 4.1618\n",
      "Epoch [330/2000], Avg Train Loss: 4.1309\n",
      "Epoch [330/2000], Avg Val Loss: 2.4972\n",
      "Validation loss improved from 2.4984 to 2.4972. Saving model...\n",
      "\n",
      "LOG: Epoch [331/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1677\n",
      "    Batch [2/2], Train Loss: 4.1025\n",
      "Epoch [331/2000], Avg Train Loss: 4.1351\n",
      "Epoch [331/2000], Avg Val Loss: 2.4961\n",
      "Validation loss improved from 2.4972 to 2.4961. Saving model...\n",
      "\n",
      "LOG: Epoch [332/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1567\n",
      "    Batch [2/2], Train Loss: 4.1116\n",
      "Epoch [332/2000], Avg Train Loss: 4.1342\n",
      "Epoch [332/2000], Avg Val Loss: 2.4950\n",
      "Validation loss improved from 2.4961 to 2.4950. Saving model...\n",
      "\n",
      "LOG: Epoch [333/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1264\n",
      "    Batch [2/2], Train Loss: 4.1486\n",
      "Epoch [333/2000], Avg Train Loss: 4.1375\n",
      "Epoch [333/2000], Avg Val Loss: 2.4939\n",
      "Validation loss improved from 2.4950 to 2.4939. Saving model...\n",
      "\n",
      "LOG: Epoch [334/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 4.1687\n",
      "    Batch [2/2], Train Loss: 4.1347\n",
      "Epoch [334/2000], Avg Train Loss: 4.1517\n",
      "Epoch [334/2000], Avg Val Loss: 2.4928\n",
      "Validation loss improved from 2.4939 to 2.4928. Saving model...\n",
      "\n",
      "LOG: Epoch [335/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1102\n",
      "    Batch [2/2], Train Loss: 4.1400\n",
      "Epoch [335/2000], Avg Train Loss: 4.1251\n",
      "Epoch [335/2000], Avg Val Loss: 2.4916\n",
      "Validation loss improved from 2.4928 to 2.4916. Saving model...\n",
      "\n",
      "LOG: Epoch [336/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1336\n",
      "    Batch [2/2], Train Loss: 4.1582\n",
      "Epoch [336/2000], Avg Train Loss: 4.1459\n",
      "Epoch [336/2000], Avg Val Loss: 2.4903\n",
      "Validation loss improved from 2.4916 to 2.4903. Saving model...\n",
      "\n",
      "LOG: Epoch [337/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1365\n",
      "    Batch [2/2], Train Loss: 4.1186\n",
      "Epoch [337/2000], Avg Train Loss: 4.1275\n",
      "Epoch [337/2000], Avg Val Loss: 2.4890\n",
      "Validation loss improved from 2.4903 to 2.4890. Saving model...\n",
      "\n",
      "LOG: Epoch [338/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1126\n",
      "    Batch [2/2], Train Loss: 4.1485\n",
      "Epoch [338/2000], Avg Train Loss: 4.1306\n",
      "Epoch [338/2000], Avg Val Loss: 2.4878\n",
      "Validation loss improved from 2.4890 to 2.4878. Saving model...\n",
      "\n",
      "LOG: Epoch [339/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1271\n",
      "    Batch [2/2], Train Loss: 4.1380\n",
      "Epoch [339/2000], Avg Train Loss: 4.1326\n",
      "Epoch [339/2000], Avg Val Loss: 2.4866\n",
      "Validation loss improved from 2.4878 to 2.4866. Saving model...\n",
      "\n",
      "LOG: Epoch [340/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0957\n",
      "    Batch [2/2], Train Loss: 4.1381\n",
      "Epoch [340/2000], Avg Train Loss: 4.1169\n",
      "Epoch [340/2000], Avg Val Loss: 2.4854\n",
      "Validation loss improved from 2.4866 to 2.4854. Saving model...\n",
      "\n",
      "LOG: Epoch [341/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1039\n",
      "    Batch [2/2], Train Loss: 4.0456\n",
      "Epoch [341/2000], Avg Train Loss: 4.0748\n",
      "Epoch [341/2000], Avg Val Loss: 2.4841\n",
      "Validation loss improved from 2.4854 to 2.4841. Saving model...\n",
      "\n",
      "LOG: Epoch [342/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1139\n",
      "    Batch [2/2], Train Loss: 4.1041\n",
      "Epoch [342/2000], Avg Train Loss: 4.1090\n",
      "Epoch [342/2000], Avg Val Loss: 2.4827\n",
      "Validation loss improved from 2.4841 to 2.4827. Saving model...\n",
      "\n",
      "LOG: Epoch [343/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0591\n",
      "    Batch [2/2], Train Loss: 4.1253\n",
      "Epoch [343/2000], Avg Train Loss: 4.0922\n",
      "Epoch [343/2000], Avg Val Loss: 2.4813\n",
      "Validation loss improved from 2.4827 to 2.4813. Saving model...\n",
      "\n",
      "LOG: Epoch [344/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1830\n",
      "    Batch [2/2], Train Loss: 4.1192\n",
      "Epoch [344/2000], Avg Train Loss: 4.1511\n",
      "Epoch [344/2000], Avg Val Loss: 2.4799\n",
      "Validation loss improved from 2.4813 to 2.4799. Saving model...\n",
      "\n",
      "LOG: Epoch [345/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0782\n",
      "    Batch [2/2], Train Loss: 4.0752\n",
      "Epoch [345/2000], Avg Train Loss: 4.0767\n",
      "Epoch [345/2000], Avg Val Loss: 2.4786\n",
      "Validation loss improved from 2.4799 to 2.4786. Saving model...\n",
      "\n",
      "LOG: Epoch [346/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0932\n",
      "    Batch [2/2], Train Loss: 4.1000\n",
      "Epoch [346/2000], Avg Train Loss: 4.0966\n",
      "Epoch [346/2000], Avg Val Loss: 2.4773\n",
      "Validation loss improved from 2.4786 to 2.4773. Saving model...\n",
      "\n",
      "LOG: Epoch [347/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0611\n",
      "    Batch [2/2], Train Loss: 4.0895\n",
      "Epoch [347/2000], Avg Train Loss: 4.0753\n",
      "Epoch [347/2000], Avg Val Loss: 2.4761\n",
      "Validation loss improved from 2.4773 to 2.4761. Saving model...\n",
      "\n",
      "LOG: Epoch [348/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1108\n",
      "    Batch [2/2], Train Loss: 4.1214\n",
      "Epoch [348/2000], Avg Train Loss: 4.1161\n",
      "Epoch [348/2000], Avg Val Loss: 2.4749\n",
      "Validation loss improved from 2.4761 to 2.4749. Saving model...\n",
      "\n",
      "LOG: Epoch [349/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1005\n",
      "    Batch [2/2], Train Loss: 4.0540\n",
      "Epoch [349/2000], Avg Train Loss: 4.0772\n",
      "Epoch [349/2000], Avg Val Loss: 2.4738\n",
      "Validation loss improved from 2.4749 to 2.4738. Saving model...\n",
      "\n",
      "LOG: Epoch [350/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1005\n",
      "    Batch [2/2], Train Loss: 4.0996\n",
      "Epoch [350/2000], Avg Train Loss: 4.1000\n",
      "Epoch [350/2000], Avg Val Loss: 2.4726\n",
      "Validation loss improved from 2.4738 to 2.4726. Saving model...\n",
      "\n",
      "LOG: Epoch [351/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1626\n",
      "    Batch [2/2], Train Loss: 4.1158\n",
      "Epoch [351/2000], Avg Train Loss: 4.1392\n",
      "Epoch [351/2000], Avg Val Loss: 2.4715\n",
      "Validation loss improved from 2.4726 to 2.4715. Saving model...\n",
      "\n",
      "LOG: Epoch [352/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 4.0854\n",
      "Epoch [352/2000], Avg Train Loss: 4.0967\n",
      "Epoch [352/2000], Avg Val Loss: 2.4704\n",
      "Validation loss improved from 2.4715 to 2.4704. Saving model...\n",
      "\n",
      "LOG: Epoch [353/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0970\n",
      "    Batch [2/2], Train Loss: 4.0794\n",
      "Epoch [353/2000], Avg Train Loss: 4.0882\n",
      "Epoch [353/2000], Avg Val Loss: 2.4692\n",
      "Validation loss improved from 2.4704 to 2.4692. Saving model...\n",
      "\n",
      "LOG: Epoch [354/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1176\n",
      "    Batch [2/2], Train Loss: 4.0598\n",
      "Epoch [354/2000], Avg Train Loss: 4.0887\n",
      "Epoch [354/2000], Avg Val Loss: 2.4680\n",
      "Validation loss improved from 2.4692 to 2.4680. Saving model...\n",
      "\n",
      "LOG: Epoch [355/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0820\n",
      "    Batch [2/2], Train Loss: 4.0613\n",
      "Epoch [355/2000], Avg Train Loss: 4.0717\n",
      "Epoch [355/2000], Avg Val Loss: 2.4669\n",
      "Validation loss improved from 2.4680 to 2.4669. Saving model...\n",
      "\n",
      "LOG: Epoch [356/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1074\n",
      "    Batch [2/2], Train Loss: 4.0590\n",
      "Epoch [356/2000], Avg Train Loss: 4.0832\n",
      "Epoch [356/2000], Avg Val Loss: 2.4657\n",
      "Validation loss improved from 2.4669 to 2.4657. Saving model...\n",
      "\n",
      "LOG: Epoch [357/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0439\n",
      "    Batch [2/2], Train Loss: 4.0253\n",
      "Epoch [357/2000], Avg Train Loss: 4.0346\n",
      "Epoch [357/2000], Avg Val Loss: 2.4644\n",
      "Validation loss improved from 2.4657 to 2.4644. Saving model...\n",
      "\n",
      "LOG: Epoch [358/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1022\n",
      "    Batch [2/2], Train Loss: 4.0680\n",
      "Epoch [358/2000], Avg Train Loss: 4.0851\n",
      "Epoch [358/2000], Avg Val Loss: 2.4631\n",
      "Validation loss improved from 2.4644 to 2.4631. Saving model...\n",
      "\n",
      "LOG: Epoch [359/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1195\n",
      "    Batch [2/2], Train Loss: 4.0879\n",
      "Epoch [359/2000], Avg Train Loss: 4.1037\n",
      "Epoch [359/2000], Avg Val Loss: 2.4619\n",
      "Validation loss improved from 2.4631 to 2.4619. Saving model...\n",
      "\n",
      "LOG: Epoch [360/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0787\n",
      "    Batch [2/2], Train Loss: 4.1327\n",
      "Epoch [360/2000], Avg Train Loss: 4.1057\n",
      "Epoch [360/2000], Avg Val Loss: 2.4606\n",
      "Validation loss improved from 2.4619 to 2.4606. Saving model...\n",
      "\n",
      "LOG: Epoch [361/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.1030\n",
      "    Batch [2/2], Train Loss: 4.0929\n",
      "Epoch [361/2000], Avg Train Loss: 4.0979\n",
      "Epoch [361/2000], Avg Val Loss: 2.4594\n",
      "Validation loss improved from 2.4606 to 2.4594. Saving model...\n",
      "\n",
      "LOG: Epoch [362/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0267\n",
      "    Batch [2/2], Train Loss: 4.0358\n",
      "Epoch [362/2000], Avg Train Loss: 4.0312\n",
      "Epoch [362/2000], Avg Val Loss: 2.4583\n",
      "Validation loss improved from 2.4594 to 2.4583. Saving model...\n",
      "\n",
      "LOG: Epoch [363/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0761\n",
      "    Batch [2/2], Train Loss: 4.0350\n",
      "Epoch [363/2000], Avg Train Loss: 4.0556\n",
      "Epoch [363/2000], Avg Val Loss: 2.4571\n",
      "Validation loss improved from 2.4583 to 2.4571. Saving model...\n",
      "\n",
      "LOG: Epoch [364/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0583\n",
      "    Batch [2/2], Train Loss: 4.0688\n",
      "Epoch [364/2000], Avg Train Loss: 4.0635\n",
      "Epoch [364/2000], Avg Val Loss: 2.4559\n",
      "Validation loss improved from 2.4571 to 2.4559. Saving model...\n",
      "\n",
      "LOG: Epoch [365/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0411\n",
      "    Batch [2/2], Train Loss: 4.0938\n",
      "Epoch [365/2000], Avg Train Loss: 4.0674\n",
      "Epoch [365/2000], Avg Val Loss: 2.4547\n",
      "Validation loss improved from 2.4559 to 2.4547. Saving model...\n",
      "\n",
      "LOG: Epoch [366/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0632\n",
      "    Batch [2/2], Train Loss: 4.0573\n",
      "Epoch [366/2000], Avg Train Loss: 4.0602\n",
      "Epoch [366/2000], Avg Val Loss: 2.4535\n",
      "Validation loss improved from 2.4547 to 2.4535. Saving model...\n",
      "\n",
      "LOG: Epoch [367/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0483\n",
      "    Batch [2/2], Train Loss: 4.0369\n",
      "Epoch [367/2000], Avg Train Loss: 4.0426\n",
      "Epoch [367/2000], Avg Val Loss: 2.4523\n",
      "Validation loss improved from 2.4535 to 2.4523. Saving model...\n",
      "\n",
      "LOG: Epoch [368/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0970\n",
      "    Batch [2/2], Train Loss: 4.0852\n",
      "Epoch [368/2000], Avg Train Loss: 4.0911\n",
      "Epoch [368/2000], Avg Val Loss: 2.4511\n",
      "Validation loss improved from 2.4523 to 2.4511. Saving model...\n",
      "\n",
      "LOG: Epoch [369/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0708\n",
      "    Batch [2/2], Train Loss: 4.0435\n",
      "Epoch [369/2000], Avg Train Loss: 4.0571\n",
      "Epoch [369/2000], Avg Val Loss: 2.4498\n",
      "Validation loss improved from 2.4511 to 2.4498. Saving model...\n",
      "\n",
      "LOG: Epoch [370/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0646\n",
      "    Batch [2/2], Train Loss: 4.0472\n",
      "Epoch [370/2000], Avg Train Loss: 4.0559\n",
      "Epoch [370/2000], Avg Val Loss: 2.4486\n",
      "Validation loss improved from 2.4498 to 2.4486. Saving model...\n",
      "\n",
      "LOG: Epoch [371/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 4.0830\n",
      "Epoch [371/2000], Avg Train Loss: 4.0546\n",
      "Epoch [371/2000], Avg Val Loss: 2.4474\n",
      "Validation loss improved from 2.4486 to 2.4474. Saving model...\n",
      "\n",
      "LOG: Epoch [372/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0368\n",
      "    Batch [2/2], Train Loss: 4.0657\n",
      "Epoch [372/2000], Avg Train Loss: 4.0512\n",
      "Epoch [372/2000], Avg Val Loss: 2.4462\n",
      "Validation loss improved from 2.4474 to 2.4462. Saving model...\n",
      "\n",
      "LOG: Epoch [373/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0663\n",
      "    Batch [2/2], Train Loss: 4.0062\n",
      "Epoch [373/2000], Avg Train Loss: 4.0363\n",
      "Epoch [373/2000], Avg Val Loss: 2.4450\n",
      "Validation loss improved from 2.4462 to 2.4450. Saving model...\n",
      "\n",
      "LOG: Epoch [374/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0567\n",
      "    Batch [2/2], Train Loss: 4.0362\n",
      "Epoch [374/2000], Avg Train Loss: 4.0465\n",
      "Epoch [374/2000], Avg Val Loss: 2.4439\n",
      "Validation loss improved from 2.4450 to 2.4439. Saving model...\n",
      "\n",
      "LOG: Epoch [375/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0856\n",
      "    Batch [2/2], Train Loss: 3.9967\n",
      "Epoch [375/2000], Avg Train Loss: 4.0412\n",
      "Epoch [375/2000], Avg Val Loss: 2.4428\n",
      "Validation loss improved from 2.4439 to 2.4428. Saving model...\n",
      "\n",
      "LOG: Epoch [376/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0590\n",
      "    Batch [2/2], Train Loss: 4.0912\n",
      "Epoch [376/2000], Avg Train Loss: 4.0751\n",
      "Epoch [376/2000], Avg Val Loss: 2.4417\n",
      "Validation loss improved from 2.4428 to 2.4417. Saving model...\n",
      "\n",
      "LOG: Epoch [377/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0356\n",
      "    Batch [2/2], Train Loss: 4.0296\n",
      "Epoch [377/2000], Avg Train Loss: 4.0326\n",
      "Epoch [377/2000], Avg Val Loss: 2.4406\n",
      "Validation loss improved from 2.4417 to 2.4406. Saving model...\n",
      "\n",
      "LOG: Epoch [378/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0246\n",
      "    Batch [2/2], Train Loss: 4.0493\n",
      "Epoch [378/2000], Avg Train Loss: 4.0370\n",
      "Epoch [378/2000], Avg Val Loss: 2.4397\n",
      "Validation loss improved from 2.4406 to 2.4397. Saving model...\n",
      "\n",
      "LOG: Epoch [379/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0021\n",
      "    Batch [2/2], Train Loss: 4.0837\n",
      "Epoch [379/2000], Avg Train Loss: 4.0429\n",
      "Epoch [379/2000], Avg Val Loss: 2.4387\n",
      "Validation loss improved from 2.4397 to 2.4387. Saving model...\n",
      "\n",
      "LOG: Epoch [380/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0800\n",
      "    Batch [2/2], Train Loss: 4.0387\n",
      "Epoch [380/2000], Avg Train Loss: 4.0594\n",
      "Epoch [380/2000], Avg Val Loss: 2.4377\n",
      "Validation loss improved from 2.4387 to 2.4377. Saving model...\n",
      "\n",
      "LOG: Epoch [381/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0729\n",
      "    Batch [2/2], Train Loss: 4.0575\n",
      "Epoch [381/2000], Avg Train Loss: 4.0652\n",
      "Epoch [381/2000], Avg Val Loss: 2.4366\n",
      "Validation loss improved from 2.4377 to 2.4366. Saving model...\n",
      "\n",
      "LOG: Epoch [382/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0689\n",
      "    Batch [2/2], Train Loss: 4.0607\n",
      "Epoch [382/2000], Avg Train Loss: 4.0648\n",
      "Epoch [382/2000], Avg Val Loss: 2.4356\n",
      "Validation loss improved from 2.4366 to 2.4356. Saving model...\n",
      "\n",
      "LOG: Epoch [383/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0030\n",
      "    Batch [2/2], Train Loss: 4.0443\n",
      "Epoch [383/2000], Avg Train Loss: 4.0237\n",
      "Epoch [383/2000], Avg Val Loss: 2.4345\n",
      "Validation loss improved from 2.4356 to 2.4345. Saving model...\n",
      "\n",
      "LOG: Epoch [384/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0450\n",
      "    Batch [2/2], Train Loss: 4.0483\n",
      "Epoch [384/2000], Avg Train Loss: 4.0466\n",
      "Epoch [384/2000], Avg Val Loss: 2.4334\n",
      "Validation loss improved from 2.4345 to 2.4334. Saving model...\n",
      "\n",
      "LOG: Epoch [385/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0189\n",
      "    Batch [2/2], Train Loss: 4.0208\n",
      "Epoch [385/2000], Avg Train Loss: 4.0198\n",
      "Epoch [385/2000], Avg Val Loss: 2.4323\n",
      "Validation loss improved from 2.4334 to 2.4323. Saving model...\n",
      "\n",
      "LOG: Epoch [386/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0688\n",
      "    Batch [2/2], Train Loss: 4.0376\n",
      "Epoch [386/2000], Avg Train Loss: 4.0532\n",
      "Epoch [386/2000], Avg Val Loss: 2.4312\n",
      "Validation loss improved from 2.4323 to 2.4312. Saving model...\n",
      "\n",
      "LOG: Epoch [387/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0365\n",
      "    Batch [2/2], Train Loss: 4.0130\n",
      "Epoch [387/2000], Avg Train Loss: 4.0248\n",
      "Epoch [387/2000], Avg Val Loss: 2.4301\n",
      "Validation loss improved from 2.4312 to 2.4301. Saving model...\n",
      "\n",
      "LOG: Epoch [388/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0613\n",
      "    Batch [2/2], Train Loss: 4.0597\n",
      "Epoch [388/2000], Avg Train Loss: 4.0605\n",
      "Epoch [388/2000], Avg Val Loss: 2.4290\n",
      "Validation loss improved from 2.4301 to 2.4290. Saving model...\n",
      "\n",
      "LOG: Epoch [389/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0873\n",
      "    Batch [2/2], Train Loss: 4.0452\n",
      "Epoch [389/2000], Avg Train Loss: 4.0662\n",
      "Epoch [389/2000], Avg Val Loss: 2.4280\n",
      "Validation loss improved from 2.4290 to 2.4280. Saving model...\n",
      "\n",
      "LOG: Epoch [390/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 4.0122\n",
      "    Batch [2/2], Train Loss: 4.0170\n",
      "Epoch [390/2000], Avg Train Loss: 4.0146\n",
      "Epoch [390/2000], Avg Val Loss: 2.4270\n",
      "Validation loss improved from 2.4280 to 2.4270. Saving model...\n",
      "\n",
      "LOG: Epoch [391/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0047\n",
      "    Batch [2/2], Train Loss: 4.0098\n",
      "Epoch [391/2000], Avg Train Loss: 4.0072\n",
      "Epoch [391/2000], Avg Val Loss: 2.4259\n",
      "Validation loss improved from 2.4270 to 2.4259. Saving model...\n",
      "\n",
      "LOG: Epoch [392/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9874\n",
      "    Batch [2/2], Train Loss: 4.0268\n",
      "Epoch [392/2000], Avg Train Loss: 4.0071\n",
      "Epoch [392/2000], Avg Val Loss: 2.4249\n",
      "Validation loss improved from 2.4259 to 2.4249. Saving model...\n",
      "\n",
      "LOG: Epoch [393/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0513\n",
      "    Batch [2/2], Train Loss: 4.0326\n",
      "Epoch [393/2000], Avg Train Loss: 4.0420\n",
      "Epoch [393/2000], Avg Val Loss: 2.4238\n",
      "Validation loss improved from 2.4249 to 2.4238. Saving model...\n",
      "\n",
      "LOG: Epoch [394/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0134\n",
      "    Batch [2/2], Train Loss: 3.9781\n",
      "Epoch [394/2000], Avg Train Loss: 3.9958\n",
      "Epoch [394/2000], Avg Val Loss: 2.4228\n",
      "Validation loss improved from 2.4238 to 2.4228. Saving model...\n",
      "\n",
      "LOG: Epoch [395/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0261\n",
      "    Batch [2/2], Train Loss: 4.0140\n",
      "Epoch [395/2000], Avg Train Loss: 4.0201\n",
      "Epoch [395/2000], Avg Val Loss: 2.4218\n",
      "Validation loss improved from 2.4228 to 2.4218. Saving model...\n",
      "\n",
      "LOG: Epoch [396/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0171\n",
      "    Batch [2/2], Train Loss: 3.9979\n",
      "Epoch [396/2000], Avg Train Loss: 4.0075\n",
      "Epoch [396/2000], Avg Val Loss: 2.4208\n",
      "Validation loss improved from 2.4218 to 2.4208. Saving model...\n",
      "\n",
      "LOG: Epoch [397/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0073\n",
      "    Batch [2/2], Train Loss: 4.0578\n",
      "Epoch [397/2000], Avg Train Loss: 4.0326\n",
      "Epoch [397/2000], Avg Val Loss: 2.4198\n",
      "Validation loss improved from 2.4208 to 2.4198. Saving model...\n",
      "\n",
      "LOG: Epoch [398/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9933\n",
      "    Batch [2/2], Train Loss: 4.0056\n",
      "Epoch [398/2000], Avg Train Loss: 3.9995\n",
      "Epoch [398/2000], Avg Val Loss: 2.4189\n",
      "Validation loss improved from 2.4198 to 2.4189. Saving model...\n",
      "\n",
      "LOG: Epoch [399/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9936\n",
      "    Batch [2/2], Train Loss: 4.0085\n",
      "Epoch [399/2000], Avg Train Loss: 4.0011\n",
      "Epoch [399/2000], Avg Val Loss: 2.4179\n",
      "Validation loss improved from 2.4189 to 2.4179. Saving model...\n",
      "\n",
      "LOG: Epoch [400/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0235\n",
      "    Batch [2/2], Train Loss: 3.9999\n",
      "Epoch [400/2000], Avg Train Loss: 4.0117\n",
      "Epoch [400/2000], Avg Val Loss: 2.4169\n",
      "Validation loss improved from 2.4179 to 2.4169. Saving model...\n",
      "\n",
      "LOG: Epoch [401/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0050\n",
      "    Batch [2/2], Train Loss: 3.9975\n",
      "Epoch [401/2000], Avg Train Loss: 4.0013\n",
      "Epoch [401/2000], Avg Val Loss: 2.4159\n",
      "Validation loss improved from 2.4169 to 2.4159. Saving model...\n",
      "\n",
      "LOG: Epoch [402/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0061\n",
      "    Batch [2/2], Train Loss: 3.9590\n",
      "Epoch [402/2000], Avg Train Loss: 3.9826\n",
      "Epoch [402/2000], Avg Val Loss: 2.4150\n",
      "Validation loss improved from 2.4159 to 2.4150. Saving model...\n",
      "\n",
      "LOG: Epoch [403/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9848\n",
      "    Batch [2/2], Train Loss: 4.0276\n",
      "Epoch [403/2000], Avg Train Loss: 4.0062\n",
      "Epoch [403/2000], Avg Val Loss: 2.4140\n",
      "Validation loss improved from 2.4150 to 2.4140. Saving model...\n",
      "\n",
      "LOG: Epoch [404/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9588\n",
      "    Batch [2/2], Train Loss: 4.0334\n",
      "Epoch [404/2000], Avg Train Loss: 3.9961\n",
      "Epoch [404/2000], Avg Val Loss: 2.4131\n",
      "Validation loss improved from 2.4140 to 2.4131. Saving model...\n",
      "\n",
      "LOG: Epoch [405/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0040\n",
      "    Batch [2/2], Train Loss: 3.9743\n",
      "Epoch [405/2000], Avg Train Loss: 3.9892\n",
      "Epoch [405/2000], Avg Val Loss: 2.4122\n",
      "Validation loss improved from 2.4131 to 2.4122. Saving model...\n",
      "\n",
      "LOG: Epoch [406/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0650\n",
      "    Batch [2/2], Train Loss: 4.0109\n",
      "Epoch [406/2000], Avg Train Loss: 4.0380\n",
      "Epoch [406/2000], Avg Val Loss: 2.4112\n",
      "Validation loss improved from 2.4122 to 2.4112. Saving model...\n",
      "\n",
      "LOG: Epoch [407/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9575\n",
      "    Batch [2/2], Train Loss: 4.0049\n",
      "Epoch [407/2000], Avg Train Loss: 3.9812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [407/2000], Avg Val Loss: 2.4101\n",
      "Validation loss improved from 2.4112 to 2.4101. Saving model...\n",
      "\n",
      "LOG: Epoch [408/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0553\n",
      "    Batch [2/2], Train Loss: 4.0086\n",
      "Epoch [408/2000], Avg Train Loss: 4.0320\n",
      "Epoch [408/2000], Avg Val Loss: 2.4091\n",
      "Validation loss improved from 2.4101 to 2.4091. Saving model...\n",
      "\n",
      "LOG: Epoch [409/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0178\n",
      "    Batch [2/2], Train Loss: 4.0001\n",
      "Epoch [409/2000], Avg Train Loss: 4.0089\n",
      "Epoch [409/2000], Avg Val Loss: 2.4080\n",
      "Validation loss improved from 2.4091 to 2.4080. Saving model...\n",
      "\n",
      "LOG: Epoch [410/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9881\n",
      "    Batch [2/2], Train Loss: 3.9652\n",
      "Epoch [410/2000], Avg Train Loss: 3.9767\n",
      "Epoch [410/2000], Avg Val Loss: 2.4069\n",
      "Validation loss improved from 2.4080 to 2.4069. Saving model...\n",
      "\n",
      "LOG: Epoch [411/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9705\n",
      "    Batch [2/2], Train Loss: 4.0463\n",
      "Epoch [411/2000], Avg Train Loss: 4.0084\n",
      "Epoch [411/2000], Avg Val Loss: 2.4059\n",
      "Validation loss improved from 2.4069 to 2.4059. Saving model...\n",
      "\n",
      "LOG: Epoch [412/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9625\n",
      "    Batch [2/2], Train Loss: 4.0013\n",
      "Epoch [412/2000], Avg Train Loss: 3.9819\n",
      "Epoch [412/2000], Avg Val Loss: 2.4049\n",
      "Validation loss improved from 2.4059 to 2.4049. Saving model...\n",
      "\n",
      "LOG: Epoch [413/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9712\n",
      "    Batch [2/2], Train Loss: 3.9835\n",
      "Epoch [413/2000], Avg Train Loss: 3.9774\n",
      "Epoch [413/2000], Avg Val Loss: 2.4039\n",
      "Validation loss improved from 2.4049 to 2.4039. Saving model...\n",
      "\n",
      "LOG: Epoch [414/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0221\n",
      "    Batch [2/2], Train Loss: 3.9790\n",
      "Epoch [414/2000], Avg Train Loss: 4.0005\n",
      "Epoch [414/2000], Avg Val Loss: 2.4028\n",
      "Validation loss improved from 2.4039 to 2.4028. Saving model...\n",
      "\n",
      "LOG: Epoch [415/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9850\n",
      "    Batch [2/2], Train Loss: 3.9635\n",
      "Epoch [415/2000], Avg Train Loss: 3.9742\n",
      "Epoch [415/2000], Avg Val Loss: 2.4018\n",
      "Validation loss improved from 2.4028 to 2.4018. Saving model...\n",
      "\n",
      "LOG: Epoch [416/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0366\n",
      "    Batch [2/2], Train Loss: 4.0286\n",
      "Epoch [416/2000], Avg Train Loss: 4.0326\n",
      "Epoch [416/2000], Avg Val Loss: 2.4009\n",
      "Validation loss improved from 2.4018 to 2.4009. Saving model...\n",
      "\n",
      "LOG: Epoch [417/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9724\n",
      "    Batch [2/2], Train Loss: 3.9906\n",
      "Epoch [417/2000], Avg Train Loss: 3.9815\n",
      "Epoch [417/2000], Avg Val Loss: 2.3999\n",
      "Validation loss improved from 2.4009 to 2.3999. Saving model...\n",
      "\n",
      "LOG: Epoch [418/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9933\n",
      "    Batch [2/2], Train Loss: 3.9998\n",
      "Epoch [418/2000], Avg Train Loss: 3.9965\n",
      "Epoch [418/2000], Avg Val Loss: 2.3988\n",
      "Validation loss improved from 2.3999 to 2.3988. Saving model...\n",
      "\n",
      "LOG: Epoch [419/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0059\n",
      "    Batch [2/2], Train Loss: 3.9640\n",
      "Epoch [419/2000], Avg Train Loss: 3.9849\n",
      "Epoch [419/2000], Avg Val Loss: 2.3977\n",
      "Validation loss improved from 2.3988 to 2.3977. Saving model...\n",
      "\n",
      "LOG: Epoch [420/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9370\n",
      "    Batch [2/2], Train Loss: 3.9792\n",
      "Epoch [420/2000], Avg Train Loss: 3.9581\n",
      "Epoch [420/2000], Avg Val Loss: 2.3966\n",
      "Validation loss improved from 2.3977 to 2.3966. Saving model...\n",
      "\n",
      "LOG: Epoch [421/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0176\n",
      "    Batch [2/2], Train Loss: 4.0016\n",
      "Epoch [421/2000], Avg Train Loss: 4.0096\n",
      "Epoch [421/2000], Avg Val Loss: 2.3956\n",
      "Validation loss improved from 2.3966 to 2.3956. Saving model...\n",
      "\n",
      "LOG: Epoch [422/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0472\n",
      "    Batch [2/2], Train Loss: 4.0204\n",
      "Epoch [422/2000], Avg Train Loss: 4.0338\n",
      "Epoch [422/2000], Avg Val Loss: 2.3946\n",
      "Validation loss improved from 2.3956 to 2.3946. Saving model...\n",
      "\n",
      "LOG: Epoch [423/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9649\n",
      "    Batch [2/2], Train Loss: 3.9441\n",
      "Epoch [423/2000], Avg Train Loss: 3.9545\n",
      "Epoch [423/2000], Avg Val Loss: 2.3935\n",
      "Validation loss improved from 2.3946 to 2.3935. Saving model...\n",
      "\n",
      "LOG: Epoch [424/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9675\n",
      "    Batch [2/2], Train Loss: 3.9296\n",
      "Epoch [424/2000], Avg Train Loss: 3.9486\n",
      "Epoch [424/2000], Avg Val Loss: 2.3925\n",
      "Validation loss improved from 2.3935 to 2.3925. Saving model...\n",
      "\n",
      "LOG: Epoch [425/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9915\n",
      "    Batch [2/2], Train Loss: 3.9897\n",
      "Epoch [425/2000], Avg Train Loss: 3.9906\n",
      "Epoch [425/2000], Avg Val Loss: 2.3916\n",
      "Validation loss improved from 2.3925 to 2.3916. Saving model...\n",
      "\n",
      "LOG: Epoch [426/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.9471\n",
      "    Batch [2/2], Train Loss: 3.9811\n",
      "Epoch [426/2000], Avg Train Loss: 3.9641\n",
      "Epoch [426/2000], Avg Val Loss: 2.3906\n",
      "Validation loss improved from 2.3916 to 2.3906. Saving model...\n",
      "\n",
      "LOG: Epoch [427/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9448\n",
      "    Batch [2/2], Train Loss: 3.9588\n",
      "Epoch [427/2000], Avg Train Loss: 3.9518\n",
      "Epoch [427/2000], Avg Val Loss: 2.3897\n",
      "Validation loss improved from 2.3906 to 2.3897. Saving model...\n",
      "\n",
      "LOG: Epoch [428/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9471\n",
      "    Batch [2/2], Train Loss: 3.9558\n",
      "Epoch [428/2000], Avg Train Loss: 3.9515\n",
      "Epoch [428/2000], Avg Val Loss: 2.3888\n",
      "Validation loss improved from 2.3897 to 2.3888. Saving model...\n",
      "\n",
      "LOG: Epoch [429/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9819\n",
      "    Batch [2/2], Train Loss: 3.9592\n",
      "Epoch [429/2000], Avg Train Loss: 3.9705\n",
      "Epoch [429/2000], Avg Val Loss: 2.3878\n",
      "Validation loss improved from 2.3888 to 2.3878. Saving model...\n",
      "\n",
      "LOG: Epoch [430/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9760\n",
      "    Batch [2/2], Train Loss: 3.9687\n",
      "Epoch [430/2000], Avg Train Loss: 3.9724\n",
      "Epoch [430/2000], Avg Val Loss: 2.3869\n",
      "Validation loss improved from 2.3878 to 2.3869. Saving model...\n",
      "\n",
      "LOG: Epoch [431/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9964\n",
      "    Batch [2/2], Train Loss: 3.9130\n",
      "Epoch [431/2000], Avg Train Loss: 3.9547\n",
      "Epoch [431/2000], Avg Val Loss: 2.3859\n",
      "Validation loss improved from 2.3869 to 2.3859. Saving model...\n",
      "\n",
      "LOG: Epoch [432/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9397\n",
      "    Batch [2/2], Train Loss: 3.9675\n",
      "Epoch [432/2000], Avg Train Loss: 3.9536\n",
      "Epoch [432/2000], Avg Val Loss: 2.3849\n",
      "Validation loss improved from 2.3859 to 2.3849. Saving model...\n",
      "\n",
      "LOG: Epoch [433/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9743\n",
      "    Batch [2/2], Train Loss: 3.9815\n",
      "Epoch [433/2000], Avg Train Loss: 3.9779\n",
      "Epoch [433/2000], Avg Val Loss: 2.3838\n",
      "Validation loss improved from 2.3849 to 2.3838. Saving model...\n",
      "\n",
      "LOG: Epoch [434/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9513\n",
      "    Batch [2/2], Train Loss: 3.9408\n",
      "Epoch [434/2000], Avg Train Loss: 3.9460\n",
      "Epoch [434/2000], Avg Val Loss: 2.3827\n",
      "Validation loss improved from 2.3838 to 2.3827. Saving model...\n",
      "\n",
      "LOG: Epoch [435/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9456\n",
      "    Batch [2/2], Train Loss: 3.9361\n",
      "Epoch [435/2000], Avg Train Loss: 3.9408\n",
      "Epoch [435/2000], Avg Val Loss: 2.3817\n",
      "Validation loss improved from 2.3827 to 2.3817. Saving model...\n",
      "\n",
      "LOG: Epoch [436/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9277\n",
      "    Batch [2/2], Train Loss: 3.9581\n",
      "Epoch [436/2000], Avg Train Loss: 3.9429\n",
      "Epoch [436/2000], Avg Val Loss: 2.3806\n",
      "Validation loss improved from 2.3817 to 2.3806. Saving model...\n",
      "\n",
      "LOG: Epoch [437/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9597\n",
      "    Batch [2/2], Train Loss: 3.9662\n",
      "Epoch [437/2000], Avg Train Loss: 3.9630\n",
      "Epoch [437/2000], Avg Val Loss: 2.3796\n",
      "Validation loss improved from 2.3806 to 2.3796. Saving model...\n",
      "\n",
      "LOG: Epoch [438/2000] - Training\n",
      "    Batch [1/2], Train Loss: 4.0101\n",
      "    Batch [2/2], Train Loss: 3.9194\n",
      "Epoch [438/2000], Avg Train Loss: 3.9648\n",
      "Epoch [438/2000], Avg Val Loss: 2.3787\n",
      "Validation loss improved from 2.3796 to 2.3787. Saving model...\n",
      "\n",
      "LOG: Epoch [439/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9399\n",
      "    Batch [2/2], Train Loss: 3.9480\n",
      "Epoch [439/2000], Avg Train Loss: 3.9439\n",
      "Epoch [439/2000], Avg Val Loss: 2.3778\n",
      "Validation loss improved from 2.3787 to 2.3778. Saving model...\n",
      "\n",
      "LOG: Epoch [440/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9553\n",
      "    Batch [2/2], Train Loss: 3.9452\n",
      "Epoch [440/2000], Avg Train Loss: 3.9502\n",
      "Epoch [440/2000], Avg Val Loss: 2.3770\n",
      "Validation loss improved from 2.3778 to 2.3770. Saving model...\n",
      "\n",
      "LOG: Epoch [441/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9739\n",
      "    Batch [2/2], Train Loss: 3.9696\n",
      "Epoch [441/2000], Avg Train Loss: 3.9718\n",
      "Epoch [441/2000], Avg Val Loss: 2.3761\n",
      "Validation loss improved from 2.3770 to 2.3761. Saving model...\n",
      "\n",
      "LOG: Epoch [442/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9183\n",
      "    Batch [2/2], Train Loss: 3.9416\n",
      "Epoch [442/2000], Avg Train Loss: 3.9299\n",
      "Epoch [442/2000], Avg Val Loss: 2.3753\n",
      "Validation loss improved from 2.3761 to 2.3753. Saving model...\n",
      "\n",
      "LOG: Epoch [443/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9509\n",
      "    Batch [2/2], Train Loss: 3.9528\n",
      "Epoch [443/2000], Avg Train Loss: 3.9518\n",
      "Epoch [443/2000], Avg Val Loss: 2.3743\n",
      "Validation loss improved from 2.3753 to 2.3743. Saving model...\n",
      "\n",
      "LOG: Epoch [444/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9238\n",
      "    Batch [2/2], Train Loss: 3.9337\n",
      "Epoch [444/2000], Avg Train Loss: 3.9287\n",
      "Epoch [444/2000], Avg Val Loss: 2.3734\n",
      "Validation loss improved from 2.3743 to 2.3734. Saving model...\n",
      "\n",
      "LOG: Epoch [445/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.9375\n",
      "    Batch [2/2], Train Loss: 3.9516\n",
      "Epoch [445/2000], Avg Train Loss: 3.9446\n",
      "Epoch [445/2000], Avg Val Loss: 2.3726\n",
      "Validation loss improved from 2.3734 to 2.3726. Saving model...\n",
      "\n",
      "LOG: Epoch [446/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9483\n",
      "    Batch [2/2], Train Loss: 3.9243\n",
      "Epoch [446/2000], Avg Train Loss: 3.9363\n",
      "Epoch [446/2000], Avg Val Loss: 2.3718\n",
      "Validation loss improved from 2.3726 to 2.3718. Saving model...\n",
      "\n",
      "LOG: Epoch [447/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9868\n",
      "    Batch [2/2], Train Loss: 3.9238\n",
      "Epoch [447/2000], Avg Train Loss: 3.9553\n",
      "Epoch [447/2000], Avg Val Loss: 2.3709\n",
      "Validation loss improved from 2.3718 to 2.3709. Saving model...\n",
      "\n",
      "LOG: Epoch [448/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9167\n",
      "    Batch [2/2], Train Loss: 3.9382\n",
      "Epoch [448/2000], Avg Train Loss: 3.9275\n",
      "Epoch [448/2000], Avg Val Loss: 2.3700\n",
      "Validation loss improved from 2.3709 to 2.3700. Saving model...\n",
      "\n",
      "LOG: Epoch [449/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9557\n",
      "    Batch [2/2], Train Loss: 3.9420\n",
      "Epoch [449/2000], Avg Train Loss: 3.9488\n",
      "Epoch [449/2000], Avg Val Loss: 2.3692\n",
      "Validation loss improved from 2.3700 to 2.3692. Saving model...\n",
      "\n",
      "LOG: Epoch [450/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9419\n",
      "    Batch [2/2], Train Loss: 3.9857\n",
      "Epoch [450/2000], Avg Train Loss: 3.9638\n",
      "Epoch [450/2000], Avg Val Loss: 2.3682\n",
      "Validation loss improved from 2.3692 to 2.3682. Saving model...\n",
      "\n",
      "LOG: Epoch [451/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9520\n",
      "    Batch [2/2], Train Loss: 3.9133\n",
      "Epoch [451/2000], Avg Train Loss: 3.9326\n",
      "Epoch [451/2000], Avg Val Loss: 2.3673\n",
      "Validation loss improved from 2.3682 to 2.3673. Saving model...\n",
      "\n",
      "LOG: Epoch [452/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9178\n",
      "    Batch [2/2], Train Loss: 3.9050\n",
      "Epoch [452/2000], Avg Train Loss: 3.9114\n",
      "Epoch [452/2000], Avg Val Loss: 2.3665\n",
      "Validation loss improved from 2.3673 to 2.3665. Saving model...\n",
      "\n",
      "LOG: Epoch [453/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9668\n",
      "    Batch [2/2], Train Loss: 3.9268\n",
      "Epoch [453/2000], Avg Train Loss: 3.9468\n",
      "Epoch [453/2000], Avg Val Loss: 2.3655\n",
      "Validation loss improved from 2.3665 to 2.3655. Saving model...\n",
      "\n",
      "LOG: Epoch [454/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9225\n",
      "    Batch [2/2], Train Loss: 3.9594\n",
      "Epoch [454/2000], Avg Train Loss: 3.9409\n",
      "Epoch [454/2000], Avg Val Loss: 2.3645\n",
      "Validation loss improved from 2.3655 to 2.3645. Saving model...\n",
      "\n",
      "LOG: Epoch [455/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9351\n",
      "    Batch [2/2], Train Loss: 3.9158\n",
      "Epoch [455/2000], Avg Train Loss: 3.9255\n",
      "Epoch [455/2000], Avg Val Loss: 2.3636\n",
      "Validation loss improved from 2.3645 to 2.3636. Saving model...\n",
      "\n",
      "LOG: Epoch [456/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8902\n",
      "    Batch [2/2], Train Loss: 3.9546\n",
      "Epoch [456/2000], Avg Train Loss: 3.9224\n",
      "Epoch [456/2000], Avg Val Loss: 2.3626\n",
      "Validation loss improved from 2.3636 to 2.3626. Saving model...\n",
      "\n",
      "LOG: Epoch [457/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9010\n",
      "    Batch [2/2], Train Loss: 3.9470\n",
      "Epoch [457/2000], Avg Train Loss: 3.9240\n",
      "Epoch [457/2000], Avg Val Loss: 2.3618\n",
      "Validation loss improved from 2.3626 to 2.3618. Saving model...\n",
      "\n",
      "LOG: Epoch [458/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8858\n",
      "    Batch [2/2], Train Loss: 3.9253\n",
      "Epoch [458/2000], Avg Train Loss: 3.9055\n",
      "Epoch [458/2000], Avg Val Loss: 2.3608\n",
      "Validation loss improved from 2.3618 to 2.3608. Saving model...\n",
      "\n",
      "LOG: Epoch [459/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9422\n",
      "    Batch [2/2], Train Loss: 3.9338\n",
      "Epoch [459/2000], Avg Train Loss: 3.9380\n",
      "Epoch [459/2000], Avg Val Loss: 2.3600\n",
      "Validation loss improved from 2.3608 to 2.3600. Saving model...\n",
      "\n",
      "LOG: Epoch [460/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9213\n",
      "    Batch [2/2], Train Loss: 3.9333\n",
      "Epoch [460/2000], Avg Train Loss: 3.9273\n",
      "Epoch [460/2000], Avg Val Loss: 2.3591\n",
      "Validation loss improved from 2.3600 to 2.3591. Saving model...\n",
      "\n",
      "LOG: Epoch [461/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9321\n",
      "    Batch [2/2], Train Loss: 3.9459\n",
      "Epoch [461/2000], Avg Train Loss: 3.9390\n",
      "Epoch [461/2000], Avg Val Loss: 2.3581\n",
      "Validation loss improved from 2.3591 to 2.3581. Saving model...\n",
      "\n",
      "LOG: Epoch [462/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9172\n",
      "    Batch [2/2], Train Loss: 3.8621\n",
      "Epoch [462/2000], Avg Train Loss: 3.8897\n",
      "Epoch [462/2000], Avg Val Loss: 2.3570\n",
      "Validation loss improved from 2.3581 to 2.3570. Saving model...\n",
      "\n",
      "LOG: Epoch [463/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8919\n",
      "    Batch [2/2], Train Loss: 3.9008\n",
      "Epoch [463/2000], Avg Train Loss: 3.8964\n",
      "Epoch [463/2000], Avg Val Loss: 2.3561\n",
      "Validation loss improved from 2.3570 to 2.3561. Saving model...\n",
      "\n",
      "LOG: Epoch [464/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.9783\n",
      "    Batch [2/2], Train Loss: 3.9315\n",
      "Epoch [464/2000], Avg Train Loss: 3.9549\n",
      "Epoch [464/2000], Avg Val Loss: 2.3553\n",
      "Validation loss improved from 2.3561 to 2.3553. Saving model...\n",
      "\n",
      "LOG: Epoch [465/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9661\n",
      "    Batch [2/2], Train Loss: 3.8723\n",
      "Epoch [465/2000], Avg Train Loss: 3.9192\n",
      "Epoch [465/2000], Avg Val Loss: 2.3546\n",
      "Validation loss improved from 2.3553 to 2.3546. Saving model...\n",
      "\n",
      "LOG: Epoch [466/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8948\n",
      "    Batch [2/2], Train Loss: 3.9364\n",
      "Epoch [466/2000], Avg Train Loss: 3.9156\n",
      "Epoch [466/2000], Avg Val Loss: 2.3539\n",
      "Validation loss improved from 2.3546 to 2.3539. Saving model...\n",
      "\n",
      "LOG: Epoch [467/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9276\n",
      "    Batch [2/2], Train Loss: 3.9168\n",
      "Epoch [467/2000], Avg Train Loss: 3.9222\n",
      "Epoch [467/2000], Avg Val Loss: 2.3532\n",
      "Validation loss improved from 2.3539 to 2.3532. Saving model...\n",
      "\n",
      "LOG: Epoch [468/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9656\n",
      "    Batch [2/2], Train Loss: 3.8371\n",
      "Epoch [468/2000], Avg Train Loss: 3.9013\n",
      "Epoch [468/2000], Avg Val Loss: 2.3525\n",
      "Validation loss improved from 2.3532 to 2.3525. Saving model...\n",
      "\n",
      "LOG: Epoch [469/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8958\n",
      "    Batch [2/2], Train Loss: 3.9265\n",
      "Epoch [469/2000], Avg Train Loss: 3.9111\n",
      "Epoch [469/2000], Avg Val Loss: 2.3518\n",
      "Validation loss improved from 2.3525 to 2.3518. Saving model...\n",
      "\n",
      "LOG: Epoch [470/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9268\n",
      "    Batch [2/2], Train Loss: 3.8855\n",
      "Epoch [470/2000], Avg Train Loss: 3.9062\n",
      "Epoch [470/2000], Avg Val Loss: 2.3512\n",
      "Validation loss improved from 2.3518 to 2.3512. Saving model...\n",
      "\n",
      "LOG: Epoch [471/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8595\n",
      "    Batch [2/2], Train Loss: 3.8676\n",
      "Epoch [471/2000], Avg Train Loss: 3.8636\n",
      "Epoch [471/2000], Avg Val Loss: 2.3505\n",
      "Validation loss improved from 2.3512 to 2.3505. Saving model...\n",
      "\n",
      "LOG: Epoch [472/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9137\n",
      "    Batch [2/2], Train Loss: 3.9387\n",
      "Epoch [472/2000], Avg Train Loss: 3.9262\n",
      "Epoch [472/2000], Avg Val Loss: 2.3499\n",
      "Validation loss improved from 2.3505 to 2.3499. Saving model...\n",
      "\n",
      "LOG: Epoch [473/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9440\n",
      "    Batch [2/2], Train Loss: 3.8571\n",
      "Epoch [473/2000], Avg Train Loss: 3.9006\n",
      "Epoch [473/2000], Avg Val Loss: 2.3493\n",
      "Validation loss improved from 2.3499 to 2.3493. Saving model...\n",
      "\n",
      "LOG: Epoch [474/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8873\n",
      "    Batch [2/2], Train Loss: 3.8844\n",
      "Epoch [474/2000], Avg Train Loss: 3.8859\n",
      "Epoch [474/2000], Avg Val Loss: 2.3485\n",
      "Validation loss improved from 2.3493 to 2.3485. Saving model...\n",
      "\n",
      "LOG: Epoch [475/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9114\n",
      "    Batch [2/2], Train Loss: 3.8978\n",
      "Epoch [475/2000], Avg Train Loss: 3.9046\n",
      "Epoch [475/2000], Avg Val Loss: 2.3479\n",
      "Validation loss improved from 2.3485 to 2.3479. Saving model...\n",
      "\n",
      "LOG: Epoch [476/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8766\n",
      "    Batch [2/2], Train Loss: 3.9338\n",
      "Epoch [476/2000], Avg Train Loss: 3.9052\n",
      "Epoch [476/2000], Avg Val Loss: 2.3473\n",
      "Validation loss improved from 2.3479 to 2.3473. Saving model...\n",
      "\n",
      "LOG: Epoch [477/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9051\n",
      "    Batch [2/2], Train Loss: 3.8557\n",
      "Epoch [477/2000], Avg Train Loss: 3.8804\n",
      "Epoch [477/2000], Avg Val Loss: 2.3467\n",
      "Validation loss improved from 2.3473 to 2.3467. Saving model...\n",
      "\n",
      "LOG: Epoch [478/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9036\n",
      "    Batch [2/2], Train Loss: 3.9241\n",
      "Epoch [478/2000], Avg Train Loss: 3.9138\n",
      "Epoch [478/2000], Avg Val Loss: 2.3460\n",
      "Validation loss improved from 2.3467 to 2.3460. Saving model...\n",
      "\n",
      "LOG: Epoch [479/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8798\n",
      "    Batch [2/2], Train Loss: 3.8698\n",
      "Epoch [479/2000], Avg Train Loss: 3.8748\n",
      "Epoch [479/2000], Avg Val Loss: 2.3451\n",
      "Validation loss improved from 2.3460 to 2.3451. Saving model...\n",
      "\n",
      "LOG: Epoch [480/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8807\n",
      "    Batch [2/2], Train Loss: 3.9255\n",
      "Epoch [480/2000], Avg Train Loss: 3.9031\n",
      "Epoch [480/2000], Avg Val Loss: 2.3443\n",
      "Validation loss improved from 2.3451 to 2.3443. Saving model...\n",
      "\n",
      "LOG: Epoch [481/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8812\n",
      "    Batch [2/2], Train Loss: 3.8965\n",
      "Epoch [481/2000], Avg Train Loss: 3.8888\n",
      "Epoch [481/2000], Avg Val Loss: 2.3436\n",
      "Validation loss improved from 2.3443 to 2.3436. Saving model...\n",
      "\n",
      "LOG: Epoch [482/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.9120\n",
      "Epoch [482/2000], Avg Train Loss: 3.9005\n",
      "Epoch [482/2000], Avg Val Loss: 2.3428\n",
      "Validation loss improved from 2.3436 to 2.3428. Saving model...\n",
      "\n",
      "LOG: Epoch [483/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9012\n",
      "    Batch [2/2], Train Loss: 3.8762\n",
      "Epoch [483/2000], Avg Train Loss: 3.8887\n",
      "Epoch [483/2000], Avg Val Loss: 2.3419\n",
      "Validation loss improved from 2.3428 to 2.3419. Saving model...\n",
      "\n",
      "LOG: Epoch [484/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8517\n",
      "    Batch [2/2], Train Loss: 3.8868\n",
      "Epoch [484/2000], Avg Train Loss: 3.8692\n",
      "Epoch [484/2000], Avg Val Loss: 2.3410\n",
      "Validation loss improved from 2.3419 to 2.3410. Saving model...\n",
      "\n",
      "LOG: Epoch [485/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8615\n",
      "    Batch [2/2], Train Loss: 3.8873\n",
      "Epoch [485/2000], Avg Train Loss: 3.8744\n",
      "Epoch [485/2000], Avg Val Loss: 2.3400\n",
      "Validation loss improved from 2.3410 to 2.3400. Saving model...\n",
      "\n",
      "LOG: Epoch [486/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8744\n",
      "    Batch [2/2], Train Loss: 3.8964\n",
      "Epoch [486/2000], Avg Train Loss: 3.8854\n",
      "Epoch [486/2000], Avg Val Loss: 2.3390\n",
      "Validation loss improved from 2.3400 to 2.3390. Saving model...\n",
      "\n",
      "LOG: Epoch [487/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9115\n",
      "    Batch [2/2], Train Loss: 3.8812\n",
      "Epoch [487/2000], Avg Train Loss: 3.8964\n",
      "Epoch [487/2000], Avg Val Loss: 2.3381\n",
      "Validation loss improved from 2.3390 to 2.3381. Saving model...\n",
      "\n",
      "LOG: Epoch [488/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8628\n",
      "    Batch [2/2], Train Loss: 3.8390\n",
      "Epoch [488/2000], Avg Train Loss: 3.8509\n",
      "Epoch [488/2000], Avg Val Loss: 2.3371\n",
      "Validation loss improved from 2.3381 to 2.3371. Saving model...\n",
      "\n",
      "LOG: Epoch [489/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8939\n",
      "    Batch [2/2], Train Loss: 3.8904\n",
      "Epoch [489/2000], Avg Train Loss: 3.8921\n",
      "Epoch [489/2000], Avg Val Loss: 2.3362\n",
      "Validation loss improved from 2.3371 to 2.3362. Saving model...\n",
      "\n",
      "LOG: Epoch [490/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8675\n",
      "    Batch [2/2], Train Loss: 3.9279\n",
      "Epoch [490/2000], Avg Train Loss: 3.8977\n",
      "Epoch [490/2000], Avg Val Loss: 2.3353\n",
      "Validation loss improved from 2.3362 to 2.3353. Saving model...\n",
      "\n",
      "LOG: Epoch [491/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8841\n",
      "    Batch [2/2], Train Loss: 3.8990\n",
      "Epoch [491/2000], Avg Train Loss: 3.8916\n",
      "Epoch [491/2000], Avg Val Loss: 2.3343\n",
      "Validation loss improved from 2.3353 to 2.3343. Saving model...\n",
      "\n",
      "LOG: Epoch [492/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8730\n",
      "    Batch [2/2], Train Loss: 3.9223\n",
      "Epoch [492/2000], Avg Train Loss: 3.8976\n",
      "Epoch [492/2000], Avg Val Loss: 2.3334\n",
      "Validation loss improved from 2.3343 to 2.3334. Saving model...\n",
      "\n",
      "LOG: Epoch [493/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9054\n",
      "    Batch [2/2], Train Loss: 3.8533\n",
      "Epoch [493/2000], Avg Train Loss: 3.8793\n",
      "Epoch [493/2000], Avg Val Loss: 2.3326\n",
      "Validation loss improved from 2.3334 to 2.3326. Saving model...\n",
      "\n",
      "LOG: Epoch [494/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8760\n",
      "    Batch [2/2], Train Loss: 3.8522\n",
      "Epoch [494/2000], Avg Train Loss: 3.8641\n",
      "Epoch [494/2000], Avg Val Loss: 2.3319\n",
      "Validation loss improved from 2.3326 to 2.3319. Saving model...\n",
      "\n",
      "LOG: Epoch [495/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8837\n",
      "    Batch [2/2], Train Loss: 3.8722\n",
      "Epoch [495/2000], Avg Train Loss: 3.8780\n",
      "Epoch [495/2000], Avg Val Loss: 2.3312\n",
      "Validation loss improved from 2.3319 to 2.3312. Saving model...\n",
      "\n",
      "LOG: Epoch [496/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9193\n",
      "    Batch [2/2], Train Loss: 3.8537\n",
      "Epoch [496/2000], Avg Train Loss: 3.8865\n",
      "Epoch [496/2000], Avg Val Loss: 2.3304\n",
      "Validation loss improved from 2.3312 to 2.3304. Saving model...\n",
      "\n",
      "LOG: Epoch [497/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8433\n",
      "    Batch [2/2], Train Loss: 3.8796\n",
      "Epoch [497/2000], Avg Train Loss: 3.8614\n",
      "Epoch [497/2000], Avg Val Loss: 2.3297\n",
      "Validation loss improved from 2.3304 to 2.3297. Saving model...\n",
      "\n",
      "LOG: Epoch [498/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8656\n",
      "    Batch [2/2], Train Loss: 3.8778\n",
      "Epoch [498/2000], Avg Train Loss: 3.8717\n",
      "Epoch [498/2000], Avg Val Loss: 2.3289\n",
      "Validation loss improved from 2.3297 to 2.3289. Saving model...\n",
      "\n",
      "LOG: Epoch [499/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8842\n",
      "    Batch [2/2], Train Loss: 3.8785\n",
      "Epoch [499/2000], Avg Train Loss: 3.8814\n",
      "Epoch [499/2000], Avg Val Loss: 2.3282\n",
      "Validation loss improved from 2.3289 to 2.3282. Saving model...\n",
      "\n",
      "LOG: Epoch [500/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8573\n",
      "    Batch [2/2], Train Loss: 3.8301\n",
      "Epoch [500/2000], Avg Train Loss: 3.8437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/2000], Avg Val Loss: 2.3274\n",
      "Validation loss improved from 2.3282 to 2.3274. Saving model...\n",
      "\n",
      "LOG: Epoch [501/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8490\n",
      "    Batch [2/2], Train Loss: 3.8800\n",
      "Epoch [501/2000], Avg Train Loss: 3.8645\n",
      "Epoch [501/2000], Avg Val Loss: 2.3265\n",
      "Validation loss improved from 2.3274 to 2.3265. Saving model...\n",
      "\n",
      "LOG: Epoch [502/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8858\n",
      "    Batch [2/2], Train Loss: 3.8532\n",
      "Epoch [502/2000], Avg Train Loss: 3.8695\n",
      "Epoch [502/2000], Avg Val Loss: 2.3257\n",
      "Validation loss improved from 2.3265 to 2.3257. Saving model...\n",
      "\n",
      "LOG: Epoch [503/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8133\n",
      "    Batch [2/2], Train Loss: 3.8510\n",
      "Epoch [503/2000], Avg Train Loss: 3.8321\n",
      "Epoch [503/2000], Avg Val Loss: 2.3249\n",
      "Validation loss improved from 2.3257 to 2.3249. Saving model...\n",
      "\n",
      "LOG: Epoch [504/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8249\n",
      "    Batch [2/2], Train Loss: 3.8866\n",
      "Epoch [504/2000], Avg Train Loss: 3.8557\n",
      "Epoch [504/2000], Avg Val Loss: 2.3240\n",
      "Validation loss improved from 2.3249 to 2.3240. Saving model...\n",
      "\n",
      "LOG: Epoch [505/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9037\n",
      "    Batch [2/2], Train Loss: 3.8992\n",
      "Epoch [505/2000], Avg Train Loss: 3.9014\n",
      "Epoch [505/2000], Avg Val Loss: 2.3233\n",
      "Validation loss improved from 2.3240 to 2.3233. Saving model...\n",
      "\n",
      "LOG: Epoch [506/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8253\n",
      "    Batch [2/2], Train Loss: 3.8006\n",
      "Epoch [506/2000], Avg Train Loss: 3.8129\n",
      "Epoch [506/2000], Avg Val Loss: 2.3225\n",
      "Validation loss improved from 2.3233 to 2.3225. Saving model...\n",
      "\n",
      "LOG: Epoch [507/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8434\n",
      "    Batch [2/2], Train Loss: 3.8869\n",
      "Epoch [507/2000], Avg Train Loss: 3.8651\n",
      "Epoch [507/2000], Avg Val Loss: 2.3216\n",
      "Validation loss improved from 2.3225 to 2.3216. Saving model...\n",
      "\n",
      "LOG: Epoch [508/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8507\n",
      "    Batch [2/2], Train Loss: 3.8055\n",
      "Epoch [508/2000], Avg Train Loss: 3.8281\n",
      "Epoch [508/2000], Avg Val Loss: 2.3206\n",
      "Validation loss improved from 2.3216 to 2.3206. Saving model...\n",
      "\n",
      "LOG: Epoch [509/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.9138\n",
      "    Batch [2/2], Train Loss: 3.8277\n",
      "Epoch [509/2000], Avg Train Loss: 3.8708\n",
      "Epoch [509/2000], Avg Val Loss: 2.3197\n",
      "Validation loss improved from 2.3206 to 2.3197. Saving model...\n",
      "\n",
      "LOG: Epoch [510/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8230\n",
      "    Batch [2/2], Train Loss: 3.8200\n",
      "Epoch [510/2000], Avg Train Loss: 3.8215\n",
      "Epoch [510/2000], Avg Val Loss: 2.3189\n",
      "Validation loss improved from 2.3197 to 2.3189. Saving model...\n",
      "\n",
      "LOG: Epoch [511/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8335\n",
      "    Batch [2/2], Train Loss: 3.8286\n",
      "Epoch [511/2000], Avg Train Loss: 3.8311\n",
      "Epoch [511/2000], Avg Val Loss: 2.3180\n",
      "Validation loss improved from 2.3189 to 2.3180. Saving model...\n",
      "\n",
      "LOG: Epoch [512/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8471\n",
      "    Batch [2/2], Train Loss: 3.8558\n",
      "Epoch [512/2000], Avg Train Loss: 3.8515\n",
      "Epoch [512/2000], Avg Val Loss: 2.3170\n",
      "Validation loss improved from 2.3180 to 2.3170. Saving model...\n",
      "\n",
      "LOG: Epoch [513/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8535\n",
      "    Batch [2/2], Train Loss: 3.8387\n",
      "Epoch [513/2000], Avg Train Loss: 3.8461\n",
      "Epoch [513/2000], Avg Val Loss: 2.3163\n",
      "Validation loss improved from 2.3170 to 2.3163. Saving model...\n",
      "\n",
      "LOG: Epoch [514/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8511\n",
      "    Batch [2/2], Train Loss: 3.8769\n",
      "Epoch [514/2000], Avg Train Loss: 3.8640\n",
      "Epoch [514/2000], Avg Val Loss: 2.3156\n",
      "Validation loss improved from 2.3163 to 2.3156. Saving model...\n",
      "\n",
      "LOG: Epoch [515/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8582\n",
      "    Batch [2/2], Train Loss: 3.8362\n",
      "Epoch [515/2000], Avg Train Loss: 3.8472\n",
      "Epoch [515/2000], Avg Val Loss: 2.3149\n",
      "Validation loss improved from 2.3156 to 2.3149. Saving model...\n",
      "\n",
      "LOG: Epoch [516/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8341\n",
      "    Batch [2/2], Train Loss: 3.8467\n",
      "Epoch [516/2000], Avg Train Loss: 3.8404\n",
      "Epoch [516/2000], Avg Val Loss: 2.3144\n",
      "Validation loss improved from 2.3149 to 2.3144. Saving model...\n",
      "\n",
      "LOG: Epoch [517/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8669\n",
      "    Batch [2/2], Train Loss: 3.8607\n",
      "Epoch [517/2000], Avg Train Loss: 3.8638\n",
      "Epoch [517/2000], Avg Val Loss: 2.3139\n",
      "Validation loss improved from 2.3144 to 2.3139. Saving model...\n",
      "\n",
      "LOG: Epoch [518/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8918\n",
      "    Batch [2/2], Train Loss: 3.8384\n",
      "Epoch [518/2000], Avg Train Loss: 3.8651\n",
      "Epoch [518/2000], Avg Val Loss: 2.3134\n",
      "Validation loss improved from 2.3139 to 2.3134. Saving model...\n",
      "\n",
      "LOG: Epoch [519/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8060\n",
      "    Batch [2/2], Train Loss: 3.8420\n",
      "Epoch [519/2000], Avg Train Loss: 3.8240\n",
      "Epoch [519/2000], Avg Val Loss: 2.3129\n",
      "Validation loss improved from 2.3134 to 2.3129. Saving model...\n",
      "\n",
      "LOG: Epoch [520/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.8464\n",
      "    Batch [2/2], Train Loss: 3.8069\n",
      "Epoch [520/2000], Avg Train Loss: 3.8266\n",
      "Epoch [520/2000], Avg Val Loss: 2.3124\n",
      "Validation loss improved from 2.3129 to 2.3124. Saving model...\n",
      "\n",
      "LOG: Epoch [521/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8703\n",
      "    Batch [2/2], Train Loss: 3.8451\n",
      "Epoch [521/2000], Avg Train Loss: 3.8577\n",
      "Epoch [521/2000], Avg Val Loss: 2.3118\n",
      "Validation loss improved from 2.3124 to 2.3118. Saving model...\n",
      "\n",
      "LOG: Epoch [522/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8990\n",
      "    Batch [2/2], Train Loss: 3.8711\n",
      "Epoch [522/2000], Avg Train Loss: 3.8850\n",
      "Epoch [522/2000], Avg Val Loss: 2.3113\n",
      "Validation loss improved from 2.3118 to 2.3113. Saving model...\n",
      "\n",
      "LOG: Epoch [523/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8119\n",
      "    Batch [2/2], Train Loss: 3.8311\n",
      "Epoch [523/2000], Avg Train Loss: 3.8215\n",
      "Epoch [523/2000], Avg Val Loss: 2.3109\n",
      "Validation loss improved from 2.3113 to 2.3109. Saving model...\n",
      "\n",
      "LOG: Epoch [524/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8821\n",
      "    Batch [2/2], Train Loss: 3.8421\n",
      "Epoch [524/2000], Avg Train Loss: 3.8621\n",
      "Epoch [524/2000], Avg Val Loss: 2.3105\n",
      "Validation loss improved from 2.3109 to 2.3105. Saving model...\n",
      "\n",
      "LOG: Epoch [525/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8406\n",
      "    Batch [2/2], Train Loss: 3.8393\n",
      "Epoch [525/2000], Avg Train Loss: 3.8399\n",
      "Epoch [525/2000], Avg Val Loss: 2.3100\n",
      "Validation loss improved from 2.3105 to 2.3100. Saving model...\n",
      "\n",
      "LOG: Epoch [526/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8229\n",
      "    Batch [2/2], Train Loss: 3.8579\n",
      "Epoch [526/2000], Avg Train Loss: 3.8404\n",
      "Epoch [526/2000], Avg Val Loss: 2.3095\n",
      "Validation loss improved from 2.3100 to 2.3095. Saving model...\n",
      "\n",
      "LOG: Epoch [527/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8404\n",
      "    Batch [2/2], Train Loss: 3.8241\n",
      "Epoch [527/2000], Avg Train Loss: 3.8323\n",
      "Epoch [527/2000], Avg Val Loss: 2.3090\n",
      "Validation loss improved from 2.3095 to 2.3090. Saving model...\n",
      "\n",
      "LOG: Epoch [528/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7881\n",
      "    Batch [2/2], Train Loss: 3.8144\n",
      "Epoch [528/2000], Avg Train Loss: 3.8013\n",
      "Epoch [528/2000], Avg Val Loss: 2.3085\n",
      "Validation loss improved from 2.3090 to 2.3085. Saving model...\n",
      "\n",
      "LOG: Epoch [529/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8150\n",
      "    Batch [2/2], Train Loss: 3.8152\n",
      "Epoch [529/2000], Avg Train Loss: 3.8151\n",
      "Epoch [529/2000], Avg Val Loss: 2.3078\n",
      "Validation loss improved from 2.3085 to 2.3078. Saving model...\n",
      "\n",
      "LOG: Epoch [530/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8664\n",
      "    Batch [2/2], Train Loss: 3.7703\n",
      "Epoch [530/2000], Avg Train Loss: 3.8184\n",
      "Epoch [530/2000], Avg Val Loss: 2.3071\n",
      "Validation loss improved from 2.3078 to 2.3071. Saving model...\n",
      "\n",
      "LOG: Epoch [531/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8398\n",
      "    Batch [2/2], Train Loss: 3.8102\n",
      "Epoch [531/2000], Avg Train Loss: 3.8250\n",
      "Epoch [531/2000], Avg Val Loss: 2.3063\n",
      "Validation loss improved from 2.3071 to 2.3063. Saving model...\n",
      "\n",
      "LOG: Epoch [532/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7984\n",
      "    Batch [2/2], Train Loss: 3.7983\n",
      "Epoch [532/2000], Avg Train Loss: 3.7983\n",
      "Epoch [532/2000], Avg Val Loss: 2.3058\n",
      "Validation loss improved from 2.3063 to 2.3058. Saving model...\n",
      "\n",
      "LOG: Epoch [533/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8614\n",
      "    Batch [2/2], Train Loss: 3.8094\n",
      "Epoch [533/2000], Avg Train Loss: 3.8354\n",
      "Epoch [533/2000], Avg Val Loss: 2.3053\n",
      "Validation loss improved from 2.3058 to 2.3053. Saving model...\n",
      "\n",
      "LOG: Epoch [534/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8168\n",
      "    Batch [2/2], Train Loss: 3.7676\n",
      "Epoch [534/2000], Avg Train Loss: 3.7922\n",
      "Epoch [534/2000], Avg Val Loss: 2.3047\n",
      "Validation loss improved from 2.3053 to 2.3047. Saving model...\n",
      "\n",
      "LOG: Epoch [535/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7675\n",
      "    Batch [2/2], Train Loss: 3.8095\n",
      "Epoch [535/2000], Avg Train Loss: 3.7885\n",
      "Epoch [535/2000], Avg Val Loss: 2.3043\n",
      "Validation loss improved from 2.3047 to 2.3043. Saving model...\n",
      "\n",
      "LOG: Epoch [536/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8008\n",
      "    Batch [2/2], Train Loss: 3.8173\n",
      "Epoch [536/2000], Avg Train Loss: 3.8090\n",
      "Epoch [536/2000], Avg Val Loss: 2.3037\n",
      "Validation loss improved from 2.3043 to 2.3037. Saving model...\n",
      "\n",
      "LOG: Epoch [537/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7850\n",
      "    Batch [2/2], Train Loss: 3.8636\n",
      "Epoch [537/2000], Avg Train Loss: 3.8243\n",
      "Epoch [537/2000], Avg Val Loss: 2.3031\n",
      "Validation loss improved from 2.3037 to 2.3031. Saving model...\n",
      "\n",
      "LOG: Epoch [538/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.8429\n",
      "Epoch [538/2000], Avg Train Loss: 3.8348\n",
      "Epoch [538/2000], Avg Val Loss: 2.3025\n",
      "Validation loss improved from 2.3031 to 2.3025. Saving model...\n",
      "\n",
      "LOG: Epoch [539/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7750\n",
      "    Batch [2/2], Train Loss: 3.8480\n",
      "Epoch [539/2000], Avg Train Loss: 3.8115\n",
      "Epoch [539/2000], Avg Val Loss: 2.3019\n",
      "Validation loss improved from 2.3025 to 2.3019. Saving model...\n",
      "\n",
      "LOG: Epoch [540/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7597\n",
      "    Batch [2/2], Train Loss: 3.8239\n",
      "Epoch [540/2000], Avg Train Loss: 3.7918\n",
      "Epoch [540/2000], Avg Val Loss: 2.3013\n",
      "Validation loss improved from 2.3019 to 2.3013. Saving model...\n",
      "\n",
      "LOG: Epoch [541/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8208\n",
      "    Batch [2/2], Train Loss: 3.8628\n",
      "Epoch [541/2000], Avg Train Loss: 3.8418\n",
      "Epoch [541/2000], Avg Val Loss: 2.3007\n",
      "Validation loss improved from 2.3013 to 2.3007. Saving model...\n",
      "\n",
      "LOG: Epoch [542/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8062\n",
      "    Batch [2/2], Train Loss: 3.7880\n",
      "Epoch [542/2000], Avg Train Loss: 3.7971\n",
      "Epoch [542/2000], Avg Val Loss: 2.3000\n",
      "Validation loss improved from 2.3007 to 2.3000. Saving model...\n",
      "\n",
      "LOG: Epoch [543/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8592\n",
      "    Batch [2/2], Train Loss: 3.8099\n",
      "Epoch [543/2000], Avg Train Loss: 3.8346\n",
      "Epoch [543/2000], Avg Val Loss: 2.2991\n",
      "Validation loss improved from 2.3000 to 2.2991. Saving model...\n",
      "\n",
      "LOG: Epoch [544/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8322\n",
      "    Batch [2/2], Train Loss: 3.8332\n",
      "Epoch [544/2000], Avg Train Loss: 3.8327\n",
      "Epoch [544/2000], Avg Val Loss: 2.2983\n",
      "Validation loss improved from 2.2991 to 2.2983. Saving model...\n",
      "\n",
      "LOG: Epoch [545/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7955\n",
      "    Batch [2/2], Train Loss: 3.7725\n",
      "Epoch [545/2000], Avg Train Loss: 3.7840\n",
      "Epoch [545/2000], Avg Val Loss: 2.2975\n",
      "Validation loss improved from 2.2983 to 2.2975. Saving model...\n",
      "\n",
      "LOG: Epoch [546/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7835\n",
      "    Batch [2/2], Train Loss: 3.8558\n",
      "Epoch [546/2000], Avg Train Loss: 3.8197\n",
      "Epoch [546/2000], Avg Val Loss: 2.2966\n",
      "Validation loss improved from 2.2975 to 2.2966. Saving model...\n",
      "\n",
      "LOG: Epoch [547/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8156\n",
      "    Batch [2/2], Train Loss: 3.8068\n",
      "Epoch [547/2000], Avg Train Loss: 3.8112\n",
      "Epoch [547/2000], Avg Val Loss: 2.2958\n",
      "Validation loss improved from 2.2966 to 2.2958. Saving model...\n",
      "\n",
      "LOG: Epoch [548/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7711\n",
      "    Batch [2/2], Train Loss: 3.8058\n",
      "Epoch [548/2000], Avg Train Loss: 3.7885\n",
      "Epoch [548/2000], Avg Val Loss: 2.2949\n",
      "Validation loss improved from 2.2958 to 2.2949. Saving model...\n",
      "\n",
      "LOG: Epoch [549/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8125\n",
      "    Batch [2/2], Train Loss: 3.7812\n",
      "Epoch [549/2000], Avg Train Loss: 3.7968\n",
      "Epoch [549/2000], Avg Val Loss: 2.2940\n",
      "Validation loss improved from 2.2949 to 2.2940. Saving model...\n",
      "\n",
      "LOG: Epoch [550/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7517\n",
      "    Batch [2/2], Train Loss: 3.7910\n",
      "Epoch [550/2000], Avg Train Loss: 3.7714\n",
      "Epoch [550/2000], Avg Val Loss: 2.2931\n",
      "Validation loss improved from 2.2940 to 2.2931. Saving model...\n",
      "\n",
      "LOG: Epoch [551/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7992\n",
      "    Batch [2/2], Train Loss: 3.8216\n",
      "Epoch [551/2000], Avg Train Loss: 3.8104\n",
      "Epoch [551/2000], Avg Val Loss: 2.2924\n",
      "Validation loss improved from 2.2931 to 2.2924. Saving model...\n",
      "\n",
      "LOG: Epoch [552/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8028\n",
      "    Batch [2/2], Train Loss: 3.7649\n",
      "Epoch [552/2000], Avg Train Loss: 3.7839\n",
      "Epoch [552/2000], Avg Val Loss: 2.2918\n",
      "Validation loss improved from 2.2924 to 2.2918. Saving model...\n",
      "\n",
      "LOG: Epoch [553/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7721\n",
      "    Batch [2/2], Train Loss: 3.7983\n",
      "Epoch [553/2000], Avg Train Loss: 3.7852\n",
      "Epoch [553/2000], Avg Val Loss: 2.2913\n",
      "Validation loss improved from 2.2918 to 2.2913. Saving model...\n",
      "\n",
      "LOG: Epoch [554/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7973\n",
      "    Batch [2/2], Train Loss: 3.7592\n",
      "Epoch [554/2000], Avg Train Loss: 3.7782\n",
      "Epoch [554/2000], Avg Val Loss: 2.2907\n",
      "Validation loss improved from 2.2913 to 2.2907. Saving model...\n",
      "\n",
      "LOG: Epoch [555/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7881\n",
      "    Batch [2/2], Train Loss: 3.7742\n",
      "Epoch [555/2000], Avg Train Loss: 3.7812\n",
      "Epoch [555/2000], Avg Val Loss: 2.2901\n",
      "Validation loss improved from 2.2907 to 2.2901. Saving model...\n",
      "\n",
      "LOG: Epoch [556/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7792\n",
      "    Batch [2/2], Train Loss: 3.7527\n",
      "Epoch [556/2000], Avg Train Loss: 3.7660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [556/2000], Avg Val Loss: 2.2895\n",
      "Validation loss improved from 2.2901 to 2.2895. Saving model...\n",
      "\n",
      "LOG: Epoch [557/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8278\n",
      "    Batch [2/2], Train Loss: 3.7627\n",
      "Epoch [557/2000], Avg Train Loss: 3.7952\n",
      "Epoch [557/2000], Avg Val Loss: 2.2890\n",
      "Validation loss improved from 2.2895 to 2.2890. Saving model...\n",
      "\n",
      "LOG: Epoch [558/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8455\n",
      "    Batch [2/2], Train Loss: 3.7902\n",
      "Epoch [558/2000], Avg Train Loss: 3.8178\n",
      "Epoch [558/2000], Avg Val Loss: 2.2883\n",
      "Validation loss improved from 2.2890 to 2.2883. Saving model...\n",
      "\n",
      "LOG: Epoch [559/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8017\n",
      "    Batch [2/2], Train Loss: 3.7776\n",
      "Epoch [559/2000], Avg Train Loss: 3.7897\n",
      "Epoch [559/2000], Avg Val Loss: 2.2878\n",
      "Validation loss improved from 2.2883 to 2.2878. Saving model...\n",
      "\n",
      "LOG: Epoch [560/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7913\n",
      "    Batch [2/2], Train Loss: 3.7897\n",
      "Epoch [560/2000], Avg Train Loss: 3.7905\n",
      "Epoch [560/2000], Avg Val Loss: 2.2872\n",
      "Validation loss improved from 2.2878 to 2.2872. Saving model...\n",
      "\n",
      "LOG: Epoch [561/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7841\n",
      "    Batch [2/2], Train Loss: 3.7969\n",
      "Epoch [561/2000], Avg Train Loss: 3.7905\n",
      "Epoch [561/2000], Avg Val Loss: 2.2867\n",
      "Validation loss improved from 2.2872 to 2.2867. Saving model...\n",
      "\n",
      "LOG: Epoch [562/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8111\n",
      "    Batch [2/2], Train Loss: 3.7797\n",
      "Epoch [562/2000], Avg Train Loss: 3.7954\n",
      "Epoch [562/2000], Avg Val Loss: 2.2860\n",
      "Validation loss improved from 2.2867 to 2.2860. Saving model...\n",
      "\n",
      "LOG: Epoch [563/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7728\n",
      "    Batch [2/2], Train Loss: 3.8090\n",
      "Epoch [563/2000], Avg Train Loss: 3.7909\n",
      "Epoch [563/2000], Avg Val Loss: 2.2853\n",
      "Validation loss improved from 2.2860 to 2.2853. Saving model...\n",
      "\n",
      "LOG: Epoch [564/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7546\n",
      "    Batch [2/2], Train Loss: 3.7402\n",
      "Epoch [564/2000], Avg Train Loss: 3.7474\n",
      "Epoch [564/2000], Avg Val Loss: 2.2846\n",
      "Validation loss improved from 2.2853 to 2.2846. Saving model...\n",
      "\n",
      "LOG: Epoch [565/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7784\n",
      "    Batch [2/2], Train Loss: 3.7648\n",
      "Epoch [565/2000], Avg Train Loss: 3.7716\n",
      "Epoch [565/2000], Avg Val Loss: 2.2838\n",
      "Validation loss improved from 2.2846 to 2.2838. Saving model...\n",
      "\n",
      "LOG: Epoch [566/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7553\n",
      "    Batch [2/2], Train Loss: 3.7983\n",
      "Epoch [566/2000], Avg Train Loss: 3.7768\n",
      "Epoch [566/2000], Avg Val Loss: 2.2830\n",
      "Validation loss improved from 2.2838 to 2.2830. Saving model...\n",
      "\n",
      "LOG: Epoch [567/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7281\n",
      "    Batch [2/2], Train Loss: 3.7760\n",
      "Epoch [567/2000], Avg Train Loss: 3.7521\n",
      "Epoch [567/2000], Avg Val Loss: 2.2821\n",
      "Validation loss improved from 2.2830 to 2.2821. Saving model...\n",
      "\n",
      "LOG: Epoch [568/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7280\n",
      "    Batch [2/2], Train Loss: 3.7830\n",
      "Epoch [568/2000], Avg Train Loss: 3.7555\n",
      "Epoch [568/2000], Avg Val Loss: 2.2813\n",
      "Validation loss improved from 2.2821 to 2.2813. Saving model...\n",
      "\n",
      "LOG: Epoch [569/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8042\n",
      "    Batch [2/2], Train Loss: 3.7818\n",
      "Epoch [569/2000], Avg Train Loss: 3.7930\n",
      "Epoch [569/2000], Avg Val Loss: 2.2805\n",
      "Validation loss improved from 2.2813 to 2.2805. Saving model...\n",
      "\n",
      "LOG: Epoch [570/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8120\n",
      "    Batch [2/2], Train Loss: 3.7706\n",
      "Epoch [570/2000], Avg Train Loss: 3.7913\n",
      "Epoch [570/2000], Avg Val Loss: 2.2797\n",
      "Validation loss improved from 2.2805 to 2.2797. Saving model...\n",
      "\n",
      "LOG: Epoch [571/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8139\n",
      "    Batch [2/2], Train Loss: 3.7926\n",
      "Epoch [571/2000], Avg Train Loss: 3.8032\n",
      "Epoch [571/2000], Avg Val Loss: 2.2790\n",
      "Validation loss improved from 2.2797 to 2.2790. Saving model...\n",
      "\n",
      "LOG: Epoch [572/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7631\n",
      "    Batch [2/2], Train Loss: 3.7546\n",
      "Epoch [572/2000], Avg Train Loss: 3.7588\n",
      "Epoch [572/2000], Avg Val Loss: 2.2782\n",
      "Validation loss improved from 2.2790 to 2.2782. Saving model...\n",
      "\n",
      "LOG: Epoch [573/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7703\n",
      "    Batch [2/2], Train Loss: 3.7663\n",
      "Epoch [573/2000], Avg Train Loss: 3.7683\n",
      "Epoch [573/2000], Avg Val Loss: 2.2774\n",
      "Validation loss improved from 2.2782 to 2.2774. Saving model...\n",
      "\n",
      "LOG: Epoch [574/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7926\n",
      "    Batch [2/2], Train Loss: 3.7488\n",
      "Epoch [574/2000], Avg Train Loss: 3.7707\n",
      "Epoch [574/2000], Avg Val Loss: 2.2765\n",
      "Validation loss improved from 2.2774 to 2.2765. Saving model...\n",
      "\n",
      "LOG: Epoch [575/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7680\n",
      "    Batch [2/2], Train Loss: 3.7361\n",
      "Epoch [575/2000], Avg Train Loss: 3.7520\n",
      "Epoch [575/2000], Avg Val Loss: 2.2754\n",
      "Validation loss improved from 2.2765 to 2.2754. Saving model...\n",
      "\n",
      "LOG: Epoch [576/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.7635\n",
      "    Batch [2/2], Train Loss: 3.7775\n",
      "Epoch [576/2000], Avg Train Loss: 3.7705\n",
      "Epoch [576/2000], Avg Val Loss: 2.2744\n",
      "Validation loss improved from 2.2754 to 2.2744. Saving model...\n",
      "\n",
      "LOG: Epoch [577/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7923\n",
      "    Batch [2/2], Train Loss: 3.7679\n",
      "Epoch [577/2000], Avg Train Loss: 3.7801\n",
      "Epoch [577/2000], Avg Val Loss: 2.2737\n",
      "Validation loss improved from 2.2744 to 2.2737. Saving model...\n",
      "\n",
      "LOG: Epoch [578/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7382\n",
      "    Batch [2/2], Train Loss: 3.7845\n",
      "Epoch [578/2000], Avg Train Loss: 3.7614\n",
      "Epoch [578/2000], Avg Val Loss: 2.2731\n",
      "Validation loss improved from 2.2737 to 2.2731. Saving model...\n",
      "\n",
      "LOG: Epoch [579/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7841\n",
      "    Batch [2/2], Train Loss: 3.7772\n",
      "Epoch [579/2000], Avg Train Loss: 3.7806\n",
      "Epoch [579/2000], Avg Val Loss: 2.2726\n",
      "Validation loss improved from 2.2731 to 2.2726. Saving model...\n",
      "\n",
      "LOG: Epoch [580/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7852\n",
      "    Batch [2/2], Train Loss: 3.7715\n",
      "Epoch [580/2000], Avg Train Loss: 3.7784\n",
      "Epoch [580/2000], Avg Val Loss: 2.2721\n",
      "Validation loss improved from 2.2726 to 2.2721. Saving model...\n",
      "\n",
      "LOG: Epoch [581/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7883\n",
      "    Batch [2/2], Train Loss: 3.7714\n",
      "Epoch [581/2000], Avg Train Loss: 3.7798\n",
      "Epoch [581/2000], Avg Val Loss: 2.2717\n",
      "Validation loss improved from 2.2721 to 2.2717. Saving model...\n",
      "\n",
      "LOG: Epoch [582/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7562\n",
      "    Batch [2/2], Train Loss: 3.7468\n",
      "Epoch [582/2000], Avg Train Loss: 3.7515\n",
      "Epoch [582/2000], Avg Val Loss: 2.2713\n",
      "Validation loss improved from 2.2717 to 2.2713. Saving model...\n",
      "\n",
      "LOG: Epoch [583/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7277\n",
      "    Batch [2/2], Train Loss: 3.8013\n",
      "Epoch [583/2000], Avg Train Loss: 3.7645\n",
      "Epoch [583/2000], Avg Val Loss: 2.2708\n",
      "Validation loss improved from 2.2713 to 2.2708. Saving model...\n",
      "\n",
      "LOG: Epoch [584/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7690\n",
      "    Batch [2/2], Train Loss: 3.7314\n",
      "Epoch [584/2000], Avg Train Loss: 3.7502\n",
      "Epoch [584/2000], Avg Val Loss: 2.2703\n",
      "Validation loss improved from 2.2708 to 2.2703. Saving model...\n",
      "\n",
      "LOG: Epoch [585/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7799\n",
      "    Batch [2/2], Train Loss: 3.8139\n",
      "Epoch [585/2000], Avg Train Loss: 3.7969\n",
      "Epoch [585/2000], Avg Val Loss: 2.2700\n",
      "Validation loss improved from 2.2703 to 2.2700. Saving model...\n",
      "\n",
      "LOG: Epoch [586/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7908\n",
      "    Batch [2/2], Train Loss: 3.7922\n",
      "Epoch [586/2000], Avg Train Loss: 3.7915\n",
      "Epoch [586/2000], Avg Val Loss: 2.2697\n",
      "Validation loss improved from 2.2700 to 2.2697. Saving model...\n",
      "\n",
      "LOG: Epoch [587/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7936\n",
      "    Batch [2/2], Train Loss: 3.7691\n",
      "Epoch [587/2000], Avg Train Loss: 3.7813\n",
      "Epoch [587/2000], Avg Val Loss: 2.2694\n",
      "Validation loss improved from 2.2697 to 2.2694. Saving model...\n",
      "\n",
      "LOG: Epoch [588/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.8047\n",
      "    Batch [2/2], Train Loss: 3.7838\n",
      "Epoch [588/2000], Avg Train Loss: 3.7943\n",
      "Epoch [588/2000], Avg Val Loss: 2.2690\n",
      "Validation loss improved from 2.2694 to 2.2690. Saving model...\n",
      "\n",
      "LOG: Epoch [589/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.7004\n",
      "Epoch [589/2000], Avg Train Loss: 3.7185\n",
      "Epoch [589/2000], Avg Val Loss: 2.2685\n",
      "Validation loss improved from 2.2690 to 2.2685. Saving model...\n",
      "\n",
      "LOG: Epoch [590/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7799\n",
      "    Batch [2/2], Train Loss: 3.7950\n",
      "Epoch [590/2000], Avg Train Loss: 3.7875\n",
      "Epoch [590/2000], Avg Val Loss: 2.2680\n",
      "Validation loss improved from 2.2685 to 2.2680. Saving model...\n",
      "\n",
      "LOG: Epoch [591/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7497\n",
      "    Batch [2/2], Train Loss: 3.7654\n",
      "Epoch [591/2000], Avg Train Loss: 3.7576\n",
      "Epoch [591/2000], Avg Val Loss: 2.2674\n",
      "Validation loss improved from 2.2680 to 2.2674. Saving model...\n",
      "\n",
      "LOG: Epoch [592/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7332\n",
      "    Batch [2/2], Train Loss: 3.6966\n",
      "Epoch [592/2000], Avg Train Loss: 3.7149\n",
      "Epoch [592/2000], Avg Val Loss: 2.2668\n",
      "Validation loss improved from 2.2674 to 2.2668. Saving model...\n",
      "\n",
      "LOG: Epoch [593/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7218\n",
      "    Batch [2/2], Train Loss: 3.7663\n",
      "Epoch [593/2000], Avg Train Loss: 3.7440\n",
      "Epoch [593/2000], Avg Val Loss: 2.2661\n",
      "Validation loss improved from 2.2668 to 2.2661. Saving model...\n",
      "\n",
      "LOG: Epoch [594/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7684\n",
      "    Batch [2/2], Train Loss: 3.7910\n",
      "Epoch [594/2000], Avg Train Loss: 3.7797\n",
      "Epoch [594/2000], Avg Val Loss: 2.2655\n",
      "Validation loss improved from 2.2661 to 2.2655. Saving model...\n",
      "\n",
      "LOG: Epoch [595/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7676\n",
      "    Batch [2/2], Train Loss: 3.7292\n",
      "Epoch [595/2000], Avg Train Loss: 3.7484\n",
      "Epoch [595/2000], Avg Val Loss: 2.2650\n",
      "Validation loss improved from 2.2655 to 2.2650. Saving model...\n",
      "\n",
      "LOG: Epoch [596/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7236\n",
      "    Batch [2/2], Train Loss: 3.7738\n",
      "Epoch [596/2000], Avg Train Loss: 3.7487\n",
      "Epoch [596/2000], Avg Val Loss: 2.2644\n",
      "Validation loss improved from 2.2650 to 2.2644. Saving model...\n",
      "\n",
      "LOG: Epoch [597/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7367\n",
      "    Batch [2/2], Train Loss: 3.6931\n",
      "Epoch [597/2000], Avg Train Loss: 3.7149\n",
      "Epoch [597/2000], Avg Val Loss: 2.2638\n",
      "Validation loss improved from 2.2644 to 2.2638. Saving model...\n",
      "\n",
      "LOG: Epoch [598/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7334\n",
      "    Batch [2/2], Train Loss: 3.7794\n",
      "Epoch [598/2000], Avg Train Loss: 3.7564\n",
      "Epoch [598/2000], Avg Val Loss: 2.2633\n",
      "Validation loss improved from 2.2638 to 2.2633. Saving model...\n",
      "\n",
      "LOG: Epoch [599/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7153\n",
      "    Batch [2/2], Train Loss: 3.7805\n",
      "Epoch [599/2000], Avg Train Loss: 3.7479\n",
      "Epoch [599/2000], Avg Val Loss: 2.2628\n",
      "Validation loss improved from 2.2633 to 2.2628. Saving model...\n",
      "\n",
      "LOG: Epoch [600/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7958\n",
      "    Batch [2/2], Train Loss: 3.7829\n",
      "Epoch [600/2000], Avg Train Loss: 3.7893\n",
      "Epoch [600/2000], Avg Val Loss: 2.2622\n",
      "Validation loss improved from 2.2628 to 2.2622. Saving model...\n",
      "\n",
      "LOG: Epoch [601/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7707\n",
      "    Batch [2/2], Train Loss: 3.7385\n",
      "Epoch [601/2000], Avg Train Loss: 3.7546\n",
      "Epoch [601/2000], Avg Val Loss: 2.2615\n",
      "Validation loss improved from 2.2622 to 2.2615. Saving model...\n",
      "\n",
      "LOG: Epoch [602/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7532\n",
      "    Batch [2/2], Train Loss: 3.7445\n",
      "Epoch [602/2000], Avg Train Loss: 3.7488\n",
      "Epoch [602/2000], Avg Val Loss: 2.2608\n",
      "Validation loss improved from 2.2615 to 2.2608. Saving model...\n",
      "\n",
      "LOG: Epoch [603/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7289\n",
      "    Batch [2/2], Train Loss: 3.7437\n",
      "Epoch [603/2000], Avg Train Loss: 3.7363\n",
      "Epoch [603/2000], Avg Val Loss: 2.2602\n",
      "Validation loss improved from 2.2608 to 2.2602. Saving model...\n",
      "\n",
      "LOG: Epoch [604/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7313\n",
      "    Batch [2/2], Train Loss: 3.6950\n",
      "Epoch [604/2000], Avg Train Loss: 3.7132\n",
      "Epoch [604/2000], Avg Val Loss: 2.2598\n",
      "Validation loss improved from 2.2602 to 2.2598. Saving model...\n",
      "\n",
      "LOG: Epoch [605/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7636\n",
      "    Batch [2/2], Train Loss: 3.7393\n",
      "Epoch [605/2000], Avg Train Loss: 3.7515\n",
      "Epoch [605/2000], Avg Val Loss: 2.2592\n",
      "Validation loss improved from 2.2598 to 2.2592. Saving model...\n",
      "\n",
      "LOG: Epoch [606/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7319\n",
      "    Batch [2/2], Train Loss: 3.7693\n",
      "Epoch [606/2000], Avg Train Loss: 3.7506\n",
      "Epoch [606/2000], Avg Val Loss: 2.2586\n",
      "Validation loss improved from 2.2592 to 2.2586. Saving model...\n",
      "\n",
      "LOG: Epoch [607/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.7243\n",
      "    Batch [2/2], Train Loss: 3.7489\n",
      "Epoch [607/2000], Avg Train Loss: 3.7366\n",
      "Epoch [607/2000], Avg Val Loss: 2.2578\n",
      "Validation loss improved from 2.2586 to 2.2578. Saving model...\n",
      "\n",
      "LOG: Epoch [608/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7517\n",
      "    Batch [2/2], Train Loss: 3.7572\n",
      "Epoch [608/2000], Avg Train Loss: 3.7545\n",
      "Epoch [608/2000], Avg Val Loss: 2.2570\n",
      "Validation loss improved from 2.2578 to 2.2570. Saving model...\n",
      "\n",
      "LOG: Epoch [609/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7586\n",
      "    Batch [2/2], Train Loss: 3.7267\n",
      "Epoch [609/2000], Avg Train Loss: 3.7427\n",
      "Epoch [609/2000], Avg Val Loss: 2.2562\n",
      "Validation loss improved from 2.2570 to 2.2562. Saving model...\n",
      "\n",
      "LOG: Epoch [610/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7268\n",
      "    Batch [2/2], Train Loss: 3.7259\n",
      "Epoch [610/2000], Avg Train Loss: 3.7264\n",
      "Epoch [610/2000], Avg Val Loss: 2.2554\n",
      "Validation loss improved from 2.2562 to 2.2554. Saving model...\n",
      "\n",
      "LOG: Epoch [611/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7085\n",
      "    Batch [2/2], Train Loss: 3.6928\n",
      "Epoch [611/2000], Avg Train Loss: 3.7006\n",
      "Epoch [611/2000], Avg Val Loss: 2.2545\n",
      "Validation loss improved from 2.2554 to 2.2545. Saving model...\n",
      "\n",
      "LOG: Epoch [612/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7871\n",
      "    Batch [2/2], Train Loss: 3.7095\n",
      "Epoch [612/2000], Avg Train Loss: 3.7483\n",
      "Epoch [612/2000], Avg Val Loss: 2.2537\n",
      "Validation loss improved from 2.2545 to 2.2537. Saving model...\n",
      "\n",
      "LOG: Epoch [613/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7193\n",
      "    Batch [2/2], Train Loss: 3.7099\n",
      "Epoch [613/2000], Avg Train Loss: 3.7146\n",
      "Epoch [613/2000], Avg Val Loss: 2.2529\n",
      "Validation loss improved from 2.2537 to 2.2529. Saving model...\n",
      "\n",
      "LOG: Epoch [614/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7687\n",
      "    Batch [2/2], Train Loss: 3.7377\n",
      "Epoch [614/2000], Avg Train Loss: 3.7532\n",
      "Epoch [614/2000], Avg Val Loss: 2.2522\n",
      "Validation loss improved from 2.2529 to 2.2522. Saving model...\n",
      "\n",
      "LOG: Epoch [615/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7121\n",
      "    Batch [2/2], Train Loss: 3.7381\n",
      "Epoch [615/2000], Avg Train Loss: 3.7251\n",
      "Epoch [615/2000], Avg Val Loss: 2.2515\n",
      "Validation loss improved from 2.2522 to 2.2515. Saving model...\n",
      "\n",
      "LOG: Epoch [616/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6998\n",
      "    Batch [2/2], Train Loss: 3.7649\n",
      "Epoch [616/2000], Avg Train Loss: 3.7323\n",
      "Epoch [616/2000], Avg Val Loss: 2.2507\n",
      "Validation loss improved from 2.2515 to 2.2507. Saving model...\n",
      "\n",
      "LOG: Epoch [617/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7265\n",
      "    Batch [2/2], Train Loss: 3.7400\n",
      "Epoch [617/2000], Avg Train Loss: 3.7332\n",
      "Epoch [617/2000], Avg Val Loss: 2.2501\n",
      "Validation loss improved from 2.2507 to 2.2501. Saving model...\n",
      "\n",
      "LOG: Epoch [618/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7195\n",
      "    Batch [2/2], Train Loss: 3.7473\n",
      "Epoch [618/2000], Avg Train Loss: 3.7334\n",
      "Epoch [618/2000], Avg Val Loss: 2.2496\n",
      "Validation loss improved from 2.2501 to 2.2496. Saving model...\n",
      "\n",
      "LOG: Epoch [619/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7305\n",
      "    Batch [2/2], Train Loss: 3.7871\n",
      "Epoch [619/2000], Avg Train Loss: 3.7588\n",
      "Epoch [619/2000], Avg Val Loss: 2.2492\n",
      "Validation loss improved from 2.2496 to 2.2492. Saving model...\n",
      "\n",
      "LOG: Epoch [620/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7142\n",
      "    Batch [2/2], Train Loss: 3.7484\n",
      "Epoch [620/2000], Avg Train Loss: 3.7313\n",
      "Epoch [620/2000], Avg Val Loss: 2.2488\n",
      "Validation loss improved from 2.2492 to 2.2488. Saving model...\n",
      "\n",
      "LOG: Epoch [621/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7909\n",
      "    Batch [2/2], Train Loss: 3.7072\n",
      "Epoch [621/2000], Avg Train Loss: 3.7491\n",
      "Epoch [621/2000], Avg Val Loss: 2.2483\n",
      "Validation loss improved from 2.2488 to 2.2483. Saving model...\n",
      "\n",
      "LOG: Epoch [622/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7344\n",
      "    Batch [2/2], Train Loss: 3.7418\n",
      "Epoch [622/2000], Avg Train Loss: 3.7381\n",
      "Epoch [622/2000], Avg Val Loss: 2.2477\n",
      "Validation loss improved from 2.2483 to 2.2477. Saving model...\n",
      "\n",
      "LOG: Epoch [623/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7180\n",
      "    Batch [2/2], Train Loss: 3.7305\n",
      "Epoch [623/2000], Avg Train Loss: 3.7243\n",
      "Epoch [623/2000], Avg Val Loss: 2.2472\n",
      "Validation loss improved from 2.2477 to 2.2472. Saving model...\n",
      "\n",
      "LOG: Epoch [624/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7296\n",
      "    Batch [2/2], Train Loss: 3.7283\n",
      "Epoch [624/2000], Avg Train Loss: 3.7290\n",
      "Epoch [624/2000], Avg Val Loss: 2.2465\n",
      "Validation loss improved from 2.2472 to 2.2465. Saving model...\n",
      "\n",
      "LOG: Epoch [625/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6878\n",
      "    Batch [2/2], Train Loss: 3.7305\n",
      "Epoch [625/2000], Avg Train Loss: 3.7092\n",
      "Epoch [625/2000], Avg Val Loss: 2.2459\n",
      "Validation loss improved from 2.2465 to 2.2459. Saving model...\n",
      "\n",
      "LOG: Epoch [626/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.7140\n",
      "    Batch [2/2], Train Loss: 3.7396\n",
      "Epoch [626/2000], Avg Train Loss: 3.7268\n",
      "Epoch [626/2000], Avg Val Loss: 2.2451\n",
      "Validation loss improved from 2.2459 to 2.2451. Saving model...\n",
      "\n",
      "LOG: Epoch [627/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7286\n",
      "    Batch [2/2], Train Loss: 3.6748\n",
      "Epoch [627/2000], Avg Train Loss: 3.7017\n",
      "Epoch [627/2000], Avg Val Loss: 2.2444\n",
      "Validation loss improved from 2.2451 to 2.2444. Saving model...\n",
      "\n",
      "LOG: Epoch [628/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7178\n",
      "    Batch [2/2], Train Loss: 3.6985\n",
      "Epoch [628/2000], Avg Train Loss: 3.7081\n",
      "Epoch [628/2000], Avg Val Loss: 2.2436\n",
      "Validation loss improved from 2.2444 to 2.2436. Saving model...\n",
      "\n",
      "LOG: Epoch [629/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7087\n",
      "    Batch [2/2], Train Loss: 3.6833\n",
      "Epoch [629/2000], Avg Train Loss: 3.6960\n",
      "Epoch [629/2000], Avg Val Loss: 2.2429\n",
      "Validation loss improved from 2.2436 to 2.2429. Saving model...\n",
      "\n",
      "LOG: Epoch [630/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6900\n",
      "    Batch [2/2], Train Loss: 3.7184\n",
      "Epoch [630/2000], Avg Train Loss: 3.7042\n",
      "Epoch [630/2000], Avg Val Loss: 2.2421\n",
      "Validation loss improved from 2.2429 to 2.2421. Saving model...\n",
      "\n",
      "LOG: Epoch [631/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6927\n",
      "    Batch [2/2], Train Loss: 3.7098\n",
      "Epoch [631/2000], Avg Train Loss: 3.7013\n",
      "Epoch [631/2000], Avg Val Loss: 2.2413\n",
      "Validation loss improved from 2.2421 to 2.2413. Saving model...\n",
      "\n",
      "LOG: Epoch [632/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6929\n",
      "    Batch [2/2], Train Loss: 3.7786\n",
      "Epoch [632/2000], Avg Train Loss: 3.7358\n",
      "Epoch [632/2000], Avg Val Loss: 2.2407\n",
      "Validation loss improved from 2.2413 to 2.2407. Saving model...\n",
      "\n",
      "LOG: Epoch [633/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6987\n",
      "    Batch [2/2], Train Loss: 3.7007\n",
      "Epoch [633/2000], Avg Train Loss: 3.6997\n",
      "Epoch [633/2000], Avg Val Loss: 2.2401\n",
      "Validation loss improved from 2.2407 to 2.2401. Saving model...\n",
      "\n",
      "LOG: Epoch [634/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7357\n",
      "    Batch [2/2], Train Loss: 3.7222\n",
      "Epoch [634/2000], Avg Train Loss: 3.7289\n",
      "Epoch [634/2000], Avg Val Loss: 2.2397\n",
      "Validation loss improved from 2.2401 to 2.2397. Saving model...\n",
      "\n",
      "LOG: Epoch [635/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6819\n",
      "    Batch [2/2], Train Loss: 3.7489\n",
      "Epoch [635/2000], Avg Train Loss: 3.7154\n",
      "Epoch [635/2000], Avg Val Loss: 2.2395\n",
      "Validation loss improved from 2.2397 to 2.2395. Saving model...\n",
      "\n",
      "LOG: Epoch [636/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7087\n",
      "    Batch [2/2], Train Loss: 3.7304\n",
      "Epoch [636/2000], Avg Train Loss: 3.7195\n",
      "Epoch [636/2000], Avg Val Loss: 2.2391\n",
      "Validation loss improved from 2.2395 to 2.2391. Saving model...\n",
      "\n",
      "LOG: Epoch [637/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7403\n",
      "    Batch [2/2], Train Loss: 3.6863\n",
      "Epoch [637/2000], Avg Train Loss: 3.7133\n",
      "Epoch [637/2000], Avg Val Loss: 2.2387\n",
      "Validation loss improved from 2.2391 to 2.2387. Saving model...\n",
      "\n",
      "LOG: Epoch [638/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6996\n",
      "    Batch [2/2], Train Loss: 3.7075\n",
      "Epoch [638/2000], Avg Train Loss: 3.7036\n",
      "Epoch [638/2000], Avg Val Loss: 2.2384\n",
      "Validation loss improved from 2.2387 to 2.2384. Saving model...\n",
      "\n",
      "LOG: Epoch [639/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7094\n",
      "    Batch [2/2], Train Loss: 3.6768\n",
      "Epoch [639/2000], Avg Train Loss: 3.6931\n",
      "Epoch [639/2000], Avg Val Loss: 2.2381\n",
      "Validation loss improved from 2.2384 to 2.2381. Saving model...\n",
      "\n",
      "LOG: Epoch [640/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6991\n",
      "    Batch [2/2], Train Loss: 3.6729\n",
      "Epoch [640/2000], Avg Train Loss: 3.6860\n",
      "Epoch [640/2000], Avg Val Loss: 2.2379\n",
      "Validation loss improved from 2.2381 to 2.2379. Saving model...\n",
      "\n",
      "LOG: Epoch [641/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6784\n",
      "    Batch [2/2], Train Loss: 3.7171\n",
      "Epoch [641/2000], Avg Train Loss: 3.6978\n",
      "Epoch [641/2000], Avg Val Loss: 2.2375\n",
      "Validation loss improved from 2.2379 to 2.2375. Saving model...\n",
      "\n",
      "LOG: Epoch [642/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6878\n",
      "    Batch [2/2], Train Loss: 3.7426\n",
      "Epoch [642/2000], Avg Train Loss: 3.7152\n",
      "Epoch [642/2000], Avg Val Loss: 2.2371\n",
      "Validation loss improved from 2.2375 to 2.2371. Saving model...\n",
      "\n",
      "LOG: Epoch [643/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7188\n",
      "    Batch [2/2], Train Loss: 3.6960\n",
      "Epoch [643/2000], Avg Train Loss: 3.7074\n",
      "Epoch [643/2000], Avg Val Loss: 2.2364\n",
      "Validation loss improved from 2.2371 to 2.2364. Saving model...\n",
      "\n",
      "LOG: Epoch [644/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6946\n",
      "    Batch [2/2], Train Loss: 3.6969\n",
      "Epoch [644/2000], Avg Train Loss: 3.6958\n",
      "Epoch [644/2000], Avg Val Loss: 2.2357\n",
      "Validation loss improved from 2.2364 to 2.2357. Saving model...\n",
      "\n",
      "LOG: Epoch [645/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.6878\n",
      "    Batch [2/2], Train Loss: 3.7760\n",
      "Epoch [645/2000], Avg Train Loss: 3.7319\n",
      "Epoch [645/2000], Avg Val Loss: 2.2350\n",
      "Validation loss improved from 2.2357 to 2.2350. Saving model...\n",
      "\n",
      "LOG: Epoch [646/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7294\n",
      "    Batch [2/2], Train Loss: 3.6789\n",
      "Epoch [646/2000], Avg Train Loss: 3.7041\n",
      "Epoch [646/2000], Avg Val Loss: 2.2344\n",
      "Validation loss improved from 2.2350 to 2.2344. Saving model...\n",
      "\n",
      "LOG: Epoch [647/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7307\n",
      "    Batch [2/2], Train Loss: 3.7231\n",
      "Epoch [647/2000], Avg Train Loss: 3.7269\n",
      "Epoch [647/2000], Avg Val Loss: 2.2340\n",
      "Validation loss improved from 2.2344 to 2.2340. Saving model...\n",
      "\n",
      "LOG: Epoch [648/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6973\n",
      "    Batch [2/2], Train Loss: 3.7274\n",
      "Epoch [648/2000], Avg Train Loss: 3.7123\n",
      "Epoch [648/2000], Avg Val Loss: 2.2334\n",
      "Validation loss improved from 2.2340 to 2.2334. Saving model...\n",
      "\n",
      "LOG: Epoch [649/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7077\n",
      "    Batch [2/2], Train Loss: 3.7423\n",
      "Epoch [649/2000], Avg Train Loss: 3.7250\n",
      "Epoch [649/2000], Avg Val Loss: 2.2328\n",
      "Validation loss improved from 2.2334 to 2.2328. Saving model...\n",
      "\n",
      "LOG: Epoch [650/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6951\n",
      "    Batch [2/2], Train Loss: 3.6676\n",
      "Epoch [650/2000], Avg Train Loss: 3.6814\n",
      "Epoch [650/2000], Avg Val Loss: 2.2321\n",
      "Validation loss improved from 2.2328 to 2.2321. Saving model...\n",
      "\n",
      "LOG: Epoch [651/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7078\n",
      "    Batch [2/2], Train Loss: 3.7593\n",
      "Epoch [651/2000], Avg Train Loss: 3.7335\n",
      "Epoch [651/2000], Avg Val Loss: 2.2312\n",
      "Validation loss improved from 2.2321 to 2.2312. Saving model...\n",
      "\n",
      "LOG: Epoch [652/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7338\n",
      "    Batch [2/2], Train Loss: 3.6852\n",
      "Epoch [652/2000], Avg Train Loss: 3.7095\n",
      "Epoch [652/2000], Avg Val Loss: 2.2306\n",
      "Validation loss improved from 2.2312 to 2.2306. Saving model...\n",
      "\n",
      "LOG: Epoch [653/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7218\n",
      "    Batch [2/2], Train Loss: 3.7418\n",
      "Epoch [653/2000], Avg Train Loss: 3.7318\n",
      "Epoch [653/2000], Avg Val Loss: 2.2302\n",
      "Validation loss improved from 2.2306 to 2.2302. Saving model...\n",
      "\n",
      "LOG: Epoch [654/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6975\n",
      "    Batch [2/2], Train Loss: 3.7091\n",
      "Epoch [654/2000], Avg Train Loss: 3.7033\n",
      "Epoch [654/2000], Avg Val Loss: 2.2299\n",
      "Validation loss improved from 2.2302 to 2.2299. Saving model...\n",
      "\n",
      "LOG: Epoch [655/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7158\n",
      "    Batch [2/2], Train Loss: 3.6902\n",
      "Epoch [655/2000], Avg Train Loss: 3.7030\n",
      "Epoch [655/2000], Avg Val Loss: 2.2296\n",
      "Validation loss improved from 2.2299 to 2.2296. Saving model...\n",
      "\n",
      "LOG: Epoch [656/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6964\n",
      "    Batch [2/2], Train Loss: 3.7032\n",
      "Epoch [656/2000], Avg Train Loss: 3.6998\n",
      "Epoch [656/2000], Avg Val Loss: 2.2294\n",
      "Validation loss improved from 2.2296 to 2.2294. Saving model...\n",
      "\n",
      "LOG: Epoch [657/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7292\n",
      "    Batch [2/2], Train Loss: 3.6699\n",
      "Epoch [657/2000], Avg Train Loss: 3.6996\n",
      "Epoch [657/2000], Avg Val Loss: 2.2291\n",
      "Validation loss improved from 2.2294 to 2.2291. Saving model...\n",
      "\n",
      "LOG: Epoch [658/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6561\n",
      "    Batch [2/2], Train Loss: 3.7312\n",
      "Epoch [658/2000], Avg Train Loss: 3.6936\n",
      "Epoch [658/2000], Avg Val Loss: 2.2285\n",
      "Validation loss improved from 2.2291 to 2.2285. Saving model...\n",
      "\n",
      "LOG: Epoch [659/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7020\n",
      "    Batch [2/2], Train Loss: 3.6867\n",
      "Epoch [659/2000], Avg Train Loss: 3.6943\n",
      "Epoch [659/2000], Avg Val Loss: 2.2280\n",
      "Validation loss improved from 2.2285 to 2.2280. Saving model...\n",
      "\n",
      "LOG: Epoch [660/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6926\n",
      "    Batch [2/2], Train Loss: 3.6905\n",
      "Epoch [660/2000], Avg Train Loss: 3.6916\n",
      "Epoch [660/2000], Avg Val Loss: 2.2275\n",
      "Validation loss improved from 2.2280 to 2.2275. Saving model...\n",
      "\n",
      "LOG: Epoch [661/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7173\n",
      "    Batch [2/2], Train Loss: 3.6889\n",
      "Epoch [661/2000], Avg Train Loss: 3.7031\n",
      "Epoch [661/2000], Avg Val Loss: 2.2269\n",
      "Validation loss improved from 2.2275 to 2.2269. Saving model...\n",
      "\n",
      "LOG: Epoch [662/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6403\n",
      "    Batch [2/2], Train Loss: 3.6617\n",
      "Epoch [662/2000], Avg Train Loss: 3.6510\n",
      "Epoch [662/2000], Avg Val Loss: 2.2264\n",
      "Validation loss improved from 2.2269 to 2.2264. Saving model...\n",
      "\n",
      "LOG: Epoch [663/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6966\n",
      "    Batch [2/2], Train Loss: 3.6510\n",
      "Epoch [663/2000], Avg Train Loss: 3.6738\n",
      "Epoch [663/2000], Avg Val Loss: 2.2260\n",
      "Validation loss improved from 2.2264 to 2.2260. Saving model...\n",
      "\n",
      "LOG: Epoch [664/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.6172\n",
      "    Batch [2/2], Train Loss: 3.6847\n",
      "Epoch [664/2000], Avg Train Loss: 3.6509\n",
      "Epoch [664/2000], Avg Val Loss: 2.2256\n",
      "Validation loss improved from 2.2260 to 2.2256. Saving model...\n",
      "\n",
      "LOG: Epoch [665/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7064\n",
      "    Batch [2/2], Train Loss: 3.6692\n",
      "Epoch [665/2000], Avg Train Loss: 3.6878\n",
      "Epoch [665/2000], Avg Val Loss: 2.2251\n",
      "Validation loss improved from 2.2256 to 2.2251. Saving model...\n",
      "\n",
      "LOG: Epoch [666/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6857\n",
      "    Batch [2/2], Train Loss: 3.6731\n",
      "Epoch [666/2000], Avg Train Loss: 3.6794\n",
      "Epoch [666/2000], Avg Val Loss: 2.2244\n",
      "Validation loss improved from 2.2251 to 2.2244. Saving model...\n",
      "\n",
      "LOG: Epoch [667/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6878\n",
      "    Batch [2/2], Train Loss: 3.6785\n",
      "Epoch [667/2000], Avg Train Loss: 3.6831\n",
      "Epoch [667/2000], Avg Val Loss: 2.2235\n",
      "Validation loss improved from 2.2244 to 2.2235. Saving model...\n",
      "\n",
      "LOG: Epoch [668/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6811\n",
      "    Batch [2/2], Train Loss: 3.6665\n",
      "Epoch [668/2000], Avg Train Loss: 3.6738\n",
      "Epoch [668/2000], Avg Val Loss: 2.2228\n",
      "Validation loss improved from 2.2235 to 2.2228. Saving model...\n",
      "\n",
      "LOG: Epoch [669/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6693\n",
      "    Batch [2/2], Train Loss: 3.6585\n",
      "Epoch [669/2000], Avg Train Loss: 3.6639\n",
      "Epoch [669/2000], Avg Val Loss: 2.2222\n",
      "Validation loss improved from 2.2228 to 2.2222. Saving model...\n",
      "\n",
      "LOG: Epoch [670/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6857\n",
      "    Batch [2/2], Train Loss: 3.6981\n",
      "Epoch [670/2000], Avg Train Loss: 3.6919\n",
      "Epoch [670/2000], Avg Val Loss: 2.2218\n",
      "Validation loss improved from 2.2222 to 2.2218. Saving model...\n",
      "\n",
      "LOG: Epoch [671/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6649\n",
      "    Batch [2/2], Train Loss: 3.6803\n",
      "Epoch [671/2000], Avg Train Loss: 3.6726\n",
      "Epoch [671/2000], Avg Val Loss: 2.2214\n",
      "Validation loss improved from 2.2218 to 2.2214. Saving model...\n",
      "\n",
      "LOG: Epoch [672/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6762\n",
      "    Batch [2/2], Train Loss: 3.7406\n",
      "Epoch [672/2000], Avg Train Loss: 3.7084\n",
      "Epoch [672/2000], Avg Val Loss: 2.2212\n",
      "Validation loss improved from 2.2214 to 2.2212. Saving model...\n",
      "\n",
      "LOG: Epoch [673/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7250\n",
      "    Batch [2/2], Train Loss: 3.6472\n",
      "Epoch [673/2000], Avg Train Loss: 3.6861\n",
      "Epoch [673/2000], Avg Val Loss: 2.2210\n",
      "Validation loss improved from 2.2212 to 2.2210. Saving model...\n",
      "\n",
      "LOG: Epoch [674/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6374\n",
      "    Batch [2/2], Train Loss: 3.6738\n",
      "Epoch [674/2000], Avg Train Loss: 3.6556\n",
      "Epoch [674/2000], Avg Val Loss: 2.2210\n",
      "Validation loss improved from 2.2210 to 2.2210. Saving model...\n",
      "\n",
      "LOG: Epoch [675/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6453\n",
      "    Batch [2/2], Train Loss: 3.6714\n",
      "Epoch [675/2000], Avg Train Loss: 3.6584\n",
      "Epoch [675/2000], Avg Val Loss: 2.2209\n",
      "Validation loss improved from 2.2210 to 2.2209. Saving model...\n",
      "\n",
      "LOG: Epoch [676/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6987\n",
      "    Batch [2/2], Train Loss: 3.6494\n",
      "Epoch [676/2000], Avg Train Loss: 3.6741\n",
      "Epoch [676/2000], Avg Val Loss: 2.2208\n",
      "Validation loss improved from 2.2209 to 2.2208. Saving model...\n",
      "\n",
      "LOG: Epoch [677/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6588\n",
      "    Batch [2/2], Train Loss: 3.6715\n",
      "Epoch [677/2000], Avg Train Loss: 3.6652\n",
      "Epoch [677/2000], Avg Val Loss: 2.2206\n",
      "Validation loss improved from 2.2208 to 2.2206. Saving model...\n",
      "\n",
      "LOG: Epoch [678/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7439\n",
      "    Batch [2/2], Train Loss: 3.7054\n",
      "Epoch [678/2000], Avg Train Loss: 3.7247\n",
      "Epoch [678/2000], Avg Val Loss: 2.2204\n",
      "Validation loss improved from 2.2206 to 2.2204. Saving model...\n",
      "\n",
      "LOG: Epoch [679/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6520\n",
      "    Batch [2/2], Train Loss: 3.7119\n",
      "Epoch [679/2000], Avg Train Loss: 3.6819\n",
      "Epoch [679/2000], Avg Val Loss: 2.2202\n",
      "Validation loss improved from 2.2204 to 2.2202. Saving model...\n",
      "\n",
      "LOG: Epoch [680/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6681\n",
      "    Batch [2/2], Train Loss: 3.6689\n",
      "Epoch [680/2000], Avg Train Loss: 3.6685\n",
      "Epoch [680/2000], Avg Val Loss: 2.2201\n",
      "Validation loss improved from 2.2202 to 2.2201. Saving model...\n",
      "\n",
      "LOG: Epoch [681/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6578\n",
      "    Batch [2/2], Train Loss: 3.6604\n",
      "Epoch [681/2000], Avg Train Loss: 3.6591\n",
      "Epoch [681/2000], Avg Val Loss: 2.2199\n",
      "Validation loss improved from 2.2201 to 2.2199. Saving model...\n",
      "\n",
      "LOG: Epoch [682/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.6959\n",
      "Epoch [682/2000], Avg Train Loss: 3.6996\n",
      "Epoch [682/2000], Avg Val Loss: 2.2194\n",
      "Validation loss improved from 2.2199 to 2.2194. Saving model...\n",
      "\n",
      "LOG: Epoch [683/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6650\n",
      "    Batch [2/2], Train Loss: 3.6822\n",
      "Epoch [683/2000], Avg Train Loss: 3.6736\n",
      "Epoch [683/2000], Avg Val Loss: 2.2189\n",
      "Validation loss improved from 2.2194 to 2.2189. Saving model...\n",
      "\n",
      "LOG: Epoch [684/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6593\n",
      "    Batch [2/2], Train Loss: 3.6406\n",
      "Epoch [684/2000], Avg Train Loss: 3.6499\n",
      "Epoch [684/2000], Avg Val Loss: 2.2183\n",
      "Validation loss improved from 2.2189 to 2.2183. Saving model...\n",
      "\n",
      "LOG: Epoch [685/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6873\n",
      "    Batch [2/2], Train Loss: 3.6497\n",
      "Epoch [685/2000], Avg Train Loss: 3.6685\n",
      "Epoch [685/2000], Avg Val Loss: 2.2177\n",
      "Validation loss improved from 2.2183 to 2.2177. Saving model...\n",
      "\n",
      "LOG: Epoch [686/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6734\n",
      "    Batch [2/2], Train Loss: 3.6626\n",
      "Epoch [686/2000], Avg Train Loss: 3.6680\n",
      "Epoch [686/2000], Avg Val Loss: 2.2170\n",
      "Validation loss improved from 2.2177 to 2.2170. Saving model...\n",
      "\n",
      "LOG: Epoch [687/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7185\n",
      "    Batch [2/2], Train Loss: 3.6357\n",
      "Epoch [687/2000], Avg Train Loss: 3.6771\n",
      "Epoch [687/2000], Avg Val Loss: 2.2165\n",
      "Validation loss improved from 2.2170 to 2.2165. Saving model...\n",
      "\n",
      "LOG: Epoch [688/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6456\n",
      "    Batch [2/2], Train Loss: 3.6473\n",
      "Epoch [688/2000], Avg Train Loss: 3.6464\n",
      "Epoch [688/2000], Avg Val Loss: 2.2160\n",
      "Validation loss improved from 2.2165 to 2.2160. Saving model...\n",
      "\n",
      "LOG: Epoch [689/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6328\n",
      "    Batch [2/2], Train Loss: 3.6217\n",
      "Epoch [689/2000], Avg Train Loss: 3.6272\n",
      "Epoch [689/2000], Avg Val Loss: 2.2156\n",
      "Validation loss improved from 2.2160 to 2.2156. Saving model...\n",
      "\n",
      "LOG: Epoch [690/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6347\n",
      "    Batch [2/2], Train Loss: 3.6591\n",
      "Epoch [690/2000], Avg Train Loss: 3.6469\n",
      "Epoch [690/2000], Avg Val Loss: 2.2154\n",
      "Validation loss improved from 2.2156 to 2.2154. Saving model...\n",
      "\n",
      "LOG: Epoch [691/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7007\n",
      "    Batch [2/2], Train Loss: 3.6461\n",
      "Epoch [691/2000], Avg Train Loss: 3.6734\n",
      "Epoch [691/2000], Avg Val Loss: 2.2152\n",
      "Validation loss improved from 2.2154 to 2.2152. Saving model...\n",
      "\n",
      "LOG: Epoch [692/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6441\n",
      "    Batch [2/2], Train Loss: 3.7095\n",
      "Epoch [692/2000], Avg Train Loss: 3.6768\n",
      "Epoch [692/2000], Avg Val Loss: 2.2149\n",
      "Validation loss improved from 2.2152 to 2.2149. Saving model...\n",
      "\n",
      "LOG: Epoch [693/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6307\n",
      "    Batch [2/2], Train Loss: 3.6553\n",
      "Epoch [693/2000], Avg Train Loss: 3.6430\n",
      "Epoch [693/2000], Avg Val Loss: 2.2145\n",
      "Validation loss improved from 2.2149 to 2.2145. Saving model...\n",
      "\n",
      "LOG: Epoch [694/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6461\n",
      "    Batch [2/2], Train Loss: 3.6382\n",
      "Epoch [694/2000], Avg Train Loss: 3.6422\n",
      "Epoch [694/2000], Avg Val Loss: 2.2141\n",
      "Validation loss improved from 2.2145 to 2.2141. Saving model...\n",
      "\n",
      "LOG: Epoch [695/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.7101\n",
      "    Batch [2/2], Train Loss: 3.6700\n",
      "Epoch [695/2000], Avg Train Loss: 3.6900\n",
      "Epoch [695/2000], Avg Val Loss: 2.2135\n",
      "Validation loss improved from 2.2141 to 2.2135. Saving model...\n",
      "\n",
      "LOG: Epoch [696/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6366\n",
      "    Batch [2/2], Train Loss: 3.6347\n",
      "Epoch [696/2000], Avg Train Loss: 3.6356\n",
      "Epoch [696/2000], Avg Val Loss: 2.2128\n",
      "Validation loss improved from 2.2135 to 2.2128. Saving model...\n",
      "\n",
      "LOG: Epoch [697/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6197\n",
      "    Batch [2/2], Train Loss: 3.6321\n",
      "Epoch [697/2000], Avg Train Loss: 3.6259\n",
      "Epoch [697/2000], Avg Val Loss: 2.2122\n",
      "Validation loss improved from 2.2128 to 2.2122. Saving model...\n",
      "\n",
      "LOG: Epoch [698/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6825\n",
      "    Batch [2/2], Train Loss: 3.6522\n",
      "Epoch [698/2000], Avg Train Loss: 3.6674\n",
      "Epoch [698/2000], Avg Val Loss: 2.2117\n",
      "Validation loss improved from 2.2122 to 2.2117. Saving model...\n",
      "\n",
      "LOG: Epoch [699/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6502\n",
      "    Batch [2/2], Train Loss: 3.6229\n",
      "Epoch [699/2000], Avg Train Loss: 3.6365\n",
      "Epoch [699/2000], Avg Val Loss: 2.2115\n",
      "Validation loss improved from 2.2117 to 2.2115. Saving model...\n",
      "\n",
      "LOG: Epoch [700/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.6909\n",
      "Epoch [700/2000], Avg Train Loss: 3.6616\n",
      "Epoch [700/2000], Avg Val Loss: 2.2112\n",
      "Validation loss improved from 2.2115 to 2.2112. Saving model...\n",
      "\n",
      "LOG: Epoch [701/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6443\n",
      "    Batch [2/2], Train Loss: 3.6547\n",
      "Epoch [701/2000], Avg Train Loss: 3.6495\n",
      "Epoch [701/2000], Avg Val Loss: 2.2108\n",
      "Validation loss improved from 2.2112 to 2.2108. Saving model...\n",
      "\n",
      "LOG: Epoch [702/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6411\n",
      "    Batch [2/2], Train Loss: 3.6410\n",
      "Epoch [702/2000], Avg Train Loss: 3.6411\n",
      "Epoch [702/2000], Avg Val Loss: 2.2106\n",
      "Validation loss improved from 2.2108 to 2.2106. Saving model...\n",
      "\n",
      "LOG: Epoch [703/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6559\n",
      "    Batch [2/2], Train Loss: 3.6594\n",
      "Epoch [703/2000], Avg Train Loss: 3.6576\n",
      "Epoch [703/2000], Avg Val Loss: 2.2103\n",
      "Validation loss improved from 2.2106 to 2.2103. Saving model...\n",
      "\n",
      "LOG: Epoch [704/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6470\n",
      "    Batch [2/2], Train Loss: 3.6564\n",
      "Epoch [704/2000], Avg Train Loss: 3.6517\n",
      "Epoch [704/2000], Avg Val Loss: 2.2102\n",
      "Validation loss improved from 2.2103 to 2.2102. Saving model...\n",
      "\n",
      "LOG: Epoch [705/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6471\n",
      "    Batch [2/2], Train Loss: 3.6066\n",
      "Epoch [705/2000], Avg Train Loss: 3.6268\n",
      "Epoch [705/2000], Avg Val Loss: 2.2101\n",
      "Validation loss improved from 2.2102 to 2.2101. Saving model...\n",
      "\n",
      "LOG: Epoch [706/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6624\n",
      "    Batch [2/2], Train Loss: 3.6442\n",
      "Epoch [706/2000], Avg Train Loss: 3.6533\n",
      "Epoch [706/2000], Avg Val Loss: 2.2101\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [707/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6499\n",
      "    Batch [2/2], Train Loss: 3.6574\n",
      "Epoch [707/2000], Avg Train Loss: 3.6536\n",
      "Epoch [707/2000], Avg Val Loss: 2.2103\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [708/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6798\n",
      "    Batch [2/2], Train Loss: 3.6533\n",
      "Epoch [708/2000], Avg Train Loss: 3.6666\n",
      "Epoch [708/2000], Avg Val Loss: 2.2106\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [709/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6553\n",
      "    Batch [2/2], Train Loss: 3.5955\n",
      "Epoch [709/2000], Avg Train Loss: 3.6254\n",
      "Epoch [709/2000], Avg Val Loss: 2.2109\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [710/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6826\n",
      "    Batch [2/2], Train Loss: 3.6537\n",
      "Epoch [710/2000], Avg Train Loss: 3.6682\n",
      "Epoch [710/2000], Avg Val Loss: 2.2111\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [711/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6217\n",
      "    Batch [2/2], Train Loss: 3.6325\n",
      "Epoch [711/2000], Avg Train Loss: 3.6271\n",
      "Epoch [711/2000], Avg Val Loss: 2.2111\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [712/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6509\n",
      "    Batch [2/2], Train Loss: 3.6132\n",
      "Epoch [712/2000], Avg Train Loss: 3.6320\n",
      "Epoch [712/2000], Avg Val Loss: 2.2109\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [713/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6303\n",
      "    Batch [2/2], Train Loss: 3.6836\n",
      "Epoch [713/2000], Avg Train Loss: 3.6569\n",
      "Epoch [713/2000], Avg Val Loss: 2.2108\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [714/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6462\n",
      "    Batch [2/2], Train Loss: 3.6389\n",
      "Epoch [714/2000], Avg Train Loss: 3.6425\n",
      "Epoch [714/2000], Avg Val Loss: 2.2110\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [715/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6349\n",
      "    Batch [2/2], Train Loss: 3.6361\n",
      "Epoch [715/2000], Avg Train Loss: 3.6355\n",
      "Epoch [715/2000], Avg Val Loss: 2.2108\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [716/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6218\n",
      "    Batch [2/2], Train Loss: 3.6448\n",
      "Epoch [716/2000], Avg Train Loss: 3.6333\n",
      "Epoch [716/2000], Avg Val Loss: 2.2105\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [717/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6498\n",
      "    Batch [2/2], Train Loss: 3.6704\n",
      "Epoch [717/2000], Avg Train Loss: 3.6601\n",
      "Epoch [717/2000], Avg Val Loss: 2.2103\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [718/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6242\n",
      "    Batch [2/2], Train Loss: 3.6330\n",
      "Epoch [718/2000], Avg Train Loss: 3.6286\n",
      "Epoch [718/2000], Avg Val Loss: 2.2102\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [719/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.6109\n",
      "    Batch [2/2], Train Loss: 3.6507\n",
      "Epoch [719/2000], Avg Train Loss: 3.6308\n",
      "Epoch [719/2000], Avg Val Loss: 2.2101\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [720/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6888\n",
      "    Batch [2/2], Train Loss: 3.6483\n",
      "Epoch [720/2000], Avg Train Loss: 3.6685\n",
      "Epoch [720/2000], Avg Val Loss: 2.2099\n",
      "Validation loss improved from 2.2101 to 2.2099. Saving model...\n",
      "\n",
      "LOG: Epoch [721/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5772\n",
      "    Batch [2/2], Train Loss: 3.6659\n",
      "Epoch [721/2000], Avg Train Loss: 3.6216\n",
      "Epoch [721/2000], Avg Val Loss: 2.2098\n",
      "Validation loss improved from 2.2099 to 2.2098. Saving model...\n",
      "\n",
      "LOG: Epoch [722/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6145\n",
      "    Batch [2/2], Train Loss: 3.6561\n",
      "Epoch [722/2000], Avg Train Loss: 3.6353\n",
      "Epoch [722/2000], Avg Val Loss: 2.2093\n",
      "Validation loss improved from 2.2098 to 2.2093. Saving model...\n",
      "\n",
      "LOG: Epoch [723/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6326\n",
      "    Batch [2/2], Train Loss: 3.6410\n",
      "Epoch [723/2000], Avg Train Loss: 3.6368\n",
      "Epoch [723/2000], Avg Val Loss: 2.2087\n",
      "Validation loss improved from 2.2093 to 2.2087. Saving model...\n",
      "\n",
      "LOG: Epoch [724/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6433\n",
      "    Batch [2/2], Train Loss: 3.6504\n",
      "Epoch [724/2000], Avg Train Loss: 3.6468\n",
      "Epoch [724/2000], Avg Val Loss: 2.2080\n",
      "Validation loss improved from 2.2087 to 2.2080. Saving model...\n",
      "\n",
      "LOG: Epoch [725/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6293\n",
      "    Batch [2/2], Train Loss: 3.6002\n",
      "Epoch [725/2000], Avg Train Loss: 3.6148\n",
      "Epoch [725/2000], Avg Val Loss: 2.2073\n",
      "Validation loss improved from 2.2080 to 2.2073. Saving model...\n",
      "\n",
      "LOG: Epoch [726/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6098\n",
      "    Batch [2/2], Train Loss: 3.6543\n",
      "Epoch [726/2000], Avg Train Loss: 3.6321\n",
      "Epoch [726/2000], Avg Val Loss: 2.2069\n",
      "Validation loss improved from 2.2073 to 2.2069. Saving model...\n",
      "\n",
      "LOG: Epoch [727/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5743\n",
      "    Batch [2/2], Train Loss: 3.6226\n",
      "Epoch [727/2000], Avg Train Loss: 3.5985\n",
      "Epoch [727/2000], Avg Val Loss: 2.2063\n",
      "Validation loss improved from 2.2069 to 2.2063. Saving model...\n",
      "\n",
      "LOG: Epoch [728/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6296\n",
      "    Batch [2/2], Train Loss: 3.6048\n",
      "Epoch [728/2000], Avg Train Loss: 3.6172\n",
      "Epoch [728/2000], Avg Val Loss: 2.2057\n",
      "Validation loss improved from 2.2063 to 2.2057. Saving model...\n",
      "\n",
      "LOG: Epoch [729/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5930\n",
      "    Batch [2/2], Train Loss: 3.6388\n",
      "Epoch [729/2000], Avg Train Loss: 3.6159\n",
      "Epoch [729/2000], Avg Val Loss: 2.2052\n",
      "Validation loss improved from 2.2057 to 2.2052. Saving model...\n",
      "\n",
      "LOG: Epoch [730/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6667\n",
      "    Batch [2/2], Train Loss: 3.6345\n",
      "Epoch [730/2000], Avg Train Loss: 3.6506\n",
      "Epoch [730/2000], Avg Val Loss: 2.2047\n",
      "Validation loss improved from 2.2052 to 2.2047. Saving model...\n",
      "\n",
      "LOG: Epoch [731/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6303\n",
      "    Batch [2/2], Train Loss: 3.6209\n",
      "Epoch [731/2000], Avg Train Loss: 3.6256\n",
      "Epoch [731/2000], Avg Val Loss: 2.2043\n",
      "Validation loss improved from 2.2047 to 2.2043. Saving model...\n",
      "\n",
      "LOG: Epoch [732/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6307\n",
      "    Batch [2/2], Train Loss: 3.6062\n",
      "Epoch [732/2000], Avg Train Loss: 3.6185\n",
      "Epoch [732/2000], Avg Val Loss: 2.2041\n",
      "Validation loss improved from 2.2043 to 2.2041. Saving model...\n",
      "\n",
      "LOG: Epoch [733/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6183\n",
      "    Batch [2/2], Train Loss: 3.6242\n",
      "Epoch [733/2000], Avg Train Loss: 3.6212\n",
      "Epoch [733/2000], Avg Val Loss: 2.2039\n",
      "Validation loss improved from 2.2041 to 2.2039. Saving model...\n",
      "\n",
      "LOG: Epoch [734/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6042\n",
      "    Batch [2/2], Train Loss: 3.6172\n",
      "Epoch [734/2000], Avg Train Loss: 3.6107\n",
      "Epoch [734/2000], Avg Val Loss: 2.2037\n",
      "Validation loss improved from 2.2039 to 2.2037. Saving model...\n",
      "\n",
      "LOG: Epoch [735/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5929\n",
      "    Batch [2/2], Train Loss: 3.6468\n",
      "Epoch [735/2000], Avg Train Loss: 3.6199\n",
      "Epoch [735/2000], Avg Val Loss: 2.2033\n",
      "Validation loss improved from 2.2037 to 2.2033. Saving model...\n",
      "\n",
      "LOG: Epoch [736/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6401\n",
      "    Batch [2/2], Train Loss: 3.6228\n",
      "Epoch [736/2000], Avg Train Loss: 3.6315\n",
      "Epoch [736/2000], Avg Val Loss: 2.2027\n",
      "Validation loss improved from 2.2033 to 2.2027. Saving model...\n",
      "\n",
      "LOG: Epoch [737/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6116\n",
      "    Batch [2/2], Train Loss: 3.6071\n",
      "Epoch [737/2000], Avg Train Loss: 3.6093\n",
      "Epoch [737/2000], Avg Val Loss: 2.2020\n",
      "Validation loss improved from 2.2027 to 2.2020. Saving model...\n",
      "\n",
      "LOG: Epoch [738/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5846\n",
      "    Batch [2/2], Train Loss: 3.6263\n",
      "Epoch [738/2000], Avg Train Loss: 3.6055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [738/2000], Avg Val Loss: 2.2015\n",
      "Validation loss improved from 2.2020 to 2.2015. Saving model...\n",
      "\n",
      "LOG: Epoch [739/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5970\n",
      "    Batch [2/2], Train Loss: 3.5499\n",
      "Epoch [739/2000], Avg Train Loss: 3.5735\n",
      "Epoch [739/2000], Avg Val Loss: 2.2010\n",
      "Validation loss improved from 2.2015 to 2.2010. Saving model...\n",
      "\n",
      "LOG: Epoch [740/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6504\n",
      "    Batch [2/2], Train Loss: 3.6074\n",
      "Epoch [740/2000], Avg Train Loss: 3.6289\n",
      "Epoch [740/2000], Avg Val Loss: 2.2006\n",
      "Validation loss improved from 2.2010 to 2.2006. Saving model...\n",
      "\n",
      "LOG: Epoch [741/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6028\n",
      "    Batch [2/2], Train Loss: 3.6330\n",
      "Epoch [741/2000], Avg Train Loss: 3.6179\n",
      "Epoch [741/2000], Avg Val Loss: 2.2003\n",
      "Validation loss improved from 2.2006 to 2.2003. Saving model...\n",
      "\n",
      "LOG: Epoch [742/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5929\n",
      "    Batch [2/2], Train Loss: 3.6194\n",
      "Epoch [742/2000], Avg Train Loss: 3.6061\n",
      "Epoch [742/2000], Avg Val Loss: 2.2001\n",
      "Validation loss improved from 2.2003 to 2.2001. Saving model...\n",
      "\n",
      "LOG: Epoch [743/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5881\n",
      "    Batch [2/2], Train Loss: 3.6367\n",
      "Epoch [743/2000], Avg Train Loss: 3.6124\n",
      "Epoch [743/2000], Avg Val Loss: 2.2000\n",
      "Validation loss improved from 2.2001 to 2.2000. Saving model...\n",
      "\n",
      "LOG: Epoch [744/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6235\n",
      "    Batch [2/2], Train Loss: 3.6081\n",
      "Epoch [744/2000], Avg Train Loss: 3.6158\n",
      "Epoch [744/2000], Avg Val Loss: 2.1997\n",
      "Validation loss improved from 2.2000 to 2.1997. Saving model...\n",
      "\n",
      "LOG: Epoch [745/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6229\n",
      "    Batch [2/2], Train Loss: 3.6191\n",
      "Epoch [745/2000], Avg Train Loss: 3.6210\n",
      "Epoch [745/2000], Avg Val Loss: 2.1994\n",
      "Validation loss improved from 2.1997 to 2.1994. Saving model...\n",
      "\n",
      "LOG: Epoch [746/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5926\n",
      "    Batch [2/2], Train Loss: 3.6023\n",
      "Epoch [746/2000], Avg Train Loss: 3.5974\n",
      "Epoch [746/2000], Avg Val Loss: 2.1991\n",
      "Validation loss improved from 2.1994 to 2.1991. Saving model...\n",
      "\n",
      "LOG: Epoch [747/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5981\n",
      "    Batch [2/2], Train Loss: 3.6634\n",
      "Epoch [747/2000], Avg Train Loss: 3.6307\n",
      "Epoch [747/2000], Avg Val Loss: 2.1986\n",
      "Validation loss improved from 2.1991 to 2.1986. Saving model...\n",
      "\n",
      "LOG: Epoch [748/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6728\n",
      "    Batch [2/2], Train Loss: 3.6146\n",
      "Epoch [748/2000], Avg Train Loss: 3.6437\n",
      "Epoch [748/2000], Avg Val Loss: 2.1983\n",
      "Validation loss improved from 2.1986 to 2.1983. Saving model...\n",
      "\n",
      "LOG: Epoch [749/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5710\n",
      "    Batch [2/2], Train Loss: 3.5786\n",
      "Epoch [749/2000], Avg Train Loss: 3.5748\n",
      "Epoch [749/2000], Avg Val Loss: 2.1981\n",
      "Validation loss improved from 2.1983 to 2.1981. Saving model...\n",
      "\n",
      "LOG: Epoch [750/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6437\n",
      "    Batch [2/2], Train Loss: 3.5699\n",
      "Epoch [750/2000], Avg Train Loss: 3.6068\n",
      "Epoch [750/2000], Avg Val Loss: 2.1980\n",
      "Validation loss improved from 2.1981 to 2.1980. Saving model...\n",
      "\n",
      "LOG: Epoch [751/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5676\n",
      "    Batch [2/2], Train Loss: 3.6204\n",
      "Epoch [751/2000], Avg Train Loss: 3.5940\n",
      "Epoch [751/2000], Avg Val Loss: 2.1977\n",
      "Validation loss improved from 2.1980 to 2.1977. Saving model...\n",
      "\n",
      "LOG: Epoch [752/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6394\n",
      "    Batch [2/2], Train Loss: 3.5903\n",
      "Epoch [752/2000], Avg Train Loss: 3.6149\n",
      "Epoch [752/2000], Avg Val Loss: 2.1974\n",
      "Validation loss improved from 2.1977 to 2.1974. Saving model...\n",
      "\n",
      "LOG: Epoch [753/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6501\n",
      "    Batch [2/2], Train Loss: 3.5972\n",
      "Epoch [753/2000], Avg Train Loss: 3.6236\n",
      "Epoch [753/2000], Avg Val Loss: 2.1972\n",
      "Validation loss improved from 2.1974 to 2.1972. Saving model...\n",
      "\n",
      "LOG: Epoch [754/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5874\n",
      "    Batch [2/2], Train Loss: 3.6346\n",
      "Epoch [754/2000], Avg Train Loss: 3.6110\n",
      "Epoch [754/2000], Avg Val Loss: 2.1969\n",
      "Validation loss improved from 2.1972 to 2.1969. Saving model...\n",
      "\n",
      "LOG: Epoch [755/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5956\n",
      "    Batch [2/2], Train Loss: 3.5777\n",
      "Epoch [755/2000], Avg Train Loss: 3.5867\n",
      "Epoch [755/2000], Avg Val Loss: 2.1966\n",
      "Validation loss improved from 2.1969 to 2.1966. Saving model...\n",
      "\n",
      "LOG: Epoch [756/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6100\n",
      "    Batch [2/2], Train Loss: 3.5968\n",
      "Epoch [756/2000], Avg Train Loss: 3.6034\n",
      "Epoch [756/2000], Avg Val Loss: 2.1964\n",
      "Validation loss improved from 2.1966 to 2.1964. Saving model...\n",
      "\n",
      "LOG: Epoch [757/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.6340\n",
      "Epoch [757/2000], Avg Train Loss: 3.6111\n",
      "Epoch [757/2000], Avg Val Loss: 2.1958\n",
      "Validation loss improved from 2.1964 to 2.1958. Saving model...\n",
      "\n",
      "LOG: Epoch [758/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5898\n",
      "    Batch [2/2], Train Loss: 3.6460\n",
      "Epoch [758/2000], Avg Train Loss: 3.6179\n",
      "Epoch [758/2000], Avg Val Loss: 2.1954\n",
      "Validation loss improved from 2.1958 to 2.1954. Saving model...\n",
      "\n",
      "LOG: Epoch [759/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6299\n",
      "    Batch [2/2], Train Loss: 3.6066\n",
      "Epoch [759/2000], Avg Train Loss: 3.6182\n",
      "Epoch [759/2000], Avg Val Loss: 2.1950\n",
      "Validation loss improved from 2.1954 to 2.1950. Saving model...\n",
      "\n",
      "LOG: Epoch [760/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5879\n",
      "    Batch [2/2], Train Loss: 3.6028\n",
      "Epoch [760/2000], Avg Train Loss: 3.5954\n",
      "Epoch [760/2000], Avg Val Loss: 2.1947\n",
      "Validation loss improved from 2.1950 to 2.1947. Saving model...\n",
      "\n",
      "LOG: Epoch [761/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5475\n",
      "    Batch [2/2], Train Loss: 3.5677\n",
      "Epoch [761/2000], Avg Train Loss: 3.5576\n",
      "Epoch [761/2000], Avg Val Loss: 2.1946\n",
      "Validation loss improved from 2.1947 to 2.1946. Saving model...\n",
      "\n",
      "LOG: Epoch [762/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5671\n",
      "    Batch [2/2], Train Loss: 3.5863\n",
      "Epoch [762/2000], Avg Train Loss: 3.5767\n",
      "Epoch [762/2000], Avg Val Loss: 2.1945\n",
      "Validation loss improved from 2.1946 to 2.1945. Saving model...\n",
      "\n",
      "LOG: Epoch [763/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5813\n",
      "    Batch [2/2], Train Loss: 3.6121\n",
      "Epoch [763/2000], Avg Train Loss: 3.5967\n",
      "Epoch [763/2000], Avg Val Loss: 2.1941\n",
      "Validation loss improved from 2.1945 to 2.1941. Saving model...\n",
      "\n",
      "LOG: Epoch [764/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6088\n",
      "    Batch [2/2], Train Loss: 3.5807\n",
      "Epoch [764/2000], Avg Train Loss: 3.5948\n",
      "Epoch [764/2000], Avg Val Loss: 2.1936\n",
      "Validation loss improved from 2.1941 to 2.1936. Saving model...\n",
      "\n",
      "LOG: Epoch [765/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6177\n",
      "    Batch [2/2], Train Loss: 3.5741\n",
      "Epoch [765/2000], Avg Train Loss: 3.5959\n",
      "Epoch [765/2000], Avg Val Loss: 2.1930\n",
      "Validation loss improved from 2.1936 to 2.1930. Saving model...\n",
      "\n",
      "LOG: Epoch [766/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6214\n",
      "    Batch [2/2], Train Loss: 3.5677\n",
      "Epoch [766/2000], Avg Train Loss: 3.5946\n",
      "Epoch [766/2000], Avg Val Loss: 2.1925\n",
      "Validation loss improved from 2.1930 to 2.1925. Saving model...\n",
      "\n",
      "LOG: Epoch [767/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6042\n",
      "    Batch [2/2], Train Loss: 3.6034\n",
      "Epoch [767/2000], Avg Train Loss: 3.6038\n",
      "Epoch [767/2000], Avg Val Loss: 2.1922\n",
      "Validation loss improved from 2.1925 to 2.1922. Saving model...\n",
      "\n",
      "LOG: Epoch [768/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6267\n",
      "    Batch [2/2], Train Loss: 3.5631\n",
      "Epoch [768/2000], Avg Train Loss: 3.5949\n",
      "Epoch [768/2000], Avg Val Loss: 2.1922\n",
      "Validation loss improved from 2.1922 to 2.1922. Saving model...\n",
      "\n",
      "LOG: Epoch [769/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5945\n",
      "    Batch [2/2], Train Loss: 3.5498\n",
      "Epoch [769/2000], Avg Train Loss: 3.5722\n",
      "Epoch [769/2000], Avg Val Loss: 2.1923\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [770/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6003\n",
      "    Batch [2/2], Train Loss: 3.5772\n",
      "Epoch [770/2000], Avg Train Loss: 3.5887\n",
      "Epoch [770/2000], Avg Val Loss: 2.1925\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [771/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6285\n",
      "    Batch [2/2], Train Loss: 3.5597\n",
      "Epoch [771/2000], Avg Train Loss: 3.5941\n",
      "Epoch [771/2000], Avg Val Loss: 2.1925\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [772/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5888\n",
      "    Batch [2/2], Train Loss: 3.6274\n",
      "Epoch [772/2000], Avg Train Loss: 3.6081\n",
      "Epoch [772/2000], Avg Val Loss: 2.1922\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [773/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5604\n",
      "    Batch [2/2], Train Loss: 3.5959\n",
      "Epoch [773/2000], Avg Train Loss: 3.5782\n",
      "Epoch [773/2000], Avg Val Loss: 2.1921\n",
      "Validation loss improved from 2.1922 to 2.1921. Saving model...\n",
      "\n",
      "LOG: Epoch [774/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5891\n",
      "    Batch [2/2], Train Loss: 3.6059\n",
      "Epoch [774/2000], Avg Train Loss: 3.5975\n",
      "Epoch [774/2000], Avg Val Loss: 2.1920\n",
      "Validation loss improved from 2.1921 to 2.1920. Saving model...\n",
      "\n",
      "LOG: Epoch [775/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6489\n",
      "    Batch [2/2], Train Loss: 3.5801\n",
      "Epoch [775/2000], Avg Train Loss: 3.6145\n",
      "Epoch [775/2000], Avg Val Loss: 2.1918\n",
      "Validation loss improved from 2.1920 to 2.1918. Saving model...\n",
      "\n",
      "LOG: Epoch [776/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.5610\n",
      "    Batch [2/2], Train Loss: 3.5993\n",
      "Epoch [776/2000], Avg Train Loss: 3.5802\n",
      "Epoch [776/2000], Avg Val Loss: 2.1914\n",
      "Validation loss improved from 2.1918 to 2.1914. Saving model...\n",
      "\n",
      "LOG: Epoch [777/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6172\n",
      "    Batch [2/2], Train Loss: 3.5990\n",
      "Epoch [777/2000], Avg Train Loss: 3.6081\n",
      "Epoch [777/2000], Avg Val Loss: 2.1909\n",
      "Validation loss improved from 2.1914 to 2.1909. Saving model...\n",
      "\n",
      "LOG: Epoch [778/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5372\n",
      "    Batch [2/2], Train Loss: 3.5890\n",
      "Epoch [778/2000], Avg Train Loss: 3.5631\n",
      "Epoch [778/2000], Avg Val Loss: 2.1903\n",
      "Validation loss improved from 2.1909 to 2.1903. Saving model...\n",
      "\n",
      "LOG: Epoch [779/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5837\n",
      "    Batch [2/2], Train Loss: 3.5738\n",
      "Epoch [779/2000], Avg Train Loss: 3.5787\n",
      "Epoch [779/2000], Avg Val Loss: 2.1897\n",
      "Validation loss improved from 2.1903 to 2.1897. Saving model...\n",
      "\n",
      "LOG: Epoch [780/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5472\n",
      "    Batch [2/2], Train Loss: 3.5713\n",
      "Epoch [780/2000], Avg Train Loss: 3.5593\n",
      "Epoch [780/2000], Avg Val Loss: 2.1893\n",
      "Validation loss improved from 2.1897 to 2.1893. Saving model...\n",
      "\n",
      "LOG: Epoch [781/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5612\n",
      "    Batch [2/2], Train Loss: 3.6352\n",
      "Epoch [781/2000], Avg Train Loss: 3.5982\n",
      "Epoch [781/2000], Avg Val Loss: 2.1890\n",
      "Validation loss improved from 2.1893 to 2.1890. Saving model...\n",
      "\n",
      "LOG: Epoch [782/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5610\n",
      "    Batch [2/2], Train Loss: 3.6118\n",
      "Epoch [782/2000], Avg Train Loss: 3.5864\n",
      "Epoch [782/2000], Avg Val Loss: 2.1887\n",
      "Validation loss improved from 2.1890 to 2.1887. Saving model...\n",
      "\n",
      "LOG: Epoch [783/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5974\n",
      "    Batch [2/2], Train Loss: 3.5996\n",
      "Epoch [783/2000], Avg Train Loss: 3.5985\n",
      "Epoch [783/2000], Avg Val Loss: 2.1885\n",
      "Validation loss improved from 2.1887 to 2.1885. Saving model...\n",
      "\n",
      "LOG: Epoch [784/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5892\n",
      "    Batch [2/2], Train Loss: 3.5972\n",
      "Epoch [784/2000], Avg Train Loss: 3.5932\n",
      "Epoch [784/2000], Avg Val Loss: 2.1884\n",
      "Validation loss improved from 2.1885 to 2.1884. Saving model...\n",
      "\n",
      "LOG: Epoch [785/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5628\n",
      "    Batch [2/2], Train Loss: 3.5890\n",
      "Epoch [785/2000], Avg Train Loss: 3.5759\n",
      "Epoch [785/2000], Avg Val Loss: 2.1881\n",
      "Validation loss improved from 2.1884 to 2.1881. Saving model...\n",
      "\n",
      "LOG: Epoch [786/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5811\n",
      "    Batch [2/2], Train Loss: 3.5644\n",
      "Epoch [786/2000], Avg Train Loss: 3.5727\n",
      "Epoch [786/2000], Avg Val Loss: 2.1880\n",
      "Validation loss improved from 2.1881 to 2.1880. Saving model...\n",
      "\n",
      "LOG: Epoch [787/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5656\n",
      "    Batch [2/2], Train Loss: 3.6120\n",
      "Epoch [787/2000], Avg Train Loss: 3.5888\n",
      "Epoch [787/2000], Avg Val Loss: 2.1881\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [788/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5701\n",
      "    Batch [2/2], Train Loss: 3.5771\n",
      "Epoch [788/2000], Avg Train Loss: 3.5736\n",
      "Epoch [788/2000], Avg Val Loss: 2.1880\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [789/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5742\n",
      "    Batch [2/2], Train Loss: 3.6114\n",
      "Epoch [789/2000], Avg Train Loss: 3.5928\n",
      "Epoch [789/2000], Avg Val Loss: 2.1878\n",
      "Validation loss improved from 2.1880 to 2.1878. Saving model...\n",
      "\n",
      "LOG: Epoch [790/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5954\n",
      "    Batch [2/2], Train Loss: 3.6203\n",
      "Epoch [790/2000], Avg Train Loss: 3.6078\n",
      "Epoch [790/2000], Avg Val Loss: 2.1874\n",
      "Validation loss improved from 2.1878 to 2.1874. Saving model...\n",
      "\n",
      "LOG: Epoch [791/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5655\n",
      "    Batch [2/2], Train Loss: 3.5180\n",
      "Epoch [791/2000], Avg Train Loss: 3.5418\n",
      "Epoch [791/2000], Avg Val Loss: 2.1869\n",
      "Validation loss improved from 2.1874 to 2.1869. Saving model...\n",
      "\n",
      "LOG: Epoch [792/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6374\n",
      "    Batch [2/2], Train Loss: 3.6213\n",
      "Epoch [792/2000], Avg Train Loss: 3.6293\n",
      "Epoch [792/2000], Avg Val Loss: 2.1862\n",
      "Validation loss improved from 2.1869 to 2.1862. Saving model...\n",
      "\n",
      "LOG: Epoch [793/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5687\n",
      "    Batch [2/2], Train Loss: 3.6041\n",
      "Epoch [793/2000], Avg Train Loss: 3.5864\n",
      "Epoch [793/2000], Avg Val Loss: 2.1855\n",
      "Validation loss improved from 2.1862 to 2.1855. Saving model...\n",
      "\n",
      "LOG: Epoch [794/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.5969\n",
      "    Batch [2/2], Train Loss: 3.5760\n",
      "Epoch [794/2000], Avg Train Loss: 3.5864\n",
      "Epoch [794/2000], Avg Val Loss: 2.1851\n",
      "Validation loss improved from 2.1855 to 2.1851. Saving model...\n",
      "\n",
      "LOG: Epoch [795/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5535\n",
      "    Batch [2/2], Train Loss: 3.5613\n",
      "Epoch [795/2000], Avg Train Loss: 3.5574\n",
      "Epoch [795/2000], Avg Val Loss: 2.1850\n",
      "Validation loss improved from 2.1851 to 2.1850. Saving model...\n",
      "\n",
      "LOG: Epoch [796/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5758\n",
      "    Batch [2/2], Train Loss: 3.5580\n",
      "Epoch [796/2000], Avg Train Loss: 3.5669\n",
      "Epoch [796/2000], Avg Val Loss: 2.1851\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [797/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5218\n",
      "    Batch [2/2], Train Loss: 3.5630\n",
      "Epoch [797/2000], Avg Train Loss: 3.5424\n",
      "Epoch [797/2000], Avg Val Loss: 2.1851\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [798/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5493\n",
      "    Batch [2/2], Train Loss: 3.5859\n",
      "Epoch [798/2000], Avg Train Loss: 3.5676\n",
      "Epoch [798/2000], Avg Val Loss: 2.1850\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [799/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5440\n",
      "    Batch [2/2], Train Loss: 3.5747\n",
      "Epoch [799/2000], Avg Train Loss: 3.5593\n",
      "Epoch [799/2000], Avg Val Loss: 2.1848\n",
      "Validation loss improved from 2.1850 to 2.1848. Saving model...\n",
      "\n",
      "LOG: Epoch [800/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5590\n",
      "    Batch [2/2], Train Loss: 3.5912\n",
      "Epoch [800/2000], Avg Train Loss: 3.5751\n",
      "Epoch [800/2000], Avg Val Loss: 2.1844\n",
      "Validation loss improved from 2.1848 to 2.1844. Saving model...\n",
      "\n",
      "LOG: Epoch [801/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5752\n",
      "    Batch [2/2], Train Loss: 3.5837\n",
      "Epoch [801/2000], Avg Train Loss: 3.5795\n",
      "Epoch [801/2000], Avg Val Loss: 2.1843\n",
      "Validation loss improved from 2.1844 to 2.1843. Saving model...\n",
      "\n",
      "LOG: Epoch [802/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5910\n",
      "    Batch [2/2], Train Loss: 3.5661\n",
      "Epoch [802/2000], Avg Train Loss: 3.5785\n",
      "Epoch [802/2000], Avg Val Loss: 2.1846\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [803/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5782\n",
      "    Batch [2/2], Train Loss: 3.5471\n",
      "Epoch [803/2000], Avg Train Loss: 3.5626\n",
      "Epoch [803/2000], Avg Val Loss: 2.1848\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [804/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5404\n",
      "    Batch [2/2], Train Loss: 3.5353\n",
      "Epoch [804/2000], Avg Train Loss: 3.5378\n",
      "Epoch [804/2000], Avg Val Loss: 2.1849\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [805/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5459\n",
      "    Batch [2/2], Train Loss: 3.5780\n",
      "Epoch [805/2000], Avg Train Loss: 3.5620\n",
      "Epoch [805/2000], Avg Val Loss: 2.1850\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [806/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5658\n",
      "    Batch [2/2], Train Loss: 3.5408\n",
      "Epoch [806/2000], Avg Train Loss: 3.5533\n",
      "Epoch [806/2000], Avg Val Loss: 2.1850\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [807/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5304\n",
      "    Batch [2/2], Train Loss: 3.5886\n",
      "Epoch [807/2000], Avg Train Loss: 3.5595\n",
      "Epoch [807/2000], Avg Val Loss: 2.1847\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [808/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5437\n",
      "    Batch [2/2], Train Loss: 3.5739\n",
      "Epoch [808/2000], Avg Train Loss: 3.5588\n",
      "Epoch [808/2000], Avg Val Loss: 2.1843\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [809/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5627\n",
      "    Batch [2/2], Train Loss: 3.6331\n",
      "Epoch [809/2000], Avg Train Loss: 3.5979\n",
      "Epoch [809/2000], Avg Val Loss: 2.1839\n",
      "Validation loss improved from 2.1843 to 2.1839. Saving model...\n",
      "\n",
      "LOG: Epoch [810/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.6090\n",
      "    Batch [2/2], Train Loss: 3.5637\n",
      "Epoch [810/2000], Avg Train Loss: 3.5864\n",
      "Epoch [810/2000], Avg Val Loss: 2.1835\n",
      "Validation loss improved from 2.1839 to 2.1835. Saving model...\n",
      "\n",
      "LOG: Epoch [811/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5895\n",
      "    Batch [2/2], Train Loss: 3.5865\n",
      "Epoch [811/2000], Avg Train Loss: 3.5880\n",
      "Epoch [811/2000], Avg Val Loss: 2.1832\n",
      "Validation loss improved from 2.1835 to 2.1832. Saving model...\n",
      "\n",
      "LOG: Epoch [812/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.5727\n",
      "Epoch [812/2000], Avg Train Loss: 3.5613\n",
      "Epoch [812/2000], Avg Val Loss: 2.1828\n",
      "Validation loss improved from 2.1832 to 2.1828. Saving model...\n",
      "\n",
      "LOG: Epoch [813/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5685\n",
      "    Batch [2/2], Train Loss: 3.5805\n",
      "Epoch [813/2000], Avg Train Loss: 3.5745\n",
      "Epoch [813/2000], Avg Val Loss: 2.1823\n",
      "Validation loss improved from 2.1828 to 2.1823. Saving model...\n",
      "\n",
      "LOG: Epoch [814/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5524\n",
      "    Batch [2/2], Train Loss: 3.5878\n",
      "Epoch [814/2000], Avg Train Loss: 3.5701\n",
      "Epoch [814/2000], Avg Val Loss: 2.1818\n",
      "Validation loss improved from 2.1823 to 2.1818. Saving model...\n",
      "\n",
      "LOG: Epoch [815/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5668\n",
      "    Batch [2/2], Train Loss: 3.5462\n",
      "Epoch [815/2000], Avg Train Loss: 3.5565\n",
      "Epoch [815/2000], Avg Val Loss: 2.1815\n",
      "Validation loss improved from 2.1818 to 2.1815. Saving model...\n",
      "\n",
      "LOG: Epoch [816/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5598\n",
      "    Batch [2/2], Train Loss: 3.6009\n",
      "Epoch [816/2000], Avg Train Loss: 3.5803\n",
      "Epoch [816/2000], Avg Val Loss: 2.1808\n",
      "Validation loss improved from 2.1815 to 2.1808. Saving model...\n",
      "\n",
      "LOG: Epoch [817/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5857\n",
      "    Batch [2/2], Train Loss: 3.5688\n",
      "Epoch [817/2000], Avg Train Loss: 3.5773\n",
      "Epoch [817/2000], Avg Val Loss: 2.1802\n",
      "Validation loss improved from 2.1808 to 2.1802. Saving model...\n",
      "\n",
      "LOG: Epoch [818/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5428\n",
      "    Batch [2/2], Train Loss: 3.5774\n",
      "Epoch [818/2000], Avg Train Loss: 3.5601\n",
      "Epoch [818/2000], Avg Val Loss: 2.1798\n",
      "Validation loss improved from 2.1802 to 2.1798. Saving model...\n",
      "\n",
      "LOG: Epoch [819/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5764\n",
      "    Batch [2/2], Train Loss: 3.5252\n",
      "Epoch [819/2000], Avg Train Loss: 3.5508\n",
      "Epoch [819/2000], Avg Val Loss: 2.1794\n",
      "Validation loss improved from 2.1798 to 2.1794. Saving model...\n",
      "\n",
      "LOG: Epoch [820/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5656\n",
      "    Batch [2/2], Train Loss: 3.5346\n",
      "Epoch [820/2000], Avg Train Loss: 3.5501\n",
      "Epoch [820/2000], Avg Val Loss: 2.1790\n",
      "Validation loss improved from 2.1794 to 2.1790. Saving model...\n",
      "\n",
      "LOG: Epoch [821/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5997\n",
      "    Batch [2/2], Train Loss: 3.6000\n",
      "Epoch [821/2000], Avg Train Loss: 3.5999\n",
      "Epoch [821/2000], Avg Val Loss: 2.1786\n",
      "Validation loss improved from 2.1790 to 2.1786. Saving model...\n",
      "\n",
      "LOG: Epoch [822/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5673\n",
      "    Batch [2/2], Train Loss: 3.5894\n",
      "Epoch [822/2000], Avg Train Loss: 3.5784\n",
      "Epoch [822/2000], Avg Val Loss: 2.1784\n",
      "Validation loss improved from 2.1786 to 2.1784. Saving model...\n",
      "\n",
      "LOG: Epoch [823/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5628\n",
      "    Batch [2/2], Train Loss: 3.6056\n",
      "Epoch [823/2000], Avg Train Loss: 3.5842\n",
      "Epoch [823/2000], Avg Val Loss: 2.1784\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [824/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5510\n",
      "    Batch [2/2], Train Loss: 3.5608\n",
      "Epoch [824/2000], Avg Train Loss: 3.5559\n",
      "Epoch [824/2000], Avg Val Loss: 2.1785\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [825/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5575\n",
      "    Batch [2/2], Train Loss: 3.5956\n",
      "Epoch [825/2000], Avg Train Loss: 3.5766\n",
      "Epoch [825/2000], Avg Val Loss: 2.1784\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [826/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5601\n",
      "    Batch [2/2], Train Loss: 3.5555\n",
      "Epoch [826/2000], Avg Train Loss: 3.5578\n",
      "Epoch [826/2000], Avg Val Loss: 2.1780\n",
      "Validation loss improved from 2.1784 to 2.1780. Saving model...\n",
      "\n",
      "LOG: Epoch [827/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5488\n",
      "    Batch [2/2], Train Loss: 3.5255\n",
      "Epoch [827/2000], Avg Train Loss: 3.5372\n",
      "Epoch [827/2000], Avg Val Loss: 2.1776\n",
      "Validation loss improved from 2.1780 to 2.1776. Saving model...\n",
      "\n",
      "LOG: Epoch [828/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5763\n",
      "    Batch [2/2], Train Loss: 3.5175\n",
      "Epoch [828/2000], Avg Train Loss: 3.5469\n",
      "Epoch [828/2000], Avg Val Loss: 2.1769\n",
      "Validation loss improved from 2.1776 to 2.1769. Saving model...\n",
      "\n",
      "LOG: Epoch [829/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5157\n",
      "    Batch [2/2], Train Loss: 3.5705\n",
      "Epoch [829/2000], Avg Train Loss: 3.5431\n",
      "Epoch [829/2000], Avg Val Loss: 2.1763\n",
      "Validation loss improved from 2.1769 to 2.1763. Saving model...\n",
      "\n",
      "LOG: Epoch [830/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.5817\n",
      "Epoch [830/2000], Avg Train Loss: 3.5725\n",
      "Epoch [830/2000], Avg Val Loss: 2.1755\n",
      "Validation loss improved from 2.1763 to 2.1755. Saving model...\n",
      "\n",
      "LOG: Epoch [831/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5159\n",
      "    Batch [2/2], Train Loss: 3.5685\n",
      "Epoch [831/2000], Avg Train Loss: 3.5422\n",
      "Epoch [831/2000], Avg Val Loss: 2.1750\n",
      "Validation loss improved from 2.1755 to 2.1750. Saving model...\n",
      "\n",
      "LOG: Epoch [832/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5246\n",
      "    Batch [2/2], Train Loss: 3.5720\n",
      "Epoch [832/2000], Avg Train Loss: 3.5483\n",
      "Epoch [832/2000], Avg Val Loss: 2.1747\n",
      "Validation loss improved from 2.1750 to 2.1747. Saving model...\n",
      "\n",
      "LOG: Epoch [833/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5936\n",
      "    Batch [2/2], Train Loss: 3.5763\n",
      "Epoch [833/2000], Avg Train Loss: 3.5850\n",
      "Epoch [833/2000], Avg Val Loss: 2.1745\n",
      "Validation loss improved from 2.1747 to 2.1745. Saving model...\n",
      "\n",
      "LOG: Epoch [834/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5739\n",
      "    Batch [2/2], Train Loss: 3.5328\n",
      "Epoch [834/2000], Avg Train Loss: 3.5534\n",
      "Epoch [834/2000], Avg Val Loss: 2.1743\n",
      "Validation loss improved from 2.1745 to 2.1743. Saving model...\n",
      "\n",
      "LOG: Epoch [835/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5436\n",
      "    Batch [2/2], Train Loss: 3.5378\n",
      "Epoch [835/2000], Avg Train Loss: 3.5407\n",
      "Epoch [835/2000], Avg Val Loss: 2.1742\n",
      "Validation loss improved from 2.1743 to 2.1742. Saving model...\n",
      "\n",
      "LOG: Epoch [836/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5450\n",
      "    Batch [2/2], Train Loss: 3.5750\n",
      "Epoch [836/2000], Avg Train Loss: 3.5600\n",
      "Epoch [836/2000], Avg Val Loss: 2.1744\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [837/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5470\n",
      "    Batch [2/2], Train Loss: 3.5159\n",
      "Epoch [837/2000], Avg Train Loss: 3.5315\n",
      "Epoch [837/2000], Avg Val Loss: 2.1741\n",
      "Validation loss improved from 2.1742 to 2.1741. Saving model...\n",
      "\n",
      "LOG: Epoch [838/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5443\n",
      "    Batch [2/2], Train Loss: 3.5499\n",
      "Epoch [838/2000], Avg Train Loss: 3.5471\n",
      "Epoch [838/2000], Avg Val Loss: 2.1735\n",
      "Validation loss improved from 2.1741 to 2.1735. Saving model...\n",
      "\n",
      "LOG: Epoch [839/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5031\n",
      "    Batch [2/2], Train Loss: 3.5357\n",
      "Epoch [839/2000], Avg Train Loss: 3.5194\n",
      "Epoch [839/2000], Avg Val Loss: 2.1728\n",
      "Validation loss improved from 2.1735 to 2.1728. Saving model...\n",
      "\n",
      "LOG: Epoch [840/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5858\n",
      "    Batch [2/2], Train Loss: 3.5602\n",
      "Epoch [840/2000], Avg Train Loss: 3.5730\n",
      "Epoch [840/2000], Avg Val Loss: 2.1721\n",
      "Validation loss improved from 2.1728 to 2.1721. Saving model...\n",
      "\n",
      "LOG: Epoch [841/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5353\n",
      "    Batch [2/2], Train Loss: 3.4963\n",
      "Epoch [841/2000], Avg Train Loss: 3.5158\n",
      "Epoch [841/2000], Avg Val Loss: 2.1714\n",
      "Validation loss improved from 2.1721 to 2.1714. Saving model...\n",
      "\n",
      "LOG: Epoch [842/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5585\n",
      "    Batch [2/2], Train Loss: 3.6369\n",
      "Epoch [842/2000], Avg Train Loss: 3.5977\n",
      "Epoch [842/2000], Avg Val Loss: 2.1704\n",
      "Validation loss improved from 2.1714 to 2.1704. Saving model...\n",
      "\n",
      "LOG: Epoch [843/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5248\n",
      "    Batch [2/2], Train Loss: 3.5631\n",
      "Epoch [843/2000], Avg Train Loss: 3.5439\n",
      "Epoch [843/2000], Avg Val Loss: 2.1694\n",
      "Validation loss improved from 2.1704 to 2.1694. Saving model...\n",
      "\n",
      "LOG: Epoch [844/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5540\n",
      "    Batch [2/2], Train Loss: 3.5361\n",
      "Epoch [844/2000], Avg Train Loss: 3.5450\n",
      "Epoch [844/2000], Avg Val Loss: 2.1685\n",
      "Validation loss improved from 2.1694 to 2.1685. Saving model...\n",
      "\n",
      "LOG: Epoch [845/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5325\n",
      "    Batch [2/2], Train Loss: 3.5527\n",
      "Epoch [845/2000], Avg Train Loss: 3.5426\n",
      "Epoch [845/2000], Avg Val Loss: 2.1680\n",
      "Validation loss improved from 2.1685 to 2.1680. Saving model...\n",
      "\n",
      "LOG: Epoch [846/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5644\n",
      "    Batch [2/2], Train Loss: 3.5466\n",
      "Epoch [846/2000], Avg Train Loss: 3.5555\n",
      "Epoch [846/2000], Avg Val Loss: 2.1676\n",
      "Validation loss improved from 2.1680 to 2.1676. Saving model...\n",
      "\n",
      "LOG: Epoch [847/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5801\n",
      "    Batch [2/2], Train Loss: 3.5544\n",
      "Epoch [847/2000], Avg Train Loss: 3.5672\n",
      "Epoch [847/2000], Avg Val Loss: 2.1674\n",
      "Validation loss improved from 2.1676 to 2.1674. Saving model...\n",
      "\n",
      "LOG: Epoch [848/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.5225\n",
      "Epoch [848/2000], Avg Train Loss: 3.5458\n",
      "Epoch [848/2000], Avg Val Loss: 2.1676\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [849/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5762\n",
      "    Batch [2/2], Train Loss: 3.5151\n",
      "Epoch [849/2000], Avg Train Loss: 3.5456\n",
      "Epoch [849/2000], Avg Val Loss: 2.1682\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [850/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5046\n",
      "    Batch [2/2], Train Loss: 3.5175\n",
      "Epoch [850/2000], Avg Train Loss: 3.5111\n",
      "Epoch [850/2000], Avg Val Loss: 2.1691\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [851/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5244\n",
      "    Batch [2/2], Train Loss: 3.5543\n",
      "Epoch [851/2000], Avg Train Loss: 3.5394\n",
      "Epoch [851/2000], Avg Val Loss: 2.1692\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [852/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5295\n",
      "    Batch [2/2], Train Loss: 3.5361\n",
      "Epoch [852/2000], Avg Train Loss: 3.5328\n",
      "Epoch [852/2000], Avg Val Loss: 2.1689\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [853/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5039\n",
      "    Batch [2/2], Train Loss: 3.5350\n",
      "Epoch [853/2000], Avg Train Loss: 3.5194\n",
      "Epoch [853/2000], Avg Val Loss: 2.1687\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [854/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5629\n",
      "    Batch [2/2], Train Loss: 3.5400\n",
      "Epoch [854/2000], Avg Train Loss: 3.5515\n",
      "Epoch [854/2000], Avg Val Loss: 2.1687\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [855/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5597\n",
      "    Batch [2/2], Train Loss: 3.5755\n",
      "Epoch [855/2000], Avg Train Loss: 3.5676\n",
      "Epoch [855/2000], Avg Val Loss: 2.1687\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [856/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5488\n",
      "    Batch [2/2], Train Loss: 3.5520\n",
      "Epoch [856/2000], Avg Train Loss: 3.5504\n",
      "Epoch [856/2000], Avg Val Loss: 2.1687\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [857/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5458\n",
      "    Batch [2/2], Train Loss: 3.5314\n",
      "Epoch [857/2000], Avg Train Loss: 3.5386\n",
      "Epoch [857/2000], Avg Val Loss: 2.1683\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [858/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4994\n",
      "    Batch [2/2], Train Loss: 3.5422\n",
      "Epoch [858/2000], Avg Train Loss: 3.5208\n",
      "Epoch [858/2000], Avg Val Loss: 2.1678\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [859/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5650\n",
      "    Batch [2/2], Train Loss: 3.5780\n",
      "Epoch [859/2000], Avg Train Loss: 3.5715\n",
      "Epoch [859/2000], Avg Val Loss: 2.1674\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [860/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4984\n",
      "    Batch [2/2], Train Loss: 3.5063\n",
      "Epoch [860/2000], Avg Train Loss: 3.5023\n",
      "Epoch [860/2000], Avg Val Loss: 2.1672\n",
      "Validation loss improved from 2.1674 to 2.1672. Saving model...\n",
      "\n",
      "LOG: Epoch [861/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5329\n",
      "    Batch [2/2], Train Loss: 3.5022\n",
      "Epoch [861/2000], Avg Train Loss: 3.5176\n",
      "Epoch [861/2000], Avg Val Loss: 2.1671\n",
      "Validation loss improved from 2.1672 to 2.1671. Saving model...\n",
      "\n",
      "LOG: Epoch [862/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5620\n",
      "    Batch [2/2], Train Loss: 3.5070\n",
      "Epoch [862/2000], Avg Train Loss: 3.5345\n",
      "Epoch [862/2000], Avg Val Loss: 2.1672\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [863/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5483\n",
      "    Batch [2/2], Train Loss: 3.5603\n",
      "Epoch [863/2000], Avg Train Loss: 3.5543\n",
      "Epoch [863/2000], Avg Val Loss: 2.1672\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [864/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5511\n",
      "    Batch [2/2], Train Loss: 3.4988\n",
      "Epoch [864/2000], Avg Train Loss: 3.5250\n",
      "Epoch [864/2000], Avg Val Loss: 2.1673\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [865/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5044\n",
      "    Batch [2/2], Train Loss: 3.4817\n",
      "Epoch [865/2000], Avg Train Loss: 3.4931\n",
      "Epoch [865/2000], Avg Val Loss: 2.1677\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [866/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5646\n",
      "    Batch [2/2], Train Loss: 3.5025\n",
      "Epoch [866/2000], Avg Train Loss: 3.5335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [866/2000], Avg Val Loss: 2.1680\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [867/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5349\n",
      "    Batch [2/2], Train Loss: 3.5459\n",
      "Epoch [867/2000], Avg Train Loss: 3.5404\n",
      "Epoch [867/2000], Avg Val Loss: 2.1681\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [868/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5220\n",
      "    Batch [2/2], Train Loss: 3.5209\n",
      "Epoch [868/2000], Avg Train Loss: 3.5214\n",
      "Epoch [868/2000], Avg Val Loss: 2.1680\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [869/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5134\n",
      "    Batch [2/2], Train Loss: 3.5433\n",
      "Epoch [869/2000], Avg Train Loss: 3.5284\n",
      "Epoch [869/2000], Avg Val Loss: 2.1677\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [870/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5429\n",
      "    Batch [2/2], Train Loss: 3.5156\n",
      "Epoch [870/2000], Avg Train Loss: 3.5293\n",
      "Epoch [870/2000], Avg Val Loss: 2.1672\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [871/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5017\n",
      "    Batch [2/2], Train Loss: 3.5483\n",
      "Epoch [871/2000], Avg Train Loss: 3.5250\n",
      "Epoch [871/2000], Avg Val Loss: 2.1667\n",
      "Validation loss improved from 2.1671 to 2.1667. Saving model...\n",
      "\n",
      "LOG: Epoch [872/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5199\n",
      "    Batch [2/2], Train Loss: 3.4938\n",
      "Epoch [872/2000], Avg Train Loss: 3.5069\n",
      "Epoch [872/2000], Avg Val Loss: 2.1662\n",
      "Validation loss improved from 2.1667 to 2.1662. Saving model...\n",
      "\n",
      "LOG: Epoch [873/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5748\n",
      "    Batch [2/2], Train Loss: 3.5812\n",
      "Epoch [873/2000], Avg Train Loss: 3.5780\n",
      "Epoch [873/2000], Avg Val Loss: 2.1655\n",
      "Validation loss improved from 2.1662 to 2.1655. Saving model...\n",
      "\n",
      "LOG: Epoch [874/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5213\n",
      "    Batch [2/2], Train Loss: 3.5360\n",
      "Epoch [874/2000], Avg Train Loss: 3.5287\n",
      "Epoch [874/2000], Avg Val Loss: 2.1649\n",
      "Validation loss improved from 2.1655 to 2.1649. Saving model...\n",
      "\n",
      "LOG: Epoch [875/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5160\n",
      "    Batch [2/2], Train Loss: 3.5240\n",
      "Epoch [875/2000], Avg Train Loss: 3.5200\n",
      "Epoch [875/2000], Avg Val Loss: 2.1644\n",
      "Validation loss improved from 2.1649 to 2.1644. Saving model...\n",
      "\n",
      "LOG: Epoch [876/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5172\n",
      "    Batch [2/2], Train Loss: 3.4829\n",
      "Epoch [876/2000], Avg Train Loss: 3.5000\n",
      "Epoch [876/2000], Avg Val Loss: 2.1641\n",
      "Validation loss improved from 2.1644 to 2.1641. Saving model...\n",
      "\n",
      "LOG: Epoch [877/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5100\n",
      "    Batch [2/2], Train Loss: 3.5196\n",
      "Epoch [877/2000], Avg Train Loss: 3.5148\n",
      "Epoch [877/2000], Avg Val Loss: 2.1640\n",
      "Validation loss improved from 2.1641 to 2.1640. Saving model...\n",
      "\n",
      "LOG: Epoch [878/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5270\n",
      "    Batch [2/2], Train Loss: 3.5224\n",
      "Epoch [878/2000], Avg Train Loss: 3.5247\n",
      "Epoch [878/2000], Avg Val Loss: 2.1638\n",
      "Validation loss improved from 2.1640 to 2.1638. Saving model...\n",
      "\n",
      "LOG: Epoch [879/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5630\n",
      "    Batch [2/2], Train Loss: 3.5168\n",
      "Epoch [879/2000], Avg Train Loss: 3.5399\n",
      "Epoch [879/2000], Avg Val Loss: 2.1639\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [880/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5312\n",
      "    Batch [2/2], Train Loss: 3.5179\n",
      "Epoch [880/2000], Avg Train Loss: 3.5245\n",
      "Epoch [880/2000], Avg Val Loss: 2.1640\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [881/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5153\n",
      "    Batch [2/2], Train Loss: 3.5459\n",
      "Epoch [881/2000], Avg Train Loss: 3.5306\n",
      "Epoch [881/2000], Avg Val Loss: 2.1641\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [882/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5252\n",
      "    Batch [2/2], Train Loss: 3.5369\n",
      "Epoch [882/2000], Avg Train Loss: 3.5310\n",
      "Epoch [882/2000], Avg Val Loss: 2.1644\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [883/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5008\n",
      "    Batch [2/2], Train Loss: 3.5320\n",
      "Epoch [883/2000], Avg Train Loss: 3.5164\n",
      "Epoch [883/2000], Avg Val Loss: 2.1648\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [884/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5216\n",
      "    Batch [2/2], Train Loss: 3.5148\n",
      "Epoch [884/2000], Avg Train Loss: 3.5182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [884/2000], Avg Val Loss: 2.1652\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [885/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5354\n",
      "    Batch [2/2], Train Loss: 3.5024\n",
      "Epoch [885/2000], Avg Train Loss: 3.5189\n",
      "Epoch [885/2000], Avg Val Loss: 2.1652\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [886/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5494\n",
      "    Batch [2/2], Train Loss: 3.5390\n",
      "Epoch [886/2000], Avg Train Loss: 3.5442\n",
      "Epoch [886/2000], Avg Val Loss: 2.1655\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [887/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5305\n",
      "    Batch [2/2], Train Loss: 3.4884\n",
      "Epoch [887/2000], Avg Train Loss: 3.5095\n",
      "Epoch [887/2000], Avg Val Loss: 2.1657\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [888/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5091\n",
      "    Batch [2/2], Train Loss: 3.5399\n",
      "Epoch [888/2000], Avg Train Loss: 3.5245\n",
      "Epoch [888/2000], Avg Val Loss: 2.1662\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [889/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5626\n",
      "    Batch [2/2], Train Loss: 3.4755\n",
      "Epoch [889/2000], Avg Train Loss: 3.5190\n",
      "Epoch [889/2000], Avg Val Loss: 2.1667\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [890/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4861\n",
      "    Batch [2/2], Train Loss: 3.5542\n",
      "Epoch [890/2000], Avg Train Loss: 3.5201\n",
      "Epoch [890/2000], Avg Val Loss: 2.1669\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [891/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4679\n",
      "    Batch [2/2], Train Loss: 3.5344\n",
      "Epoch [891/2000], Avg Train Loss: 3.5012\n",
      "Epoch [891/2000], Avg Val Loss: 2.1667\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [892/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4997\n",
      "    Batch [2/2], Train Loss: 3.5153\n",
      "Epoch [892/2000], Avg Train Loss: 3.5075\n",
      "Epoch [892/2000], Avg Val Loss: 2.1664\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [893/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5422\n",
      "    Batch [2/2], Train Loss: 3.5233\n",
      "Epoch [893/2000], Avg Train Loss: 3.5327\n",
      "Epoch [893/2000], Avg Val Loss: 2.1659\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [894/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5125\n",
      "    Batch [2/2], Train Loss: 3.5415\n",
      "Epoch [894/2000], Avg Train Loss: 3.5270\n",
      "Epoch [894/2000], Avg Val Loss: 2.1655\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [895/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5257\n",
      "    Batch [2/2], Train Loss: 3.5231\n",
      "Epoch [895/2000], Avg Train Loss: 3.5244\n",
      "Epoch [895/2000], Avg Val Loss: 2.1651\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [896/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5205\n",
      "    Batch [2/2], Train Loss: 3.5254\n",
      "Epoch [896/2000], Avg Train Loss: 3.5229\n",
      "Epoch [896/2000], Avg Val Loss: 2.1647\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [897/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5310\n",
      "    Batch [2/2], Train Loss: 3.4833\n",
      "Epoch [897/2000], Avg Train Loss: 3.5071\n",
      "Epoch [897/2000], Avg Val Loss: 2.1644\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [898/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5246\n",
      "    Batch [2/2], Train Loss: 3.4988\n",
      "Epoch [898/2000], Avg Train Loss: 3.5117\n",
      "Epoch [898/2000], Avg Val Loss: 2.1644\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [899/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5071\n",
      "    Batch [2/2], Train Loss: 3.4986\n",
      "Epoch [899/2000], Avg Train Loss: 3.5029\n",
      "Epoch [899/2000], Avg Val Loss: 2.1642\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [900/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4994\n",
      "    Batch [2/2], Train Loss: 3.5254\n",
      "Epoch [900/2000], Avg Train Loss: 3.5124\n",
      "Epoch [900/2000], Avg Val Loss: 2.1641\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [901/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5309\n",
      "    Batch [2/2], Train Loss: 3.5946\n",
      "Epoch [901/2000], Avg Train Loss: 3.5627\n",
      "Epoch [901/2000], Avg Val Loss: 2.1638\n",
      "Validation loss improved from 2.1638 to 2.1638. Saving model...\n",
      "\n",
      "LOG: Epoch [902/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5595\n",
      "    Batch [2/2], Train Loss: 3.4939\n",
      "Epoch [902/2000], Avg Train Loss: 3.5267\n",
      "Epoch [902/2000], Avg Val Loss: 2.1634\n",
      "Validation loss improved from 2.1638 to 2.1634. Saving model...\n",
      "\n",
      "LOG: Epoch [903/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.5164\n",
      "Epoch [903/2000], Avg Train Loss: 3.5159\n",
      "Epoch [903/2000], Avg Val Loss: 2.1629\n",
      "Validation loss improved from 2.1634 to 2.1629. Saving model...\n",
      "\n",
      "LOG: Epoch [904/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5072\n",
      "    Batch [2/2], Train Loss: 3.5065\n",
      "Epoch [904/2000], Avg Train Loss: 3.5069\n",
      "Epoch [904/2000], Avg Val Loss: 2.1621\n",
      "Validation loss improved from 2.1629 to 2.1621. Saving model...\n",
      "\n",
      "LOG: Epoch [905/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4864\n",
      "    Batch [2/2], Train Loss: 3.4888\n",
      "Epoch [905/2000], Avg Train Loss: 3.4876\n",
      "Epoch [905/2000], Avg Val Loss: 2.1617\n",
      "Validation loss improved from 2.1621 to 2.1617. Saving model...\n",
      "\n",
      "LOG: Epoch [906/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4905\n",
      "    Batch [2/2], Train Loss: 3.5085\n",
      "Epoch [906/2000], Avg Train Loss: 3.4995\n",
      "Epoch [906/2000], Avg Val Loss: 2.1612\n",
      "Validation loss improved from 2.1617 to 2.1612. Saving model...\n",
      "\n",
      "LOG: Epoch [907/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5298\n",
      "    Batch [2/2], Train Loss: 3.5561\n",
      "Epoch [907/2000], Avg Train Loss: 3.5430\n",
      "Epoch [907/2000], Avg Val Loss: 2.1605\n",
      "Validation loss improved from 2.1612 to 2.1605. Saving model...\n",
      "\n",
      "LOG: Epoch [908/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5330\n",
      "    Batch [2/2], Train Loss: 3.5020\n",
      "Epoch [908/2000], Avg Train Loss: 3.5175\n",
      "Epoch [908/2000], Avg Val Loss: 2.1603\n",
      "Validation loss improved from 2.1605 to 2.1603. Saving model...\n",
      "\n",
      "LOG: Epoch [909/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5300\n",
      "    Batch [2/2], Train Loss: 3.4692\n",
      "Epoch [909/2000], Avg Train Loss: 3.4996\n",
      "Epoch [909/2000], Avg Val Loss: 2.1603\n",
      "Validation loss improved from 2.1603 to 2.1603. Saving model...\n",
      "\n",
      "LOG: Epoch [910/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4749\n",
      "    Batch [2/2], Train Loss: 3.4939\n",
      "Epoch [910/2000], Avg Train Loss: 3.4844\n",
      "Epoch [910/2000], Avg Val Loss: 2.1603\n",
      "Validation loss improved from 2.1603 to 2.1603. Saving model...\n",
      "\n",
      "LOG: Epoch [911/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5357\n",
      "    Batch [2/2], Train Loss: 3.5348\n",
      "Epoch [911/2000], Avg Train Loss: 3.5353\n",
      "Epoch [911/2000], Avg Val Loss: 2.1602\n",
      "Validation loss improved from 2.1603 to 2.1602. Saving model...\n",
      "\n",
      "LOG: Epoch [912/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5054\n",
      "    Batch [2/2], Train Loss: 3.5405\n",
      "Epoch [912/2000], Avg Train Loss: 3.5230\n",
      "Epoch [912/2000], Avg Val Loss: 2.1600\n",
      "Validation loss improved from 2.1602 to 2.1600. Saving model...\n",
      "\n",
      "LOG: Epoch [913/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4809\n",
      "    Batch [2/2], Train Loss: 3.5152\n",
      "Epoch [913/2000], Avg Train Loss: 3.4981\n",
      "Epoch [913/2000], Avg Val Loss: 2.1600\n",
      "Validation loss improved from 2.1600 to 2.1600. Saving model...\n",
      "\n",
      "LOG: Epoch [914/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5435\n",
      "    Batch [2/2], Train Loss: 3.4602\n",
      "Epoch [914/2000], Avg Train Loss: 3.5018\n",
      "Epoch [914/2000], Avg Val Loss: 2.1600\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [915/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4861\n",
      "    Batch [2/2], Train Loss: 3.4774\n",
      "Epoch [915/2000], Avg Train Loss: 3.4818\n",
      "Epoch [915/2000], Avg Val Loss: 2.1597\n",
      "Validation loss improved from 2.1600 to 2.1597. Saving model...\n",
      "\n",
      "LOG: Epoch [916/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4737\n",
      "    Batch [2/2], Train Loss: 3.4845\n",
      "Epoch [916/2000], Avg Train Loss: 3.4791\n",
      "Epoch [916/2000], Avg Val Loss: 2.1594\n",
      "Validation loss improved from 2.1597 to 2.1594. Saving model...\n",
      "\n",
      "LOG: Epoch [917/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5085\n",
      "    Batch [2/2], Train Loss: 3.5455\n",
      "Epoch [917/2000], Avg Train Loss: 3.5270\n",
      "Epoch [917/2000], Avg Val Loss: 2.1590\n",
      "Validation loss improved from 2.1594 to 2.1590. Saving model...\n",
      "\n",
      "LOG: Epoch [918/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4389\n",
      "    Batch [2/2], Train Loss: 3.5655\n",
      "Epoch [918/2000], Avg Train Loss: 3.5022\n",
      "Epoch [918/2000], Avg Val Loss: 2.1582\n",
      "Validation loss improved from 2.1590 to 2.1582. Saving model...\n",
      "\n",
      "LOG: Epoch [919/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5002\n",
      "    Batch [2/2], Train Loss: 3.4755\n",
      "Epoch [919/2000], Avg Train Loss: 3.4879\n",
      "Epoch [919/2000], Avg Val Loss: 2.1576\n",
      "Validation loss improved from 2.1582 to 2.1576. Saving model...\n",
      "\n",
      "LOG: Epoch [920/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5025\n",
      "    Batch [2/2], Train Loss: 3.4972\n",
      "Epoch [920/2000], Avg Train Loss: 3.4998\n",
      "Epoch [920/2000], Avg Val Loss: 2.1569\n",
      "Validation loss improved from 2.1576 to 2.1569. Saving model...\n",
      "\n",
      "LOG: Epoch [921/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.4532\n",
      "Epoch [921/2000], Avg Train Loss: 3.4665\n",
      "Epoch [921/2000], Avg Val Loss: 2.1564\n",
      "Validation loss improved from 2.1569 to 2.1564. Saving model...\n",
      "\n",
      "LOG: Epoch [922/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5004\n",
      "    Batch [2/2], Train Loss: 3.4908\n",
      "Epoch [922/2000], Avg Train Loss: 3.4956\n",
      "Epoch [922/2000], Avg Val Loss: 2.1560\n",
      "Validation loss improved from 2.1564 to 2.1560. Saving model...\n",
      "\n",
      "LOG: Epoch [923/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5405\n",
      "    Batch [2/2], Train Loss: 3.5139\n",
      "Epoch [923/2000], Avg Train Loss: 3.5272\n",
      "Epoch [923/2000], Avg Val Loss: 2.1559\n",
      "Validation loss improved from 2.1560 to 2.1559. Saving model...\n",
      "\n",
      "LOG: Epoch [924/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5062\n",
      "    Batch [2/2], Train Loss: 3.5214\n",
      "Epoch [924/2000], Avg Train Loss: 3.5138\n",
      "Epoch [924/2000], Avg Val Loss: 2.1555\n",
      "Validation loss improved from 2.1559 to 2.1555. Saving model...\n",
      "\n",
      "LOG: Epoch [925/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5034\n",
      "    Batch [2/2], Train Loss: 3.4742\n",
      "Epoch [925/2000], Avg Train Loss: 3.4888\n",
      "Epoch [925/2000], Avg Val Loss: 2.1552\n",
      "Validation loss improved from 2.1555 to 2.1552. Saving model...\n",
      "\n",
      "LOG: Epoch [926/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5397\n",
      "    Batch [2/2], Train Loss: 3.4645\n",
      "Epoch [926/2000], Avg Train Loss: 3.5021\n",
      "Epoch [926/2000], Avg Val Loss: 2.1550\n",
      "Validation loss improved from 2.1552 to 2.1550. Saving model...\n",
      "\n",
      "LOG: Epoch [927/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4949\n",
      "    Batch [2/2], Train Loss: 3.4816\n",
      "Epoch [927/2000], Avg Train Loss: 3.4883\n",
      "Epoch [927/2000], Avg Val Loss: 2.1550\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [928/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5371\n",
      "    Batch [2/2], Train Loss: 3.4880\n",
      "Epoch [928/2000], Avg Train Loss: 3.5125\n",
      "Epoch [928/2000], Avg Val Loss: 2.1551\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [929/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4716\n",
      "    Batch [2/2], Train Loss: 3.5231\n",
      "Epoch [929/2000], Avg Train Loss: 3.4973\n",
      "Epoch [929/2000], Avg Val Loss: 2.1551\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [930/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5312\n",
      "    Batch [2/2], Train Loss: 3.4625\n",
      "Epoch [930/2000], Avg Train Loss: 3.4969\n",
      "Epoch [930/2000], Avg Val Loss: 2.1551\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [931/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4808\n",
      "    Batch [2/2], Train Loss: 3.4697\n",
      "Epoch [931/2000], Avg Train Loss: 3.4753\n",
      "Epoch [931/2000], Avg Val Loss: 2.1553\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [932/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5518\n",
      "    Batch [2/2], Train Loss: 3.4651\n",
      "Epoch [932/2000], Avg Train Loss: 3.5085\n",
      "Epoch [932/2000], Avg Val Loss: 2.1554\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [933/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4710\n",
      "    Batch [2/2], Train Loss: 3.4501\n",
      "Epoch [933/2000], Avg Train Loss: 3.4606\n",
      "Epoch [933/2000], Avg Val Loss: 2.1553\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [934/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4653\n",
      "    Batch [2/2], Train Loss: 3.5134\n",
      "Epoch [934/2000], Avg Train Loss: 3.4893\n",
      "Epoch [934/2000], Avg Val Loss: 2.1551\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [935/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5293\n",
      "    Batch [2/2], Train Loss: 3.4282\n",
      "Epoch [935/2000], Avg Train Loss: 3.4788\n",
      "Epoch [935/2000], Avg Val Loss: 2.1547\n",
      "Validation loss improved from 2.1550 to 2.1547. Saving model...\n",
      "\n",
      "LOG: Epoch [936/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5451\n",
      "    Batch [2/2], Train Loss: 3.4526\n",
      "Epoch [936/2000], Avg Train Loss: 3.4988\n",
      "Epoch [936/2000], Avg Val Loss: 2.1543\n",
      "Validation loss improved from 2.1547 to 2.1543. Saving model...\n",
      "\n",
      "LOG: Epoch [937/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4997\n",
      "    Batch [2/2], Train Loss: 3.5292\n",
      "Epoch [937/2000], Avg Train Loss: 3.5145\n",
      "Epoch [937/2000], Avg Val Loss: 2.1538\n",
      "Validation loss improved from 2.1543 to 2.1538. Saving model...\n",
      "\n",
      "LOG: Epoch [938/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4794\n",
      "    Batch [2/2], Train Loss: 3.4598\n",
      "Epoch [938/2000], Avg Train Loss: 3.4696\n",
      "Epoch [938/2000], Avg Val Loss: 2.1539\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [939/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.4864\n",
      "    Batch [2/2], Train Loss: 3.4793\n",
      "Epoch [939/2000], Avg Train Loss: 3.4828\n",
      "Epoch [939/2000], Avg Val Loss: 2.1540\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [940/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4683\n",
      "    Batch [2/2], Train Loss: 3.5146\n",
      "Epoch [940/2000], Avg Train Loss: 3.4915\n",
      "Epoch [940/2000], Avg Val Loss: 2.1538\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [941/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5260\n",
      "    Batch [2/2], Train Loss: 3.5208\n",
      "Epoch [941/2000], Avg Train Loss: 3.5234\n",
      "Epoch [941/2000], Avg Val Loss: 2.1540\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [942/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4789\n",
      "    Batch [2/2], Train Loss: 3.5002\n",
      "Epoch [942/2000], Avg Train Loss: 3.4896\n",
      "Epoch [942/2000], Avg Val Loss: 2.1541\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [943/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4606\n",
      "    Batch [2/2], Train Loss: 3.4535\n",
      "Epoch [943/2000], Avg Train Loss: 3.4570\n",
      "Epoch [943/2000], Avg Val Loss: 2.1540\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [944/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4890\n",
      "    Batch [2/2], Train Loss: 3.4680\n",
      "Epoch [944/2000], Avg Train Loss: 3.4785\n",
      "Epoch [944/2000], Avg Val Loss: 2.1540\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [945/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5207\n",
      "    Batch [2/2], Train Loss: 3.5103\n",
      "Epoch [945/2000], Avg Train Loss: 3.5155\n",
      "Epoch [945/2000], Avg Val Loss: 2.1542\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [946/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4689\n",
      "    Batch [2/2], Train Loss: 3.4804\n",
      "Epoch [946/2000], Avg Train Loss: 3.4746\n",
      "Epoch [946/2000], Avg Val Loss: 2.1543\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [947/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5261\n",
      "    Batch [2/2], Train Loss: 3.4817\n",
      "Epoch [947/2000], Avg Train Loss: 3.5039\n",
      "Epoch [947/2000], Avg Val Loss: 2.1541\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [948/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4781\n",
      "    Batch [2/2], Train Loss: 3.4691\n",
      "Epoch [948/2000], Avg Train Loss: 3.4736\n",
      "Epoch [948/2000], Avg Val Loss: 2.1540\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [949/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4751\n",
      "    Batch [2/2], Train Loss: 3.4931\n",
      "Epoch [949/2000], Avg Train Loss: 3.4841\n",
      "Epoch [949/2000], Avg Val Loss: 2.1539\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [950/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4617\n",
      "    Batch [2/2], Train Loss: 3.4986\n",
      "Epoch [950/2000], Avg Train Loss: 3.4801\n",
      "Epoch [950/2000], Avg Val Loss: 2.1535\n",
      "Validation loss improved from 2.1538 to 2.1535. Saving model...\n",
      "\n",
      "LOG: Epoch [951/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4864\n",
      "    Batch [2/2], Train Loss: 3.4749\n",
      "Epoch [951/2000], Avg Train Loss: 3.4807\n",
      "Epoch [951/2000], Avg Val Loss: 2.1530\n",
      "Validation loss improved from 2.1535 to 2.1530. Saving model...\n",
      "\n",
      "LOG: Epoch [952/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4681\n",
      "    Batch [2/2], Train Loss: 3.4747\n",
      "Epoch [952/2000], Avg Train Loss: 3.4714\n",
      "Epoch [952/2000], Avg Val Loss: 2.1522\n",
      "Validation loss improved from 2.1530 to 2.1522. Saving model...\n",
      "\n",
      "LOG: Epoch [953/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4917\n",
      "    Batch [2/2], Train Loss: 3.4920\n",
      "Epoch [953/2000], Avg Train Loss: 3.4919\n",
      "Epoch [953/2000], Avg Val Loss: 2.1513\n",
      "Validation loss improved from 2.1522 to 2.1513. Saving model...\n",
      "\n",
      "LOG: Epoch [954/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5078\n",
      "    Batch [2/2], Train Loss: 3.5073\n",
      "Epoch [954/2000], Avg Train Loss: 3.5076\n",
      "Epoch [954/2000], Avg Val Loss: 2.1509\n",
      "Validation loss improved from 2.1513 to 2.1509. Saving model...\n",
      "\n",
      "LOG: Epoch [955/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4308\n",
      "    Batch [2/2], Train Loss: 3.4816\n",
      "Epoch [955/2000], Avg Train Loss: 3.4562\n",
      "Epoch [955/2000], Avg Val Loss: 2.1501\n",
      "Validation loss improved from 2.1509 to 2.1501. Saving model...\n",
      "\n",
      "LOG: Epoch [956/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4871\n",
      "    Batch [2/2], Train Loss: 3.4781\n",
      "Epoch [956/2000], Avg Train Loss: 3.4826\n",
      "Epoch [956/2000], Avg Val Loss: 2.1494\n",
      "Validation loss improved from 2.1501 to 2.1494. Saving model...\n",
      "\n",
      "LOG: Epoch [957/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4861\n",
      "    Batch [2/2], Train Loss: 3.5245\n",
      "Epoch [957/2000], Avg Train Loss: 3.5053\n",
      "Epoch [957/2000], Avg Val Loss: 2.1492\n",
      "Validation loss improved from 2.1494 to 2.1492. Saving model...\n",
      "\n",
      "LOG: Epoch [958/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.4668\n",
      "    Batch [2/2], Train Loss: 3.4813\n",
      "Epoch [958/2000], Avg Train Loss: 3.4741\n",
      "Epoch [958/2000], Avg Val Loss: 2.1491\n",
      "Validation loss improved from 2.1492 to 2.1491. Saving model...\n",
      "\n",
      "LOG: Epoch [959/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4926\n",
      "    Batch [2/2], Train Loss: 3.4368\n",
      "Epoch [959/2000], Avg Train Loss: 3.4647\n",
      "Epoch [959/2000], Avg Val Loss: 2.1491\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [960/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4984\n",
      "    Batch [2/2], Train Loss: 3.4612\n",
      "Epoch [960/2000], Avg Train Loss: 3.4798\n",
      "Epoch [960/2000], Avg Val Loss: 2.1498\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [961/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4771\n",
      "    Batch [2/2], Train Loss: 3.5229\n",
      "Epoch [961/2000], Avg Train Loss: 3.5000\n",
      "Epoch [961/2000], Avg Val Loss: 2.1504\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [962/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4577\n",
      "    Batch [2/2], Train Loss: 3.4801\n",
      "Epoch [962/2000], Avg Train Loss: 3.4689\n",
      "Epoch [962/2000], Avg Val Loss: 2.1512\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [963/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4651\n",
      "    Batch [2/2], Train Loss: 3.4371\n",
      "Epoch [963/2000], Avg Train Loss: 3.4511\n",
      "Epoch [963/2000], Avg Val Loss: 2.1515\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [964/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4466\n",
      "    Batch [2/2], Train Loss: 3.4722\n",
      "Epoch [964/2000], Avg Train Loss: 3.4594\n",
      "Epoch [964/2000], Avg Val Loss: 2.1516\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [965/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4719\n",
      "    Batch [2/2], Train Loss: 3.4732\n",
      "Epoch [965/2000], Avg Train Loss: 3.4726\n",
      "Epoch [965/2000], Avg Val Loss: 2.1515\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [966/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4735\n",
      "    Batch [2/2], Train Loss: 3.4896\n",
      "Epoch [966/2000], Avg Train Loss: 3.4815\n",
      "Epoch [966/2000], Avg Val Loss: 2.1515\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [967/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5028\n",
      "    Batch [2/2], Train Loss: 3.4433\n",
      "Epoch [967/2000], Avg Train Loss: 3.4731\n",
      "Epoch [967/2000], Avg Val Loss: 2.1514\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [968/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4691\n",
      "    Batch [2/2], Train Loss: 3.4982\n",
      "Epoch [968/2000], Avg Train Loss: 3.4836\n",
      "Epoch [968/2000], Avg Val Loss: 2.1509\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [969/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4880\n",
      "    Batch [2/2], Train Loss: 3.4797\n",
      "Epoch [969/2000], Avg Train Loss: 3.4838\n",
      "Epoch [969/2000], Avg Val Loss: 2.1504\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [970/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4931\n",
      "    Batch [2/2], Train Loss: 3.4701\n",
      "Epoch [970/2000], Avg Train Loss: 3.4816\n",
      "Epoch [970/2000], Avg Val Loss: 2.1504\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [971/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4886\n",
      "    Batch [2/2], Train Loss: 3.4728\n",
      "Epoch [971/2000], Avg Train Loss: 3.4807\n",
      "Epoch [971/2000], Avg Val Loss: 2.1507\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [972/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4830\n",
      "    Batch [2/2], Train Loss: 3.5293\n",
      "Epoch [972/2000], Avg Train Loss: 3.5061\n",
      "Epoch [972/2000], Avg Val Loss: 2.1513\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [973/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4568\n",
      "    Batch [2/2], Train Loss: 3.4710\n",
      "Epoch [973/2000], Avg Train Loss: 3.4639\n",
      "Epoch [973/2000], Avg Val Loss: 2.1517\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [974/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4521\n",
      "    Batch [2/2], Train Loss: 3.4615\n",
      "Epoch [974/2000], Avg Train Loss: 3.4568\n",
      "Epoch [974/2000], Avg Val Loss: 2.1518\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [975/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4636\n",
      "    Batch [2/2], Train Loss: 3.4750\n",
      "Epoch [975/2000], Avg Train Loss: 3.4693\n",
      "Epoch [975/2000], Avg Val Loss: 2.1520\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [976/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.4949\n",
      "Epoch [976/2000], Avg Train Loss: 3.4607\n",
      "Epoch [976/2000], Avg Val Loss: 2.1520\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [977/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4306\n",
      "    Batch [2/2], Train Loss: 3.4873\n",
      "Epoch [977/2000], Avg Train Loss: 3.4590\n",
      "Epoch [977/2000], Avg Val Loss: 2.1517\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [978/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5016\n",
      "    Batch [2/2], Train Loss: 3.4654\n",
      "Epoch [978/2000], Avg Train Loss: 3.4835\n",
      "Epoch [978/2000], Avg Val Loss: 2.1511\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [979/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4995\n",
      "    Batch [2/2], Train Loss: 3.4799\n",
      "Epoch [979/2000], Avg Train Loss: 3.4897\n",
      "Epoch [979/2000], Avg Val Loss: 2.1502\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [980/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4916\n",
      "    Batch [2/2], Train Loss: 3.4378\n",
      "Epoch [980/2000], Avg Train Loss: 3.4647\n",
      "Epoch [980/2000], Avg Val Loss: 2.1497\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [981/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5123\n",
      "    Batch [2/2], Train Loss: 3.5019\n",
      "Epoch [981/2000], Avg Train Loss: 3.5071\n",
      "Epoch [981/2000], Avg Val Loss: 2.1491\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [982/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4389\n",
      "    Batch [2/2], Train Loss: 3.4703\n",
      "Epoch [982/2000], Avg Train Loss: 3.4546\n",
      "Epoch [982/2000], Avg Val Loss: 2.1487\n",
      "Validation loss improved from 2.1491 to 2.1487. Saving model...\n",
      "\n",
      "LOG: Epoch [983/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4442\n",
      "    Batch [2/2], Train Loss: 3.4641\n",
      "Epoch [983/2000], Avg Train Loss: 3.4542\n",
      "Epoch [983/2000], Avg Val Loss: 2.1482\n",
      "Validation loss improved from 2.1487 to 2.1482. Saving model...\n",
      "\n",
      "LOG: Epoch [984/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4599\n",
      "    Batch [2/2], Train Loss: 3.4661\n",
      "Epoch [984/2000], Avg Train Loss: 3.4630\n",
      "Epoch [984/2000], Avg Val Loss: 2.1476\n",
      "Validation loss improved from 2.1482 to 2.1476. Saving model...\n",
      "\n",
      "LOG: Epoch [985/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4576\n",
      "    Batch [2/2], Train Loss: 3.4598\n",
      "Epoch [985/2000], Avg Train Loss: 3.4587\n",
      "Epoch [985/2000], Avg Val Loss: 2.1472\n",
      "Validation loss improved from 2.1476 to 2.1472. Saving model...\n",
      "\n",
      "LOG: Epoch [986/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4812\n",
      "    Batch [2/2], Train Loss: 3.4837\n",
      "Epoch [986/2000], Avg Train Loss: 3.4825\n",
      "Epoch [986/2000], Avg Val Loss: 2.1470\n",
      "Validation loss improved from 2.1472 to 2.1470. Saving model...\n",
      "\n",
      "LOG: Epoch [987/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4650\n",
      "    Batch [2/2], Train Loss: 3.4670\n",
      "Epoch [987/2000], Avg Train Loss: 3.4660\n",
      "Epoch [987/2000], Avg Val Loss: 2.1465\n",
      "Validation loss improved from 2.1470 to 2.1465. Saving model...\n",
      "\n",
      "LOG: Epoch [988/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5062\n",
      "    Batch [2/2], Train Loss: 3.4494\n",
      "Epoch [988/2000], Avg Train Loss: 3.4778\n",
      "Epoch [988/2000], Avg Val Loss: 2.1460\n",
      "Validation loss improved from 2.1465 to 2.1460. Saving model...\n",
      "\n",
      "LOG: Epoch [989/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4749\n",
      "    Batch [2/2], Train Loss: 3.5134\n",
      "Epoch [989/2000], Avg Train Loss: 3.4941\n",
      "Epoch [989/2000], Avg Val Loss: 2.1456\n",
      "Validation loss improved from 2.1460 to 2.1456. Saving model...\n",
      "\n",
      "LOG: Epoch [990/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4931\n",
      "    Batch [2/2], Train Loss: 3.4474\n",
      "Epoch [990/2000], Avg Train Loss: 3.4703\n",
      "Epoch [990/2000], Avg Val Loss: 2.1450\n",
      "Validation loss improved from 2.1456 to 2.1450. Saving model...\n",
      "\n",
      "LOG: Epoch [991/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4573\n",
      "    Batch [2/2], Train Loss: 3.4401\n",
      "Epoch [991/2000], Avg Train Loss: 3.4487\n",
      "Epoch [991/2000], Avg Val Loss: 2.1445\n",
      "Validation loss improved from 2.1450 to 2.1445. Saving model...\n",
      "\n",
      "LOG: Epoch [992/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4626\n",
      "    Batch [2/2], Train Loss: 3.5020\n",
      "Epoch [992/2000], Avg Train Loss: 3.4823\n",
      "Epoch [992/2000], Avg Val Loss: 2.1441\n",
      "Validation loss improved from 2.1445 to 2.1441. Saving model...\n",
      "\n",
      "LOG: Epoch [993/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4914\n",
      "    Batch [2/2], Train Loss: 3.4873\n",
      "Epoch [993/2000], Avg Train Loss: 3.4893\n",
      "Epoch [993/2000], Avg Val Loss: 2.1437\n",
      "Validation loss improved from 2.1441 to 2.1437. Saving model...\n",
      "\n",
      "LOG: Epoch [994/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5114\n",
      "    Batch [2/2], Train Loss: 3.4925\n",
      "Epoch [994/2000], Avg Train Loss: 3.5020\n",
      "Epoch [994/2000], Avg Val Loss: 2.1432\n",
      "Validation loss improved from 2.1437 to 2.1432. Saving model...\n",
      "\n",
      "LOG: Epoch [995/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.4710\n",
      "    Batch [2/2], Train Loss: 3.4452\n",
      "Epoch [995/2000], Avg Train Loss: 3.4581\n",
      "Epoch [995/2000], Avg Val Loss: 2.1426\n",
      "Validation loss improved from 2.1432 to 2.1426. Saving model...\n",
      "\n",
      "LOG: Epoch [996/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4878\n",
      "    Batch [2/2], Train Loss: 3.4707\n",
      "Epoch [996/2000], Avg Train Loss: 3.4792\n",
      "Epoch [996/2000], Avg Val Loss: 2.1420\n",
      "Validation loss improved from 2.1426 to 2.1420. Saving model...\n",
      "\n",
      "LOG: Epoch [997/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4866\n",
      "    Batch [2/2], Train Loss: 3.4697\n",
      "Epoch [997/2000], Avg Train Loss: 3.4781\n",
      "Epoch [997/2000], Avg Val Loss: 2.1416\n",
      "Validation loss improved from 2.1420 to 2.1416. Saving model...\n",
      "\n",
      "LOG: Epoch [998/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4834\n",
      "    Batch [2/2], Train Loss: 3.4671\n",
      "Epoch [998/2000], Avg Train Loss: 3.4752\n",
      "Epoch [998/2000], Avg Val Loss: 2.1412\n",
      "Validation loss improved from 2.1416 to 2.1412. Saving model...\n",
      "\n",
      "LOG: Epoch [999/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4442\n",
      "    Batch [2/2], Train Loss: 3.4325\n",
      "Epoch [999/2000], Avg Train Loss: 3.4383\n",
      "Epoch [999/2000], Avg Val Loss: 2.1406\n",
      "Validation loss improved from 2.1412 to 2.1406. Saving model...\n",
      "\n",
      "LOG: Epoch [1000/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.5079\n",
      "    Batch [2/2], Train Loss: 3.3941\n",
      "Epoch [1000/2000], Avg Train Loss: 3.4510\n",
      "Epoch [1000/2000], Avg Val Loss: 2.1400\n",
      "Validation loss improved from 2.1406 to 2.1400. Saving model...\n",
      "\n",
      "LOG: Epoch [1001/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4516\n",
      "    Batch [2/2], Train Loss: 3.4739\n",
      "Epoch [1001/2000], Avg Train Loss: 3.4628\n",
      "Epoch [1001/2000], Avg Val Loss: 2.1391\n",
      "Validation loss improved from 2.1400 to 2.1391. Saving model...\n",
      "\n",
      "LOG: Epoch [1002/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4413\n",
      "    Batch [2/2], Train Loss: 3.5023\n",
      "Epoch [1002/2000], Avg Train Loss: 3.4718\n",
      "Epoch [1002/2000], Avg Val Loss: 2.1388\n",
      "Validation loss improved from 2.1391 to 2.1388. Saving model...\n",
      "\n",
      "LOG: Epoch [1003/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4691\n",
      "    Batch [2/2], Train Loss: 3.4947\n",
      "Epoch [1003/2000], Avg Train Loss: 3.4819\n",
      "Epoch [1003/2000], Avg Val Loss: 2.1387\n",
      "Validation loss improved from 2.1388 to 2.1387. Saving model...\n",
      "\n",
      "LOG: Epoch [1004/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4975\n",
      "    Batch [2/2], Train Loss: 3.4566\n",
      "Epoch [1004/2000], Avg Train Loss: 3.4770\n",
      "Epoch [1004/2000], Avg Val Loss: 2.1386\n",
      "Validation loss improved from 2.1387 to 2.1386. Saving model...\n",
      "\n",
      "LOG: Epoch [1005/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4686\n",
      "    Batch [2/2], Train Loss: 3.4722\n",
      "Epoch [1005/2000], Avg Train Loss: 3.4704\n",
      "Epoch [1005/2000], Avg Val Loss: 2.1382\n",
      "Validation loss improved from 2.1386 to 2.1382. Saving model...\n",
      "\n",
      "LOG: Epoch [1006/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4665\n",
      "    Batch [2/2], Train Loss: 3.4190\n",
      "Epoch [1006/2000], Avg Train Loss: 3.4427\n",
      "Epoch [1006/2000], Avg Val Loss: 2.1381\n",
      "Validation loss improved from 2.1382 to 2.1381. Saving model...\n",
      "\n",
      "LOG: Epoch [1007/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4454\n",
      "    Batch [2/2], Train Loss: 3.4719\n",
      "Epoch [1007/2000], Avg Train Loss: 3.4586\n",
      "Epoch [1007/2000], Avg Val Loss: 2.1379\n",
      "Validation loss improved from 2.1381 to 2.1379. Saving model...\n",
      "\n",
      "LOG: Epoch [1008/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4914\n",
      "    Batch [2/2], Train Loss: 3.4914\n",
      "Epoch [1008/2000], Avg Train Loss: 3.4914\n",
      "Epoch [1008/2000], Avg Val Loss: 2.1379\n",
      "Validation loss improved from 2.1379 to 2.1379. Saving model...\n",
      "\n",
      "LOG: Epoch [1009/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4821\n",
      "    Batch [2/2], Train Loss: 3.4330\n",
      "Epoch [1009/2000], Avg Train Loss: 3.4576\n",
      "Epoch [1009/2000], Avg Val Loss: 2.1379\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1010/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4791\n",
      "    Batch [2/2], Train Loss: 3.4374\n",
      "Epoch [1010/2000], Avg Train Loss: 3.4582\n",
      "Epoch [1010/2000], Avg Val Loss: 2.1380\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1011/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4753\n",
      "    Batch [2/2], Train Loss: 3.4359\n",
      "Epoch [1011/2000], Avg Train Loss: 3.4556\n",
      "Epoch [1011/2000], Avg Val Loss: 2.1384\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1012/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4727\n",
      "    Batch [2/2], Train Loss: 3.4630\n",
      "Epoch [1012/2000], Avg Train Loss: 3.4678\n",
      "Epoch [1012/2000], Avg Val Loss: 2.1389\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1013/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.4560\n",
      "    Batch [2/2], Train Loss: 3.4839\n",
      "Epoch [1013/2000], Avg Train Loss: 3.4700\n",
      "Epoch [1013/2000], Avg Val Loss: 2.1395\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1014/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4345\n",
      "    Batch [2/2], Train Loss: 3.4364\n",
      "Epoch [1014/2000], Avg Train Loss: 3.4355\n",
      "Epoch [1014/2000], Avg Val Loss: 2.1398\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1015/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4574\n",
      "    Batch [2/2], Train Loss: 3.4839\n",
      "Epoch [1015/2000], Avg Train Loss: 3.4707\n",
      "Epoch [1015/2000], Avg Val Loss: 2.1398\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1016/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4905\n",
      "    Batch [2/2], Train Loss: 3.4314\n",
      "Epoch [1016/2000], Avg Train Loss: 3.4610\n",
      "Epoch [1016/2000], Avg Val Loss: 2.1400\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1017/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4244\n",
      "    Batch [2/2], Train Loss: 3.4585\n",
      "Epoch [1017/2000], Avg Train Loss: 3.4414\n",
      "Epoch [1017/2000], Avg Val Loss: 2.1403\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1018/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4690\n",
      "    Batch [2/2], Train Loss: 3.4789\n",
      "Epoch [1018/2000], Avg Train Loss: 3.4739\n",
      "Epoch [1018/2000], Avg Val Loss: 2.1403\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1019/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4371\n",
      "    Batch [2/2], Train Loss: 3.4185\n",
      "Epoch [1019/2000], Avg Train Loss: 3.4278\n",
      "Epoch [1019/2000], Avg Val Loss: 2.1400\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1020/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4560\n",
      "    Batch [2/2], Train Loss: 3.4330\n",
      "Epoch [1020/2000], Avg Train Loss: 3.4445\n",
      "Epoch [1020/2000], Avg Val Loss: 2.1393\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1021/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4244\n",
      "    Batch [2/2], Train Loss: 3.4818\n",
      "Epoch [1021/2000], Avg Train Loss: 3.4531\n",
      "Epoch [1021/2000], Avg Val Loss: 2.1389\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1022/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4806\n",
      "    Batch [2/2], Train Loss: 3.4593\n",
      "Epoch [1022/2000], Avg Train Loss: 3.4699\n",
      "Epoch [1022/2000], Avg Val Loss: 2.1385\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1023/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4659\n",
      "    Batch [2/2], Train Loss: 3.4285\n",
      "Epoch [1023/2000], Avg Train Loss: 3.4472\n",
      "Epoch [1023/2000], Avg Val Loss: 2.1380\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1024/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4399\n",
      "    Batch [2/2], Train Loss: 3.4377\n",
      "Epoch [1024/2000], Avg Train Loss: 3.4388\n",
      "Epoch [1024/2000], Avg Val Loss: 2.1376\n",
      "Validation loss improved from 2.1379 to 2.1376. Saving model...\n",
      "\n",
      "LOG: Epoch [1025/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4696\n",
      "    Batch [2/2], Train Loss: 3.4432\n",
      "Epoch [1025/2000], Avg Train Loss: 3.4564\n",
      "Epoch [1025/2000], Avg Val Loss: 2.1379\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1026/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4240\n",
      "    Batch [2/2], Train Loss: 3.4429\n",
      "Epoch [1026/2000], Avg Train Loss: 3.4334\n",
      "Epoch [1026/2000], Avg Val Loss: 2.1382\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1027/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4604\n",
      "    Batch [2/2], Train Loss: 3.4653\n",
      "Epoch [1027/2000], Avg Train Loss: 3.4629\n",
      "Epoch [1027/2000], Avg Val Loss: 2.1384\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1028/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4357\n",
      "    Batch [2/2], Train Loss: 3.4177\n",
      "Epoch [1028/2000], Avg Train Loss: 3.4267\n",
      "Epoch [1028/2000], Avg Val Loss: 2.1387\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1029/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4369\n",
      "    Batch [2/2], Train Loss: 3.4852\n",
      "Epoch [1029/2000], Avg Train Loss: 3.4611\n",
      "Epoch [1029/2000], Avg Val Loss: 2.1393\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1030/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4842\n",
      "    Batch [2/2], Train Loss: 3.4648\n",
      "Epoch [1030/2000], Avg Train Loss: 3.4745\n",
      "Epoch [1030/2000], Avg Val Loss: 2.1396\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1031/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.4588\n",
      "Epoch [1031/2000], Avg Train Loss: 3.4561\n",
      "Epoch [1031/2000], Avg Val Loss: 2.1398\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1032/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4660\n",
      "    Batch [2/2], Train Loss: 3.4662\n",
      "Epoch [1032/2000], Avg Train Loss: 3.4661\n",
      "Epoch [1032/2000], Avg Val Loss: 2.1398\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1033/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4452\n",
      "    Batch [2/2], Train Loss: 3.4411\n",
      "Epoch [1033/2000], Avg Train Loss: 3.4431\n",
      "Epoch [1033/2000], Avg Val Loss: 2.1398\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1034/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4683\n",
      "    Batch [2/2], Train Loss: 3.3952\n",
      "Epoch [1034/2000], Avg Train Loss: 3.4317\n",
      "Epoch [1034/2000], Avg Val Loss: 2.1398\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1035/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4166\n",
      "    Batch [2/2], Train Loss: 3.4809\n",
      "Epoch [1035/2000], Avg Train Loss: 3.4487\n",
      "Epoch [1035/2000], Avg Val Loss: 2.1394\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1036/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4126\n",
      "    Batch [2/2], Train Loss: 3.4247\n",
      "Epoch [1036/2000], Avg Train Loss: 3.4187\n",
      "Epoch [1036/2000], Avg Val Loss: 2.1389\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1037/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4097\n",
      "    Batch [2/2], Train Loss: 3.4298\n",
      "Epoch [1037/2000], Avg Train Loss: 3.4197\n",
      "Epoch [1037/2000], Avg Val Loss: 2.1387\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1038/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4794\n",
      "    Batch [2/2], Train Loss: 3.4710\n",
      "Epoch [1038/2000], Avg Train Loss: 3.4752\n",
      "Epoch [1038/2000], Avg Val Loss: 2.1379\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1039/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4197\n",
      "    Batch [2/2], Train Loss: 3.4223\n",
      "Epoch [1039/2000], Avg Train Loss: 3.4210\n",
      "Epoch [1039/2000], Avg Val Loss: 2.1372\n",
      "Validation loss improved from 2.1376 to 2.1372. Saving model...\n",
      "\n",
      "LOG: Epoch [1040/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4870\n",
      "    Batch [2/2], Train Loss: 3.4478\n",
      "Epoch [1040/2000], Avg Train Loss: 3.4674\n",
      "Epoch [1040/2000], Avg Val Loss: 2.1368\n",
      "Validation loss improved from 2.1372 to 2.1368. Saving model...\n",
      "\n",
      "LOG: Epoch [1041/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4093\n",
      "    Batch [2/2], Train Loss: 3.4191\n",
      "Epoch [1041/2000], Avg Train Loss: 3.4142\n",
      "Epoch [1041/2000], Avg Val Loss: 2.1364\n",
      "Validation loss improved from 2.1368 to 2.1364. Saving model...\n",
      "\n",
      "LOG: Epoch [1042/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4350\n",
      "    Batch [2/2], Train Loss: 3.4760\n",
      "Epoch [1042/2000], Avg Train Loss: 3.4555\n",
      "Epoch [1042/2000], Avg Val Loss: 2.1360\n",
      "Validation loss improved from 2.1364 to 2.1360. Saving model...\n",
      "\n",
      "LOG: Epoch [1043/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4382\n",
      "    Batch [2/2], Train Loss: 3.4270\n",
      "Epoch [1043/2000], Avg Train Loss: 3.4326\n",
      "Epoch [1043/2000], Avg Val Loss: 2.1359\n",
      "Validation loss improved from 2.1360 to 2.1359. Saving model...\n",
      "\n",
      "LOG: Epoch [1044/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4659\n",
      "    Batch [2/2], Train Loss: 3.4200\n",
      "Epoch [1044/2000], Avg Train Loss: 3.4430\n",
      "Epoch [1044/2000], Avg Val Loss: 2.1356\n",
      "Validation loss improved from 2.1359 to 2.1356. Saving model...\n",
      "\n",
      "LOG: Epoch [1045/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4179\n",
      "    Batch [2/2], Train Loss: 3.4466\n",
      "Epoch [1045/2000], Avg Train Loss: 3.4322\n",
      "Epoch [1045/2000], Avg Val Loss: 2.1356\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1046/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4122\n",
      "    Batch [2/2], Train Loss: 3.4341\n",
      "Epoch [1046/2000], Avg Train Loss: 3.4231\n",
      "Epoch [1046/2000], Avg Val Loss: 2.1356\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1047/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4256\n",
      "    Batch [2/2], Train Loss: 3.4500\n",
      "Epoch [1047/2000], Avg Train Loss: 3.4378\n",
      "Epoch [1047/2000], Avg Val Loss: 2.1357\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1048/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4342\n",
      "    Batch [2/2], Train Loss: 3.4206\n",
      "Epoch [1048/2000], Avg Train Loss: 3.4274\n",
      "Epoch [1048/2000], Avg Val Loss: 2.1359\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1049/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4364\n",
      "    Batch [2/2], Train Loss: 3.4134\n",
      "Epoch [1049/2000], Avg Train Loss: 3.4249\n",
      "Epoch [1049/2000], Avg Val Loss: 2.1358\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1050/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4777\n",
      "    Batch [2/2], Train Loss: 3.4302\n",
      "Epoch [1050/2000], Avg Train Loss: 3.4540\n",
      "Epoch [1050/2000], Avg Val Loss: 2.1357\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1051/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.4340\n",
      "    Batch [2/2], Train Loss: 3.4104\n",
      "Epoch [1051/2000], Avg Train Loss: 3.4222\n",
      "Epoch [1051/2000], Avg Val Loss: 2.1353\n",
      "Validation loss improved from 2.1356 to 2.1353. Saving model...\n",
      "\n",
      "LOG: Epoch [1052/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4766\n",
      "    Batch [2/2], Train Loss: 3.4471\n",
      "Epoch [1052/2000], Avg Train Loss: 3.4619\n",
      "Epoch [1052/2000], Avg Val Loss: 2.1352\n",
      "Validation loss improved from 2.1353 to 2.1352. Saving model...\n",
      "\n",
      "LOG: Epoch [1053/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4491\n",
      "    Batch [2/2], Train Loss: 3.4731\n",
      "Epoch [1053/2000], Avg Train Loss: 3.4611\n",
      "Epoch [1053/2000], Avg Val Loss: 2.1348\n",
      "Validation loss improved from 2.1352 to 2.1348. Saving model...\n",
      "\n",
      "LOG: Epoch [1054/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4268\n",
      "    Batch [2/2], Train Loss: 3.4063\n",
      "Epoch [1054/2000], Avg Train Loss: 3.4166\n",
      "Epoch [1054/2000], Avg Val Loss: 2.1346\n",
      "Validation loss improved from 2.1348 to 2.1346. Saving model...\n",
      "\n",
      "LOG: Epoch [1055/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4005\n",
      "    Batch [2/2], Train Loss: 3.4162\n",
      "Epoch [1055/2000], Avg Train Loss: 3.4084\n",
      "Epoch [1055/2000], Avg Val Loss: 2.1347\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1056/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4369\n",
      "    Batch [2/2], Train Loss: 3.4556\n",
      "Epoch [1056/2000], Avg Train Loss: 3.4462\n",
      "Epoch [1056/2000], Avg Val Loss: 2.1350\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1057/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4064\n",
      "    Batch [2/2], Train Loss: 3.4496\n",
      "Epoch [1057/2000], Avg Train Loss: 3.4280\n",
      "Epoch [1057/2000], Avg Val Loss: 2.1353\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1058/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4341\n",
      "    Batch [2/2], Train Loss: 3.4757\n",
      "Epoch [1058/2000], Avg Train Loss: 3.4549\n",
      "Epoch [1058/2000], Avg Val Loss: 2.1354\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1059/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4401\n",
      "    Batch [2/2], Train Loss: 3.4617\n",
      "Epoch [1059/2000], Avg Train Loss: 3.4509\n",
      "Epoch [1059/2000], Avg Val Loss: 2.1353\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1060/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4336\n",
      "    Batch [2/2], Train Loss: 3.4442\n",
      "Epoch [1060/2000], Avg Train Loss: 3.4389\n",
      "Epoch [1060/2000], Avg Val Loss: 2.1353\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1061/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4115\n",
      "    Batch [2/2], Train Loss: 3.4576\n",
      "Epoch [1061/2000], Avg Train Loss: 3.4345\n",
      "Epoch [1061/2000], Avg Val Loss: 2.1353\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1062/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4268\n",
      "    Batch [2/2], Train Loss: 3.4479\n",
      "Epoch [1062/2000], Avg Train Loss: 3.4374\n",
      "Epoch [1062/2000], Avg Val Loss: 2.1349\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1063/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4057\n",
      "    Batch [2/2], Train Loss: 3.4537\n",
      "Epoch [1063/2000], Avg Train Loss: 3.4297\n",
      "Epoch [1063/2000], Avg Val Loss: 2.1345\n",
      "Validation loss improved from 2.1346 to 2.1345. Saving model...\n",
      "\n",
      "LOG: Epoch [1064/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4111\n",
      "    Batch [2/2], Train Loss: 3.3919\n",
      "Epoch [1064/2000], Avg Train Loss: 3.4015\n",
      "Epoch [1064/2000], Avg Val Loss: 2.1340\n",
      "Validation loss improved from 2.1345 to 2.1340. Saving model...\n",
      "\n",
      "LOG: Epoch [1065/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4130\n",
      "    Batch [2/2], Train Loss: 3.4256\n",
      "Epoch [1065/2000], Avg Train Loss: 3.4193\n",
      "Epoch [1065/2000], Avg Val Loss: 2.1334\n",
      "Validation loss improved from 2.1340 to 2.1334. Saving model...\n",
      "\n",
      "LOG: Epoch [1066/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4706\n",
      "    Batch [2/2], Train Loss: 3.4059\n",
      "Epoch [1066/2000], Avg Train Loss: 3.4382\n",
      "Epoch [1066/2000], Avg Val Loss: 2.1330\n",
      "Validation loss improved from 2.1334 to 2.1330. Saving model...\n",
      "\n",
      "LOG: Epoch [1067/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4211\n",
      "    Batch [2/2], Train Loss: 3.4416\n",
      "Epoch [1067/2000], Avg Train Loss: 3.4313\n",
      "Epoch [1067/2000], Avg Val Loss: 2.1326\n",
      "Validation loss improved from 2.1330 to 2.1326. Saving model...\n",
      "\n",
      "LOG: Epoch [1068/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4114\n",
      "    Batch [2/2], Train Loss: 3.4334\n",
      "Epoch [1068/2000], Avg Train Loss: 3.4224\n",
      "Epoch [1068/2000], Avg Val Loss: 2.1324\n",
      "Validation loss improved from 2.1326 to 2.1324. Saving model...\n",
      "\n",
      "LOG: Epoch [1069/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.4748\n",
      "    Batch [2/2], Train Loss: 3.4011\n",
      "Epoch [1069/2000], Avg Train Loss: 3.4379\n",
      "Epoch [1069/2000], Avg Val Loss: 2.1327\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1070/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4634\n",
      "    Batch [2/2], Train Loss: 3.4153\n",
      "Epoch [1070/2000], Avg Train Loss: 3.4393\n",
      "Epoch [1070/2000], Avg Val Loss: 2.1333\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1071/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4566\n",
      "    Batch [2/2], Train Loss: 3.4632\n",
      "Epoch [1071/2000], Avg Train Loss: 3.4599\n",
      "Epoch [1071/2000], Avg Val Loss: 2.1336\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1072/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4153\n",
      "    Batch [2/2], Train Loss: 3.4106\n",
      "Epoch [1072/2000], Avg Train Loss: 3.4129\n",
      "Epoch [1072/2000], Avg Val Loss: 2.1337\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1073/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4077\n",
      "    Batch [2/2], Train Loss: 3.4561\n",
      "Epoch [1073/2000], Avg Train Loss: 3.4319\n",
      "Epoch [1073/2000], Avg Val Loss: 2.1339\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1074/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4689\n",
      "    Batch [2/2], Train Loss: 3.4269\n",
      "Epoch [1074/2000], Avg Train Loss: 3.4479\n",
      "Epoch [1074/2000], Avg Val Loss: 2.1336\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1075/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4375\n",
      "    Batch [2/2], Train Loss: 3.4380\n",
      "Epoch [1075/2000], Avg Train Loss: 3.4378\n",
      "Epoch [1075/2000], Avg Val Loss: 2.1332\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1076/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4511\n",
      "    Batch [2/2], Train Loss: 3.4579\n",
      "Epoch [1076/2000], Avg Train Loss: 3.4545\n",
      "Epoch [1076/2000], Avg Val Loss: 2.1330\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1077/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4253\n",
      "    Batch [2/2], Train Loss: 3.3721\n",
      "Epoch [1077/2000], Avg Train Loss: 3.3987\n",
      "Epoch [1077/2000], Avg Val Loss: 2.1333\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1078/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4432\n",
      "    Batch [2/2], Train Loss: 3.4233\n",
      "Epoch [1078/2000], Avg Train Loss: 3.4333\n",
      "Epoch [1078/2000], Avg Val Loss: 2.1333\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1079/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4309\n",
      "    Batch [2/2], Train Loss: 3.4230\n",
      "Epoch [1079/2000], Avg Train Loss: 3.4270\n",
      "Epoch [1079/2000], Avg Val Loss: 2.1331\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1080/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4121\n",
      "    Batch [2/2], Train Loss: 3.4518\n",
      "Epoch [1080/2000], Avg Train Loss: 3.4320\n",
      "Epoch [1080/2000], Avg Val Loss: 2.1327\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1081/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4064\n",
      "    Batch [2/2], Train Loss: 3.4483\n",
      "Epoch [1081/2000], Avg Train Loss: 3.4274\n",
      "Epoch [1081/2000], Avg Val Loss: 2.1325\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1082/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4251\n",
      "    Batch [2/2], Train Loss: 3.4254\n",
      "Epoch [1082/2000], Avg Train Loss: 3.4253\n",
      "Epoch [1082/2000], Avg Val Loss: 2.1328\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1083/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4181\n",
      "    Batch [2/2], Train Loss: 3.4310\n",
      "Epoch [1083/2000], Avg Train Loss: 3.4246\n",
      "Epoch [1083/2000], Avg Val Loss: 2.1333\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1084/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4364\n",
      "    Batch [2/2], Train Loss: 3.4402\n",
      "Epoch [1084/2000], Avg Train Loss: 3.4383\n",
      "Epoch [1084/2000], Avg Val Loss: 2.1342\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1085/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4353\n",
      "    Batch [2/2], Train Loss: 3.4592\n",
      "Epoch [1085/2000], Avg Train Loss: 3.4472\n",
      "Epoch [1085/2000], Avg Val Loss: 2.1350\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1086/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4180\n",
      "    Batch [2/2], Train Loss: 3.4625\n",
      "Epoch [1086/2000], Avg Train Loss: 3.4403\n",
      "Epoch [1086/2000], Avg Val Loss: 2.1354\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1087/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4044\n",
      "    Batch [2/2], Train Loss: 3.4356\n",
      "Epoch [1087/2000], Avg Train Loss: 3.4200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1087/2000], Avg Val Loss: 2.1358\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1088/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4100\n",
      "    Batch [2/2], Train Loss: 3.4101\n",
      "Epoch [1088/2000], Avg Train Loss: 3.4101\n",
      "Epoch [1088/2000], Avg Val Loss: 2.1358\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1089/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4278\n",
      "    Batch [2/2], Train Loss: 3.4078\n",
      "Epoch [1089/2000], Avg Train Loss: 3.4178\n",
      "Epoch [1089/2000], Avg Val Loss: 2.1360\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1090/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4125\n",
      "    Batch [2/2], Train Loss: 3.4027\n",
      "Epoch [1090/2000], Avg Train Loss: 3.4076\n",
      "Epoch [1090/2000], Avg Val Loss: 2.1365\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1091/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4246\n",
      "    Batch [2/2], Train Loss: 3.4484\n",
      "Epoch [1091/2000], Avg Train Loss: 3.4365\n",
      "Epoch [1091/2000], Avg Val Loss: 2.1370\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1092/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4018\n",
      "    Batch [2/2], Train Loss: 3.3879\n",
      "Epoch [1092/2000], Avg Train Loss: 3.3949\n",
      "Epoch [1092/2000], Avg Val Loss: 2.1371\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1093/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4106\n",
      "    Batch [2/2], Train Loss: 3.3901\n",
      "Epoch [1093/2000], Avg Train Loss: 3.4003\n",
      "Epoch [1093/2000], Avg Val Loss: 2.1366\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1094/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3984\n",
      "    Batch [2/2], Train Loss: 3.4743\n",
      "Epoch [1094/2000], Avg Train Loss: 3.4364\n",
      "Epoch [1094/2000], Avg Val Loss: 2.1361\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1095/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4186\n",
      "    Batch [2/2], Train Loss: 3.3944\n",
      "Epoch [1095/2000], Avg Train Loss: 3.4065\n",
      "Epoch [1095/2000], Avg Val Loss: 2.1357\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1096/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4258\n",
      "    Batch [2/2], Train Loss: 3.4695\n",
      "Epoch [1096/2000], Avg Train Loss: 3.4476\n",
      "Epoch [1096/2000], Avg Val Loss: 2.1354\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1097/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4236\n",
      "    Batch [2/2], Train Loss: 3.4299\n",
      "Epoch [1097/2000], Avg Train Loss: 3.4267\n",
      "Epoch [1097/2000], Avg Val Loss: 2.1349\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1098/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4103\n",
      "    Batch [2/2], Train Loss: 3.3942\n",
      "Epoch [1098/2000], Avg Train Loss: 3.4023\n",
      "Epoch [1098/2000], Avg Val Loss: 2.1346\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1099/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4425\n",
      "    Batch [2/2], Train Loss: 3.4043\n",
      "Epoch [1099/2000], Avg Train Loss: 3.4234\n",
      "Epoch [1099/2000], Avg Val Loss: 2.1349\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1100/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3982\n",
      "    Batch [2/2], Train Loss: 3.3883\n",
      "Epoch [1100/2000], Avg Train Loss: 3.3933\n",
      "Epoch [1100/2000], Avg Val Loss: 2.1352\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1101/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4553\n",
      "    Batch [2/2], Train Loss: 3.4624\n",
      "Epoch [1101/2000], Avg Train Loss: 3.4588\n",
      "Epoch [1101/2000], Avg Val Loss: 2.1356\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1102/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4002\n",
      "    Batch [2/2], Train Loss: 3.4421\n",
      "Epoch [1102/2000], Avg Train Loss: 3.4211\n",
      "Epoch [1102/2000], Avg Val Loss: 2.1362\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1103/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4030\n",
      "    Batch [2/2], Train Loss: 3.3869\n",
      "Epoch [1103/2000], Avg Train Loss: 3.3950\n",
      "Epoch [1103/2000], Avg Val Loss: 2.1366\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1104/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4258\n",
      "    Batch [2/2], Train Loss: 3.4164\n",
      "Epoch [1104/2000], Avg Train Loss: 3.4211\n",
      "Epoch [1104/2000], Avg Val Loss: 2.1369\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1105/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4265\n",
      "    Batch [2/2], Train Loss: 3.4236\n",
      "Epoch [1105/2000], Avg Train Loss: 3.4251\n",
      "Epoch [1105/2000], Avg Val Loss: 2.1374\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1106/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.4026\n",
      "Epoch [1106/2000], Avg Train Loss: 3.3911\n",
      "Epoch [1106/2000], Avg Val Loss: 2.1379\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1107/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4170\n",
      "    Batch [2/2], Train Loss: 3.4189\n",
      "Epoch [1107/2000], Avg Train Loss: 3.4179\n",
      "Epoch [1107/2000], Avg Val Loss: 2.1384\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1108/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3915\n",
      "    Batch [2/2], Train Loss: 3.4463\n",
      "Epoch [1108/2000], Avg Train Loss: 3.4189\n",
      "Epoch [1108/2000], Avg Val Loss: 2.1389\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1109/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4272\n",
      "    Batch [2/2], Train Loss: 3.3923\n",
      "Epoch [1109/2000], Avg Train Loss: 3.4098\n",
      "Epoch [1109/2000], Avg Val Loss: 2.1390\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1110/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4010\n",
      "    Batch [2/2], Train Loss: 3.4045\n",
      "Epoch [1110/2000], Avg Train Loss: 3.4028\n",
      "Epoch [1110/2000], Avg Val Loss: 2.1393\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1111/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3757\n",
      "    Batch [2/2], Train Loss: 3.4139\n",
      "Epoch [1111/2000], Avg Train Loss: 3.3948\n",
      "Epoch [1111/2000], Avg Val Loss: 2.1395\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1112/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4152\n",
      "    Batch [2/2], Train Loss: 3.4174\n",
      "Epoch [1112/2000], Avg Train Loss: 3.4163\n",
      "Epoch [1112/2000], Avg Val Loss: 2.1397\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1113/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3873\n",
      "    Batch [2/2], Train Loss: 3.3949\n",
      "Epoch [1113/2000], Avg Train Loss: 3.3911\n",
      "Epoch [1113/2000], Avg Val Loss: 2.1396\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1114/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3821\n",
      "    Batch [2/2], Train Loss: 3.4376\n",
      "Epoch [1114/2000], Avg Train Loss: 3.4098\n",
      "Epoch [1114/2000], Avg Val Loss: 2.1390\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1115/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4168\n",
      "    Batch [2/2], Train Loss: 3.4103\n",
      "Epoch [1115/2000], Avg Train Loss: 3.4135\n",
      "Epoch [1115/2000], Avg Val Loss: 2.1380\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1116/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4026\n",
      "    Batch [2/2], Train Loss: 3.4066\n",
      "Epoch [1116/2000], Avg Train Loss: 3.4046\n",
      "Epoch [1116/2000], Avg Val Loss: 2.1370\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1117/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4006\n",
      "    Batch [2/2], Train Loss: 3.4252\n",
      "Epoch [1117/2000], Avg Train Loss: 3.4129\n",
      "Epoch [1117/2000], Avg Val Loss: 2.1357\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1118/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4024\n",
      "    Batch [2/2], Train Loss: 3.4222\n",
      "Epoch [1118/2000], Avg Train Loss: 3.4123\n",
      "Epoch [1118/2000], Avg Val Loss: 2.1344\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1119/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4021\n",
      "    Batch [2/2], Train Loss: 3.4188\n",
      "Epoch [1119/2000], Avg Train Loss: 3.4105\n",
      "Epoch [1119/2000], Avg Val Loss: 2.1332\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1120/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4355\n",
      "    Batch [2/2], Train Loss: 3.3725\n",
      "Epoch [1120/2000], Avg Train Loss: 3.4040\n",
      "Epoch [1120/2000], Avg Val Loss: 2.1325\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1121/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3620\n",
      "    Batch [2/2], Train Loss: 3.3983\n",
      "Epoch [1121/2000], Avg Train Loss: 3.3801\n",
      "Epoch [1121/2000], Avg Val Loss: 2.1323\n",
      "Validation loss improved from 2.1324 to 2.1323. Saving model...\n",
      "\n",
      "LOG: Epoch [1122/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4808\n",
      "    Batch [2/2], Train Loss: 3.4116\n",
      "Epoch [1122/2000], Avg Train Loss: 3.4462\n",
      "Epoch [1122/2000], Avg Val Loss: 2.1322\n",
      "Validation loss improved from 2.1323 to 2.1322. Saving model...\n",
      "\n",
      "LOG: Epoch [1123/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3618\n",
      "    Batch [2/2], Train Loss: 3.3596\n",
      "Epoch [1123/2000], Avg Train Loss: 3.3607\n",
      "Epoch [1123/2000], Avg Val Loss: 2.1322\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1124/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3766\n",
      "    Batch [2/2], Train Loss: 3.3873\n",
      "Epoch [1124/2000], Avg Train Loss: 3.3819\n",
      "Epoch [1124/2000], Avg Val Loss: 2.1323\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1125/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.4081\n",
      "    Batch [2/2], Train Loss: 3.3816\n",
      "Epoch [1125/2000], Avg Train Loss: 3.3948\n",
      "Epoch [1125/2000], Avg Val Loss: 2.1330\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1126/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4000\n",
      "    Batch [2/2], Train Loss: 3.4297\n",
      "Epoch [1126/2000], Avg Train Loss: 3.4148\n",
      "Epoch [1126/2000], Avg Val Loss: 2.1339\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1127/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4164\n",
      "    Batch [2/2], Train Loss: 3.4352\n",
      "Epoch [1127/2000], Avg Train Loss: 3.4258\n",
      "Epoch [1127/2000], Avg Val Loss: 2.1343\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1128/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4404\n",
      "    Batch [2/2], Train Loss: 3.4134\n",
      "Epoch [1128/2000], Avg Train Loss: 3.4269\n",
      "Epoch [1128/2000], Avg Val Loss: 2.1343\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1129/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4149\n",
      "    Batch [2/2], Train Loss: 3.3690\n",
      "Epoch [1129/2000], Avg Train Loss: 3.3919\n",
      "Epoch [1129/2000], Avg Val Loss: 2.1338\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1130/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4164\n",
      "    Batch [2/2], Train Loss: 3.4129\n",
      "Epoch [1130/2000], Avg Train Loss: 3.4146\n",
      "Epoch [1130/2000], Avg Val Loss: 2.1333\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1131/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3911\n",
      "    Batch [2/2], Train Loss: 3.4299\n",
      "Epoch [1131/2000], Avg Train Loss: 3.4105\n",
      "Epoch [1131/2000], Avg Val Loss: 2.1328\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1132/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4064\n",
      "    Batch [2/2], Train Loss: 3.3796\n",
      "Epoch [1132/2000], Avg Train Loss: 3.3930\n",
      "Epoch [1132/2000], Avg Val Loss: 2.1324\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1133/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3861\n",
      "    Batch [2/2], Train Loss: 3.4305\n",
      "Epoch [1133/2000], Avg Train Loss: 3.4083\n",
      "Epoch [1133/2000], Avg Val Loss: 2.1320\n",
      "Validation loss improved from 2.1322 to 2.1320. Saving model...\n",
      "\n",
      "LOG: Epoch [1134/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4052\n",
      "    Batch [2/2], Train Loss: 3.4229\n",
      "Epoch [1134/2000], Avg Train Loss: 3.4140\n",
      "Epoch [1134/2000], Avg Val Loss: 2.1319\n",
      "Validation loss improved from 2.1320 to 2.1319. Saving model...\n",
      "\n",
      "LOG: Epoch [1135/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4460\n",
      "    Batch [2/2], Train Loss: 3.4368\n",
      "Epoch [1135/2000], Avg Train Loss: 3.4414\n",
      "Epoch [1135/2000], Avg Val Loss: 2.1318\n",
      "Validation loss improved from 2.1319 to 2.1318. Saving model...\n",
      "\n",
      "LOG: Epoch [1136/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4189\n",
      "    Batch [2/2], Train Loss: 3.3826\n",
      "Epoch [1136/2000], Avg Train Loss: 3.4008\n",
      "Epoch [1136/2000], Avg Val Loss: 2.1318\n",
      "Validation loss improved from 2.1318 to 2.1318. Saving model...\n",
      "\n",
      "LOG: Epoch [1137/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4016\n",
      "    Batch [2/2], Train Loss: 3.4206\n",
      "Epoch [1137/2000], Avg Train Loss: 3.4111\n",
      "Epoch [1137/2000], Avg Val Loss: 2.1313\n",
      "Validation loss improved from 2.1318 to 2.1313. Saving model...\n",
      "\n",
      "LOG: Epoch [1138/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4097\n",
      "    Batch [2/2], Train Loss: 3.3995\n",
      "Epoch [1138/2000], Avg Train Loss: 3.4046\n",
      "Epoch [1138/2000], Avg Val Loss: 2.1309\n",
      "Validation loss improved from 2.1313 to 2.1309. Saving model...\n",
      "\n",
      "LOG: Epoch [1139/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3845\n",
      "    Batch [2/2], Train Loss: 3.4212\n",
      "Epoch [1139/2000], Avg Train Loss: 3.4029\n",
      "Epoch [1139/2000], Avg Val Loss: 2.1309\n",
      "Validation loss improved from 2.1309 to 2.1309. Saving model...\n",
      "\n",
      "LOG: Epoch [1140/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3893\n",
      "    Batch [2/2], Train Loss: 3.4039\n",
      "Epoch [1140/2000], Avg Train Loss: 3.3966\n",
      "Epoch [1140/2000], Avg Val Loss: 2.1306\n",
      "Validation loss improved from 2.1309 to 2.1306. Saving model...\n",
      "\n",
      "LOG: Epoch [1141/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3767\n",
      "    Batch [2/2], Train Loss: 3.4217\n",
      "Epoch [1141/2000], Avg Train Loss: 3.3992\n",
      "Epoch [1141/2000], Avg Val Loss: 2.1301\n",
      "Validation loss improved from 2.1306 to 2.1301. Saving model...\n",
      "\n",
      "LOG: Epoch [1142/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3958\n",
      "    Batch [2/2], Train Loss: 3.4762\n",
      "Epoch [1142/2000], Avg Train Loss: 3.4360\n",
      "Epoch [1142/2000], Avg Val Loss: 2.1294\n",
      "Validation loss improved from 2.1301 to 2.1294. Saving model...\n",
      "\n",
      "LOG: Epoch [1143/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.3577\n",
      "Epoch [1143/2000], Avg Train Loss: 3.3731\n",
      "Epoch [1143/2000], Avg Val Loss: 2.1288\n",
      "Validation loss improved from 2.1294 to 2.1288. Saving model...\n",
      "\n",
      "LOG: Epoch [1144/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4032\n",
      "    Batch [2/2], Train Loss: 3.4210\n",
      "Epoch [1144/2000], Avg Train Loss: 3.4121\n",
      "Epoch [1144/2000], Avg Val Loss: 2.1286\n",
      "Validation loss improved from 2.1288 to 2.1286. Saving model...\n",
      "\n",
      "LOG: Epoch [1145/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3831\n",
      "    Batch [2/2], Train Loss: 3.4277\n",
      "Epoch [1145/2000], Avg Train Loss: 3.4054\n",
      "Epoch [1145/2000], Avg Val Loss: 2.1287\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1146/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4114\n",
      "    Batch [2/2], Train Loss: 3.4026\n",
      "Epoch [1146/2000], Avg Train Loss: 3.4070\n",
      "Epoch [1146/2000], Avg Val Loss: 2.1288\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1147/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3818\n",
      "    Batch [2/2], Train Loss: 3.3953\n",
      "Epoch [1147/2000], Avg Train Loss: 3.3885\n",
      "Epoch [1147/2000], Avg Val Loss: 2.1295\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1148/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4105\n",
      "    Batch [2/2], Train Loss: 3.4137\n",
      "Epoch [1148/2000], Avg Train Loss: 3.4121\n",
      "Epoch [1148/2000], Avg Val Loss: 2.1301\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1149/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4000\n",
      "    Batch [2/2], Train Loss: 3.4198\n",
      "Epoch [1149/2000], Avg Train Loss: 3.4099\n",
      "Epoch [1149/2000], Avg Val Loss: 2.1300\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1150/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3568\n",
      "    Batch [2/2], Train Loss: 3.4027\n",
      "Epoch [1150/2000], Avg Train Loss: 3.3797\n",
      "Epoch [1150/2000], Avg Val Loss: 2.1300\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1151/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4015\n",
      "    Batch [2/2], Train Loss: 3.4346\n",
      "Epoch [1151/2000], Avg Train Loss: 3.4181\n",
      "Epoch [1151/2000], Avg Val Loss: 2.1298\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1152/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4128\n",
      "    Batch [2/2], Train Loss: 3.4040\n",
      "Epoch [1152/2000], Avg Train Loss: 3.4084\n",
      "Epoch [1152/2000], Avg Val Loss: 2.1298\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1153/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3762\n",
      "    Batch [2/2], Train Loss: 3.3788\n",
      "Epoch [1153/2000], Avg Train Loss: 3.3775\n",
      "Epoch [1153/2000], Avg Val Loss: 2.1299\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1154/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3665\n",
      "    Batch [2/2], Train Loss: 3.3509\n",
      "Epoch [1154/2000], Avg Train Loss: 3.3587\n",
      "Epoch [1154/2000], Avg Val Loss: 2.1298\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1155/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3383\n",
      "    Batch [2/2], Train Loss: 3.4228\n",
      "Epoch [1155/2000], Avg Train Loss: 3.3805\n",
      "Epoch [1155/2000], Avg Val Loss: 2.1297\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1156/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3954\n",
      "    Batch [2/2], Train Loss: 3.4186\n",
      "Epoch [1156/2000], Avg Train Loss: 3.4070\n",
      "Epoch [1156/2000], Avg Val Loss: 2.1301\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1157/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3837\n",
      "    Batch [2/2], Train Loss: 3.3821\n",
      "Epoch [1157/2000], Avg Train Loss: 3.3829\n",
      "Epoch [1157/2000], Avg Val Loss: 2.1304\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1158/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3931\n",
      "    Batch [2/2], Train Loss: 3.4229\n",
      "Epoch [1158/2000], Avg Train Loss: 3.4080\n",
      "Epoch [1158/2000], Avg Val Loss: 2.1311\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1159/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4215\n",
      "    Batch [2/2], Train Loss: 3.3639\n",
      "Epoch [1159/2000], Avg Train Loss: 3.3927\n",
      "Epoch [1159/2000], Avg Val Loss: 2.1317\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1160/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3853\n",
      "    Batch [2/2], Train Loss: 3.3902\n",
      "Epoch [1160/2000], Avg Train Loss: 3.3878\n",
      "Epoch [1160/2000], Avg Val Loss: 2.1321\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1161/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4161\n",
      "    Batch [2/2], Train Loss: 3.3703\n",
      "Epoch [1161/2000], Avg Train Loss: 3.3932\n",
      "Epoch [1161/2000], Avg Val Loss: 2.1322\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1162/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.3821\n",
      "    Batch [2/2], Train Loss: 3.3911\n",
      "Epoch [1162/2000], Avg Train Loss: 3.3866\n",
      "Epoch [1162/2000], Avg Val Loss: 2.1324\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1163/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3824\n",
      "    Batch [2/2], Train Loss: 3.3790\n",
      "Epoch [1163/2000], Avg Train Loss: 3.3807\n",
      "Epoch [1163/2000], Avg Val Loss: 2.1324\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1164/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3884\n",
      "    Batch [2/2], Train Loss: 3.4658\n",
      "Epoch [1164/2000], Avg Train Loss: 3.4271\n",
      "Epoch [1164/2000], Avg Val Loss: 2.1322\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1165/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3508\n",
      "    Batch [2/2], Train Loss: 3.3638\n",
      "Epoch [1165/2000], Avg Train Loss: 3.3573\n",
      "Epoch [1165/2000], Avg Val Loss: 2.1327\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1166/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3743\n",
      "    Batch [2/2], Train Loss: 3.3649\n",
      "Epoch [1166/2000], Avg Train Loss: 3.3696\n",
      "Epoch [1166/2000], Avg Val Loss: 2.1329\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1167/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3927\n",
      "    Batch [2/2], Train Loss: 3.4108\n",
      "Epoch [1167/2000], Avg Train Loss: 3.4017\n",
      "Epoch [1167/2000], Avg Val Loss: 2.1326\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1168/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4374\n",
      "    Batch [2/2], Train Loss: 3.3976\n",
      "Epoch [1168/2000], Avg Train Loss: 3.4175\n",
      "Epoch [1168/2000], Avg Val Loss: 2.1315\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1169/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3679\n",
      "    Batch [2/2], Train Loss: 3.3458\n",
      "Epoch [1169/2000], Avg Train Loss: 3.3568\n",
      "Epoch [1169/2000], Avg Val Loss: 2.1301\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1170/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3712\n",
      "    Batch [2/2], Train Loss: 3.3783\n",
      "Epoch [1170/2000], Avg Train Loss: 3.3748\n",
      "Epoch [1170/2000], Avg Val Loss: 2.1290\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1171/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3824\n",
      "    Batch [2/2], Train Loss: 3.3940\n",
      "Epoch [1171/2000], Avg Train Loss: 3.3882\n",
      "Epoch [1171/2000], Avg Val Loss: 2.1284\n",
      "Validation loss improved from 2.1286 to 2.1284. Saving model...\n",
      "\n",
      "LOG: Epoch [1172/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3855\n",
      "    Batch [2/2], Train Loss: 3.3832\n",
      "Epoch [1172/2000], Avg Train Loss: 3.3843\n",
      "Epoch [1172/2000], Avg Val Loss: 2.1282\n",
      "Validation loss improved from 2.1284 to 2.1282. Saving model...\n",
      "\n",
      "LOG: Epoch [1173/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3811\n",
      "    Batch [2/2], Train Loss: 3.3980\n",
      "Epoch [1173/2000], Avg Train Loss: 3.3896\n",
      "Epoch [1173/2000], Avg Val Loss: 2.1282\n",
      "Validation loss improved from 2.1282 to 2.1282. Saving model...\n",
      "\n",
      "LOG: Epoch [1174/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4072\n",
      "    Batch [2/2], Train Loss: 3.3970\n",
      "Epoch [1174/2000], Avg Train Loss: 3.4021\n",
      "Epoch [1174/2000], Avg Val Loss: 2.1285\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1175/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.4014\n",
      "    Batch [2/2], Train Loss: 3.3937\n",
      "Epoch [1175/2000], Avg Train Loss: 3.3976\n",
      "Epoch [1175/2000], Avg Val Loss: 2.1290\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1176/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3905\n",
      "    Batch [2/2], Train Loss: 3.3787\n",
      "Epoch [1176/2000], Avg Train Loss: 3.3846\n",
      "Epoch [1176/2000], Avg Val Loss: 2.1292\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1177/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3657\n",
      "    Batch [2/2], Train Loss: 3.4240\n",
      "Epoch [1177/2000], Avg Train Loss: 3.3948\n",
      "Epoch [1177/2000], Avg Val Loss: 2.1293\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1178/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4249\n",
      "    Batch [2/2], Train Loss: 3.3970\n",
      "Epoch [1178/2000], Avg Train Loss: 3.4110\n",
      "Epoch [1178/2000], Avg Val Loss: 2.1291\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1179/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4079\n",
      "    Batch [2/2], Train Loss: 3.3570\n",
      "Epoch [1179/2000], Avg Train Loss: 3.3824\n",
      "Epoch [1179/2000], Avg Val Loss: 2.1287\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1180/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4178\n",
      "    Batch [2/2], Train Loss: 3.3836\n",
      "Epoch [1180/2000], Avg Train Loss: 3.4007\n",
      "Epoch [1180/2000], Avg Val Loss: 2.1285\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1181/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4103\n",
      "    Batch [2/2], Train Loss: 3.3654\n",
      "Epoch [1181/2000], Avg Train Loss: 3.3879\n",
      "Epoch [1181/2000], Avg Val Loss: 2.1286\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1182/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3700\n",
      "    Batch [2/2], Train Loss: 3.3231\n",
      "Epoch [1182/2000], Avg Train Loss: 3.3466\n",
      "Epoch [1182/2000], Avg Val Loss: 2.1288\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1183/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3600\n",
      "    Batch [2/2], Train Loss: 3.4044\n",
      "Epoch [1183/2000], Avg Train Loss: 3.3822\n",
      "Epoch [1183/2000], Avg Val Loss: 2.1289\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1184/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3794\n",
      "    Batch [2/2], Train Loss: 3.3679\n",
      "Epoch [1184/2000], Avg Train Loss: 3.3736\n",
      "Epoch [1184/2000], Avg Val Loss: 2.1292\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1185/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3539\n",
      "    Batch [2/2], Train Loss: 3.4334\n",
      "Epoch [1185/2000], Avg Train Loss: 3.3936\n",
      "Epoch [1185/2000], Avg Val Loss: 2.1291\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1186/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3907\n",
      "    Batch [2/2], Train Loss: 3.3669\n",
      "Epoch [1186/2000], Avg Train Loss: 3.3788\n",
      "Epoch [1186/2000], Avg Val Loss: 2.1288\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1187/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4604\n",
      "    Batch [2/2], Train Loss: 3.3598\n",
      "Epoch [1187/2000], Avg Train Loss: 3.4101\n",
      "Epoch [1187/2000], Avg Val Loss: 2.1285\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1188/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3652\n",
      "    Batch [2/2], Train Loss: 3.3723\n",
      "Epoch [1188/2000], Avg Train Loss: 3.3688\n",
      "Epoch [1188/2000], Avg Val Loss: 2.1287\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1189/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3680\n",
      "    Batch [2/2], Train Loss: 3.3724\n",
      "Epoch [1189/2000], Avg Train Loss: 3.3702\n",
      "Epoch [1189/2000], Avg Val Loss: 2.1295\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1190/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3834\n",
      "    Batch [2/2], Train Loss: 3.3955\n",
      "Epoch [1190/2000], Avg Train Loss: 3.3895\n",
      "Epoch [1190/2000], Avg Val Loss: 2.1303\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1191/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3996\n",
      "    Batch [2/2], Train Loss: 3.3820\n",
      "Epoch [1191/2000], Avg Train Loss: 3.3908\n",
      "Epoch [1191/2000], Avg Val Loss: 2.1306\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1192/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4006\n",
      "    Batch [2/2], Train Loss: 3.3707\n",
      "Epoch [1192/2000], Avg Train Loss: 3.3856\n",
      "Epoch [1192/2000], Avg Val Loss: 2.1311\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1193/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3558\n",
      "    Batch [2/2], Train Loss: 3.3682\n",
      "Epoch [1193/2000], Avg Train Loss: 3.3620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1193/2000], Avg Val Loss: 2.1313\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1194/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3929\n",
      "    Batch [2/2], Train Loss: 3.3924\n",
      "Epoch [1194/2000], Avg Train Loss: 3.3927\n",
      "Epoch [1194/2000], Avg Val Loss: 2.1318\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1195/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3652\n",
      "    Batch [2/2], Train Loss: 3.3363\n",
      "Epoch [1195/2000], Avg Train Loss: 3.3507\n",
      "Epoch [1195/2000], Avg Val Loss: 2.1322\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1196/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3724\n",
      "    Batch [2/2], Train Loss: 3.3518\n",
      "Epoch [1196/2000], Avg Train Loss: 3.3621\n",
      "Epoch [1196/2000], Avg Val Loss: 2.1323\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1197/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3569\n",
      "    Batch [2/2], Train Loss: 3.3545\n",
      "Epoch [1197/2000], Avg Train Loss: 3.3557\n",
      "Epoch [1197/2000], Avg Val Loss: 2.1325\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1198/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4132\n",
      "    Batch [2/2], Train Loss: 3.3578\n",
      "Epoch [1198/2000], Avg Train Loss: 3.3855\n",
      "Epoch [1198/2000], Avg Val Loss: 2.1330\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1199/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3596\n",
      "    Batch [2/2], Train Loss: 3.3797\n",
      "Epoch [1199/2000], Avg Train Loss: 3.3697\n",
      "Epoch [1199/2000], Avg Val Loss: 2.1333\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1200/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3707\n",
      "    Batch [2/2], Train Loss: 3.3986\n",
      "Epoch [1200/2000], Avg Train Loss: 3.3847\n",
      "Epoch [1200/2000], Avg Val Loss: 2.1330\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1201/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3755\n",
      "    Batch [2/2], Train Loss: 3.3943\n",
      "Epoch [1201/2000], Avg Train Loss: 3.3849\n",
      "Epoch [1201/2000], Avg Val Loss: 2.1324\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1202/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3582\n",
      "    Batch [2/2], Train Loss: 3.3712\n",
      "Epoch [1202/2000], Avg Train Loss: 3.3647\n",
      "Epoch [1202/2000], Avg Val Loss: 2.1319\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1203/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3775\n",
      "    Batch [2/2], Train Loss: 3.4147\n",
      "Epoch [1203/2000], Avg Train Loss: 3.3961\n",
      "Epoch [1203/2000], Avg Val Loss: 2.1314\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1204/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3860\n",
      "    Batch [2/2], Train Loss: 3.3804\n",
      "Epoch [1204/2000], Avg Train Loss: 3.3832\n",
      "Epoch [1204/2000], Avg Val Loss: 2.1310\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1205/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3992\n",
      "    Batch [2/2], Train Loss: 3.4284\n",
      "Epoch [1205/2000], Avg Train Loss: 3.4138\n",
      "Epoch [1205/2000], Avg Val Loss: 2.1311\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1206/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3867\n",
      "    Batch [2/2], Train Loss: 3.3647\n",
      "Epoch [1206/2000], Avg Train Loss: 3.3757\n",
      "Epoch [1206/2000], Avg Val Loss: 2.1310\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1207/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3830\n",
      "    Batch [2/2], Train Loss: 3.3955\n",
      "Epoch [1207/2000], Avg Train Loss: 3.3892\n",
      "Epoch [1207/2000], Avg Val Loss: 2.1304\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1208/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3877\n",
      "    Batch [2/2], Train Loss: 3.3961\n",
      "Epoch [1208/2000], Avg Train Loss: 3.3919\n",
      "Epoch [1208/2000], Avg Val Loss: 2.1299\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1209/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3551\n",
      "    Batch [2/2], Train Loss: 3.3754\n",
      "Epoch [1209/2000], Avg Train Loss: 3.3652\n",
      "Epoch [1209/2000], Avg Val Loss: 2.1296\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1210/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3876\n",
      "    Batch [2/2], Train Loss: 3.3720\n",
      "Epoch [1210/2000], Avg Train Loss: 3.3798\n",
      "Epoch [1210/2000], Avg Val Loss: 2.1297\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1211/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3688\n",
      "    Batch [2/2], Train Loss: 3.3724\n",
      "Epoch [1211/2000], Avg Train Loss: 3.3706\n",
      "Epoch [1211/2000], Avg Val Loss: 2.1299\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1212/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.3710\n",
      "    Batch [2/2], Train Loss: 3.3747\n",
      "Epoch [1212/2000], Avg Train Loss: 3.3729\n",
      "Epoch [1212/2000], Avg Val Loss: 2.1304\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1213/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3756\n",
      "    Batch [2/2], Train Loss: 3.3804\n",
      "Epoch [1213/2000], Avg Train Loss: 3.3780\n",
      "Epoch [1213/2000], Avg Val Loss: 2.1307\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1214/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3728\n",
      "    Batch [2/2], Train Loss: 3.3698\n",
      "Epoch [1214/2000], Avg Train Loss: 3.3713\n",
      "Epoch [1214/2000], Avg Val Loss: 2.1305\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1215/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3631\n",
      "    Batch [2/2], Train Loss: 3.3786\n",
      "Epoch [1215/2000], Avg Train Loss: 3.3708\n",
      "Epoch [1215/2000], Avg Val Loss: 2.1302\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1216/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3710\n",
      "    Batch [2/2], Train Loss: 3.4097\n",
      "Epoch [1216/2000], Avg Train Loss: 3.3904\n",
      "Epoch [1216/2000], Avg Val Loss: 2.1296\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1217/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3823\n",
      "    Batch [2/2], Train Loss: 3.3846\n",
      "Epoch [1217/2000], Avg Train Loss: 3.3835\n",
      "Epoch [1217/2000], Avg Val Loss: 2.1291\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1218/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3734\n",
      "    Batch [2/2], Train Loss: 3.3817\n",
      "Epoch [1218/2000], Avg Train Loss: 3.3775\n",
      "Epoch [1218/2000], Avg Val Loss: 2.1288\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1219/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3764\n",
      "    Batch [2/2], Train Loss: 3.3772\n",
      "Epoch [1219/2000], Avg Train Loss: 3.3768\n",
      "Epoch [1219/2000], Avg Val Loss: 2.1282\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1220/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3291\n",
      "    Batch [2/2], Train Loss: 3.3655\n",
      "Epoch [1220/2000], Avg Train Loss: 3.3473\n",
      "Epoch [1220/2000], Avg Val Loss: 2.1280\n",
      "Validation loss improved from 2.1282 to 2.1280. Saving model...\n",
      "\n",
      "LOG: Epoch [1221/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3619\n",
      "    Batch [2/2], Train Loss: 3.3488\n",
      "Epoch [1221/2000], Avg Train Loss: 3.3553\n",
      "Epoch [1221/2000], Avg Val Loss: 2.1275\n",
      "Validation loss improved from 2.1280 to 2.1275. Saving model...\n",
      "\n",
      "LOG: Epoch [1222/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3238\n",
      "    Batch [2/2], Train Loss: 3.3831\n",
      "Epoch [1222/2000], Avg Train Loss: 3.3535\n",
      "Epoch [1222/2000], Avg Val Loss: 2.1274\n",
      "Validation loss improved from 2.1275 to 2.1274. Saving model...\n",
      "\n",
      "LOG: Epoch [1223/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3756\n",
      "    Batch [2/2], Train Loss: 3.3749\n",
      "Epoch [1223/2000], Avg Train Loss: 3.3753\n",
      "Epoch [1223/2000], Avg Val Loss: 2.1273\n",
      "Validation loss improved from 2.1274 to 2.1273. Saving model...\n",
      "\n",
      "LOG: Epoch [1224/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3284\n",
      "    Batch [2/2], Train Loss: 3.3639\n",
      "Epoch [1224/2000], Avg Train Loss: 3.3462\n",
      "Epoch [1224/2000], Avg Val Loss: 2.1272\n",
      "Validation loss improved from 2.1273 to 2.1272. Saving model...\n",
      "\n",
      "LOG: Epoch [1225/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4022\n",
      "    Batch [2/2], Train Loss: 3.3714\n",
      "Epoch [1225/2000], Avg Train Loss: 3.3868\n",
      "Epoch [1225/2000], Avg Val Loss: 2.1272\n",
      "Validation loss improved from 2.1272 to 2.1272. Saving model...\n",
      "\n",
      "LOG: Epoch [1226/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3709\n",
      "    Batch [2/2], Train Loss: 3.3569\n",
      "Epoch [1226/2000], Avg Train Loss: 3.3639\n",
      "Epoch [1226/2000], Avg Val Loss: 2.1276\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1227/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3674\n",
      "    Batch [2/2], Train Loss: 3.3616\n",
      "Epoch [1227/2000], Avg Train Loss: 3.3645\n",
      "Epoch [1227/2000], Avg Val Loss: 2.1280\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1228/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3917\n",
      "    Batch [2/2], Train Loss: 3.3444\n",
      "Epoch [1228/2000], Avg Train Loss: 3.3681\n",
      "Epoch [1228/2000], Avg Val Loss: 2.1287\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1229/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3997\n",
      "    Batch [2/2], Train Loss: 3.3736\n",
      "Epoch [1229/2000], Avg Train Loss: 3.3867\n",
      "Epoch [1229/2000], Avg Val Loss: 2.1290\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1230/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.3095\n",
      "Epoch [1230/2000], Avg Train Loss: 3.3335\n",
      "Epoch [1230/2000], Avg Val Loss: 2.1291\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1231/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3368\n",
      "    Batch [2/2], Train Loss: 3.3882\n",
      "Epoch [1231/2000], Avg Train Loss: 3.3625\n",
      "Epoch [1231/2000], Avg Val Loss: 2.1293\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1232/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3533\n",
      "    Batch [2/2], Train Loss: 3.3727\n",
      "Epoch [1232/2000], Avg Train Loss: 3.3630\n",
      "Epoch [1232/2000], Avg Val Loss: 2.1292\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1233/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3657\n",
      "    Batch [2/2], Train Loss: 3.3603\n",
      "Epoch [1233/2000], Avg Train Loss: 3.3630\n",
      "Epoch [1233/2000], Avg Val Loss: 2.1290\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1234/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3894\n",
      "    Batch [2/2], Train Loss: 3.3624\n",
      "Epoch [1234/2000], Avg Train Loss: 3.3759\n",
      "Epoch [1234/2000], Avg Val Loss: 2.1292\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1235/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3389\n",
      "    Batch [2/2], Train Loss: 3.3822\n",
      "Epoch [1235/2000], Avg Train Loss: 3.3606\n",
      "Epoch [1235/2000], Avg Val Loss: 2.1290\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1236/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3508\n",
      "    Batch [2/2], Train Loss: 3.4069\n",
      "Epoch [1236/2000], Avg Train Loss: 3.3788\n",
      "Epoch [1236/2000], Avg Val Loss: 2.1286\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1237/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3712\n",
      "    Batch [2/2], Train Loss: 3.3699\n",
      "Epoch [1237/2000], Avg Train Loss: 3.3706\n",
      "Epoch [1237/2000], Avg Val Loss: 2.1278\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1238/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3867\n",
      "    Batch [2/2], Train Loss: 3.3814\n",
      "Epoch [1238/2000], Avg Train Loss: 3.3841\n",
      "Epoch [1238/2000], Avg Val Loss: 2.1268\n",
      "Validation loss improved from 2.1272 to 2.1268. Saving model...\n",
      "\n",
      "LOG: Epoch [1239/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3773\n",
      "    Batch [2/2], Train Loss: 3.3847\n",
      "Epoch [1239/2000], Avg Train Loss: 3.3810\n",
      "Epoch [1239/2000], Avg Val Loss: 2.1257\n",
      "Validation loss improved from 2.1268 to 2.1257. Saving model...\n",
      "\n",
      "LOG: Epoch [1240/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3733\n",
      "    Batch [2/2], Train Loss: 3.3343\n",
      "Epoch [1240/2000], Avg Train Loss: 3.3538\n",
      "Epoch [1240/2000], Avg Val Loss: 2.1250\n",
      "Validation loss improved from 2.1257 to 2.1250. Saving model...\n",
      "\n",
      "LOG: Epoch [1241/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4081\n",
      "    Batch [2/2], Train Loss: 3.3754\n",
      "Epoch [1241/2000], Avg Train Loss: 3.3918\n",
      "Epoch [1241/2000], Avg Val Loss: 2.1242\n",
      "Validation loss improved from 2.1250 to 2.1242. Saving model...\n",
      "\n",
      "LOG: Epoch [1242/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3643\n",
      "    Batch [2/2], Train Loss: 3.3467\n",
      "Epoch [1242/2000], Avg Train Loss: 3.3555\n",
      "Epoch [1242/2000], Avg Val Loss: 2.1237\n",
      "Validation loss improved from 2.1242 to 2.1237. Saving model...\n",
      "\n",
      "LOG: Epoch [1243/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3765\n",
      "    Batch [2/2], Train Loss: 3.3790\n",
      "Epoch [1243/2000], Avg Train Loss: 3.3777\n",
      "Epoch [1243/2000], Avg Val Loss: 2.1237\n",
      "Validation loss improved from 2.1237 to 2.1237. Saving model...\n",
      "\n",
      "LOG: Epoch [1244/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3721\n",
      "    Batch [2/2], Train Loss: 3.3975\n",
      "Epoch [1244/2000], Avg Train Loss: 3.3848\n",
      "Epoch [1244/2000], Avg Val Loss: 2.1239\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1245/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3818\n",
      "    Batch [2/2], Train Loss: 3.3650\n",
      "Epoch [1245/2000], Avg Train Loss: 3.3734\n",
      "Epoch [1245/2000], Avg Val Loss: 2.1241\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1246/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3991\n",
      "    Batch [2/2], Train Loss: 3.4073\n",
      "Epoch [1246/2000], Avg Train Loss: 3.4032\n",
      "Epoch [1246/2000], Avg Val Loss: 2.1242\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1247/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4107\n",
      "    Batch [2/2], Train Loss: 3.3277\n",
      "Epoch [1247/2000], Avg Train Loss: 3.3692\n",
      "Epoch [1247/2000], Avg Val Loss: 2.1246\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1248/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3880\n",
      "    Batch [2/2], Train Loss: 3.3394\n",
      "Epoch [1248/2000], Avg Train Loss: 3.3637\n",
      "Epoch [1248/2000], Avg Val Loss: 2.1250\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1249/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.3717\n",
      "Epoch [1249/2000], Avg Train Loss: 3.3810\n",
      "Epoch [1249/2000], Avg Val Loss: 2.1258\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1250/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3629\n",
      "    Batch [2/2], Train Loss: 3.3262\n",
      "Epoch [1250/2000], Avg Train Loss: 3.3445\n",
      "Epoch [1250/2000], Avg Val Loss: 2.1265\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1251/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3841\n",
      "    Batch [2/2], Train Loss: 3.3761\n",
      "Epoch [1251/2000], Avg Train Loss: 3.3801\n",
      "Epoch [1251/2000], Avg Val Loss: 2.1271\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1252/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3578\n",
      "    Batch [2/2], Train Loss: 3.3888\n",
      "Epoch [1252/2000], Avg Train Loss: 3.3733\n",
      "Epoch [1252/2000], Avg Val Loss: 2.1278\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1253/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3458\n",
      "    Batch [2/2], Train Loss: 3.3407\n",
      "Epoch [1253/2000], Avg Train Loss: 3.3432\n",
      "Epoch [1253/2000], Avg Val Loss: 2.1285\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1254/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3767\n",
      "    Batch [2/2], Train Loss: 3.3465\n",
      "Epoch [1254/2000], Avg Train Loss: 3.3616\n",
      "Epoch [1254/2000], Avg Val Loss: 2.1295\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1255/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3649\n",
      "    Batch [2/2], Train Loss: 3.3467\n",
      "Epoch [1255/2000], Avg Train Loss: 3.3558\n",
      "Epoch [1255/2000], Avg Val Loss: 2.1297\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1256/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3686\n",
      "    Batch [2/2], Train Loss: 3.3433\n",
      "Epoch [1256/2000], Avg Train Loss: 3.3559\n",
      "Epoch [1256/2000], Avg Val Loss: 2.1306\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1257/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3592\n",
      "    Batch [2/2], Train Loss: 3.3775\n",
      "Epoch [1257/2000], Avg Train Loss: 3.3684\n",
      "Epoch [1257/2000], Avg Val Loss: 2.1313\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1258/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3264\n",
      "    Batch [2/2], Train Loss: 3.3399\n",
      "Epoch [1258/2000], Avg Train Loss: 3.3332\n",
      "Epoch [1258/2000], Avg Val Loss: 2.1319\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1259/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3574\n",
      "    Batch [2/2], Train Loss: 3.3458\n",
      "Epoch [1259/2000], Avg Train Loss: 3.3516\n",
      "Epoch [1259/2000], Avg Val Loss: 2.1322\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1260/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3727\n",
      "    Batch [2/2], Train Loss: 3.3392\n",
      "Epoch [1260/2000], Avg Train Loss: 3.3559\n",
      "Epoch [1260/2000], Avg Val Loss: 2.1325\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1261/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3366\n",
      "    Batch [2/2], Train Loss: 3.4000\n",
      "Epoch [1261/2000], Avg Train Loss: 3.3683\n",
      "Epoch [1261/2000], Avg Val Loss: 2.1330\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1262/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3687\n",
      "    Batch [2/2], Train Loss: 3.2933\n",
      "Epoch [1262/2000], Avg Train Loss: 3.3310\n",
      "Epoch [1262/2000], Avg Val Loss: 2.1335\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1263/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3441\n",
      "    Batch [2/2], Train Loss: 3.3643\n",
      "Epoch [1263/2000], Avg Train Loss: 3.3542\n",
      "Epoch [1263/2000], Avg Val Loss: 2.1339\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1264/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3749\n",
      "    Batch [2/2], Train Loss: 3.3350\n",
      "Epoch [1264/2000], Avg Train Loss: 3.3549\n",
      "Epoch [1264/2000], Avg Val Loss: 2.1341\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1265/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.4089\n",
      "    Batch [2/2], Train Loss: 3.3706\n",
      "Epoch [1265/2000], Avg Train Loss: 3.3898\n",
      "Epoch [1265/2000], Avg Val Loss: 2.1339\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1266/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3818\n",
      "    Batch [2/2], Train Loss: 3.3745\n",
      "Epoch [1266/2000], Avg Train Loss: 3.3781\n",
      "Epoch [1266/2000], Avg Val Loss: 2.1336\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1267/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3878\n",
      "    Batch [2/2], Train Loss: 3.3501\n",
      "Epoch [1267/2000], Avg Train Loss: 3.3690\n",
      "Epoch [1267/2000], Avg Val Loss: 2.1332\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1268/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.3669\n",
      "    Batch [2/2], Train Loss: 3.3385\n",
      "Epoch [1268/2000], Avg Train Loss: 3.3527\n",
      "Epoch [1268/2000], Avg Val Loss: 2.1329\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1269/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3493\n",
      "    Batch [2/2], Train Loss: 3.3993\n",
      "Epoch [1269/2000], Avg Train Loss: 3.3743\n",
      "Epoch [1269/2000], Avg Val Loss: 2.1325\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1270/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3574\n",
      "    Batch [2/2], Train Loss: 3.3315\n",
      "Epoch [1270/2000], Avg Train Loss: 3.3445\n",
      "Epoch [1270/2000], Avg Val Loss: 2.1317\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1271/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3537\n",
      "    Batch [2/2], Train Loss: 3.3555\n",
      "Epoch [1271/2000], Avg Train Loss: 3.3546\n",
      "Epoch [1271/2000], Avg Val Loss: 2.1313\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1272/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3625\n",
      "    Batch [2/2], Train Loss: 3.3466\n",
      "Epoch [1272/2000], Avg Train Loss: 3.3546\n",
      "Epoch [1272/2000], Avg Val Loss: 2.1307\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1273/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3638\n",
      "    Batch [2/2], Train Loss: 3.3419\n",
      "Epoch [1273/2000], Avg Train Loss: 3.3529\n",
      "Epoch [1273/2000], Avg Val Loss: 2.1303\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1274/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3696\n",
      "    Batch [2/2], Train Loss: 3.3503\n",
      "Epoch [1274/2000], Avg Train Loss: 3.3600\n",
      "Epoch [1274/2000], Avg Val Loss: 2.1302\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1275/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3710\n",
      "    Batch [2/2], Train Loss: 3.3361\n",
      "Epoch [1275/2000], Avg Train Loss: 3.3535\n",
      "Epoch [1275/2000], Avg Val Loss: 2.1302\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1276/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3461\n",
      "    Batch [2/2], Train Loss: 3.3366\n",
      "Epoch [1276/2000], Avg Train Loss: 3.3413\n",
      "Epoch [1276/2000], Avg Val Loss: 2.1302\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1277/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3250\n",
      "    Batch [2/2], Train Loss: 3.3194\n",
      "Epoch [1277/2000], Avg Train Loss: 3.3222\n",
      "Epoch [1277/2000], Avg Val Loss: 2.1307\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1278/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3271\n",
      "    Batch [2/2], Train Loss: 3.3938\n",
      "Epoch [1278/2000], Avg Train Loss: 3.3605\n",
      "Epoch [1278/2000], Avg Val Loss: 2.1313\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1279/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3372\n",
      "    Batch [2/2], Train Loss: 3.3579\n",
      "Epoch [1279/2000], Avg Train Loss: 3.3476\n",
      "Epoch [1279/2000], Avg Val Loss: 2.1315\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1280/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3269\n",
      "    Batch [2/2], Train Loss: 3.4045\n",
      "Epoch [1280/2000], Avg Train Loss: 3.3657\n",
      "Epoch [1280/2000], Avg Val Loss: 2.1317\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1281/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3359\n",
      "    Batch [2/2], Train Loss: 3.3886\n",
      "Epoch [1281/2000], Avg Train Loss: 3.3623\n",
      "Epoch [1281/2000], Avg Val Loss: 2.1321\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1282/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3169\n",
      "    Batch [2/2], Train Loss: 3.3377\n",
      "Epoch [1282/2000], Avg Train Loss: 3.3273\n",
      "Epoch [1282/2000], Avg Val Loss: 2.1323\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1283/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3593\n",
      "    Batch [2/2], Train Loss: 3.3551\n",
      "Epoch [1283/2000], Avg Train Loss: 3.3572\n",
      "Epoch [1283/2000], Avg Val Loss: 2.1326\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1284/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3204\n",
      "    Batch [2/2], Train Loss: 3.3391\n",
      "Epoch [1284/2000], Avg Train Loss: 3.3298\n",
      "Epoch [1284/2000], Avg Val Loss: 2.1327\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1285/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3430\n",
      "    Batch [2/2], Train Loss: 3.3541\n",
      "Epoch [1285/2000], Avg Train Loss: 3.3485\n",
      "Epoch [1285/2000], Avg Val Loss: 2.1325\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1286/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.3399\n",
      "Epoch [1286/2000], Avg Train Loss: 3.3426\n",
      "Epoch [1286/2000], Avg Val Loss: 2.1320\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1287/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3247\n",
      "    Batch [2/2], Train Loss: 3.3701\n",
      "Epoch [1287/2000], Avg Train Loss: 3.3474\n",
      "Epoch [1287/2000], Avg Val Loss: 2.1309\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1288/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3209\n",
      "    Batch [2/2], Train Loss: 3.3285\n",
      "Epoch [1288/2000], Avg Train Loss: 3.3247\n",
      "Epoch [1288/2000], Avg Val Loss: 2.1299\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1289/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3689\n",
      "    Batch [2/2], Train Loss: 3.3077\n",
      "Epoch [1289/2000], Avg Train Loss: 3.3383\n",
      "Epoch [1289/2000], Avg Val Loss: 2.1289\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1290/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3297\n",
      "    Batch [2/2], Train Loss: 3.3701\n",
      "Epoch [1290/2000], Avg Train Loss: 3.3499\n",
      "Epoch [1290/2000], Avg Val Loss: 2.1281\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1291/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3772\n",
      "    Batch [2/2], Train Loss: 3.3526\n",
      "Epoch [1291/2000], Avg Train Loss: 3.3649\n",
      "Epoch [1291/2000], Avg Val Loss: 2.1274\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1292/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3706\n",
      "    Batch [2/2], Train Loss: 3.4062\n",
      "Epoch [1292/2000], Avg Train Loss: 3.3884\n",
      "Epoch [1292/2000], Avg Val Loss: 2.1269\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1293/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3338\n",
      "    Batch [2/2], Train Loss: 3.3510\n",
      "Epoch [1293/2000], Avg Train Loss: 3.3424\n",
      "Epoch [1293/2000], Avg Val Loss: 2.1260\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1294/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3424\n",
      "    Batch [2/2], Train Loss: 3.3751\n",
      "Epoch [1294/2000], Avg Train Loss: 3.3588\n",
      "Epoch [1294/2000], Avg Val Loss: 2.1255\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1295/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3602\n",
      "    Batch [2/2], Train Loss: 3.3379\n",
      "Epoch [1295/2000], Avg Train Loss: 3.3491\n",
      "Epoch [1295/2000], Avg Val Loss: 2.1255\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1296/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3827\n",
      "    Batch [2/2], Train Loss: 3.3442\n",
      "Epoch [1296/2000], Avg Train Loss: 3.3635\n",
      "Epoch [1296/2000], Avg Val Loss: 2.1255\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1297/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3688\n",
      "    Batch [2/2], Train Loss: 3.3622\n",
      "Epoch [1297/2000], Avg Train Loss: 3.3655\n",
      "Epoch [1297/2000], Avg Val Loss: 2.1251\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1298/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3364\n",
      "    Batch [2/2], Train Loss: 3.3819\n",
      "Epoch [1298/2000], Avg Train Loss: 3.3591\n",
      "Epoch [1298/2000], Avg Val Loss: 2.1247\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1299/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3748\n",
      "    Batch [2/2], Train Loss: 3.3522\n",
      "Epoch [1299/2000], Avg Train Loss: 3.3635\n",
      "Epoch [1299/2000], Avg Val Loss: 2.1239\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1300/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3461\n",
      "    Batch [2/2], Train Loss: 3.3789\n",
      "Epoch [1300/2000], Avg Train Loss: 3.3625\n",
      "Epoch [1300/2000], Avg Val Loss: 2.1235\n",
      "Validation loss improved from 2.1237 to 2.1235. Saving model...\n",
      "\n",
      "LOG: Epoch [1301/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3746\n",
      "    Batch [2/2], Train Loss: 3.3599\n",
      "Epoch [1301/2000], Avg Train Loss: 3.3673\n",
      "Epoch [1301/2000], Avg Val Loss: 2.1231\n",
      "Validation loss improved from 2.1235 to 2.1231. Saving model...\n",
      "\n",
      "LOG: Epoch [1302/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3439\n",
      "    Batch [2/2], Train Loss: 3.3766\n",
      "Epoch [1302/2000], Avg Train Loss: 3.3603\n",
      "Epoch [1302/2000], Avg Val Loss: 2.1227\n",
      "Validation loss improved from 2.1231 to 2.1227. Saving model...\n",
      "\n",
      "LOG: Epoch [1303/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3367\n",
      "    Batch [2/2], Train Loss: 3.3648\n",
      "Epoch [1303/2000], Avg Train Loss: 3.3507\n",
      "Epoch [1303/2000], Avg Val Loss: 2.1225\n",
      "Validation loss improved from 2.1227 to 2.1225. Saving model...\n",
      "\n",
      "LOG: Epoch [1304/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.3539\n",
      "Epoch [1304/2000], Avg Train Loss: 3.3306\n",
      "Epoch [1304/2000], Avg Val Loss: 2.1226\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1305/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3779\n",
      "    Batch [2/2], Train Loss: 3.3478\n",
      "Epoch [1305/2000], Avg Train Loss: 3.3628\n",
      "Epoch [1305/2000], Avg Val Loss: 2.1232\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1306/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3312\n",
      "    Batch [2/2], Train Loss: 3.3437\n",
      "Epoch [1306/2000], Avg Train Loss: 3.3375\n",
      "Epoch [1306/2000], Avg Val Loss: 2.1238\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1307/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3442\n",
      "    Batch [2/2], Train Loss: 3.3347\n",
      "Epoch [1307/2000], Avg Train Loss: 3.3394\n",
      "Epoch [1307/2000], Avg Val Loss: 2.1247\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1308/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3716\n",
      "    Batch [2/2], Train Loss: 3.3705\n",
      "Epoch [1308/2000], Avg Train Loss: 3.3711\n",
      "Epoch [1308/2000], Avg Val Loss: 2.1253\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1309/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3450\n",
      "    Batch [2/2], Train Loss: 3.3485\n",
      "Epoch [1309/2000], Avg Train Loss: 3.3467\n",
      "Epoch [1309/2000], Avg Val Loss: 2.1257\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1310/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3371\n",
      "    Batch [2/2], Train Loss: 3.3374\n",
      "Epoch [1310/2000], Avg Train Loss: 3.3372\n",
      "Epoch [1310/2000], Avg Val Loss: 2.1262\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1311/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3430\n",
      "    Batch [2/2], Train Loss: 3.3529\n",
      "Epoch [1311/2000], Avg Train Loss: 3.3480\n",
      "Epoch [1311/2000], Avg Val Loss: 2.1263\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1312/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3434\n",
      "    Batch [2/2], Train Loss: 3.3576\n",
      "Epoch [1312/2000], Avg Train Loss: 3.3505\n",
      "Epoch [1312/2000], Avg Val Loss: 2.1267\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1313/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3546\n",
      "    Batch [2/2], Train Loss: 3.3514\n",
      "Epoch [1313/2000], Avg Train Loss: 3.3530\n",
      "Epoch [1313/2000], Avg Val Loss: 2.1270\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1314/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3761\n",
      "    Batch [2/2], Train Loss: 3.3560\n",
      "Epoch [1314/2000], Avg Train Loss: 3.3661\n",
      "Epoch [1314/2000], Avg Val Loss: 2.1274\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1315/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3480\n",
      "    Batch [2/2], Train Loss: 3.3233\n",
      "Epoch [1315/2000], Avg Train Loss: 3.3357\n",
      "Epoch [1315/2000], Avg Val Loss: 2.1279\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1316/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3034\n",
      "    Batch [2/2], Train Loss: 3.2979\n",
      "Epoch [1316/2000], Avg Train Loss: 3.3006\n",
      "Epoch [1316/2000], Avg Val Loss: 2.1283\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1317/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3271\n",
      "    Batch [2/2], Train Loss: 3.3234\n",
      "Epoch [1317/2000], Avg Train Loss: 3.3252\n",
      "Epoch [1317/2000], Avg Val Loss: 2.1283\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1318/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2922\n",
      "    Batch [2/2], Train Loss: 3.3654\n",
      "Epoch [1318/2000], Avg Train Loss: 3.3288\n",
      "Epoch [1318/2000], Avg Val Loss: 2.1284\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1319/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3681\n",
      "    Batch [2/2], Train Loss: 3.3190\n",
      "Epoch [1319/2000], Avg Train Loss: 3.3436\n",
      "Epoch [1319/2000], Avg Val Loss: 2.1283\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1320/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3587\n",
      "    Batch [2/2], Train Loss: 3.3912\n",
      "Epoch [1320/2000], Avg Train Loss: 3.3750\n",
      "Epoch [1320/2000], Avg Val Loss: 2.1279\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1321/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3044\n",
      "    Batch [2/2], Train Loss: 3.3223\n",
      "Epoch [1321/2000], Avg Train Loss: 3.3134\n",
      "Epoch [1321/2000], Avg Val Loss: 2.1278\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1322/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3435\n",
      "    Batch [2/2], Train Loss: 3.3395\n",
      "Epoch [1322/2000], Avg Train Loss: 3.3415\n",
      "Epoch [1322/2000], Avg Val Loss: 2.1278\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1323/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.3298\n",
      "Epoch [1323/2000], Avg Train Loss: 3.3583\n",
      "Epoch [1323/2000], Avg Val Loss: 2.1273\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1324/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3257\n",
      "    Batch [2/2], Train Loss: 3.3281\n",
      "Epoch [1324/2000], Avg Train Loss: 3.3269\n",
      "Epoch [1324/2000], Avg Val Loss: 2.1267\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1325/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3581\n",
      "    Batch [2/2], Train Loss: 3.3456\n",
      "Epoch [1325/2000], Avg Train Loss: 3.3519\n",
      "Epoch [1325/2000], Avg Val Loss: 2.1258\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1326/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3258\n",
      "    Batch [2/2], Train Loss: 3.3445\n",
      "Epoch [1326/2000], Avg Train Loss: 3.3352\n",
      "Epoch [1326/2000], Avg Val Loss: 2.1249\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1327/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3943\n",
      "    Batch [2/2], Train Loss: 3.3393\n",
      "Epoch [1327/2000], Avg Train Loss: 3.3668\n",
      "Epoch [1327/2000], Avg Val Loss: 2.1249\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1328/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3401\n",
      "    Batch [2/2], Train Loss: 3.3720\n",
      "Epoch [1328/2000], Avg Train Loss: 3.3560\n",
      "Epoch [1328/2000], Avg Val Loss: 2.1252\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1329/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3188\n",
      "    Batch [2/2], Train Loss: 3.3323\n",
      "Epoch [1329/2000], Avg Train Loss: 3.3256\n",
      "Epoch [1329/2000], Avg Val Loss: 2.1258\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1330/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3478\n",
      "    Batch [2/2], Train Loss: 3.3046\n",
      "Epoch [1330/2000], Avg Train Loss: 3.3262\n",
      "Epoch [1330/2000], Avg Val Loss: 2.1270\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1331/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3080\n",
      "    Batch [2/2], Train Loss: 3.3564\n",
      "Epoch [1331/2000], Avg Train Loss: 3.3322\n",
      "Epoch [1331/2000], Avg Val Loss: 2.1281\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1332/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3504\n",
      "    Batch [2/2], Train Loss: 3.3119\n",
      "Epoch [1332/2000], Avg Train Loss: 3.3311\n",
      "Epoch [1332/2000], Avg Val Loss: 2.1288\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1333/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3514\n",
      "    Batch [2/2], Train Loss: 3.3232\n",
      "Epoch [1333/2000], Avg Train Loss: 3.3373\n",
      "Epoch [1333/2000], Avg Val Loss: 2.1293\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1334/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3213\n",
      "    Batch [2/2], Train Loss: 3.3466\n",
      "Epoch [1334/2000], Avg Train Loss: 3.3339\n",
      "Epoch [1334/2000], Avg Val Loss: 2.1297\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1335/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3356\n",
      "    Batch [2/2], Train Loss: 3.2932\n",
      "Epoch [1335/2000], Avg Train Loss: 3.3144\n",
      "Epoch [1335/2000], Avg Val Loss: 2.1297\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1336/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3273\n",
      "    Batch [2/2], Train Loss: 3.3496\n",
      "Epoch [1336/2000], Avg Train Loss: 3.3385\n",
      "Epoch [1336/2000], Avg Val Loss: 2.1293\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1337/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3339\n",
      "    Batch [2/2], Train Loss: 3.3568\n",
      "Epoch [1337/2000], Avg Train Loss: 3.3454\n",
      "Epoch [1337/2000], Avg Val Loss: 2.1287\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1338/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3888\n",
      "    Batch [2/2], Train Loss: 3.3652\n",
      "Epoch [1338/2000], Avg Train Loss: 3.3770\n",
      "Epoch [1338/2000], Avg Val Loss: 2.1280\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1339/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3479\n",
      "    Batch [2/2], Train Loss: 3.3614\n",
      "Epoch [1339/2000], Avg Train Loss: 3.3546\n",
      "Epoch [1339/2000], Avg Val Loss: 2.1276\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1340/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3442\n",
      "    Batch [2/2], Train Loss: 3.3566\n",
      "Epoch [1340/2000], Avg Train Loss: 3.3504\n",
      "Epoch [1340/2000], Avg Val Loss: 2.1268\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1341/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3193\n",
      "    Batch [2/2], Train Loss: 3.3062\n",
      "Epoch [1341/2000], Avg Train Loss: 3.3127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1341/2000], Avg Val Loss: 2.1261\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1342/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3277\n",
      "    Batch [2/2], Train Loss: 3.3353\n",
      "Epoch [1342/2000], Avg Train Loss: 3.3315\n",
      "Epoch [1342/2000], Avg Val Loss: 2.1257\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1343/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3428\n",
      "    Batch [2/2], Train Loss: 3.3514\n",
      "Epoch [1343/2000], Avg Train Loss: 3.3471\n",
      "Epoch [1343/2000], Avg Val Loss: 2.1254\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1344/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3005\n",
      "    Batch [2/2], Train Loss: 3.3247\n",
      "Epoch [1344/2000], Avg Train Loss: 3.3126\n",
      "Epoch [1344/2000], Avg Val Loss: 2.1251\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1345/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3539\n",
      "    Batch [2/2], Train Loss: 3.3700\n",
      "Epoch [1345/2000], Avg Train Loss: 3.3619\n",
      "Epoch [1345/2000], Avg Val Loss: 2.1248\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1346/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3375\n",
      "    Batch [2/2], Train Loss: 3.3247\n",
      "Epoch [1346/2000], Avg Train Loss: 3.3311\n",
      "Epoch [1346/2000], Avg Val Loss: 2.1247\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1347/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3651\n",
      "    Batch [2/2], Train Loss: 3.3345\n",
      "Epoch [1347/2000], Avg Train Loss: 3.3498\n",
      "Epoch [1347/2000], Avg Val Loss: 2.1247\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1348/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3214\n",
      "    Batch [2/2], Train Loss: 3.3304\n",
      "Epoch [1348/2000], Avg Train Loss: 3.3259\n",
      "Epoch [1348/2000], Avg Val Loss: 2.1248\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1349/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3297\n",
      "    Batch [2/2], Train Loss: 3.3757\n",
      "Epoch [1349/2000], Avg Train Loss: 3.3527\n",
      "Epoch [1349/2000], Avg Val Loss: 2.1249\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1350/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3225\n",
      "    Batch [2/2], Train Loss: 3.3297\n",
      "Epoch [1350/2000], Avg Train Loss: 3.3261\n",
      "Epoch [1350/2000], Avg Val Loss: 2.1253\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1351/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3315\n",
      "    Batch [2/2], Train Loss: 3.3072\n",
      "Epoch [1351/2000], Avg Train Loss: 3.3194\n",
      "Epoch [1351/2000], Avg Val Loss: 2.1260\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1352/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3316\n",
      "    Batch [2/2], Train Loss: 3.3321\n",
      "Epoch [1352/2000], Avg Train Loss: 3.3319\n",
      "Epoch [1352/2000], Avg Val Loss: 2.1267\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1353/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3676\n",
      "    Batch [2/2], Train Loss: 3.3168\n",
      "Epoch [1353/2000], Avg Train Loss: 3.3422\n",
      "Epoch [1353/2000], Avg Val Loss: 2.1270\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1354/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3115\n",
      "    Batch [2/2], Train Loss: 3.2988\n",
      "Epoch [1354/2000], Avg Train Loss: 3.3052\n",
      "Epoch [1354/2000], Avg Val Loss: 2.1273\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1355/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3066\n",
      "    Batch [2/2], Train Loss: 3.3648\n",
      "Epoch [1355/2000], Avg Train Loss: 3.3357\n",
      "Epoch [1355/2000], Avg Val Loss: 2.1276\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1356/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3259\n",
      "    Batch [2/2], Train Loss: 3.3008\n",
      "Epoch [1356/2000], Avg Train Loss: 3.3133\n",
      "Epoch [1356/2000], Avg Val Loss: 2.1282\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1357/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3245\n",
      "    Batch [2/2], Train Loss: 3.3132\n",
      "Epoch [1357/2000], Avg Train Loss: 3.3188\n",
      "Epoch [1357/2000], Avg Val Loss: 2.1283\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1358/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3157\n",
      "    Batch [2/2], Train Loss: 3.3581\n",
      "Epoch [1358/2000], Avg Train Loss: 3.3369\n",
      "Epoch [1358/2000], Avg Val Loss: 2.1281\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1359/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.3087\n",
      "    Batch [2/2], Train Loss: 3.3480\n",
      "Epoch [1359/2000], Avg Train Loss: 3.3284\n",
      "Epoch [1359/2000], Avg Val Loss: 2.1271\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1360/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3284\n",
      "    Batch [2/2], Train Loss: 3.3428\n",
      "Epoch [1360/2000], Avg Train Loss: 3.3356\n",
      "Epoch [1360/2000], Avg Val Loss: 2.1260\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1361/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3549\n",
      "    Batch [2/2], Train Loss: 3.3384\n",
      "Epoch [1361/2000], Avg Train Loss: 3.3467\n",
      "Epoch [1361/2000], Avg Val Loss: 2.1247\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1362/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3209\n",
      "    Batch [2/2], Train Loss: 3.3091\n",
      "Epoch [1362/2000], Avg Train Loss: 3.3150\n",
      "Epoch [1362/2000], Avg Val Loss: 2.1236\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1363/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2968\n",
      "    Batch [2/2], Train Loss: 3.3540\n",
      "Epoch [1363/2000], Avg Train Loss: 3.3254\n",
      "Epoch [1363/2000], Avg Val Loss: 2.1228\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1364/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3237\n",
      "    Batch [2/2], Train Loss: 3.3113\n",
      "Epoch [1364/2000], Avg Train Loss: 3.3175\n",
      "Epoch [1364/2000], Avg Val Loss: 2.1226\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1365/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3250\n",
      "    Batch [2/2], Train Loss: 3.3343\n",
      "Epoch [1365/2000], Avg Train Loss: 3.3297\n",
      "Epoch [1365/2000], Avg Val Loss: 2.1225\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1366/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3605\n",
      "    Batch [2/2], Train Loss: 3.3220\n",
      "Epoch [1366/2000], Avg Train Loss: 3.3412\n",
      "Epoch [1366/2000], Avg Val Loss: 2.1224\n",
      "Validation loss improved from 2.1225 to 2.1224. Saving model...\n",
      "\n",
      "LOG: Epoch [1367/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3151\n",
      "    Batch [2/2], Train Loss: 3.2969\n",
      "Epoch [1367/2000], Avg Train Loss: 3.3060\n",
      "Epoch [1367/2000], Avg Val Loss: 2.1226\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1368/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2821\n",
      "    Batch [2/2], Train Loss: 3.3191\n",
      "Epoch [1368/2000], Avg Train Loss: 3.3006\n",
      "Epoch [1368/2000], Avg Val Loss: 2.1227\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1369/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3565\n",
      "    Batch [2/2], Train Loss: 3.2927\n",
      "Epoch [1369/2000], Avg Train Loss: 3.3246\n",
      "Epoch [1369/2000], Avg Val Loss: 2.1228\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1370/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3484\n",
      "    Batch [2/2], Train Loss: 3.3080\n",
      "Epoch [1370/2000], Avg Train Loss: 3.3282\n",
      "Epoch [1370/2000], Avg Val Loss: 2.1236\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1371/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3580\n",
      "    Batch [2/2], Train Loss: 3.3434\n",
      "Epoch [1371/2000], Avg Train Loss: 3.3507\n",
      "Epoch [1371/2000], Avg Val Loss: 2.1248\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1372/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3111\n",
      "    Batch [2/2], Train Loss: 3.3468\n",
      "Epoch [1372/2000], Avg Train Loss: 3.3289\n",
      "Epoch [1372/2000], Avg Val Loss: 2.1259\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1373/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3230\n",
      "    Batch [2/2], Train Loss: 3.3167\n",
      "Epoch [1373/2000], Avg Train Loss: 3.3199\n",
      "Epoch [1373/2000], Avg Val Loss: 2.1267\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1374/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3070\n",
      "    Batch [2/2], Train Loss: 3.2921\n",
      "Epoch [1374/2000], Avg Train Loss: 3.2995\n",
      "Epoch [1374/2000], Avg Val Loss: 2.1273\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1375/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3261\n",
      "    Batch [2/2], Train Loss: 3.3109\n",
      "Epoch [1375/2000], Avg Train Loss: 3.3185\n",
      "Epoch [1375/2000], Avg Val Loss: 2.1279\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1376/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3263\n",
      "    Batch [2/2], Train Loss: 3.3191\n",
      "Epoch [1376/2000], Avg Train Loss: 3.3227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1376/2000], Avg Val Loss: 2.1282\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1377/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3183\n",
      "    Batch [2/2], Train Loss: 3.3461\n",
      "Epoch [1377/2000], Avg Train Loss: 3.3322\n",
      "Epoch [1377/2000], Avg Val Loss: 2.1284\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1378/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3569\n",
      "    Batch [2/2], Train Loss: 3.3471\n",
      "Epoch [1378/2000], Avg Train Loss: 3.3520\n",
      "Epoch [1378/2000], Avg Val Loss: 2.1281\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1379/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3405\n",
      "    Batch [2/2], Train Loss: 3.2968\n",
      "Epoch [1379/2000], Avg Train Loss: 3.3187\n",
      "Epoch [1379/2000], Avg Val Loss: 2.1276\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1380/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3044\n",
      "    Batch [2/2], Train Loss: 3.3190\n",
      "Epoch [1380/2000], Avg Train Loss: 3.3117\n",
      "Epoch [1380/2000], Avg Val Loss: 2.1273\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1381/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3447\n",
      "    Batch [2/2], Train Loss: 3.3194\n",
      "Epoch [1381/2000], Avg Train Loss: 3.3321\n",
      "Epoch [1381/2000], Avg Val Loss: 2.1275\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1382/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3080\n",
      "    Batch [2/2], Train Loss: 3.3216\n",
      "Epoch [1382/2000], Avg Train Loss: 3.3148\n",
      "Epoch [1382/2000], Avg Val Loss: 2.1282\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1383/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3581\n",
      "    Batch [2/2], Train Loss: 3.3161\n",
      "Epoch [1383/2000], Avg Train Loss: 3.3371\n",
      "Epoch [1383/2000], Avg Val Loss: 2.1290\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1384/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2979\n",
      "    Batch [2/2], Train Loss: 3.3116\n",
      "Epoch [1384/2000], Avg Train Loss: 3.3047\n",
      "Epoch [1384/2000], Avg Val Loss: 2.1292\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1385/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3279\n",
      "    Batch [2/2], Train Loss: 3.2771\n",
      "Epoch [1385/2000], Avg Train Loss: 3.3025\n",
      "Epoch [1385/2000], Avg Val Loss: 2.1289\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1386/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3346\n",
      "    Batch [2/2], Train Loss: 3.3472\n",
      "Epoch [1386/2000], Avg Train Loss: 3.3409\n",
      "Epoch [1386/2000], Avg Val Loss: 2.1285\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1387/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3560\n",
      "    Batch [2/2], Train Loss: 3.3184\n",
      "Epoch [1387/2000], Avg Train Loss: 3.3372\n",
      "Epoch [1387/2000], Avg Val Loss: 2.1281\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1388/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3227\n",
      "    Batch [2/2], Train Loss: 3.3609\n",
      "Epoch [1388/2000], Avg Train Loss: 3.3418\n",
      "Epoch [1388/2000], Avg Val Loss: 2.1277\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1389/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3340\n",
      "    Batch [2/2], Train Loss: 3.2956\n",
      "Epoch [1389/2000], Avg Train Loss: 3.3148\n",
      "Epoch [1389/2000], Avg Val Loss: 2.1274\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1390/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3227\n",
      "    Batch [2/2], Train Loss: 3.3600\n",
      "Epoch [1390/2000], Avg Train Loss: 3.3414\n",
      "Epoch [1390/2000], Avg Val Loss: 2.1274\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1391/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3452\n",
      "    Batch [2/2], Train Loss: 3.3536\n",
      "Epoch [1391/2000], Avg Train Loss: 3.3494\n",
      "Epoch [1391/2000], Avg Val Loss: 2.1271\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1392/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3153\n",
      "    Batch [2/2], Train Loss: 3.2839\n",
      "Epoch [1392/2000], Avg Train Loss: 3.2996\n",
      "Epoch [1392/2000], Avg Val Loss: 2.1269\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1393/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3599\n",
      "    Batch [2/2], Train Loss: 3.3230\n",
      "Epoch [1393/2000], Avg Train Loss: 3.3414\n",
      "Epoch [1393/2000], Avg Val Loss: 2.1261\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1394/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.3122\n",
      "    Batch [2/2], Train Loss: 3.3005\n",
      "Epoch [1394/2000], Avg Train Loss: 3.3063\n",
      "Epoch [1394/2000], Avg Val Loss: 2.1253\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1395/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3067\n",
      "    Batch [2/2], Train Loss: 3.2594\n",
      "Epoch [1395/2000], Avg Train Loss: 3.2831\n",
      "Epoch [1395/2000], Avg Val Loss: 2.1248\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1396/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3123\n",
      "    Batch [2/2], Train Loss: 3.3319\n",
      "Epoch [1396/2000], Avg Train Loss: 3.3221\n",
      "Epoch [1396/2000], Avg Val Loss: 2.1248\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1397/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3345\n",
      "    Batch [2/2], Train Loss: 3.3244\n",
      "Epoch [1397/2000], Avg Train Loss: 3.3294\n",
      "Epoch [1397/2000], Avg Val Loss: 2.1248\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1398/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3091\n",
      "    Batch [2/2], Train Loss: 3.3495\n",
      "Epoch [1398/2000], Avg Train Loss: 3.3293\n",
      "Epoch [1398/2000], Avg Val Loss: 2.1248\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1399/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2917\n",
      "    Batch [2/2], Train Loss: 3.2988\n",
      "Epoch [1399/2000], Avg Train Loss: 3.2953\n",
      "Epoch [1399/2000], Avg Val Loss: 2.1249\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1400/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3268\n",
      "    Batch [2/2], Train Loss: 3.2980\n",
      "Epoch [1400/2000], Avg Train Loss: 3.3124\n",
      "Epoch [1400/2000], Avg Val Loss: 2.1249\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1401/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3126\n",
      "    Batch [2/2], Train Loss: 3.3226\n",
      "Epoch [1401/2000], Avg Train Loss: 3.3176\n",
      "Epoch [1401/2000], Avg Val Loss: 2.1252\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1402/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3366\n",
      "    Batch [2/2], Train Loss: 3.3221\n",
      "Epoch [1402/2000], Avg Train Loss: 3.3294\n",
      "Epoch [1402/2000], Avg Val Loss: 2.1258\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1403/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3006\n",
      "    Batch [2/2], Train Loss: 3.3451\n",
      "Epoch [1403/2000], Avg Train Loss: 3.3229\n",
      "Epoch [1403/2000], Avg Val Loss: 2.1259\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1404/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3413\n",
      "    Batch [2/2], Train Loss: 3.3097\n",
      "Epoch [1404/2000], Avg Train Loss: 3.3255\n",
      "Epoch [1404/2000], Avg Val Loss: 2.1260\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1405/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3154\n",
      "    Batch [2/2], Train Loss: 3.3206\n",
      "Epoch [1405/2000], Avg Train Loss: 3.3180\n",
      "Epoch [1405/2000], Avg Val Loss: 2.1264\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1406/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3271\n",
      "    Batch [2/2], Train Loss: 3.2913\n",
      "Epoch [1406/2000], Avg Train Loss: 3.3092\n",
      "Epoch [1406/2000], Avg Val Loss: 2.1267\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1407/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3311\n",
      "    Batch [2/2], Train Loss: 3.3254\n",
      "Epoch [1407/2000], Avg Train Loss: 3.3283\n",
      "Epoch [1407/2000], Avg Val Loss: 2.1272\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1408/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3548\n",
      "    Batch [2/2], Train Loss: 3.2789\n",
      "Epoch [1408/2000], Avg Train Loss: 3.3169\n",
      "Epoch [1408/2000], Avg Val Loss: 2.1274\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1409/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2901\n",
      "    Batch [2/2], Train Loss: 3.3447\n",
      "Epoch [1409/2000], Avg Train Loss: 3.3174\n",
      "Epoch [1409/2000], Avg Val Loss: 2.1277\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1410/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3241\n",
      "    Batch [2/2], Train Loss: 3.3329\n",
      "Epoch [1410/2000], Avg Train Loss: 3.3285\n",
      "Epoch [1410/2000], Avg Val Loss: 2.1279\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1411/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3107\n",
      "    Batch [2/2], Train Loss: 3.3203\n",
      "Epoch [1411/2000], Avg Train Loss: 3.3155\n",
      "Epoch [1411/2000], Avg Val Loss: 2.1282\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1412/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 3.3202\n",
      "Epoch [1412/2000], Avg Train Loss: 3.3133\n",
      "Epoch [1412/2000], Avg Val Loss: 2.1282\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1413/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3161\n",
      "    Batch [2/2], Train Loss: 3.2816\n",
      "Epoch [1413/2000], Avg Train Loss: 3.2988\n",
      "Epoch [1413/2000], Avg Val Loss: 2.1286\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1414/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3304\n",
      "    Batch [2/2], Train Loss: 3.3392\n",
      "Epoch [1414/2000], Avg Train Loss: 3.3348\n",
      "Epoch [1414/2000], Avg Val Loss: 2.1289\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1415/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3226\n",
      "    Batch [2/2], Train Loss: 3.3649\n",
      "Epoch [1415/2000], Avg Train Loss: 3.3438\n",
      "Epoch [1415/2000], Avg Val Loss: 2.1293\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1416/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3203\n",
      "    Batch [2/2], Train Loss: 3.3016\n",
      "Epoch [1416/2000], Avg Train Loss: 3.3109\n",
      "Epoch [1416/2000], Avg Val Loss: 2.1297\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1417/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3512\n",
      "    Batch [2/2], Train Loss: 3.2925\n",
      "Epoch [1417/2000], Avg Train Loss: 3.3218\n",
      "Epoch [1417/2000], Avg Val Loss: 2.1302\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1418/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2790\n",
      "    Batch [2/2], Train Loss: 3.2892\n",
      "Epoch [1418/2000], Avg Train Loss: 3.2841\n",
      "Epoch [1418/2000], Avg Val Loss: 2.1307\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1419/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3150\n",
      "    Batch [2/2], Train Loss: 3.3237\n",
      "Epoch [1419/2000], Avg Train Loss: 3.3194\n",
      "Epoch [1419/2000], Avg Val Loss: 2.1314\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1420/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3361\n",
      "    Batch [2/2], Train Loss: 3.2977\n",
      "Epoch [1420/2000], Avg Train Loss: 3.3169\n",
      "Epoch [1420/2000], Avg Val Loss: 2.1320\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1421/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2818\n",
      "    Batch [2/2], Train Loss: 3.3214\n",
      "Epoch [1421/2000], Avg Train Loss: 3.3016\n",
      "Epoch [1421/2000], Avg Val Loss: 2.1323\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1422/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3359\n",
      "    Batch [2/2], Train Loss: 3.2962\n",
      "Epoch [1422/2000], Avg Train Loss: 3.3160\n",
      "Epoch [1422/2000], Avg Val Loss: 2.1325\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1423/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3075\n",
      "    Batch [2/2], Train Loss: 3.3115\n",
      "Epoch [1423/2000], Avg Train Loss: 3.3095\n",
      "Epoch [1423/2000], Avg Val Loss: 2.1325\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1424/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2808\n",
      "    Batch [2/2], Train Loss: 3.3275\n",
      "Epoch [1424/2000], Avg Train Loss: 3.3041\n",
      "Epoch [1424/2000], Avg Val Loss: 2.1327\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1425/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3429\n",
      "    Batch [2/2], Train Loss: 3.3277\n",
      "Epoch [1425/2000], Avg Train Loss: 3.3353\n",
      "Epoch [1425/2000], Avg Val Loss: 2.1318\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1426/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3114\n",
      "    Batch [2/2], Train Loss: 3.3183\n",
      "Epoch [1426/2000], Avg Train Loss: 3.3148\n",
      "Epoch [1426/2000], Avg Val Loss: 2.1302\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1427/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3099\n",
      "    Batch [2/2], Train Loss: 3.3195\n",
      "Epoch [1427/2000], Avg Train Loss: 3.3147\n",
      "Epoch [1427/2000], Avg Val Loss: 2.1290\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1428/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3245\n",
      "    Batch [2/2], Train Loss: 3.3328\n",
      "Epoch [1428/2000], Avg Train Loss: 3.3286\n",
      "Epoch [1428/2000], Avg Val Loss: 2.1273\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1429/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3002\n",
      "    Batch [2/2], Train Loss: 3.3365\n",
      "Epoch [1429/2000], Avg Train Loss: 3.3184\n",
      "Epoch [1429/2000], Avg Val Loss: 2.1256\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [1430/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3204\n",
      "    Batch [2/2], Train Loss: 3.2798\n",
      "Epoch [1430/2000], Avg Train Loss: 3.3001\n",
      "Epoch [1430/2000], Avg Val Loss: 2.1248\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [1431/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.3187\n",
      "    Batch [2/2], Train Loss: 3.3031\n",
      "Epoch [1431/2000], Avg Train Loss: 3.3109\n",
      "Epoch [1431/2000], Avg Val Loss: 2.1246\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [1432/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3077\n",
      "    Batch [2/2], Train Loss: 3.3245\n",
      "Epoch [1432/2000], Avg Train Loss: 3.3161\n",
      "Epoch [1432/2000], Avg Val Loss: 2.1244\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [1433/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3168\n",
      "    Batch [2/2], Train Loss: 3.2894\n",
      "Epoch [1433/2000], Avg Train Loss: 3.3031\n",
      "Epoch [1433/2000], Avg Val Loss: 2.1246\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [1434/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3263\n",
      "    Batch [2/2], Train Loss: 3.3238\n",
      "Epoch [1434/2000], Avg Train Loss: 3.3250\n",
      "Epoch [1434/2000], Avg Val Loss: 2.1246\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [1435/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3197\n",
      "    Batch [2/2], Train Loss: 3.3123\n",
      "Epoch [1435/2000], Avg Train Loss: 3.3160\n",
      "Epoch [1435/2000], Avg Val Loss: 2.1246\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [1436/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2753\n",
      "    Batch [2/2], Train Loss: 3.3461\n",
      "Epoch [1436/2000], Avg Train Loss: 3.3107\n",
      "Epoch [1436/2000], Avg Val Loss: 2.1244\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [1437/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3493\n",
      "    Batch [2/2], Train Loss: 3.2871\n",
      "Epoch [1437/2000], Avg Train Loss: 3.3182\n",
      "Epoch [1437/2000], Avg Val Loss: 2.1243\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [1438/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3384\n",
      "    Batch [2/2], Train Loss: 3.2721\n",
      "Epoch [1438/2000], Avg Train Loss: 3.3053\n",
      "Epoch [1438/2000], Avg Val Loss: 2.1245\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [1439/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2771\n",
      "    Batch [2/2], Train Loss: 3.2784\n",
      "Epoch [1439/2000], Avg Train Loss: 3.2777\n",
      "Epoch [1439/2000], Avg Val Loss: 2.1248\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [1440/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3094\n",
      "    Batch [2/2], Train Loss: 3.2918\n",
      "Epoch [1440/2000], Avg Train Loss: 3.3006\n",
      "Epoch [1440/2000], Avg Val Loss: 2.1245\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [1441/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3256\n",
      "    Batch [2/2], Train Loss: 3.3278\n",
      "Epoch [1441/2000], Avg Train Loss: 3.3267\n",
      "Epoch [1441/2000], Avg Val Loss: 2.1238\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [1442/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3063\n",
      "    Batch [2/2], Train Loss: 3.3078\n",
      "Epoch [1442/2000], Avg Train Loss: 3.3070\n",
      "Epoch [1442/2000], Avg Val Loss: 2.1235\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [1443/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2902\n",
      "    Batch [2/2], Train Loss: 3.3079\n",
      "Epoch [1443/2000], Avg Train Loss: 3.2990\n",
      "Epoch [1443/2000], Avg Val Loss: 2.1235\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [1444/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3236\n",
      "    Batch [2/2], Train Loss: 3.3188\n",
      "Epoch [1444/2000], Avg Train Loss: 3.3212\n",
      "Epoch [1444/2000], Avg Val Loss: 2.1236\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [1445/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3050\n",
      "    Batch [2/2], Train Loss: 3.2843\n",
      "Epoch [1445/2000], Avg Train Loss: 3.2946\n",
      "Epoch [1445/2000], Avg Val Loss: 2.1238\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [1446/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2986\n",
      "    Batch [2/2], Train Loss: 3.3076\n",
      "Epoch [1446/2000], Avg Train Loss: 3.3031\n",
      "Epoch [1446/2000], Avg Val Loss: 2.1241\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [1447/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3197\n",
      "    Batch [2/2], Train Loss: 3.2933\n",
      "Epoch [1447/2000], Avg Train Loss: 3.3065\n",
      "Epoch [1447/2000], Avg Val Loss: 2.1251\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [1448/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2992\n",
      "    Batch [2/2], Train Loss: 3.2931\n",
      "Epoch [1448/2000], Avg Train Loss: 3.2962\n",
      "Epoch [1448/2000], Avg Val Loss: 2.1257\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [1449/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3202\n",
      "    Batch [2/2], Train Loss: 3.3247\n",
      "Epoch [1449/2000], Avg Train Loss: 3.3224\n",
      "Epoch [1449/2000], Avg Val Loss: 2.1261\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [1450/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 3.3032\n",
      "    Batch [2/2], Train Loss: 3.3065\n",
      "Epoch [1450/2000], Avg Train Loss: 3.3048\n",
      "Epoch [1450/2000], Avg Val Loss: 2.1265\n",
      "Validation loss did not improve. Patience: 84/100\n",
      "\n",
      "LOG: Epoch [1451/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2995\n",
      "    Batch [2/2], Train Loss: 3.3168\n",
      "Epoch [1451/2000], Avg Train Loss: 3.3081\n",
      "Epoch [1451/2000], Avg Val Loss: 2.1266\n",
      "Validation loss did not improve. Patience: 85/100\n",
      "\n",
      "LOG: Epoch [1452/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2914\n",
      "    Batch [2/2], Train Loss: 3.2505\n",
      "Epoch [1452/2000], Avg Train Loss: 3.2709\n",
      "Epoch [1452/2000], Avg Val Loss: 2.1269\n",
      "Validation loss did not improve. Patience: 86/100\n",
      "\n",
      "LOG: Epoch [1453/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3095\n",
      "    Batch [2/2], Train Loss: 3.3087\n",
      "Epoch [1453/2000], Avg Train Loss: 3.3091\n",
      "Epoch [1453/2000], Avg Val Loss: 2.1275\n",
      "Validation loss did not improve. Patience: 87/100\n",
      "\n",
      "LOG: Epoch [1454/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3088\n",
      "    Batch [2/2], Train Loss: 3.3488\n",
      "Epoch [1454/2000], Avg Train Loss: 3.3288\n",
      "Epoch [1454/2000], Avg Val Loss: 2.1281\n",
      "Validation loss did not improve. Patience: 88/100\n",
      "\n",
      "LOG: Epoch [1455/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2920\n",
      "    Batch [2/2], Train Loss: 3.2889\n",
      "Epoch [1455/2000], Avg Train Loss: 3.2905\n",
      "Epoch [1455/2000], Avg Val Loss: 2.1288\n",
      "Validation loss did not improve. Patience: 89/100\n",
      "\n",
      "LOG: Epoch [1456/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2772\n",
      "    Batch [2/2], Train Loss: 3.2818\n",
      "Epoch [1456/2000], Avg Train Loss: 3.2795\n",
      "Epoch [1456/2000], Avg Val Loss: 2.1296\n",
      "Validation loss did not improve. Patience: 90/100\n",
      "\n",
      "LOG: Epoch [1457/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3050\n",
      "    Batch [2/2], Train Loss: 3.2843\n",
      "Epoch [1457/2000], Avg Train Loss: 3.2946\n",
      "Epoch [1457/2000], Avg Val Loss: 2.1300\n",
      "Validation loss did not improve. Patience: 91/100\n",
      "\n",
      "LOG: Epoch [1458/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2819\n",
      "    Batch [2/2], Train Loss: 3.3040\n",
      "Epoch [1458/2000], Avg Train Loss: 3.2930\n",
      "Epoch [1458/2000], Avg Val Loss: 2.1301\n",
      "Validation loss did not improve. Patience: 92/100\n",
      "\n",
      "LOG: Epoch [1459/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3311\n",
      "    Batch [2/2], Train Loss: 3.2833\n",
      "Epoch [1459/2000], Avg Train Loss: 3.3072\n",
      "Epoch [1459/2000], Avg Val Loss: 2.1299\n",
      "Validation loss did not improve. Patience: 93/100\n",
      "\n",
      "LOG: Epoch [1460/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3005\n",
      "    Batch [2/2], Train Loss: 3.2963\n",
      "Epoch [1460/2000], Avg Train Loss: 3.2984\n",
      "Epoch [1460/2000], Avg Val Loss: 2.1298\n",
      "Validation loss did not improve. Patience: 94/100\n",
      "\n",
      "LOG: Epoch [1461/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2944\n",
      "    Batch [2/2], Train Loss: 3.3008\n",
      "Epoch [1461/2000], Avg Train Loss: 3.2976\n",
      "Epoch [1461/2000], Avg Val Loss: 2.1307\n",
      "Validation loss did not improve. Patience: 95/100\n",
      "\n",
      "LOG: Epoch [1462/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2767\n",
      "    Batch [2/2], Train Loss: 3.3019\n",
      "Epoch [1462/2000], Avg Train Loss: 3.2893\n",
      "Epoch [1462/2000], Avg Val Loss: 2.1311\n",
      "Validation loss did not improve. Patience: 96/100\n",
      "\n",
      "LOG: Epoch [1463/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3220\n",
      "    Batch [2/2], Train Loss: 3.2977\n",
      "Epoch [1463/2000], Avg Train Loss: 3.3098\n",
      "Epoch [1463/2000], Avg Val Loss: 2.1317\n",
      "Validation loss did not improve. Patience: 97/100\n",
      "\n",
      "LOG: Epoch [1464/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.3172\n",
      "    Batch [2/2], Train Loss: 3.2420\n",
      "Epoch [1464/2000], Avg Train Loss: 3.2796\n",
      "Epoch [1464/2000], Avg Val Loss: 2.1318\n",
      "Validation loss did not improve. Patience: 98/100\n",
      "\n",
      "LOG: Epoch [1465/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2624\n",
      "    Batch [2/2], Train Loss: 3.2972\n",
      "Epoch [1465/2000], Avg Train Loss: 3.2798\n",
      "Epoch [1465/2000], Avg Val Loss: 2.1320\n",
      "Validation loss did not improve. Patience: 99/100\n",
      "\n",
      "LOG: Epoch [1466/2000] - Training\n",
      "    Batch [1/2], Train Loss: 3.2576\n",
      "    Batch [2/2], Train Loss: 3.3055\n",
      "Epoch [1466/2000], Avg Train Loss: 3.2816\n",
      "Epoch [1466/2000], Avg Val Loss: 2.1325\n",
      "Validation loss did not improve. Patience: 100/100\n",
      "Early stopping triggered at epoch 1466. No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_model = SupConNet().to(device)\n",
    "tscl_criterion = SupConLoss(temperature=0.07).to(device)\n",
    "tscl_optimizer = optim.Adam(tscl_model.parameters(), lr=1e-4, weight_decay=1e-5)  # Increased learning rate\n",
    "\n",
    "tscl_patience = 100\n",
    "tscl_best_val_loss = float('inf')\n",
    "tscl_epochs_without_improvement = 0\n",
    "\n",
    "tscl_num_epochs = 2000\n",
    "tscl_train_losses = []\n",
    "tscl_val_losses = []\n",
    "\n",
    "# TRAINING\n",
    "for tscl_epoch in range(tscl_num_epochs):\n",
    "    print(f\"\\nLOG: Epoch [{tscl_epoch + 1}/{tscl_num_epochs}] - Training\")\n",
    "    tscl_model.train()\n",
    "    tscl_total_loss = 0\n",
    "\n",
    "    for batch_idx, (vectors, labels) in enumerate(tscl_train_loader):\n",
    "        vectors = vectors.to(device).float()  # moving input tensors to GPU\n",
    "        labels = labels.to(device)  # moving labels to GPU\n",
    "\n",
    "        # forward pass to get projections\n",
    "        projections = tscl_model(vectors)\n",
    "\n",
    "        # calc contrastive loss\n",
    "        loss = tscl_criterion(projections, labels)\n",
    "\n",
    "        # backprop and optimization\n",
    "        tscl_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        tscl_optimizer.step()\n",
    "\n",
    "        tscl_total_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 1 == 0:\n",
    "            print(f\"    Batch [{batch_idx + 1}/{len(tscl_train_loader)}], \"\n",
    "                  f\"Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc avg training loss for the epoch\n",
    "    tscl_avg_train_loss = tscl_total_loss / len(tscl_train_loader)\n",
    "    tscl_train_losses.append(tscl_avg_train_loss)\n",
    "    print(f\"Epoch [{tscl_epoch + 1}/{tscl_num_epochs}], \"\n",
    "          f\"Avg Train Loss: {tscl_avg_train_loss:.4f}\")\n",
    "\n",
    "    # VALIDATION\n",
    "    tscl_model.eval()\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (vectors, labels) in enumerate(tscl_val_loader):\n",
    "            vectors = vectors.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            projections = tscl_model(vectors)\n",
    "\n",
    "            loss = tscl_criterion(projections, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"    Batch [{batch_idx + 1}/{len(tscl_val_loader)}], \"\n",
    "                      f\"Val Loss: {loss.item():.4f}\")\n",
    "\n",
    "    tscl_avg_val_loss = total_val_loss / len(tscl_val_loader)\n",
    "    tscl_val_losses.append(tscl_avg_val_loss)\n",
    "    print(f\"Epoch [{tscl_epoch + 1}/{tscl_num_epochs}], \"\n",
    "          f\"Avg Val Loss: {tscl_avg_val_loss:.4f}\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if tscl_avg_val_loss < tscl_best_val_loss:\n",
    "        print(f\"Validation loss improved from {tscl_best_val_loss:.4f} to {tscl_avg_val_loss:.4f}. Saving model...\")\n",
    "        tscl_best_val_loss = tscl_avg_val_loss\n",
    "        tscl_epochs_without_improvement = 0\n",
    "    else:\n",
    "        tscl_epochs_without_improvement += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {tscl_epochs_without_improvement}/{tscl_patience}\")\n",
    "\n",
    "    # stopping training if validation loss hasn't improved for patience amount of epochs\n",
    "    if tscl_epochs_without_improvement >= tscl_patience:\n",
    "        print(f\"Early stopping triggered at epoch {tscl_epoch + 1}. No improvement for {tscl_patience} epochs.\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(tscl_train_losses) + 1), tscl_train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(1, len(tscl_val_losses) + 1), tscl_val_losses, label=\"Validation Loss\", marker='x')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:44:01.370037Z",
     "iopub.status.busy": "2025-05-08T19:44:01.370037Z",
     "iopub.status.idle": "2025-05-08T19:44:01.507887Z",
     "shell.execute_reply": "2025-05-08T19:44:01.507887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [10/11], Loss: 4.8996\n",
      "\n",
      "Test Loss: 5.0542\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "tscl_model.eval()\n",
    "total_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (vectors, labels) in enumerate(tscl_test_loader):\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        projections = tscl_model(vectors)\n",
    "        loss = criterion(projections, labels)\n",
    "        total_test_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Test Batch [{batch_idx + 1}/{len(tscl_test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "avg_test_loss = total_test_loss / len(tscl_test_loader)\n",
    "print(f\"\\nTest Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "epochs = range(1, len(tscl_train_losses) + 1)\n",
    "plt.plot(epochs, tscl_train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(epochs, tscl_val_losses, label=\"Validation Loss\", marker='x')\n",
    "# test loss = horizontal dashed line\n",
    "plt.axhline(y=avg_test_loss, color='r', linestyle='--', label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving representations learnt by Typical SCL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:44:01.510893Z",
     "iopub.status.busy": "2025-05-08T19:44:01.509895Z",
     "iopub.status.idle": "2025-05-08T19:44:01.583109Z",
     "shell.execute_reply": "2025-05-08T19:44:01.583109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'tscl_representations\\train'.\n",
      "\n",
      "Extracting SCL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'tscl_representations\\val'.\n",
      "\n",
      "Extracting SCL representations for the test dataset...\n",
      "  Processed batch 10/11 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'tscl_representations\\test'.\n",
      "SCL representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the SCL representations\n",
    "tscl_rep_dir = \"tscl_representations\"\n",
    "os.makedirs(tscl_rep_dir, exist_ok=True)\n",
    "\n",
    "tscl_loaders = {\n",
    "    'train': tscl_train_loader,\n",
    "    'val': tscl_val_loader,\n",
    "    'test': tscl_test_loader\n",
    "}\n",
    "\n",
    "tscl_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tscl_split_name, tscl_loader in tscl_loaders.items():\n",
    "        print(f\"\\nExtracting SCL representations for the {tscl_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        tscl_split_dir = os.path.join(tscl_rep_dir, tscl_split_name)\n",
    "        os.makedirs(tscl_split_dir, exist_ok=True)\n",
    "        \n",
    "        # processing the data batch-wise\n",
    "        for tscl_batch_idx, (tscl_vectors, tscl_labels) in enumerate(tscl_loader):\n",
    "            tscl_vectors = tscl_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            tscl_projections = tscl_model(tscl_vectors)\n",
    "            \n",
    "            # converting projections and labels to np arrays\n",
    "            tscl_projections_np = tscl_projections.cpu().numpy()\n",
    "            tscl_labels_np = tscl_labels.cpu().numpy()\n",
    "            \n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(tscl_split_dir, f\"scl_encoded_batch_{tscl_batch_idx}.npy\"), tscl_projections_np)\n",
    "            np.save(os.path.join(tscl_split_dir, f\"scl_labels_batch_{tscl_batch_idx}.npy\"), tscl_labels_np)\n",
    "            \n",
    "            if (tscl_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {tscl_batch_idx + 1}/{len(tscl_loader)} for {tscl_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {tscl_split_name} dataset. Representations saved in '{tscl_split_dir}'.\")\n",
    "\n",
    "print(\"SCL representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying representations learnt by SCL Model with LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:44:01.586115Z",
     "iopub.status.busy": "2025-05-08T19:44:01.586115Z",
     "iopub.status.idle": "2025-05-08T19:44:01.589403Z",
     "shell.execute_reply": "2025-05-08T19:44:01.589403Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_tscl_reps_and_labels(split_dir):\n",
    "    #gather all the scl_encoded_batch npy files in sorted order\n",
    "    tscl_rep_files = sorted(glob.glob(os.path.join(split_dir, \"scl_encoded_batch_*.npy\")))\n",
    "\n",
    "    tscl_all_reps = []\n",
    "    tscl_all_labels = []\n",
    "\n",
    "    for tscl_rep_file in tscl_rep_files:\n",
    "        #deriving label filenames\n",
    "        tscl_label_file = tscl_rep_file.replace(\"scl_encoded_batch_\", \"scl_labels_batch_\")\n",
    "\n",
    "        tscl_reps = np.load(tscl_rep_file)\n",
    "        tscl_labels = np.load(tscl_label_file)\n",
    "\n",
    "        tscl_all_reps.append(tscl_reps)\n",
    "        tscl_all_labels.append(tscl_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    tscl_all_reps = np.concatenate(tscl_all_reps, axis = 0)\n",
    "    tscl_all_labels = np.concatenate(tscl_all_labels, axis = 0)\n",
    "\n",
    "    return tscl_all_reps, tscl_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:44:01.592921Z",
     "iopub.status.busy": "2025-05-08T19:44:01.591920Z",
     "iopub.status.idle": "2025-05-08T19:44:01.765927Z",
     "shell.execute_reply": "2025-05-08T19:44:01.765927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (560, 128)\n",
      "Train labels shape: (560,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2618, 128)\n",
      "Test labels shape: (2618,)\n"
     ]
    }
   ],
   "source": [
    "tscl_lrm_train_dir = os.path.join(\"tscl_representations\", \"train\")\n",
    "tscl_lrm_val_dir   = os.path.join(\"tscl_representations\", \"val\")\n",
    "tscl_lrm_test_dir  = os.path.join(\"tscl_representations\", \"test\")\n",
    "\n",
    "tscl_lrm_train_reps, tscl_lrm_train_labels = load_tscl_reps_and_labels(tscl_lrm_train_dir)\n",
    "tscl_lrm_val_reps, tscl_lrm_val_labels = load_tscl_reps_and_labels(tscl_lrm_val_dir)\n",
    "tscl_lrm_test_reps, tscl_lrm_test_labels = load_tscl_reps_and_labels(tscl_lrm_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", tscl_lrm_train_reps.shape)\n",
    "print(\"Train labels shape:\", tscl_lrm_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", tscl_lrm_val_reps.shape)\n",
    "print(\"Val labels shape:\", tscl_lrm_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", tscl_lrm_test_reps.shape)\n",
    "print(\"Test labels shape:\", tscl_lrm_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:44:01.768440Z",
     "iopub.status.busy": "2025-05-08T19:44:01.768440Z",
     "iopub.status.idle": "2025-05-08T19:44:01.818487Z",
     "shell.execute_reply": "2025-05-08T19:44:01.818487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Training Logistic Regression model on SCL SDL representations...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 95.71%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       0.83      1.00      0.91         5\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       1.00      0.60      0.75         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      0.80      0.89         5\n",
      "           8       0.83      1.00      0.91         5\n",
      "           9       0.83      1.00      0.91         5\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      1.00      1.00         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.96        70\n",
      "   macro avg       0.96      0.96      0.95        70\n",
      "weighted avg       0.96      0.96      0.95        70\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 89.00%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       225\n",
      "           1       0.80      0.91      0.85        56\n",
      "           2       0.92      0.96      0.94       206\n",
      "           3       0.74      1.00      0.85       170\n",
      "           4       0.82      0.85      0.83       224\n",
      "           5       0.81      0.71      0.76       224\n",
      "           6       0.98      0.95      0.97       214\n",
      "           7       0.90      0.90      0.90       158\n",
      "           8       0.89      0.78      0.83       269\n",
      "           9       0.81      0.92      0.86       203\n",
      "          10       1.00      0.90      0.95       260\n",
      "          11       0.90      0.96      0.93       136\n",
      "          12       0.95      0.84      0.90       223\n",
      "          13       0.89      0.98      0.93        50\n",
      "\n",
      "    accuracy                           0.89      2618\n",
      "   macro avg       0.89      0.90      0.89      2618\n",
      "weighted avg       0.90      0.89      0.89      2618\n",
      "\n",
      "Saved CAE+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "# training LRM on the tscl representations\n",
    "print(\"\\nLOG: Training Logistic Regression model on SCL SDL representations...\")\n",
    "tscl_logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced')\n",
    "tscl_logistic_clf.fit(tscl_lrm_train_reps, tscl_lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "# eval on val set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "tscl_lrm_val_predictions = tscl_logistic_clf.predict(tscl_lrm_val_reps)\n",
    "tscl_lrm_val_accuracy = accuracy_score(tscl_lrm_val_labels, tscl_lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {tscl_lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(tscl_lrm_val_labels, tscl_lrm_val_predictions))\n",
    "\n",
    "# eval on test\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "tscl_lrm_test_predictions = tscl_logistic_clf.predict(tscl_lrm_test_reps)\n",
    "tscl_lrm_test_accuracy = accuracy_score(tscl_lrm_test_labels, tscl_lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {tscl_lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(tscl_lrm_test_labels, tscl_lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'tscl_lrm_predictions.npy'), tscl_lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'tscl_lrm_true_labels.npy'), tscl_lrm_test_labels)\n",
    "print(f\"Saved CAE+LRM predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the representations learnt by Typical SCL Model with MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:44:01.822026Z",
     "iopub.status.busy": "2025-05-08T19:44:01.821018Z",
     "iopub.status.idle": "2025-05-08T19:44:01.827044Z",
     "shell.execute_reply": "2025-05-08T19:44:01.826027Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:44:01.829045Z",
     "iopub.status.busy": "2025-05-08T19:44:01.829045Z",
     "iopub.status.idle": "2025-05-08T19:44:01.839364Z",
     "shell.execute_reply": "2025-05-08T19:44:01.839364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (560, 128)\n",
      "Train labels shape: (560,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2618, 128)\n",
      "Test labels shape: (2618,)\n"
     ]
    }
   ],
   "source": [
    "tscl_mlp_train_dir = os.path.join(\"tscl_representations\", \"train\")\n",
    "tscl_mlp_val_dir   = os.path.join(\"tscl_representations\", \"val\")\n",
    "tscl_mlp_test_dir  = os.path.join(\"tscl_representations\", \"test\")\n",
    "\n",
    "tscl_mlp_train_reps, tscl_mlp_train_labels = load_tscl_reps_and_labels(tscl_mlp_train_dir)\n",
    "tscl_mlp_val_reps, tscl_mlp_val_labels = load_tscl_reps_and_labels(tscl_mlp_val_dir)\n",
    "tscl_mlp_test_reps, tscl_mlp_test_labels = load_tscl_reps_and_labels(tscl_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\",tscl_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", tscl_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", tscl_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", tscl_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", tscl_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", tscl_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:44:01.841884Z",
     "iopub.status.busy": "2025-05-08T19:44:01.841884Z",
     "iopub.status.idle": "2025-05-08T19:44:01.847386Z",
     "shell.execute_reply": "2025-05-08T19:44:01.846882Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "tscl_mlp_train_embeddings_torch = torch.tensor(tscl_mlp_train_reps, dtype=torch.float32)\n",
    "tscl_mlp_train_labels_torch = torch.tensor(tscl_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "tscl_mlp_val_embeddings_torch = torch.tensor(tscl_mlp_val_reps, dtype=torch.float32)\n",
    "tscl_mlp_val_labels_torch = torch.tensor(tscl_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "tscl_mlp_test_embeddings_torch = torch.tensor(tscl_mlp_test_reps, dtype=torch.float32)\n",
    "tscl_mlp_test_labels_torch = torch.tensor(tscl_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "tscl_mlp_train_dataset = TensorDataset(tscl_mlp_train_embeddings_torch, tscl_mlp_train_labels_torch)\n",
    "tscl_mlp_val_dataset = TensorDataset(tscl_mlp_val_embeddings_torch, tscl_mlp_val_labels_torch)\n",
    "tscl_mlp_test_dataset = TensorDataset(tscl_mlp_test_embeddings_torch, tscl_mlp_test_labels_torch)\n",
    "\n",
    "tscl_mlp_batch_size = 64\n",
    "tscl_mlp_train_loader = DataLoader(tscl_mlp_train_dataset, batch_size=tscl_mlp_batch_size, shuffle=True)\n",
    "tscl_mlp_val_loader = DataLoader(tscl_mlp_val_dataset, batch_size=tscl_mlp_batch_size, shuffle=False)\n",
    "tscl_mlp_test_loader = DataLoader(tscl_mlp_test_dataset, batch_size=tscl_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:44:01.850893Z",
     "iopub.status.busy": "2025-05-08T19:44:01.849390Z",
     "iopub.status.idle": "2025-05-08T19:44:10.834160Z",
     "shell.execute_reply": "2025-05-08T19:44:10.834160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 3.0211  |  Val Loss: 2.8963\n",
      "Validation loss improved from inf to 2.8963.\n",
      "[Epoch 2/1000] Train Loss: 2.8708  |  Val Loss: 2.7752\n",
      "Validation loss improved from 2.8963 to 2.7752.\n",
      "[Epoch 3/1000] Train Loss: 2.7515  |  Val Loss: 2.6739\n",
      "Validation loss improved from 2.7752 to 2.6739.\n",
      "[Epoch 4/1000] Train Loss: 2.6508  |  Val Loss: 2.5888\n",
      "Validation loss improved from 2.6739 to 2.5888.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/1000] Train Loss: 2.5656  |  Val Loss: 2.5086\n",
      "Validation loss improved from 2.5888 to 2.5086.\n",
      "[Epoch 6/1000] Train Loss: 2.4858  |  Val Loss: 2.4475\n",
      "Validation loss improved from 2.5086 to 2.4475.\n",
      "[Epoch 7/1000] Train Loss: 2.4218  |  Val Loss: 2.3995\n",
      "Validation loss improved from 2.4475 to 2.3995.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/1000] Train Loss: 2.3747  |  Val Loss: 2.3565\n",
      "Validation loss improved from 2.3995 to 2.3565.\n",
      "[Epoch 9/1000] Train Loss: 2.3311  |  Val Loss: 2.3163\n",
      "Validation loss improved from 2.3565 to 2.3163.\n",
      "[Epoch 10/1000] Train Loss: 2.2919  |  Val Loss: 2.2792\n",
      "Validation loss improved from 2.3163 to 2.2792.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/1000] Train Loss: 2.2573  |  Val Loss: 2.2453\n",
      "Validation loss improved from 2.2792 to 2.2453.\n",
      "[Epoch 12/1000] Train Loss: 2.2238  |  Val Loss: 2.2129\n",
      "Validation loss improved from 2.2453 to 2.2129.\n",
      "[Epoch 13/1000] Train Loss: 2.1912  |  Val Loss: 2.1808\n",
      "Validation loss improved from 2.2129 to 2.1808.\n",
      "[Epoch 14/1000] Train Loss: 2.1602  |  Val Loss: 2.1477\n",
      "Validation loss improved from 2.1808 to 2.1477.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/1000] Train Loss: 2.1267  |  Val Loss: 2.1101\n",
      "Validation loss improved from 2.1477 to 2.1101.\n",
      "[Epoch 16/1000] Train Loss: 2.0903  |  Val Loss: 2.0714\n",
      "Validation loss improved from 2.1101 to 2.0714.\n",
      "[Epoch 17/1000] Train Loss: 2.0515  |  Val Loss: 2.0343\n",
      "Validation loss improved from 2.0714 to 2.0343.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/1000] Train Loss: 2.0155  |  Val Loss: 1.9980\n",
      "Validation loss improved from 2.0343 to 1.9980.\n",
      "[Epoch 19/1000] Train Loss: 1.9802  |  Val Loss: 1.9632\n",
      "Validation loss improved from 1.9980 to 1.9632.\n",
      "[Epoch 20/1000] Train Loss: 1.9466  |  Val Loss: 1.9291\n",
      "Validation loss improved from 1.9632 to 1.9291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/1000] Train Loss: 1.9119  |  Val Loss: 1.8963\n",
      "Validation loss improved from 1.9291 to 1.8963.\n",
      "[Epoch 22/1000] Train Loss: 1.8786  |  Val Loss: 1.8626\n",
      "Validation loss improved from 1.8963 to 1.8626.\n",
      "[Epoch 23/1000] Train Loss: 1.8454  |  Val Loss: 1.8307\n",
      "Validation loss improved from 1.8626 to 1.8307.\n",
      "[Epoch 24/1000] Train Loss: 1.8132  |  Val Loss: 1.8001\n",
      "Validation loss improved from 1.8307 to 1.8001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25/1000] Train Loss: 1.7825  |  Val Loss: 1.7707\n",
      "Validation loss improved from 1.8001 to 1.7707.\n",
      "[Epoch 26/1000] Train Loss: 1.7519  |  Val Loss: 1.7424\n",
      "Validation loss improved from 1.7707 to 1.7424.\n",
      "[Epoch 27/1000] Train Loss: 1.7225  |  Val Loss: 1.7150\n",
      "Validation loss improved from 1.7424 to 1.7150.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28/1000] Train Loss: 1.6938  |  Val Loss: 1.6881\n",
      "Validation loss improved from 1.7150 to 1.6881.\n",
      "[Epoch 29/1000] Train Loss: 1.6650  |  Val Loss: 1.6608\n",
      "Validation loss improved from 1.6881 to 1.6608.\n",
      "[Epoch 30/1000] Train Loss: 1.6361  |  Val Loss: 1.6346\n",
      "Validation loss improved from 1.6608 to 1.6346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31/1000] Train Loss: 1.6085  |  Val Loss: 1.6087\n",
      "Validation loss improved from 1.6346 to 1.6087.\n",
      "[Epoch 32/1000] Train Loss: 1.5811  |  Val Loss: 1.5841\n",
      "Validation loss improved from 1.6087 to 1.5841.\n",
      "[Epoch 33/1000] Train Loss: 1.5544  |  Val Loss: 1.5585\n",
      "Validation loss improved from 1.5841 to 1.5585.\n",
      "[Epoch 34/1000] Train Loss: 1.5282  |  Val Loss: 1.5336\n",
      "Validation loss improved from 1.5585 to 1.5336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35/1000] Train Loss: 1.5016  |  Val Loss: 1.5090\n",
      "Validation loss improved from 1.5336 to 1.5090.\n",
      "[Epoch 36/1000] Train Loss: 1.4755  |  Val Loss: 1.4842\n",
      "Validation loss improved from 1.5090 to 1.4842.\n",
      "[Epoch 37/1000] Train Loss: 1.4495  |  Val Loss: 1.4595\n",
      "Validation loss improved from 1.4842 to 1.4595.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38/1000] Train Loss: 1.4234  |  Val Loss: 1.4357\n",
      "Validation loss improved from 1.4595 to 1.4357.\n",
      "[Epoch 39/1000] Train Loss: 1.3979  |  Val Loss: 1.4120\n",
      "Validation loss improved from 1.4357 to 1.4120.\n",
      "[Epoch 40/1000] Train Loss: 1.3728  |  Val Loss: 1.3876\n",
      "Validation loss improved from 1.4120 to 1.3876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41/1000] Train Loss: 1.3481  |  Val Loss: 1.3641\n",
      "Validation loss improved from 1.3876 to 1.3641.\n",
      "[Epoch 42/1000] Train Loss: 1.3227  |  Val Loss: 1.3421\n",
      "Validation loss improved from 1.3641 to 1.3421.\n",
      "[Epoch 43/1000] Train Loss: 1.2982  |  Val Loss: 1.3202\n",
      "Validation loss improved from 1.3421 to 1.3202.\n",
      "[Epoch 44/1000] Train Loss: 1.2738  |  Val Loss: 1.2978\n",
      "Validation loss improved from 1.3202 to 1.2978.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 45/1000] Train Loss: 1.2496  |  Val Loss: 1.2752\n",
      "Validation loss improved from 1.2978 to 1.2752.\n",
      "[Epoch 46/1000] Train Loss: 1.2251  |  Val Loss: 1.2538\n",
      "Validation loss improved from 1.2752 to 1.2538.\n",
      "[Epoch 47/1000] Train Loss: 1.2012  |  Val Loss: 1.2321\n",
      "Validation loss improved from 1.2538 to 1.2321.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 48/1000] Train Loss: 1.1777  |  Val Loss: 1.2105\n",
      "Validation loss improved from 1.2321 to 1.2105.\n",
      "[Epoch 49/1000] Train Loss: 1.1543  |  Val Loss: 1.1896\n",
      "Validation loss improved from 1.2105 to 1.1896.\n",
      "[Epoch 50/1000] Train Loss: 1.1308  |  Val Loss: 1.1689\n",
      "Validation loss improved from 1.1896 to 1.1689.\n",
      "[Epoch 51/1000] Train Loss: 1.1077  |  Val Loss: 1.1484\n",
      "Validation loss improved from 1.1689 to 1.1484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 52/1000] Train Loss: 1.0851  |  Val Loss: 1.1285\n",
      "Validation loss improved from 1.1484 to 1.1285.\n",
      "[Epoch 53/1000] Train Loss: 1.0625  |  Val Loss: 1.1088\n",
      "Validation loss improved from 1.1285 to 1.1088.\n",
      "[Epoch 54/1000] Train Loss: 1.0400  |  Val Loss: 1.0896\n",
      "Validation loss improved from 1.1088 to 1.0896.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 55/1000] Train Loss: 1.0181  |  Val Loss: 1.0704\n",
      "Validation loss improved from 1.0896 to 1.0704.\n",
      "[Epoch 56/1000] Train Loss: 0.9965  |  Val Loss: 1.0506\n",
      "Validation loss improved from 1.0704 to 1.0506.\n",
      "[Epoch 57/1000] Train Loss: 0.9747  |  Val Loss: 1.0321\n",
      "Validation loss improved from 1.0506 to 1.0321.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 58/1000] Train Loss: 0.9533  |  Val Loss: 1.0144\n",
      "Validation loss improved from 1.0321 to 1.0144.\n",
      "[Epoch 59/1000] Train Loss: 0.9324  |  Val Loss: 0.9958\n",
      "Validation loss improved from 1.0144 to 0.9958.\n",
      "[Epoch 60/1000] Train Loss: 0.9114  |  Val Loss: 0.9786\n",
      "Validation loss improved from 0.9958 to 0.9786.\n",
      "[Epoch 61/1000] Train Loss: 0.8907  |  Val Loss: 0.9611\n",
      "Validation loss improved from 0.9786 to 0.9611.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 62/1000] Train Loss: 0.8703  |  Val Loss: 0.9448\n",
      "Validation loss improved from 0.9611 to 0.9448.\n",
      "[Epoch 63/1000] Train Loss: 0.8502  |  Val Loss: 0.9276\n",
      "Validation loss improved from 0.9448 to 0.9276.\n",
      "[Epoch 64/1000] Train Loss: 0.8303  |  Val Loss: 0.9106\n",
      "Validation loss improved from 0.9276 to 0.9106.\n",
      "[Epoch 65/1000] Train Loss: 0.8103  |  Val Loss: 0.8946\n",
      "Validation loss improved from 0.9106 to 0.8946.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 66/1000] Train Loss: 0.7909  |  Val Loss: 0.8789\n",
      "Validation loss improved from 0.8946 to 0.8789.\n",
      "[Epoch 67/1000] Train Loss: 0.7717  |  Val Loss: 0.8629\n",
      "Validation loss improved from 0.8789 to 0.8629.\n",
      "[Epoch 68/1000] Train Loss: 0.7526  |  Val Loss: 0.8470\n",
      "Validation loss improved from 0.8629 to 0.8470.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 69/1000] Train Loss: 0.7340  |  Val Loss: 0.8309\n",
      "Validation loss improved from 0.8470 to 0.8309.\n",
      "[Epoch 70/1000] Train Loss: 0.7147  |  Val Loss: 0.8161\n",
      "Validation loss improved from 0.8309 to 0.8161.\n",
      "[Epoch 71/1000] Train Loss: 0.6963  |  Val Loss: 0.8007\n",
      "Validation loss improved from 0.8161 to 0.8007.\n",
      "[Epoch 72/1000] Train Loss: 0.6775  |  Val Loss: 0.7868\n",
      "Validation loss improved from 0.8007 to 0.7868.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 73/1000] Train Loss: 0.6598  |  Val Loss: 0.7717\n",
      "Validation loss improved from 0.7868 to 0.7717.\n",
      "[Epoch 74/1000] Train Loss: 0.6413  |  Val Loss: 0.7572\n",
      "Validation loss improved from 0.7717 to 0.7572.\n",
      "[Epoch 75/1000] Train Loss: 0.6233  |  Val Loss: 0.7428\n",
      "Validation loss improved from 0.7572 to 0.7428.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 76/1000] Train Loss: 0.6054  |  Val Loss: 0.7286\n",
      "Validation loss improved from 0.7428 to 0.7286.\n",
      "[Epoch 77/1000] Train Loss: 0.5880  |  Val Loss: 0.7147\n",
      "Validation loss improved from 0.7286 to 0.7147.\n",
      "[Epoch 78/1000] Train Loss: 0.5707  |  Val Loss: 0.7007\n",
      "Validation loss improved from 0.7147 to 0.7007.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 79/1000] Train Loss: 0.5530  |  Val Loss: 0.6868\n",
      "Validation loss improved from 0.7007 to 0.6868.\n",
      "[Epoch 80/1000] Train Loss: 0.5358  |  Val Loss: 0.6738\n",
      "Validation loss improved from 0.6868 to 0.6738.\n",
      "[Epoch 81/1000] Train Loss: 0.5193  |  Val Loss: 0.6607\n",
      "Validation loss improved from 0.6738 to 0.6607.\n",
      "[Epoch 82/1000] Train Loss: 0.5023  |  Val Loss: 0.6476\n",
      "Validation loss improved from 0.6607 to 0.6476.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 83/1000] Train Loss: 0.4862  |  Val Loss: 0.6339\n",
      "Validation loss improved from 0.6476 to 0.6339.\n",
      "[Epoch 84/1000] Train Loss: 0.4700  |  Val Loss: 0.6209\n",
      "Validation loss improved from 0.6339 to 0.6209.\n",
      "[Epoch 85/1000] Train Loss: 0.4542  |  Val Loss: 0.6086\n",
      "Validation loss improved from 0.6209 to 0.6086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 86/1000] Train Loss: 0.4387  |  Val Loss: 0.5958\n",
      "Validation loss improved from 0.6086 to 0.5958.\n",
      "[Epoch 87/1000] Train Loss: 0.4232  |  Val Loss: 0.5846\n",
      "Validation loss improved from 0.5958 to 0.5846.\n",
      "[Epoch 88/1000] Train Loss: 0.4083  |  Val Loss: 0.5722\n",
      "Validation loss improved from 0.5846 to 0.5722.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 89/1000] Train Loss: 0.3938  |  Val Loss: 0.5604\n",
      "Validation loss improved from 0.5722 to 0.5604.\n",
      "[Epoch 90/1000] Train Loss: 0.3802  |  Val Loss: 0.5490\n",
      "Validation loss improved from 0.5604 to 0.5490.\n",
      "[Epoch 91/1000] Train Loss: 0.3662  |  Val Loss: 0.5377\n",
      "Validation loss improved from 0.5490 to 0.5377.\n",
      "[Epoch 92/1000] Train Loss: 0.3528  |  Val Loss: 0.5273\n",
      "Validation loss improved from 0.5377 to 0.5273.\n",
      "[Epoch 93/1000] Train Loss: 0.3400  |  Val Loss: 0.5168\n",
      "Validation loss improved from 0.5273 to 0.5168.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 94/1000] Train Loss: 0.3276  |  Val Loss: 0.5061\n",
      "Validation loss improved from 0.5168 to 0.5061.\n",
      "[Epoch 95/1000] Train Loss: 0.3156  |  Val Loss: 0.4955\n",
      "Validation loss improved from 0.5061 to 0.4955.\n",
      "[Epoch 96/1000] Train Loss: 0.3039  |  Val Loss: 0.4862\n",
      "Validation loss improved from 0.4955 to 0.4862.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 97/1000] Train Loss: 0.2929  |  Val Loss: 0.4761\n",
      "Validation loss improved from 0.4862 to 0.4761.\n",
      "[Epoch 98/1000] Train Loss: 0.2818  |  Val Loss: 0.4669\n",
      "Validation loss improved from 0.4761 to 0.4669.\n",
      "[Epoch 99/1000] Train Loss: 0.2714  |  Val Loss: 0.4578\n",
      "Validation loss improved from 0.4669 to 0.4578.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 100/1000] Train Loss: 0.2615  |  Val Loss: 0.4493\n",
      "Validation loss improved from 0.4578 to 0.4493.\n",
      "[Epoch 101/1000] Train Loss: 0.2518  |  Val Loss: 0.4406\n",
      "Validation loss improved from 0.4493 to 0.4406.\n",
      "[Epoch 102/1000] Train Loss: 0.2427  |  Val Loss: 0.4325\n",
      "Validation loss improved from 0.4406 to 0.4325.\n",
      "[Epoch 103/1000] Train Loss: 0.2340  |  Val Loss: 0.4241\n",
      "Validation loss improved from 0.4325 to 0.4241.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 104/1000] Train Loss: 0.2254  |  Val Loss: 0.4167\n",
      "Validation loss improved from 0.4241 to 0.4167.\n",
      "[Epoch 105/1000] Train Loss: 0.2174  |  Val Loss: 0.4087\n",
      "Validation loss improved from 0.4167 to 0.4087.\n",
      "[Epoch 106/1000] Train Loss: 0.2095  |  Val Loss: 0.4019\n",
      "Validation loss improved from 0.4087 to 0.4019.\n",
      "[Epoch 107/1000] Train Loss: 0.2022  |  Val Loss: 0.3947\n",
      "Validation loss improved from 0.4019 to 0.3947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 108/1000] Train Loss: 0.1951  |  Val Loss: 0.3877\n",
      "Validation loss improved from 0.3947 to 0.3877.\n",
      "[Epoch 109/1000] Train Loss: 0.1883  |  Val Loss: 0.3808\n",
      "Validation loss improved from 0.3877 to 0.3808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 110/1000] Train Loss: 0.1820  |  Val Loss: 0.3746\n",
      "Validation loss improved from 0.3808 to 0.3746.\n",
      "[Epoch 111/1000] Train Loss: 0.1757  |  Val Loss: 0.3681\n",
      "Validation loss improved from 0.3746 to 0.3681.\n",
      "[Epoch 112/1000] Train Loss: 0.1697  |  Val Loss: 0.3622\n",
      "Validation loss improved from 0.3681 to 0.3622.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 113/1000] Train Loss: 0.1641  |  Val Loss: 0.3565\n",
      "Validation loss improved from 0.3622 to 0.3565.\n",
      "[Epoch 114/1000] Train Loss: 0.1588  |  Val Loss: 0.3503\n",
      "Validation loss improved from 0.3565 to 0.3503.\n",
      "[Epoch 115/1000] Train Loss: 0.1535  |  Val Loss: 0.3450\n",
      "Validation loss improved from 0.3503 to 0.3450.\n",
      "[Epoch 116/1000] Train Loss: 0.1487  |  Val Loss: 0.3397\n",
      "Validation loss improved from 0.3450 to 0.3397.\n",
      "[Epoch 117/1000] Train Loss: 0.1438  |  Val Loss: 0.3353\n",
      "Validation loss improved from 0.3397 to 0.3353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 118/1000] Train Loss: 0.1394  |  Val Loss: 0.3296\n",
      "Validation loss improved from 0.3353 to 0.3296.\n",
      "[Epoch 119/1000] Train Loss: 0.1351  |  Val Loss: 0.3251\n",
      "Validation loss improved from 0.3296 to 0.3251.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 120/1000] Train Loss: 0.1309  |  Val Loss: 0.3214\n",
      "Validation loss improved from 0.3251 to 0.3214.\n",
      "[Epoch 121/1000] Train Loss: 0.1270  |  Val Loss: 0.3164\n",
      "Validation loss improved from 0.3214 to 0.3164.\n",
      "[Epoch 122/1000] Train Loss: 0.1233  |  Val Loss: 0.3124\n",
      "Validation loss improved from 0.3164 to 0.3124.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 123/1000] Train Loss: 0.1196  |  Val Loss: 0.3081\n",
      "Validation loss improved from 0.3124 to 0.3081.\n",
      "[Epoch 124/1000] Train Loss: 0.1162  |  Val Loss: 0.3045\n",
      "Validation loss improved from 0.3081 to 0.3045.\n",
      "[Epoch 125/1000] Train Loss: 0.1129  |  Val Loss: 0.3002\n",
      "Validation loss improved from 0.3045 to 0.3002.\n",
      "[Epoch 126/1000] Train Loss: 0.1096  |  Val Loss: 0.2968\n",
      "Validation loss improved from 0.3002 to 0.2968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 127/1000] Train Loss: 0.1066  |  Val Loss: 0.2933\n",
      "Validation loss improved from 0.2968 to 0.2933.\n",
      "[Epoch 128/1000] Train Loss: 0.1037  |  Val Loss: 0.2897\n",
      "Validation loss improved from 0.2933 to 0.2897.\n",
      "[Epoch 129/1000] Train Loss: 0.1008  |  Val Loss: 0.2862\n",
      "Validation loss improved from 0.2897 to 0.2862.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 130/1000] Train Loss: 0.0981  |  Val Loss: 0.2832\n",
      "Validation loss improved from 0.2862 to 0.2832.\n",
      "[Epoch 131/1000] Train Loss: 0.0956  |  Val Loss: 0.2804\n",
      "Validation loss improved from 0.2832 to 0.2804.\n",
      "[Epoch 132/1000] Train Loss: 0.0931  |  Val Loss: 0.2770\n",
      "Validation loss improved from 0.2804 to 0.2770.\n",
      "[Epoch 133/1000] Train Loss: 0.0907  |  Val Loss: 0.2744\n",
      "Validation loss improved from 0.2770 to 0.2744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 134/1000] Train Loss: 0.0883  |  Val Loss: 0.2716\n",
      "Validation loss improved from 0.2744 to 0.2716.\n",
      "[Epoch 135/1000] Train Loss: 0.0861  |  Val Loss: 0.2688\n",
      "Validation loss improved from 0.2716 to 0.2688.\n",
      "[Epoch 136/1000] Train Loss: 0.0840  |  Val Loss: 0.2660\n",
      "Validation loss improved from 0.2688 to 0.2660.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 137/1000] Train Loss: 0.0819  |  Val Loss: 0.2637\n",
      "Validation loss improved from 0.2660 to 0.2637.\n",
      "[Epoch 138/1000] Train Loss: 0.0801  |  Val Loss: 0.2611\n",
      "Validation loss improved from 0.2637 to 0.2611.\n",
      "[Epoch 139/1000] Train Loss: 0.0781  |  Val Loss: 0.2588\n",
      "Validation loss improved from 0.2611 to 0.2588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 140/1000] Train Loss: 0.0762  |  Val Loss: 0.2562\n",
      "Validation loss improved from 0.2588 to 0.2562.\n",
      "[Epoch 141/1000] Train Loss: 0.0744  |  Val Loss: 0.2539\n",
      "Validation loss improved from 0.2562 to 0.2539.\n",
      "[Epoch 142/1000] Train Loss: 0.0728  |  Val Loss: 0.2520\n",
      "Validation loss improved from 0.2539 to 0.2520.\n",
      "[Epoch 143/1000] Train Loss: 0.0711  |  Val Loss: 0.2496\n",
      "Validation loss improved from 0.2520 to 0.2496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 144/1000] Train Loss: 0.0695  |  Val Loss: 0.2476\n",
      "Validation loss improved from 0.2496 to 0.2476.\n",
      "[Epoch 145/1000] Train Loss: 0.0679  |  Val Loss: 0.2452\n",
      "Validation loss improved from 0.2476 to 0.2452.\n",
      "[Epoch 146/1000] Train Loss: 0.0664  |  Val Loss: 0.2432\n",
      "Validation loss improved from 0.2452 to 0.2432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 147/1000] Train Loss: 0.0650  |  Val Loss: 0.2413\n",
      "Validation loss improved from 0.2432 to 0.2413.\n",
      "[Epoch 148/1000] Train Loss: 0.0636  |  Val Loss: 0.2393\n",
      "Validation loss improved from 0.2413 to 0.2393.\n",
      "[Epoch 149/1000] Train Loss: 0.0623  |  Val Loss: 0.2379\n",
      "Validation loss improved from 0.2393 to 0.2379.\n",
      "[Epoch 150/1000] Train Loss: 0.0609  |  Val Loss: 0.2363\n",
      "Validation loss improved from 0.2379 to 0.2363.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 151/1000] Train Loss: 0.0598  |  Val Loss: 0.2342\n",
      "Validation loss improved from 0.2363 to 0.2342.\n",
      "[Epoch 152/1000] Train Loss: 0.0585  |  Val Loss: 0.2324\n",
      "Validation loss improved from 0.2342 to 0.2324.\n",
      "[Epoch 153/1000] Train Loss: 0.0573  |  Val Loss: 0.2308\n",
      "Validation loss improved from 0.2324 to 0.2308.\n",
      "[Epoch 154/1000] Train Loss: 0.0562  |  Val Loss: 0.2293\n",
      "Validation loss improved from 0.2308 to 0.2293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 155/1000] Train Loss: 0.0550  |  Val Loss: 0.2276\n",
      "Validation loss improved from 0.2293 to 0.2276.\n",
      "[Epoch 156/1000] Train Loss: 0.0540  |  Val Loss: 0.2266\n",
      "Validation loss improved from 0.2276 to 0.2266.\n",
      "[Epoch 157/1000] Train Loss: 0.0529  |  Val Loss: 0.2251\n",
      "Validation loss improved from 0.2266 to 0.2251.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 158/1000] Train Loss: 0.0519  |  Val Loss: 0.2236\n",
      "Validation loss improved from 0.2251 to 0.2236.\n",
      "[Epoch 159/1000] Train Loss: 0.0509  |  Val Loss: 0.2223\n",
      "Validation loss improved from 0.2236 to 0.2223.\n",
      "[Epoch 160/1000] Train Loss: 0.0500  |  Val Loss: 0.2209\n",
      "Validation loss improved from 0.2223 to 0.2209.\n",
      "[Epoch 161/1000] Train Loss: 0.0491  |  Val Loss: 0.2194\n",
      "Validation loss improved from 0.2209 to 0.2194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 162/1000] Train Loss: 0.0482  |  Val Loss: 0.2183\n",
      "Validation loss improved from 0.2194 to 0.2183.\n",
      "[Epoch 163/1000] Train Loss: 0.0473  |  Val Loss: 0.2174\n",
      "Validation loss improved from 0.2183 to 0.2174.\n",
      "[Epoch 164/1000] Train Loss: 0.0464  |  Val Loss: 0.2162\n",
      "Validation loss improved from 0.2174 to 0.2162.\n",
      "[Epoch 165/1000] Train Loss: 0.0456  |  Val Loss: 0.2149\n",
      "Validation loss improved from 0.2162 to 0.2149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 166/1000] Train Loss: 0.0448  |  Val Loss: 0.2137\n",
      "Validation loss improved from 0.2149 to 0.2137.\n",
      "[Epoch 167/1000] Train Loss: 0.0440  |  Val Loss: 0.2127\n",
      "Validation loss improved from 0.2137 to 0.2127.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 168/1000] Train Loss: 0.0432  |  Val Loss: 0.2111\n",
      "Validation loss improved from 0.2127 to 0.2111.\n",
      "[Epoch 169/1000] Train Loss: 0.0424  |  Val Loss: 0.2103\n",
      "Validation loss improved from 0.2111 to 0.2103.\n",
      "[Epoch 170/1000] Train Loss: 0.0416  |  Val Loss: 0.2087\n",
      "Validation loss improved from 0.2103 to 0.2087.\n",
      "[Epoch 171/1000] Train Loss: 0.0408  |  Val Loss: 0.2078\n",
      "Validation loss improved from 0.2087 to 0.2078.\n",
      "[Epoch 172/1000] Train Loss: 0.0401  |  Val Loss: 0.2074\n",
      "Validation loss improved from 0.2078 to 0.2074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 173/1000] Train Loss: 0.0394  |  Val Loss: 0.2063\n",
      "Validation loss improved from 0.2074 to 0.2063.\n",
      "[Epoch 174/1000] Train Loss: 0.0387  |  Val Loss: 0.2054\n",
      "Validation loss improved from 0.2063 to 0.2054.\n",
      "[Epoch 175/1000] Train Loss: 0.0381  |  Val Loss: 0.2045\n",
      "Validation loss improved from 0.2054 to 0.2045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 176/1000] Train Loss: 0.0374  |  Val Loss: 0.2035\n",
      "Validation loss improved from 0.2045 to 0.2035.\n",
      "[Epoch 177/1000] Train Loss: 0.0368  |  Val Loss: 0.2024\n",
      "Validation loss improved from 0.2035 to 0.2024.\n",
      "[Epoch 178/1000] Train Loss: 0.0362  |  Val Loss: 0.2016\n",
      "Validation loss improved from 0.2024 to 0.2016.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 179/1000] Train Loss: 0.0356  |  Val Loss: 0.2011\n",
      "Validation loss improved from 0.2016 to 0.2011.\n",
      "[Epoch 180/1000] Train Loss: 0.0350  |  Val Loss: 0.2003\n",
      "Validation loss improved from 0.2011 to 0.2003.\n",
      "[Epoch 181/1000] Train Loss: 0.0344  |  Val Loss: 0.1998\n",
      "Validation loss improved from 0.2003 to 0.1998.\n",
      "[Epoch 182/1000] Train Loss: 0.0338  |  Val Loss: 0.1991\n",
      "Validation loss improved from 0.1998 to 0.1991.\n",
      "[Epoch 183/1000] Train Loss: 0.0333  |  Val Loss: 0.1984\n",
      "Validation loss improved from 0.1991 to 0.1984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 184/1000] Train Loss: 0.0328  |  Val Loss: 0.1975\n",
      "Validation loss improved from 0.1984 to 0.1975.\n",
      "[Epoch 185/1000] Train Loss: 0.0323  |  Val Loss: 0.1968\n",
      "Validation loss improved from 0.1975 to 0.1968.\n",
      "[Epoch 186/1000] Train Loss: 0.0318  |  Val Loss: 0.1962\n",
      "Validation loss improved from 0.1968 to 0.1962.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 187/1000] Train Loss: 0.0313  |  Val Loss: 0.1956\n",
      "Validation loss improved from 0.1962 to 0.1956.\n",
      "[Epoch 188/1000] Train Loss: 0.0309  |  Val Loss: 0.1949\n",
      "Validation loss improved from 0.1956 to 0.1949.\n",
      "[Epoch 189/1000] Train Loss: 0.0304  |  Val Loss: 0.1942\n",
      "Validation loss improved from 0.1949 to 0.1942.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 190/1000] Train Loss: 0.0299  |  Val Loss: 0.1935\n",
      "Validation loss improved from 0.1942 to 0.1935.\n",
      "[Epoch 191/1000] Train Loss: 0.0295  |  Val Loss: 0.1930\n",
      "Validation loss improved from 0.1935 to 0.1930.\n",
      "[Epoch 192/1000] Train Loss: 0.0291  |  Val Loss: 0.1922\n",
      "Validation loss improved from 0.1930 to 0.1922.\n",
      "[Epoch 193/1000] Train Loss: 0.0287  |  Val Loss: 0.1925\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 194/1000] Train Loss: 0.0283  |  Val Loss: 0.1914\n",
      "Validation loss improved from 0.1922 to 0.1914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 195/1000] Train Loss: 0.0278  |  Val Loss: 0.1911\n",
      "Validation loss improved from 0.1914 to 0.1911.\n",
      "[Epoch 196/1000] Train Loss: 0.0274  |  Val Loss: 0.1906\n",
      "Validation loss improved from 0.1911 to 0.1906.\n",
      "[Epoch 197/1000] Train Loss: 0.0271  |  Val Loss: 0.1898\n",
      "Validation loss improved from 0.1906 to 0.1898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 198/1000] Train Loss: 0.0267  |  Val Loss: 0.1897\n",
      "Validation loss improved from 0.1898 to 0.1897.\n",
      "[Epoch 199/1000] Train Loss: 0.0263  |  Val Loss: 0.1890\n",
      "Validation loss improved from 0.1897 to 0.1890.\n",
      "[Epoch 200/1000] Train Loss: 0.0260  |  Val Loss: 0.1885\n",
      "Validation loss improved from 0.1890 to 0.1885.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 201/1000] Train Loss: 0.0256  |  Val Loss: 0.1879\n",
      "Validation loss improved from 0.1885 to 0.1879.\n",
      "[Epoch 202/1000] Train Loss: 0.0253  |  Val Loss: 0.1875\n",
      "Validation loss improved from 0.1879 to 0.1875.\n",
      "[Epoch 203/1000] Train Loss: 0.0250  |  Val Loss: 0.1872\n",
      "Validation loss improved from 0.1875 to 0.1872.\n",
      "[Epoch 204/1000] Train Loss: 0.0246  |  Val Loss: 0.1868\n",
      "Validation loss improved from 0.1872 to 0.1868.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 205/1000] Train Loss: 0.0243  |  Val Loss: 0.1864\n",
      "Validation loss improved from 0.1868 to 0.1864.\n",
      "[Epoch 206/1000] Train Loss: 0.0240  |  Val Loss: 0.1857\n",
      "Validation loss improved from 0.1864 to 0.1857.\n",
      "[Epoch 207/1000] Train Loss: 0.0237  |  Val Loss: 0.1855\n",
      "Validation loss improved from 0.1857 to 0.1855.\n",
      "[Epoch 208/1000] Train Loss: 0.0234  |  Val Loss: 0.1852\n",
      "Validation loss improved from 0.1855 to 0.1852.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 209/1000] Train Loss: 0.0231  |  Val Loss: 0.1848\n",
      "Validation loss improved from 0.1852 to 0.1848.\n",
      "[Epoch 210/1000] Train Loss: 0.0228  |  Val Loss: 0.1842\n",
      "Validation loss improved from 0.1848 to 0.1842.\n",
      "[Epoch 211/1000] Train Loss: 0.0225  |  Val Loss: 0.1841\n",
      "Validation loss improved from 0.1842 to 0.1841.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 212/1000] Train Loss: 0.0223  |  Val Loss: 0.1837\n",
      "Validation loss improved from 0.1841 to 0.1837.\n",
      "[Epoch 213/1000] Train Loss: 0.0220  |  Val Loss: 0.1829\n",
      "Validation loss improved from 0.1837 to 0.1829.\n",
      "[Epoch 214/1000] Train Loss: 0.0217  |  Val Loss: 0.1828\n",
      "Validation loss improved from 0.1829 to 0.1828.\n",
      "[Epoch 215/1000] Train Loss: 0.0215  |  Val Loss: 0.1823\n",
      "Validation loss improved from 0.1828 to 0.1823.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 216/1000] Train Loss: 0.0212  |  Val Loss: 0.1820\n",
      "Validation loss improved from 0.1823 to 0.1820.\n",
      "[Epoch 217/1000] Train Loss: 0.0210  |  Val Loss: 0.1819\n",
      "Validation loss improved from 0.1820 to 0.1819.\n",
      "[Epoch 218/1000] Train Loss: 0.0207  |  Val Loss: 0.1818\n",
      "Validation loss improved from 0.1819 to 0.1818.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 219/1000] Train Loss: 0.0205  |  Val Loss: 0.1811\n",
      "Validation loss improved from 0.1818 to 0.1811.\n",
      "[Epoch 220/1000] Train Loss: 0.0203  |  Val Loss: 0.1810\n",
      "Validation loss improved from 0.1811 to 0.1810.\n",
      "[Epoch 221/1000] Train Loss: 0.0200  |  Val Loss: 0.1801\n",
      "Validation loss improved from 0.1810 to 0.1801.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 222/1000] Train Loss: 0.0198  |  Val Loss: 0.1798\n",
      "Validation loss improved from 0.1801 to 0.1798.\n",
      "[Epoch 223/1000] Train Loss: 0.0196  |  Val Loss: 0.1798\n",
      "Validation loss improved from 0.1798 to 0.1798.\n",
      "[Epoch 224/1000] Train Loss: 0.0193  |  Val Loss: 0.1797\n",
      "Validation loss improved from 0.1798 to 0.1797.\n",
      "[Epoch 225/1000] Train Loss: 0.0191  |  Val Loss: 0.1794\n",
      "Validation loss improved from 0.1797 to 0.1794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 226/1000] Train Loss: 0.0189  |  Val Loss: 0.1789\n",
      "Validation loss improved from 0.1794 to 0.1789.\n",
      "[Epoch 227/1000] Train Loss: 0.0187  |  Val Loss: 0.1788\n",
      "Validation loss improved from 0.1789 to 0.1788.\n",
      "[Epoch 228/1000] Train Loss: 0.0185  |  Val Loss: 0.1782\n",
      "Validation loss improved from 0.1788 to 0.1782.\n",
      "[Epoch 229/1000] Train Loss: 0.0183  |  Val Loss: 0.1782\n",
      "Validation loss improved from 0.1782 to 0.1782.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 230/1000] Train Loss: 0.0181  |  Val Loss: 0.1781\n",
      "Validation loss improved from 0.1782 to 0.1781.\n",
      "[Epoch 231/1000] Train Loss: 0.0179  |  Val Loss: 0.1774\n",
      "Validation loss improved from 0.1781 to 0.1774.\n",
      "[Epoch 232/1000] Train Loss: 0.0177  |  Val Loss: 0.1776\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 233/1000] Train Loss: 0.0175  |  Val Loss: 0.1773\n",
      "Validation loss improved from 0.1774 to 0.1773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 234/1000] Train Loss: 0.0173  |  Val Loss: 0.1769\n",
      "Validation loss improved from 0.1773 to 0.1769.\n",
      "[Epoch 235/1000] Train Loss: 0.0171  |  Val Loss: 0.1764\n",
      "Validation loss improved from 0.1769 to 0.1764.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 236/1000] Train Loss: 0.0170  |  Val Loss: 0.1761\n",
      "Validation loss improved from 0.1764 to 0.1761.\n",
      "[Epoch 237/1000] Train Loss: 0.0168  |  Val Loss: 0.1761\n",
      "Validation loss improved from 0.1761 to 0.1761.\n",
      "[Epoch 238/1000] Train Loss: 0.0166  |  Val Loss: 0.1762\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 239/1000] Train Loss: 0.0164  |  Val Loss: 0.1757\n",
      "Validation loss improved from 0.1761 to 0.1757.\n",
      "[Epoch 240/1000] Train Loss: 0.0163  |  Val Loss: 0.1758\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 241/1000] Train Loss: 0.0161  |  Val Loss: 0.1754\n",
      "Validation loss improved from 0.1757 to 0.1754.\n",
      "[Epoch 242/1000] Train Loss: 0.0160  |  Val Loss: 0.1756\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 243/1000] Train Loss: 0.0158  |  Val Loss: 0.1751\n",
      "Validation loss improved from 0.1754 to 0.1751.\n",
      "[Epoch 244/1000] Train Loss: 0.0157  |  Val Loss: 0.1749\n",
      "Validation loss improved from 0.1751 to 0.1749.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 245/1000] Train Loss: 0.0156  |  Val Loss: 0.1751\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 246/1000] Train Loss: 0.0153  |  Val Loss: 0.1746\n",
      "Validation loss improved from 0.1749 to 0.1746.\n",
      "[Epoch 247/1000] Train Loss: 0.0152  |  Val Loss: 0.1744\n",
      "Validation loss improved from 0.1746 to 0.1744.\n",
      "[Epoch 248/1000] Train Loss: 0.0150  |  Val Loss: 0.1740\n",
      "Validation loss improved from 0.1744 to 0.1740.\n",
      "[Epoch 249/1000] Train Loss: 0.0149  |  Val Loss: 0.1737\n",
      "Validation loss improved from 0.1740 to 0.1737.\n",
      "[Epoch 250/1000] Train Loss: 0.0147  |  Val Loss: 0.1737\n",
      "Validation loss improved from 0.1737 to 0.1737.\n",
      "[Epoch 251/1000] Train Loss: 0.0146  |  Val Loss: 0.1735\n",
      "Validation loss improved from 0.1737 to 0.1735.\n",
      "[Epoch 252/1000] Train Loss: 0.0145  |  Val Loss: 0.1736\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 253/1000] Train Loss: 0.0143  |  Val Loss: 0.1734\n",
      "Validation loss improved from 0.1735 to 0.1734.\n",
      "[Epoch 254/1000] Train Loss: 0.0142  |  Val Loss: 0.1734\n",
      "Validation loss improved from 0.1734 to 0.1734.\n",
      "[Epoch 255/1000] Train Loss: 0.0141  |  Val Loss: 0.1737\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 256/1000] Train Loss: 0.0140  |  Val Loss: 0.1731\n",
      "Validation loss improved from 0.1734 to 0.1731.\n",
      "[Epoch 257/1000] Train Loss: 0.0138  |  Val Loss: 0.1725\n",
      "Validation loss improved from 0.1731 to 0.1725.\n",
      "[Epoch 258/1000] Train Loss: 0.0137  |  Val Loss: 0.1725\n",
      "Validation loss improved from 0.1725 to 0.1725.\n",
      "[Epoch 259/1000] Train Loss: 0.0136  |  Val Loss: 0.1726\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 260/1000] Train Loss: 0.0134  |  Val Loss: 0.1720\n",
      "Validation loss improved from 0.1725 to 0.1720.\n",
      "[Epoch 261/1000] Train Loss: 0.0134  |  Val Loss: 0.1718\n",
      "Validation loss improved from 0.1720 to 0.1718.\n",
      "[Epoch 262/1000] Train Loss: 0.0132  |  Val Loss: 0.1718\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 263/1000] Train Loss: 0.0131  |  Val Loss: 0.1720\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 264/1000] Train Loss: 0.0129  |  Val Loss: 0.1721\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 265/1000] Train Loss: 0.0129  |  Val Loss: 0.1722\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 266/1000] Train Loss: 0.0127  |  Val Loss: 0.1721\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 267/1000] Train Loss: 0.0126  |  Val Loss: 0.1717\n",
      "Validation loss improved from 0.1718 to 0.1717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 268/1000] Train Loss: 0.0125  |  Val Loss: 0.1713\n",
      "Validation loss improved from 0.1717 to 0.1713.\n",
      "[Epoch 269/1000] Train Loss: 0.0124  |  Val Loss: 0.1713\n",
      "Validation loss improved from 0.1713 to 0.1713.\n",
      "[Epoch 270/1000] Train Loss: 0.0123  |  Val Loss: 0.1711\n",
      "Validation loss improved from 0.1713 to 0.1711.\n",
      "[Epoch 271/1000] Train Loss: 0.0122  |  Val Loss: 0.1713\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 272/1000] Train Loss: 0.0121  |  Val Loss: 0.1705\n",
      "Validation loss improved from 0.1711 to 0.1705.\n",
      "[Epoch 273/1000] Train Loss: 0.0120  |  Val Loss: 0.1707\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 274/1000] Train Loss: 0.0119  |  Val Loss: 0.1702\n",
      "Validation loss improved from 0.1705 to 0.1702.\n",
      "[Epoch 275/1000] Train Loss: 0.0118  |  Val Loss: 0.1703\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 276/1000] Train Loss: 0.0117  |  Val Loss: 0.1706\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 277/1000] Train Loss: 0.0116  |  Val Loss: 0.1703\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 278/1000] Train Loss: 0.0115  |  Val Loss: 0.1705\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 279/1000] Train Loss: 0.0114  |  Val Loss: 0.1708\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 280/1000] Train Loss: 0.0113  |  Val Loss: 0.1699\n",
      "Validation loss improved from 0.1702 to 0.1699.\n",
      "[Epoch 281/1000] Train Loss: 0.0112  |  Val Loss: 0.1698\n",
      "Validation loss improved from 0.1699 to 0.1698.\n",
      "[Epoch 282/1000] Train Loss: 0.0111  |  Val Loss: 0.1701\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 283/1000] Train Loss: 0.0110  |  Val Loss: 0.1697\n",
      "Validation loss improved from 0.1698 to 0.1697.\n",
      "[Epoch 284/1000] Train Loss: 0.0109  |  Val Loss: 0.1696\n",
      "Validation loss improved from 0.1697 to 0.1696.\n",
      "[Epoch 285/1000] Train Loss: 0.0108  |  Val Loss: 0.1698\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 286/1000] Train Loss: 0.0107  |  Val Loss: 0.1697\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 287/1000] Train Loss: 0.0107  |  Val Loss: 0.1696\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 288/1000] Train Loss: 0.0106  |  Val Loss: 0.1695\n",
      "Validation loss improved from 0.1696 to 0.1695.\n",
      "[Epoch 289/1000] Train Loss: 0.0105  |  Val Loss: 0.1697\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 290/1000] Train Loss: 0.0104  |  Val Loss: 0.1695\n",
      "Validation loss improved from 0.1695 to 0.1695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 291/1000] Train Loss: 0.0103  |  Val Loss: 0.1693\n",
      "Validation loss improved from 0.1695 to 0.1693.\n",
      "[Epoch 292/1000] Train Loss: 0.0102  |  Val Loss: 0.1695\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 293/1000] Train Loss: 0.0102  |  Val Loss: 0.1690\n",
      "Validation loss improved from 0.1693 to 0.1690.\n",
      "[Epoch 294/1000] Train Loss: 0.0101  |  Val Loss: 0.1686\n",
      "Validation loss improved from 0.1690 to 0.1686.\n",
      "[Epoch 295/1000] Train Loss: 0.0100  |  Val Loss: 0.1689\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 296/1000] Train Loss: 0.0099  |  Val Loss: 0.1696\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 297/1000] Train Loss: 0.0098  |  Val Loss: 0.1691\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 298/1000] Train Loss: 0.0098  |  Val Loss: 0.1690\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 299/1000] Train Loss: 0.0097  |  Val Loss: 0.1691\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 300/1000] Train Loss: 0.0096  |  Val Loss: 0.1691\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 301/1000] Train Loss: 0.0096  |  Val Loss: 0.1696\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 302/1000] Train Loss: 0.0095  |  Val Loss: 0.1691\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 303/1000] Train Loss: 0.0095  |  Val Loss: 0.1689\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 304/1000] Train Loss: 0.0093  |  Val Loss: 0.1686\n",
      "Validation loss improved from 0.1686 to 0.1686.\n",
      "[Epoch 305/1000] Train Loss: 0.0092  |  Val Loss: 0.1684\n",
      "Validation loss improved from 0.1686 to 0.1684.\n",
      "[Epoch 306/1000] Train Loss: 0.0092  |  Val Loss: 0.1681\n",
      "Validation loss improved from 0.1684 to 0.1681.\n",
      "[Epoch 307/1000] Train Loss: 0.0091  |  Val Loss: 0.1684\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 308/1000] Train Loss: 0.0091  |  Val Loss: 0.1686\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 309/1000] Train Loss: 0.0090  |  Val Loss: 0.1689\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 310/1000] Train Loss: 0.0090  |  Val Loss: 0.1690\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 311/1000] Train Loss: 0.0089  |  Val Loss: 0.1689\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 312/1000] Train Loss: 0.0088  |  Val Loss: 0.1684\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 313/1000] Train Loss: 0.0087  |  Val Loss: 0.1683\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 314/1000] Train Loss: 0.0086  |  Val Loss: 0.1682\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 315/1000] Train Loss: 0.0087  |  Val Loss: 0.1688\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 316/1000] Train Loss: 0.0085  |  Val Loss: 0.1688\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 317/1000] Train Loss: 0.0085  |  Val Loss: 0.1684\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 318/1000] Train Loss: 0.0084  |  Val Loss: 0.1682\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 319/1000] Train Loss: 0.0084  |  Val Loss: 0.1686\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 320/1000] Train Loss: 0.0083  |  Val Loss: 0.1684\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 321/1000] Train Loss: 0.0082  |  Val Loss: 0.1685\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 322/1000] Train Loss: 0.0081  |  Val Loss: 0.1685\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 323/1000] Train Loss: 0.0082  |  Val Loss: 0.1689\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 324/1000] Train Loss: 0.0081  |  Val Loss: 0.1685\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 325/1000] Train Loss: 0.0080  |  Val Loss: 0.1683\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 326/1000] Train Loss: 0.0080  |  Val Loss: 0.1683\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 327/1000] Train Loss: 0.0079  |  Val Loss: 0.1683\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 328/1000] Train Loss: 0.0079  |  Val Loss: 0.1686\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 329/1000] Train Loss: 0.0078  |  Val Loss: 0.1691\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 330/1000] Train Loss: 0.0077  |  Val Loss: 0.1687\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 331/1000] Train Loss: 0.0076  |  Val Loss: 0.1680\n",
      "Validation loss improved from 0.1681 to 0.1680.\n",
      "[Epoch 332/1000] Train Loss: 0.0076  |  Val Loss: 0.1680\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 333/1000] Train Loss: 0.0076  |  Val Loss: 0.1686\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 334/1000] Train Loss: 0.0075  |  Val Loss: 0.1682\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 335/1000] Train Loss: 0.0074  |  Val Loss: 0.1683\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 336/1000] Train Loss: 0.0074  |  Val Loss: 0.1678\n",
      "Validation loss improved from 0.1680 to 0.1678.\n",
      "[Epoch 337/1000] Train Loss: 0.0073  |  Val Loss: 0.1677\n",
      "Validation loss improved from 0.1678 to 0.1677.\n",
      "[Epoch 338/1000] Train Loss: 0.0073  |  Val Loss: 0.1677\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 339/1000] Train Loss: 0.0072  |  Val Loss: 0.1680\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 340/1000] Train Loss: 0.0072  |  Val Loss: 0.1687\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 341/1000] Train Loss: 0.0071  |  Val Loss: 0.1687\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 342/1000] Train Loss: 0.0071  |  Val Loss: 0.1680\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 343/1000] Train Loss: 0.0071  |  Val Loss: 0.1683\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 344/1000] Train Loss: 0.0070  |  Val Loss: 0.1686\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 345/1000] Train Loss: 0.0070  |  Val Loss: 0.1687\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 346/1000] Train Loss: 0.0069  |  Val Loss: 0.1682\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 347/1000] Train Loss: 0.0069  |  Val Loss: 0.1682\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 348/1000] Train Loss: 0.0068  |  Val Loss: 0.1687\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 349/1000] Train Loss: 0.0068  |  Val Loss: 0.1686\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 350/1000] Train Loss: 0.0067  |  Val Loss: 0.1686\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 351/1000] Train Loss: 0.0067  |  Val Loss: 0.1682\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 352/1000] Train Loss: 0.0067  |  Val Loss: 0.1688\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 353/1000] Train Loss: 0.0066  |  Val Loss: 0.1690\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 354/1000] Train Loss: 0.0066  |  Val Loss: 0.1689\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 355/1000] Train Loss: 0.0065  |  Val Loss: 0.1686\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 356/1000] Train Loss: 0.0065  |  Val Loss: 0.1688\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 357/1000] Train Loss: 0.0064  |  Val Loss: 0.1684\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 358/1000] Train Loss: 0.0064  |  Val Loss: 0.1683\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 359/1000] Train Loss: 0.0063  |  Val Loss: 0.1685\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 360/1000] Train Loss: 0.0063  |  Val Loss: 0.1687\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 361/1000] Train Loss: 0.0063  |  Val Loss: 0.1690\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 362/1000] Train Loss: 0.0062  |  Val Loss: 0.1689\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 363/1000] Train Loss: 0.0062  |  Val Loss: 0.1692\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 364/1000] Train Loss: 0.0062  |  Val Loss: 0.1689\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 365/1000] Train Loss: 0.0061  |  Val Loss: 0.1691\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 366/1000] Train Loss: 0.0061  |  Val Loss: 0.1693\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 367/1000] Train Loss: 0.0060  |  Val Loss: 0.1691\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 368/1000] Train Loss: 0.0060  |  Val Loss: 0.1687\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 369/1000] Train Loss: 0.0060  |  Val Loss: 0.1690\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 370/1000] Train Loss: 0.0060  |  Val Loss: 0.1691\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 371/1000] Train Loss: 0.0059  |  Val Loss: 0.1692\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 372/1000] Train Loss: 0.0059  |  Val Loss: 0.1689\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 373/1000] Train Loss: 0.0059  |  Val Loss: 0.1693\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 374/1000] Train Loss: 0.0058  |  Val Loss: 0.1692\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 375/1000] Train Loss: 0.0057  |  Val Loss: 0.1689\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 376/1000] Train Loss: 0.0057  |  Val Loss: 0.1690\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 377/1000] Train Loss: 0.0057  |  Val Loss: 0.1695\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 378/1000] Train Loss: 0.0056  |  Val Loss: 0.1689\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 379/1000] Train Loss: 0.0056  |  Val Loss: 0.1688\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 380/1000] Train Loss: 0.0056  |  Val Loss: 0.1689\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 381/1000] Train Loss: 0.0055  |  Val Loss: 0.1688\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 382/1000] Train Loss: 0.0055  |  Val Loss: 0.1694\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 383/1000] Train Loss: 0.0055  |  Val Loss: 0.1690\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 384/1000] Train Loss: 0.0054  |  Val Loss: 0.1688\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 385/1000] Train Loss: 0.0054  |  Val Loss: 0.1689\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 386/1000] Train Loss: 0.0054  |  Val Loss: 0.1695\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 387/1000] Train Loss: 0.0053  |  Val Loss: 0.1693\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 388/1000] Train Loss: 0.0053  |  Val Loss: 0.1695\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 389/1000] Train Loss: 0.0053  |  Val Loss: 0.1697\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 390/1000] Train Loss: 0.0052  |  Val Loss: 0.1692\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 391/1000] Train Loss: 0.0052  |  Val Loss: 0.1694\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 392/1000] Train Loss: 0.0052  |  Val Loss: 0.1697\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 393/1000] Train Loss: 0.0051  |  Val Loss: 0.1697\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 394/1000] Train Loss: 0.0051  |  Val Loss: 0.1701\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 395/1000] Train Loss: 0.0051  |  Val Loss: 0.1703\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 396/1000] Train Loss: 0.0051  |  Val Loss: 0.1694\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 397/1000] Train Loss: 0.0050  |  Val Loss: 0.1692\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 398/1000] Train Loss: 0.0050  |  Val Loss: 0.1692\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 399/1000] Train Loss: 0.0050  |  Val Loss: 0.1693\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 400/1000] Train Loss: 0.0049  |  Val Loss: 0.1695\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 401/1000] Train Loss: 0.0049  |  Val Loss: 0.1699\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 402/1000] Train Loss: 0.0049  |  Val Loss: 0.1700\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 403/1000] Train Loss: 0.0048  |  Val Loss: 0.1704\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 404/1000] Train Loss: 0.0048  |  Val Loss: 0.1701\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 405/1000] Train Loss: 0.0048  |  Val Loss: 0.1704\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 406/1000] Train Loss: 0.0047  |  Val Loss: 0.1701\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 407/1000] Train Loss: 0.0047  |  Val Loss: 0.1701\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 408/1000] Train Loss: 0.0047  |  Val Loss: 0.1702\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 409/1000] Train Loss: 0.0047  |  Val Loss: 0.1702\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 410/1000] Train Loss: 0.0047  |  Val Loss: 0.1701\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 411/1000] Train Loss: 0.0047  |  Val Loss: 0.1706\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 412/1000] Train Loss: 0.0046  |  Val Loss: 0.1704\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 413/1000] Train Loss: 0.0046  |  Val Loss: 0.1709\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "[Epoch 414/1000] Train Loss: 0.0045  |  Val Loss: 0.1708\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "[Epoch 415/1000] Train Loss: 0.0045  |  Val Loss: 0.1704\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 416/1000] Train Loss: 0.0045  |  Val Loss: 0.1706\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 417/1000] Train Loss: 0.0045  |  Val Loss: 0.1708\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 418/1000] Train Loss: 0.0044  |  Val Loss: 0.1709\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 419/1000] Train Loss: 0.0044  |  Val Loss: 0.1707\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 420/1000] Train Loss: 0.0044  |  Val Loss: 0.1710\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 421/1000] Train Loss: 0.0043  |  Val Loss: 0.1709\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "[Epoch 422/1000] Train Loss: 0.0044  |  Val Loss: 0.1706\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 423/1000] Train Loss: 0.0043  |  Val Loss: 0.1714\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 424/1000] Train Loss: 0.0043  |  Val Loss: 0.1713\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "[Epoch 425/1000] Train Loss: 0.0043  |  Val Loss: 0.1708\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 426/1000] Train Loss: 0.0042  |  Val Loss: 0.1711\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 427/1000] Train Loss: 0.0042  |  Val Loss: 0.1711\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 428/1000] Train Loss: 0.0042  |  Val Loss: 0.1712\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 429/1000] Train Loss: 0.0042  |  Val Loss: 0.1715\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 430/1000] Train Loss: 0.0042  |  Val Loss: 0.1709\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "[Epoch 431/1000] Train Loss: 0.0042  |  Val Loss: 0.1711\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "[Epoch 432/1000] Train Loss: 0.0041  |  Val Loss: 0.1717\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 433/1000] Train Loss: 0.0041  |  Val Loss: 0.1716\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 434/1000] Train Loss: 0.0040  |  Val Loss: 0.1718\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 435/1000] Train Loss: 0.0040  |  Val Loss: 0.1715\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "[Epoch 436/1000] Train Loss: 0.0040  |  Val Loss: 0.1712\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 437/1000] Train Loss: 0.0040  |  Val Loss: 0.1715\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 437 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_mlp_input_dim = tscl_mlp_train_reps.shape[1]\n",
    "tscl_mlp_num_classes = len(torch.unique(tscl_mlp_train_labels_torch))\n",
    "tscl_mlp_model = MLPClassifier(tscl_mlp_input_dim, tscl_mlp_num_classes).to(device)\n",
    "\n",
    "tscl_mlp_criterion = nn.CrossEntropyLoss()\n",
    "tscl_mlp_optimizer = optim.Adam(tscl_mlp_model.parameters(), lr=1e-4)\n",
    "\n",
    "tscl_mlp_num_epochs = 1000\n",
    "tscl_mlp_patience = 100\n",
    "\n",
    "tscl_mlp_train_losses = []\n",
    "tscl_mlp_val_losses = []\n",
    "\n",
    "tscl_mlp_best_val_loss = float('inf')\n",
    "tscl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for tscl_mlp_epoch in range(tscl_mlp_num_epochs):\n",
    "    # Training\n",
    "    tscl_mlp_model.train()\n",
    "    tscl_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for tscl_mlp_embeddings_batch, tscl_mlp_labels_batch in tscl_mlp_train_loader:\n",
    "        tscl_mlp_embeddings_batch = tscl_mlp_embeddings_batch.to(device)\n",
    "        tscl_mlp_labels_batch = tscl_mlp_labels_batch.to(device)\n",
    "        \n",
    "        tscl_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        tscl_mlp_outputs = tscl_mlp_model(tscl_mlp_embeddings_batch)\n",
    "        tscl_mlp_loss = tscl_mlp_criterion(tscl_mlp_outputs, tscl_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        tscl_mlp_loss.backward()\n",
    "        tscl_mlp_optimizer.step()\n",
    "        \n",
    "        tscl_mlp_train_running_loss += tscl_mlp_loss.item() * tscl_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    tscl_mlp_epoch_train_loss = tscl_mlp_train_running_loss / len(tscl_mlp_train_loader.dataset)\n",
    "    tscl_mlp_train_losses.append(tscl_mlp_epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    tscl_mlp_model.eval()\n",
    "    tscl_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for tscl_mlp_val_embeddings_batch, tscl_mlp_val_labels_batch in tscl_mlp_val_loader:\n",
    "            tscl_mlp_val_embeddings_batch = tscl_mlp_val_embeddings_batch.to(device)\n",
    "            tscl_mlp_val_labels_batch = tscl_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            tscl_mlp_val_outputs = tscl_mlp_model(tscl_mlp_val_embeddings_batch)\n",
    "            tscl_mlp_val_loss = tscl_mlp_criterion(tscl_mlp_val_outputs, tscl_mlp_val_labels_batch)\n",
    "\n",
    "            tscl_mlp_val_running_loss += tscl_mlp_val_loss.item() * tscl_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    tscl_mlp_epoch_val_loss = tscl_mlp_val_running_loss / len(tscl_mlp_val_loader.dataset)\n",
    "    tscl_mlp_val_losses.append(tscl_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {tscl_mlp_epoch+1}/{tscl_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {tscl_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {tscl_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if tscl_mlp_epoch_val_loss < tscl_mlp_best_val_loss:\n",
    "        print(f\"Validation loss improved from {tscl_mlp_best_val_loss:.4f} to {tscl_mlp_epoch_val_loss:.4f}.\")\n",
    "        tscl_mlp_best_val_loss = tscl_mlp_epoch_val_loss\n",
    "        tscl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "    else:\n",
    "        # no improvement\n",
    "        tscl_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {tscl_mlp_epochs_without_improvement}/{tscl_mlp_patience}\")\n",
    "        \n",
    "        if tscl_mlp_epochs_without_improvement >= tscl_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {tscl_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {tscl_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(tscl_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(tscl_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:44:10.837168Z",
     "iopub.status.busy": "2025-05-08T19:44:10.836165Z",
     "iopub.status.idle": "2025-05-08T19:44:10.973782Z",
     "shell.execute_reply": "2025-05-08T19:44:10.973782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TSCL+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.4700 | Test Accuracy: 88.69%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_mlp_model.eval()\n",
    "\n",
    "tscl_mlp_test_running_loss = 0.0\n",
    "tscl_mlp_test_correct = 0\n",
    "tscl_mlp_all_predictions = []\n",
    "tscl_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tscl_mlp_test_embeddings_batch, tscl_mlp_test_labels_batch in tscl_mlp_test_loader:\n",
    "        tscl_mlp_test_embeddings_batch = tscl_mlp_test_embeddings_batch.to(device)\n",
    "        tscl_mlp_test_labels_batch = tscl_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        tscl_mlp_test_outputs = tscl_mlp_model(tscl_mlp_test_embeddings_batch)\n",
    "        \n",
    "        tscl_mlp_test_loss_batch = tscl_mlp_criterion(tscl_mlp_test_outputs, tscl_mlp_test_labels_batch)\n",
    "        tscl_mlp_test_running_loss += tscl_mlp_test_loss_batch.item() * tscl_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, tscl_mlp_test_predicted = torch.max(tscl_mlp_test_outputs, dim=1)\n",
    "        tscl_mlp_test_correct += (tscl_mlp_test_predicted == tscl_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        tscl_mlp_all_predictions.extend(tscl_mlp_test_predicted.cpu().numpy())\n",
    "        tscl_mlp_all_true_labels.extend(tscl_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'tscl_mlp_predictions.npy'), np.array(tscl_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'tscl_mlp_true_labels.npy'), np.array(tscl_mlp_all_true_labels))\n",
    "print(f\"Saved TSCL+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "tscl_mlp_epoch_test_loss = tscl_mlp_test_running_loss / len(tscl_mlp_test_loader.dataset)\n",
    "tscl_mlp_test_accuracy = tscl_mlp_test_correct / len(tscl_mlp_test_loader.dataset)\n",
    "\n",
    "tscl_mlp_test_accuracy_pct = tscl_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {tscl_mlp_epoch_test_loss:.4f} | Test Accuracy: {tscl_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "tscl_mlp_num_epochs_run = len(tscl_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         tscl_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         tscl_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         [tscl_mlp_epoch_test_loss]*tscl_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Supervised Contrastive Learning with Silhouette Distance Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:44:10.975792Z",
     "iopub.status.busy": "2025-05-08T19:44:10.975792Z",
     "iopub.status.idle": "2025-05-08T19:44:10.987135Z",
     "shell.execute_reply": "2025-05-08T19:44:10.987135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 560 samples with 64 features each\n",
      "LOG: Labels shape: (560,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2618 samples with 64 features each\n",
      "LOG: Labels shape: (2618,)\n",
      "\n",
      "\n",
      "Train embeddings shape: (560, 64), \n",
      "Train labels shape: (560,)\n",
      "\n",
      "\n",
      "Val embeddings shape: (70, 64), \n",
      "Val labels shape: (70,)\n",
      "\n",
      "\n",
      "Test embeddings shape: (2618, 64), \n",
      "Test labels shape: (2618,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "sclsdl_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "sclsdl_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "sclsdl_train_embeddings, sclsdl_train_labels = load_encoded_data(sclsdl_encoded_train_dir)\n",
    "sclsdl_val_embeddings, sclsdl_val_labels = load_encoded_data(sclsdl_encoded_val_dir)\n",
    "sclsdl_test_embeddings, sclsdl_test_labels = load_encoded_data(sclsdl_encoded_test_dir)\n",
    "\n",
    "#shape verification\n",
    "print(f\"\\n\\nTrain embeddings shape: {sclsdl_train_embeddings.shape}, \\nTrain labels shape: {sclsdl_train_labels.shape}\")\n",
    "print(f\"\\n\\nVal embeddings shape: {sclsdl_val_embeddings.shape}, \\nVal labels shape: {sclsdl_val_labels.shape}\")\n",
    "print(f\"\\n\\nTest embeddings shape: {sclsdl_test_embeddings.shape}, \\nTest labels shape: {sclsdl_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:44:10.990140Z",
     "iopub.status.busy": "2025-05-08T19:44:10.989140Z",
     "iopub.status.idle": "2025-05-08T19:44:11.001151Z",
     "shell.execute_reply": "2025-05-08T19:44:11.001151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20, 9: 20, 10: 20, 11: 20, 12: 20, 13: 20}\n",
      "Training batch size: 280\n"
     ]
    }
   ],
   "source": [
    "#flattening embeddings to (num_samples, 64)\n",
    "sclsdl_train_embeddings = sclsdl_train_embeddings.reshape(sclsdl_train_embeddings.shape[0], -1)\n",
    "sclsdl_val_embeddings = sclsdl_val_embeddings.reshape(sclsdl_val_embeddings.shape[0], -1)\n",
    "sclsdl_test_embeddings = sclsdl_test_embeddings.reshape(sclsdl_test_embeddings.shape[0], -1)\n",
    "\n",
    "#compute mean and std from training set\n",
    "sclsdl_train_mean = np.mean(sclsdl_train_embeddings, axis=0)\n",
    "sclsdl_train_std = np.std(sclsdl_train_embeddings, axis=0)\n",
    "\n",
    "#normalize all datasets from above training mean and std\n",
    "#sclsdl_train_embeddings = (sclsdl_train_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "#sclsdl_val_embeddings = (sclsdl_val_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "#sclsdl_test_embeddings = (sclsdl_test_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "\n",
    "sclsdl_train_dataset = TensorDataset(torch.tensor(sclsdl_train_embeddings, dtype=torch.float32), torch.tensor(sclsdl_train_labels, dtype=torch.long))\n",
    "sclsdl_val_dataset = TensorDataset(torch.tensor(sclsdl_val_embeddings, dtype=torch.float32), torch.tensor(sclsdl_val_labels, dtype=torch.long))\n",
    "sclsdl_test_dataset = TensorDataset(torch.tensor(sclsdl_test_embeddings, dtype=torch.float32), torch.tensor(sclsdl_test_labels, dtype=torch.long))\n",
    "\n",
    "\n",
    "sclsdl_m = 20\n",
    "sclsdl_num_classes = len(np.unique(sclsdl_train_labels))\n",
    "\n",
    "# calc theoretical required batch size\n",
    "sclsdl_required_batch_size = sclsdl_m * sclsdl_num_classes\n",
    "\n",
    "if sclsdl_required_batch_size > len(sclsdl_train_dataset):\n",
    "    sclsdl_max_possible_m = len(sclsdl_train_dataset) // sclsdl_num_classes\n",
    "    sclsdl_m = max(1, sclsdl_max_possible_m)\n",
    "    sclsdl_batch_size_train = sclsdl_m * sclsdl_num_classes\n",
    "else:\n",
    "    sclsdl_batch_size_train = sclsdl_required_batch_size\n",
    "\n",
    "sclsdl_sampler = MPerClassSampler(labels = sclsdl_train_labels, m = sclsdl_m, batch_size = sclsdl_batch_size_train, length_before_new_iter=len(sclsdl_train_dataset))\n",
    "sclsdl_train_loader = DataLoader(sclsdl_train_dataset, batch_size=sclsdl_batch_size_train, sampler=sclsdl_sampler)\n",
    "\n",
    "#creating dataloaders for scl\n",
    "sclsdl_dataloader_bs = 64\n",
    "sclsdl_val_loader = DataLoader(sclsdl_val_dataset, batch_size=sclsdl_dataloader_bs, shuffle=False)\n",
    "sclsdl_test_loader = DataLoader(sclsdl_test_dataset, batch_size=sclsdl_dataloader_bs, shuffle=False)\n",
    "\n",
    "for sclsdl_X_batch, sclsdl_y_batch in sclsdl_train_loader:\n",
    "    sclsdl_unique, sclsdl_counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(\"Class distribution in batch:\", dict(zip(sclsdl_unique, sclsdl_counts)))\n",
    "    print(f\"Training batch size: {sclsdl_batch_size_train}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:44:11.004164Z",
     "iopub.status.busy": "2025-05-08T19:44:11.004164Z",
     "iopub.status.idle": "2025-05-08T19:44:11.007584Z",
     "shell.execute_reply": "2025-05-08T19:44:11.007584Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SupConNet, self).__init__()\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.projection_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:44:11.009589Z",
     "iopub.status.busy": "2025-05-08T19:44:11.009589Z",
     "iopub.status.idle": "2025-05-08T19:44:11.017216Z",
     "shell.execute_reply": "2025-05-08T19:44:11.017216Z"
    }
   },
   "outputs": [],
   "source": [
    "class SilhouetteDistanceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SilhouetteDistanceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        return self.score(features, labels, True,True)\n",
    "\n",
    "    def score(self,X, labels,feature_norm=True, loss=False):\n",
    "        unique_labels = torch.unique(labels)\n",
    "        if feature_norm:\n",
    "            X= F.normalize(X, p=2, dim=1)\n",
    "\n",
    "\n",
    "        A, B = self._compute_distances(X, labels, unique_labels)\n",
    "\n",
    "        # A= scale*A\n",
    "        # B = (1-scale)*B\n",
    "        sil_samples = (B - A) / torch.clamp(torch.maximum(A, B), min=0.0001)\n",
    "\n",
    "        # nan values are for clusters of size 1, and should be 0\n",
    "        mean_sil_score = torch.mean(torch.nan_to_num(sil_samples))\n",
    "        if loss:\n",
    "            return (1 - mean_sil_score) / 2\n",
    "        else:\n",
    "            return mean_sil_score.item()\n",
    "\n",
    "\n",
    "    def _compute_distances(self,X, labels, unique_labels):\n",
    "        intra_dist = torch.zeros_like(labels, dtype=torch.float32)\n",
    "        inter_dist = torch.full_like(labels, torch.inf, dtype=torch.float32)\n",
    "\n",
    "        for i, label_a in enumerate(unique_labels):\n",
    "            cluster_indices_a = (labels == label_a)\n",
    "            subX_a = X[cluster_indices_a]\n",
    "\n",
    "\n",
    "            intra_distances_a = torch.cdist(subX_a, subX_a)\n",
    "            div = (subX_a.size(0) - 1) if subX_a.shape[0]>1 else 1\n",
    "            intra_dist[cluster_indices_a] = intra_distances_a.sum(dim=1) / div\n",
    "\n",
    "            for label_b in unique_labels[i + 1:]:\n",
    "                cluster_indices_b = (labels == label_b)\n",
    "                subX_b = X[cluster_indices_b]\n",
    "                inter_distances_ab = torch.cdist(subX_a, subX_b)\n",
    "                inter_distances_ba = torch.cdist(subX_b, subX_a)\n",
    "\n",
    "                inter_dist[cluster_indices_a] = torch.minimum(inter_distances_ab.mean(dim=1), inter_dist[cluster_indices_a])\n",
    "                inter_dist[cluster_indices_b] = torch.minimum(inter_distances_ba.mean(dim=1), inter_dist[cluster_indices_b])\n",
    "\n",
    "        return intra_dist, inter_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:44:11.020222Z",
     "iopub.status.busy": "2025-05-08T19:44:11.019223Z",
     "iopub.status.idle": "2025-05-08T19:50:41.363170Z",
     "shell.execute_reply": "2025-05-08T19:50:41.362165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Epoch [1/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4881\n",
      "    Batch [2/2], Train Loss: 0.4889\n",
      "LOG: Epoch [1/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4541\n",
      "    Batch [2/2], Val Loss: 0.2280\n",
      "Epoch [1/2000], Avg Train Loss: 0.4885, Avg Val Loss: 0.3411\n",
      "\n",
      "Validation loss improved from inf to 0.3411. Saving model...\n",
      "LOG: Epoch [2/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4847\n",
      "LOG: Epoch [2/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4537\n",
      "    Batch [2/2], Val Loss: 0.2309\n",
      "Epoch [2/2000], Avg Train Loss: 0.4837, Avg Val Loss: 0.3423\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [3/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4820\n",
      "    Batch [2/2], Train Loss: 0.4822\n",
      "LOG: Epoch [3/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4532\n",
      "    Batch [2/2], Val Loss: 0.2361\n",
      "Epoch [3/2000], Avg Train Loss: 0.4821, Avg Val Loss: 0.3447\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [4/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4806\n",
      "LOG: Epoch [4/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4532\n",
      "    Batch [2/2], Val Loss: 0.2419\n",
      "Epoch [4/2000], Avg Train Loss: 0.4800, Avg Val Loss: 0.3476\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [5/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4779\n",
      "    Batch [2/2], Train Loss: 0.4784\n",
      "LOG: Epoch [5/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4538\n",
      "    Batch [2/2], Val Loss: 0.2487\n",
      "Epoch [5/2000], Avg Train Loss: 0.4782, Avg Val Loss: 0.3512\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [6/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4733\n",
      "LOG: Epoch [6/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4540\n",
      "    Batch [2/2], Val Loss: 0.2532\n",
      "Epoch [6/2000], Avg Train Loss: 0.4749, Avg Val Loss: 0.3536\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [7/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4728\n",
      "    Batch [2/2], Train Loss: 0.4751\n",
      "LOG: Epoch [7/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4526\n",
      "    Batch [2/2], Val Loss: 0.2520\n",
      "Epoch [7/2000], Avg Train Loss: 0.4739, Avg Val Loss: 0.3523\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [8/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4746\n",
      "LOG: Epoch [8/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4503\n",
      "    Batch [2/2], Val Loss: 0.2510\n",
      "Epoch [8/2000], Avg Train Loss: 0.4738, Avg Val Loss: 0.3506\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [9/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4707\n",
      "    Batch [2/2], Train Loss: 0.4741\n",
      "LOG: Epoch [9/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4482\n",
      "    Batch [2/2], Val Loss: 0.2365\n",
      "Epoch [9/2000], Avg Train Loss: 0.4724, Avg Val Loss: 0.3424\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [10/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4707\n",
      "    Batch [2/2], Train Loss: 0.4700\n",
      "LOG: Epoch [10/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4473\n",
      "    Batch [2/2], Val Loss: 0.2218\n",
      "Epoch [10/2000], Avg Train Loss: 0.4704, Avg Val Loss: 0.3345\n",
      "\n",
      "Validation loss improved from 0.3411 to 0.3345. Saving model...\n",
      "LOG: Epoch [11/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4710\n",
      "LOG: Epoch [11/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4471\n",
      "    Batch [2/2], Val Loss: 0.2109\n",
      "Epoch [11/2000], Avg Train Loss: 0.4708, Avg Val Loss: 0.3290\n",
      "\n",
      "Validation loss improved from 0.3345 to 0.3290. Saving model...\n",
      "LOG: Epoch [12/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4638\n",
      "    Batch [2/2], Train Loss: 0.4656\n",
      "LOG: Epoch [12/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4447\n",
      "    Batch [2/2], Val Loss: 0.1980\n",
      "Epoch [12/2000], Avg Train Loss: 0.4647, Avg Val Loss: 0.3213\n",
      "\n",
      "Validation loss improved from 0.3290 to 0.3213. Saving model...\n",
      "LOG: Epoch [13/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4657\n",
      "LOG: Epoch [13/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4461\n",
      "    Batch [2/2], Val Loss: 0.1865\n",
      "Epoch [13/2000], Avg Train Loss: 0.4628, Avg Val Loss: 0.3163\n",
      "\n",
      "Validation loss improved from 0.3213 to 0.3163. Saving model...\n",
      "LOG: Epoch [14/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4585\n",
      "LOG: Epoch [14/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4449\n",
      "    Batch [2/2], Val Loss: 0.1783\n",
      "Epoch [14/2000], Avg Train Loss: 0.4608, Avg Val Loss: 0.3116\n",
      "\n",
      "Validation loss improved from 0.3163 to 0.3116. Saving model...\n",
      "LOG: Epoch [15/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4608\n",
      "    Batch [2/2], Train Loss: 0.4598\n",
      "LOG: Epoch [15/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4411\n",
      "    Batch [2/2], Val Loss: 0.1701\n",
      "Epoch [15/2000], Avg Train Loss: 0.4603, Avg Val Loss: 0.3056\n",
      "\n",
      "Validation loss improved from 0.3116 to 0.3056. Saving model...\n",
      "LOG: Epoch [16/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4573\n",
      "LOG: Epoch [16/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4391\n",
      "    Batch [2/2], Val Loss: 0.1642\n",
      "Epoch [16/2000], Avg Train Loss: 0.4582, Avg Val Loss: 0.3017\n",
      "\n",
      "Validation loss improved from 0.3056 to 0.3017. Saving model...\n",
      "LOG: Epoch [17/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4550\n",
      "    Batch [2/2], Train Loss: 0.4521\n",
      "LOG: Epoch [17/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4374\n",
      "    Batch [2/2], Val Loss: 0.1589\n",
      "Epoch [17/2000], Avg Train Loss: 0.4536, Avg Val Loss: 0.2981\n",
      "\n",
      "Validation loss improved from 0.3017 to 0.2981. Saving model...\n",
      "LOG: Epoch [18/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4574\n",
      "LOG: Epoch [18/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4364\n",
      "    Batch [2/2], Val Loss: 0.1549\n",
      "Epoch [18/2000], Avg Train Loss: 0.4567, Avg Val Loss: 0.2956\n",
      "\n",
      "Validation loss improved from 0.2981 to 0.2956. Saving model...\n",
      "LOG: Epoch [19/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4575\n",
      "    Batch [2/2], Train Loss: 0.4557\n",
      "LOG: Epoch [19/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4353\n",
      "    Batch [2/2], Val Loss: 0.1533\n",
      "Epoch [19/2000], Avg Train Loss: 0.4566, Avg Val Loss: 0.2943\n",
      "\n",
      "Validation loss improved from 0.2956 to 0.2943. Saving model...\n",
      "LOG: Epoch [20/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4567\n",
      "LOG: Epoch [20/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4344\n",
      "    Batch [2/2], Val Loss: 0.1531\n",
      "Epoch [20/2000], Avg Train Loss: 0.4543, Avg Val Loss: 0.2938\n",
      "\n",
      "Validation loss improved from 0.2943 to 0.2938. Saving model...\n",
      "LOG: Epoch [21/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4510\n",
      "    Batch [2/2], Train Loss: 0.4497\n",
      "LOG: Epoch [21/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4339\n",
      "    Batch [2/2], Val Loss: 0.1540\n",
      "Epoch [21/2000], Avg Train Loss: 0.4503, Avg Val Loss: 0.2940\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [22/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4544\n",
      "LOG: Epoch [22/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4338\n",
      "    Batch [2/2], Val Loss: 0.1550\n",
      "Epoch [22/2000], Avg Train Loss: 0.4534, Avg Val Loss: 0.2944\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [23/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4510\n",
      "    Batch [2/2], Train Loss: 0.4501\n",
      "LOG: Epoch [23/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4334\n",
      "    Batch [2/2], Val Loss: 0.1567\n",
      "Epoch [23/2000], Avg Train Loss: 0.4505, Avg Val Loss: 0.2951\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [24/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4476\n",
      "LOG: Epoch [24/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4329\n",
      "    Batch [2/2], Val Loss: 0.1586\n",
      "Epoch [24/2000], Avg Train Loss: 0.4474, Avg Val Loss: 0.2958\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [25/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4486\n",
      "    Batch [2/2], Train Loss: 0.4447\n",
      "LOG: Epoch [25/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4326\n",
      "    Batch [2/2], Val Loss: 0.1601\n",
      "Epoch [25/2000], Avg Train Loss: 0.4466, Avg Val Loss: 0.2964\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [26/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4433\n",
      "LOG: Epoch [26/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4326\n",
      "    Batch [2/2], Val Loss: 0.1618\n",
      "Epoch [26/2000], Avg Train Loss: 0.4432, Avg Val Loss: 0.2972\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [27/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4397\n",
      "    Batch [2/2], Train Loss: 0.4379\n",
      "LOG: Epoch [27/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4325\n",
      "    Batch [2/2], Val Loss: 0.1637\n",
      "Epoch [27/2000], Avg Train Loss: 0.4388, Avg Val Loss: 0.2981\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [28/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4386\n",
      "LOG: Epoch [28/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4314\n",
      "    Batch [2/2], Val Loss: 0.1658\n",
      "Epoch [28/2000], Avg Train Loss: 0.4413, Avg Val Loss: 0.2986\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [29/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4430\n",
      "    Batch [2/2], Train Loss: 0.4440\n",
      "LOG: Epoch [29/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4293\n",
      "    Batch [2/2], Val Loss: 0.1682\n",
      "Epoch [29/2000], Avg Train Loss: 0.4435, Avg Val Loss: 0.2987\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [30/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4352\n",
      "LOG: Epoch [30/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4275\n",
      "    Batch [2/2], Val Loss: 0.1702\n",
      "Epoch [30/2000], Avg Train Loss: 0.4388, Avg Val Loss: 0.2988\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [31/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4434\n",
      "    Batch [2/2], Train Loss: 0.4351\n",
      "LOG: Epoch [31/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4252\n",
      "    Batch [2/2], Val Loss: 0.1723\n",
      "Epoch [31/2000], Avg Train Loss: 0.4393, Avg Val Loss: 0.2988\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [32/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4398\n",
      "LOG: Epoch [32/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4232\n",
      "    Batch [2/2], Val Loss: 0.1756\n",
      "Epoch [32/2000], Avg Train Loss: 0.4396, Avg Val Loss: 0.2994\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [33/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4342\n",
      "    Batch [2/2], Train Loss: 0.4384\n",
      "LOG: Epoch [33/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4215\n",
      "    Batch [2/2], Val Loss: 0.1788\n",
      "Epoch [33/2000], Avg Train Loss: 0.4363, Avg Val Loss: 0.3002\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [34/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4373\n",
      "LOG: Epoch [34/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4199\n",
      "    Batch [2/2], Val Loss: 0.1821\n",
      "Epoch [34/2000], Avg Train Loss: 0.4376, Avg Val Loss: 0.3010\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [35/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4358\n",
      "    Batch [2/2], Train Loss: 0.4374\n",
      "LOG: Epoch [35/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4183\n",
      "    Batch [2/2], Val Loss: 0.1848\n",
      "Epoch [35/2000], Avg Train Loss: 0.4366, Avg Val Loss: 0.3016\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [36/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4335\n",
      "LOG: Epoch [36/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4173\n",
      "    Batch [2/2], Val Loss: 0.1872\n",
      "Epoch [36/2000], Avg Train Loss: 0.4329, Avg Val Loss: 0.3023\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [37/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4337\n",
      "    Batch [2/2], Train Loss: 0.4347\n",
      "LOG: Epoch [37/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4158\n",
      "    Batch [2/2], Val Loss: 0.1884\n",
      "Epoch [37/2000], Avg Train Loss: 0.4342, Avg Val Loss: 0.3021\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [38/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4308\n",
      "LOG: Epoch [38/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4157\n",
      "    Batch [2/2], Val Loss: 0.1893\n",
      "Epoch [38/2000], Avg Train Loss: 0.4326, Avg Val Loss: 0.3025\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [39/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4382\n",
      "    Batch [2/2], Train Loss: 0.4278\n",
      "LOG: Epoch [39/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4161\n",
      "    Batch [2/2], Val Loss: 0.1902\n",
      "Epoch [39/2000], Avg Train Loss: 0.4330, Avg Val Loss: 0.3032\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [40/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4293\n",
      "LOG: Epoch [40/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4169\n",
      "    Batch [2/2], Val Loss: 0.1887\n",
      "Epoch [40/2000], Avg Train Loss: 0.4286, Avg Val Loss: 0.3028\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [41/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4233\n",
      "    Batch [2/2], Train Loss: 0.4356\n",
      "LOG: Epoch [41/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4178\n",
      "    Batch [2/2], Val Loss: 0.1868\n",
      "Epoch [41/2000], Avg Train Loss: 0.4294, Avg Val Loss: 0.3023\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [42/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4242\n",
      "    Batch [2/2], Train Loss: 0.4330\n",
      "LOG: Epoch [42/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4184\n",
      "    Batch [2/2], Val Loss: 0.1852\n",
      "Epoch [42/2000], Avg Train Loss: 0.4286, Avg Val Loss: 0.3018\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [43/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4229\n",
      "    Batch [2/2], Train Loss: 0.4259\n",
      "LOG: Epoch [43/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4178\n",
      "    Batch [2/2], Val Loss: 0.1826\n",
      "Epoch [43/2000], Avg Train Loss: 0.4244, Avg Val Loss: 0.3002\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [44/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4264\n",
      "    Batch [2/2], Train Loss: 0.4265\n",
      "LOG: Epoch [44/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4167\n",
      "    Batch [2/2], Val Loss: 0.1809\n",
      "Epoch [44/2000], Avg Train Loss: 0.4264, Avg Val Loss: 0.2988\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [45/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4274\n",
      "LOG: Epoch [45/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4153\n",
      "    Batch [2/2], Val Loss: 0.1802\n",
      "Epoch [45/2000], Avg Train Loss: 0.4266, Avg Val Loss: 0.2977\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [46/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4231\n",
      "LOG: Epoch [46/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4135\n",
      "    Batch [2/2], Val Loss: 0.1790\n",
      "Epoch [46/2000], Avg Train Loss: 0.4254, Avg Val Loss: 0.2962\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [47/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4271\n",
      "    Batch [2/2], Train Loss: 0.4274\n",
      "LOG: Epoch [47/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4094\n",
      "    Batch [2/2], Val Loss: 0.1726\n",
      "Epoch [47/2000], Avg Train Loss: 0.4272, Avg Val Loss: 0.2910\n",
      "\n",
      "Validation loss improved from 0.2938 to 0.2910. Saving model...\n",
      "LOG: Epoch [48/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4200\n",
      "LOG: Epoch [48/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1668\n",
      "Epoch [48/2000], Avg Train Loss: 0.4227, Avg Val Loss: 0.2861\n",
      "\n",
      "Validation loss improved from 0.2910 to 0.2861. Saving model...\n",
      "LOG: Epoch [49/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4274\n",
      "    Batch [2/2], Train Loss: 0.4266\n",
      "LOG: Epoch [49/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.4022\n",
      "    Batch [2/2], Val Loss: 0.1623\n",
      "Epoch [49/2000], Avg Train Loss: 0.4270, Avg Val Loss: 0.2822\n",
      "\n",
      "Validation loss improved from 0.2861 to 0.2822. Saving model...\n",
      "LOG: Epoch [50/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4270\n",
      "LOG: Epoch [50/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3999\n",
      "    Batch [2/2], Val Loss: 0.1584\n",
      "Epoch [50/2000], Avg Train Loss: 0.4240, Avg Val Loss: 0.2792\n",
      "\n",
      "Validation loss improved from 0.2822 to 0.2792. Saving model...\n",
      "LOG: Epoch [51/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4252\n",
      "    Batch [2/2], Train Loss: 0.4207\n",
      "LOG: Epoch [51/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3981\n",
      "    Batch [2/2], Val Loss: 0.1564\n",
      "Epoch [51/2000], Avg Train Loss: 0.4229, Avg Val Loss: 0.2772\n",
      "\n",
      "Validation loss improved from 0.2792 to 0.2772. Saving model...\n",
      "LOG: Epoch [52/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4186\n",
      "    Batch [2/2], Train Loss: 0.4208\n",
      "LOG: Epoch [52/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3966\n",
      "    Batch [2/2], Val Loss: 0.1547\n",
      "Epoch [52/2000], Avg Train Loss: 0.4197, Avg Val Loss: 0.2757\n",
      "\n",
      "Validation loss improved from 0.2772 to 0.2757. Saving model...\n",
      "LOG: Epoch [53/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4202\n",
      "LOG: Epoch [53/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3953\n",
      "    Batch [2/2], Val Loss: 0.1540\n",
      "Epoch [53/2000], Avg Train Loss: 0.4224, Avg Val Loss: 0.2746\n",
      "\n",
      "Validation loss improved from 0.2757 to 0.2746. Saving model...\n",
      "LOG: Epoch [54/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4252\n",
      "    Batch [2/2], Train Loss: 0.4247\n",
      "LOG: Epoch [54/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3944\n",
      "    Batch [2/2], Val Loss: 0.1527\n",
      "Epoch [54/2000], Avg Train Loss: 0.4249, Avg Val Loss: 0.2735\n",
      "\n",
      "Validation loss improved from 0.2746 to 0.2735. Saving model...\n",
      "LOG: Epoch [55/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4222\n",
      "LOG: Epoch [55/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3935\n",
      "    Batch [2/2], Val Loss: 0.1520\n",
      "Epoch [55/2000], Avg Train Loss: 0.4228, Avg Val Loss: 0.2728\n",
      "\n",
      "Validation loss improved from 0.2735 to 0.2728. Saving model...\n",
      "LOG: Epoch [56/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4177\n",
      "    Batch [2/2], Train Loss: 0.4134\n",
      "LOG: Epoch [56/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3927\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [56/2000], Avg Train Loss: 0.4156, Avg Val Loss: 0.2725\n",
      "\n",
      "Validation loss improved from 0.2728 to 0.2725. Saving model...\n",
      "LOG: Epoch [57/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4144\n",
      "LOG: Epoch [57/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3923\n",
      "    Batch [2/2], Val Loss: 0.1525\n",
      "Epoch [57/2000], Avg Train Loss: 0.4189, Avg Val Loss: 0.2724\n",
      "\n",
      "Validation loss improved from 0.2725 to 0.2724. Saving model...\n",
      "LOG: Epoch [58/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4157\n",
      "    Batch [2/2], Train Loss: 0.4198\n",
      "LOG: Epoch [58/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3919\n",
      "    Batch [2/2], Val Loss: 0.1522\n",
      "Epoch [58/2000], Avg Train Loss: 0.4177, Avg Val Loss: 0.2721\n",
      "\n",
      "Validation loss improved from 0.2724 to 0.2721. Saving model...\n",
      "LOG: Epoch [59/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4243\n",
      "LOG: Epoch [59/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3917\n",
      "    Batch [2/2], Val Loss: 0.1521\n",
      "Epoch [59/2000], Avg Train Loss: 0.4182, Avg Val Loss: 0.2719\n",
      "\n",
      "Validation loss improved from 0.2721 to 0.2719. Saving model...\n",
      "LOG: Epoch [60/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4200\n",
      "    Batch [2/2], Train Loss: 0.4207\n",
      "LOG: Epoch [60/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3916\n",
      "    Batch [2/2], Val Loss: 0.1518\n",
      "Epoch [60/2000], Avg Train Loss: 0.4203, Avg Val Loss: 0.2717\n",
      "\n",
      "Validation loss improved from 0.2719 to 0.2717. Saving model...\n",
      "LOG: Epoch [61/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4192\n",
      "LOG: Epoch [61/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3913\n",
      "    Batch [2/2], Val Loss: 0.1516\n",
      "Epoch [61/2000], Avg Train Loss: 0.4234, Avg Val Loss: 0.2714\n",
      "\n",
      "Validation loss improved from 0.2717 to 0.2714. Saving model...\n",
      "LOG: Epoch [62/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4189\n",
      "    Batch [2/2], Train Loss: 0.4198\n",
      "LOG: Epoch [62/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3912\n",
      "    Batch [2/2], Val Loss: 0.1508\n",
      "Epoch [62/2000], Avg Train Loss: 0.4194, Avg Val Loss: 0.2710\n",
      "\n",
      "Validation loss improved from 0.2714 to 0.2710. Saving model...\n",
      "LOG: Epoch [63/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4229\n",
      "LOG: Epoch [63/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3911\n",
      "    Batch [2/2], Val Loss: 0.1506\n",
      "Epoch [63/2000], Avg Train Loss: 0.4231, Avg Val Loss: 0.2709\n",
      "\n",
      "Validation loss improved from 0.2710 to 0.2709. Saving model...\n",
      "LOG: Epoch [64/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4199\n",
      "    Batch [2/2], Train Loss: 0.4160\n",
      "LOG: Epoch [64/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3910\n",
      "    Batch [2/2], Val Loss: 0.1507\n",
      "Epoch [64/2000], Avg Train Loss: 0.4180, Avg Val Loss: 0.2709\n",
      "\n",
      "Validation loss improved from 0.2709 to 0.2709. Saving model...\n",
      "LOG: Epoch [65/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4215\n",
      "LOG: Epoch [65/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3909\n",
      "    Batch [2/2], Val Loss: 0.1507\n",
      "Epoch [65/2000], Avg Train Loss: 0.4216, Avg Val Loss: 0.2708\n",
      "\n",
      "Validation loss improved from 0.2709 to 0.2708. Saving model...\n",
      "LOG: Epoch [66/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4192\n",
      "    Batch [2/2], Train Loss: 0.4197\n",
      "LOG: Epoch [66/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3906\n",
      "    Batch [2/2], Val Loss: 0.1507\n",
      "Epoch [66/2000], Avg Train Loss: 0.4194, Avg Val Loss: 0.2707\n",
      "\n",
      "Validation loss improved from 0.2708 to 0.2707. Saving model...\n",
      "LOG: Epoch [67/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4173\n",
      "LOG: Epoch [67/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3906\n",
      "    Batch [2/2], Val Loss: 0.1504\n",
      "Epoch [67/2000], Avg Train Loss: 0.4198, Avg Val Loss: 0.2705\n",
      "\n",
      "Validation loss improved from 0.2707 to 0.2705. Saving model...\n",
      "LOG: Epoch [68/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4270\n",
      "    Batch [2/2], Train Loss: 0.4206\n",
      "LOG: Epoch [68/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3905\n",
      "    Batch [2/2], Val Loss: 0.1500\n",
      "Epoch [68/2000], Avg Train Loss: 0.4238, Avg Val Loss: 0.2702\n",
      "\n",
      "Validation loss improved from 0.2705 to 0.2702. Saving model...\n",
      "LOG: Epoch [69/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4211\n",
      "LOG: Epoch [69/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3903\n",
      "    Batch [2/2], Val Loss: 0.1500\n",
      "Epoch [69/2000], Avg Train Loss: 0.4183, Avg Val Loss: 0.2702\n",
      "\n",
      "Validation loss improved from 0.2702 to 0.2702. Saving model...\n",
      "LOG: Epoch [70/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4162\n",
      "    Batch [2/2], Train Loss: 0.4239\n",
      "LOG: Epoch [70/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3904\n",
      "    Batch [2/2], Val Loss: 0.1501\n",
      "Epoch [70/2000], Avg Train Loss: 0.4201, Avg Val Loss: 0.2702\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [71/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4175\n",
      "LOG: Epoch [71/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3904\n",
      "    Batch [2/2], Val Loss: 0.1501\n",
      "Epoch [71/2000], Avg Train Loss: 0.4180, Avg Val Loss: 0.2703\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [72/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4140\n",
      "    Batch [2/2], Train Loss: 0.4218\n",
      "LOG: Epoch [72/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3902\n",
      "    Batch [2/2], Val Loss: 0.1504\n",
      "Epoch [72/2000], Avg Train Loss: 0.4179, Avg Val Loss: 0.2703\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [73/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4220\n",
      "LOG: Epoch [73/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3902\n",
      "    Batch [2/2], Val Loss: 0.1508\n",
      "Epoch [73/2000], Avg Train Loss: 0.4221, Avg Val Loss: 0.2705\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [74/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4233\n",
      "    Batch [2/2], Train Loss: 0.4162\n",
      "LOG: Epoch [74/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3903\n",
      "    Batch [2/2], Val Loss: 0.1510\n",
      "Epoch [74/2000], Avg Train Loss: 0.4198, Avg Val Loss: 0.2706\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [75/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4230\n",
      "LOG: Epoch [75/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3903\n",
      "    Batch [2/2], Val Loss: 0.1505\n",
      "Epoch [75/2000], Avg Train Loss: 0.4219, Avg Val Loss: 0.2704\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [76/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4248\n",
      "    Batch [2/2], Train Loss: 0.4136\n",
      "LOG: Epoch [76/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3902\n",
      "    Batch [2/2], Val Loss: 0.1503\n",
      "Epoch [76/2000], Avg Train Loss: 0.4192, Avg Val Loss: 0.2702\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [77/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4192\n",
      "    Batch [2/2], Train Loss: 0.4182\n",
      "LOG: Epoch [77/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3900\n",
      "    Batch [2/2], Val Loss: 0.1504\n",
      "Epoch [77/2000], Avg Train Loss: 0.4187, Avg Val Loss: 0.2702\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [78/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4171\n",
      "LOG: Epoch [78/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3899\n",
      "    Batch [2/2], Val Loss: 0.1500\n",
      "Epoch [78/2000], Avg Train Loss: 0.4189, Avg Val Loss: 0.2700\n",
      "\n",
      "Validation loss improved from 0.2702 to 0.2700. Saving model...\n",
      "LOG: Epoch [79/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4164\n",
      "    Batch [2/2], Train Loss: 0.4201\n",
      "LOG: Epoch [79/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3900\n",
      "    Batch [2/2], Val Loss: 0.1494\n",
      "Epoch [79/2000], Avg Train Loss: 0.4183, Avg Val Loss: 0.2697\n",
      "\n",
      "Validation loss improved from 0.2700 to 0.2697. Saving model...\n",
      "LOG: Epoch [80/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4180\n",
      "LOG: Epoch [80/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3899\n",
      "    Batch [2/2], Val Loss: 0.1491\n",
      "Epoch [80/2000], Avg Train Loss: 0.4188, Avg Val Loss: 0.2695\n",
      "\n",
      "Validation loss improved from 0.2697 to 0.2695. Saving model...\n",
      "LOG: Epoch [81/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4166\n",
      "    Batch [2/2], Train Loss: 0.4203\n",
      "LOG: Epoch [81/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3898\n",
      "    Batch [2/2], Val Loss: 0.1486\n",
      "Epoch [81/2000], Avg Train Loss: 0.4184, Avg Val Loss: 0.2692\n",
      "\n",
      "Validation loss improved from 0.2695 to 0.2692. Saving model...\n",
      "LOG: Epoch [82/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4226\n",
      "LOG: Epoch [82/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3896\n",
      "    Batch [2/2], Val Loss: 0.1489\n",
      "Epoch [82/2000], Avg Train Loss: 0.4204, Avg Val Loss: 0.2692\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [83/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4204\n",
      "    Batch [2/2], Train Loss: 0.4193\n",
      "LOG: Epoch [83/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3896\n",
      "    Batch [2/2], Val Loss: 0.1488\n",
      "Epoch [83/2000], Avg Train Loss: 0.4198, Avg Val Loss: 0.2692\n",
      "\n",
      "Validation loss improved from 0.2692 to 0.2692. Saving model...\n",
      "LOG: Epoch [84/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4208\n",
      "    Batch [2/2], Train Loss: 0.4186\n",
      "LOG: Epoch [84/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3896\n",
      "    Batch [2/2], Val Loss: 0.1483\n",
      "Epoch [84/2000], Avg Train Loss: 0.4197, Avg Val Loss: 0.2690\n",
      "\n",
      "Validation loss improved from 0.2692 to 0.2690. Saving model...\n",
      "LOG: Epoch [85/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4174\n",
      "LOG: Epoch [85/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3898\n",
      "    Batch [2/2], Val Loss: 0.1481\n",
      "Epoch [85/2000], Avg Train Loss: 0.4213, Avg Val Loss: 0.2689\n",
      "\n",
      "Validation loss improved from 0.2690 to 0.2689. Saving model...\n",
      "LOG: Epoch [86/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4205\n",
      "    Batch [2/2], Train Loss: 0.4198\n",
      "LOG: Epoch [86/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3898\n",
      "    Batch [2/2], Val Loss: 0.1482\n",
      "Epoch [86/2000], Avg Train Loss: 0.4202, Avg Val Loss: 0.2690\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [87/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4156\n",
      "LOG: Epoch [87/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3898\n",
      "    Batch [2/2], Val Loss: 0.1483\n",
      "Epoch [87/2000], Avg Train Loss: 0.4153, Avg Val Loss: 0.2690\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [88/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4190\n",
      "    Batch [2/2], Train Loss: 0.4230\n",
      "LOG: Epoch [88/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3896\n",
      "    Batch [2/2], Val Loss: 0.1485\n",
      "Epoch [88/2000], Avg Train Loss: 0.4210, Avg Val Loss: 0.2690\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [89/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4206\n",
      "LOG: Epoch [89/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3894\n",
      "    Batch [2/2], Val Loss: 0.1483\n",
      "Epoch [89/2000], Avg Train Loss: 0.4218, Avg Val Loss: 0.2688\n",
      "\n",
      "Validation loss improved from 0.2689 to 0.2688. Saving model...\n",
      "LOG: Epoch [90/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4223\n",
      "LOG: Epoch [90/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3893\n",
      "    Batch [2/2], Val Loss: 0.1483\n",
      "Epoch [90/2000], Avg Train Loss: 0.4191, Avg Val Loss: 0.2688\n",
      "\n",
      "Validation loss improved from 0.2688 to 0.2688. Saving model...\n",
      "LOG: Epoch [91/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4141\n",
      "    Batch [2/2], Train Loss: 0.4178\n",
      "LOG: Epoch [91/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3892\n",
      "    Batch [2/2], Val Loss: 0.1486\n",
      "Epoch [91/2000], Avg Train Loss: 0.4160, Avg Val Loss: 0.2689\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [92/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4218\n",
      "LOG: Epoch [92/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3893\n",
      "    Batch [2/2], Val Loss: 0.1489\n",
      "Epoch [92/2000], Avg Train Loss: 0.4204, Avg Val Loss: 0.2691\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [93/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4159\n",
      "    Batch [2/2], Train Loss: 0.4179\n",
      "LOG: Epoch [93/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3893\n",
      "    Batch [2/2], Val Loss: 0.1482\n",
      "Epoch [93/2000], Avg Train Loss: 0.4169, Avg Val Loss: 0.2688\n",
      "\n",
      "Validation loss improved from 0.2688 to 0.2688. Saving model...\n",
      "LOG: Epoch [94/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4218\n",
      "    Batch [2/2], Train Loss: 0.4142\n",
      "LOG: Epoch [94/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3891\n",
      "    Batch [2/2], Val Loss: 0.1479\n",
      "Epoch [94/2000], Avg Train Loss: 0.4180, Avg Val Loss: 0.2685\n",
      "\n",
      "Validation loss improved from 0.2688 to 0.2685. Saving model...\n",
      "LOG: Epoch [95/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4185\n",
      "LOG: Epoch [95/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3890\n",
      "    Batch [2/2], Val Loss: 0.1481\n",
      "Epoch [95/2000], Avg Train Loss: 0.4200, Avg Val Loss: 0.2685\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [96/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4167\n",
      "    Batch [2/2], Train Loss: 0.4175\n",
      "LOG: Epoch [96/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3889\n",
      "    Batch [2/2], Val Loss: 0.1483\n",
      "Epoch [96/2000], Avg Train Loss: 0.4171, Avg Val Loss: 0.2686\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [97/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4211\n",
      "LOG: Epoch [97/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3887\n",
      "    Batch [2/2], Val Loss: 0.1485\n",
      "Epoch [97/2000], Avg Train Loss: 0.4182, Avg Val Loss: 0.2686\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [98/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4187\n",
      "    Batch [2/2], Train Loss: 0.4183\n",
      "LOG: Epoch [98/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3885\n",
      "    Batch [2/2], Val Loss: 0.1487\n",
      "Epoch [98/2000], Avg Train Loss: 0.4185, Avg Val Loss: 0.2686\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [99/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4151\n",
      "LOG: Epoch [99/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3884\n",
      "    Batch [2/2], Val Loss: 0.1483\n",
      "Epoch [99/2000], Avg Train Loss: 0.4178, Avg Val Loss: 0.2683\n",
      "\n",
      "Validation loss improved from 0.2685 to 0.2683. Saving model...\n",
      "LOG: Epoch [100/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4207\n",
      "    Batch [2/2], Train Loss: 0.4140\n",
      "LOG: Epoch [100/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3882\n",
      "    Batch [2/2], Val Loss: 0.1483\n",
      "Epoch [100/2000], Avg Train Loss: 0.4174, Avg Val Loss: 0.2682\n",
      "\n",
      "Validation loss improved from 0.2683 to 0.2682. Saving model...\n",
      "LOG: Epoch [101/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4104\n",
      "LOG: Epoch [101/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3881\n",
      "    Batch [2/2], Val Loss: 0.1477\n",
      "Epoch [101/2000], Avg Train Loss: 0.4147, Avg Val Loss: 0.2679\n",
      "\n",
      "Validation loss improved from 0.2682 to 0.2679. Saving model...\n",
      "LOG: Epoch [102/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4215\n",
      "    Batch [2/2], Train Loss: 0.4145\n",
      "LOG: Epoch [102/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3882\n",
      "    Batch [2/2], Val Loss: 0.1469\n",
      "Epoch [102/2000], Avg Train Loss: 0.4180, Avg Val Loss: 0.2676\n",
      "\n",
      "Validation loss improved from 0.2679 to 0.2676. Saving model...\n",
      "LOG: Epoch [103/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4147\n",
      "LOG: Epoch [103/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3883\n",
      "    Batch [2/2], Val Loss: 0.1466\n",
      "Epoch [103/2000], Avg Train Loss: 0.4167, Avg Val Loss: 0.2674\n",
      "\n",
      "Validation loss improved from 0.2676 to 0.2674. Saving model...\n",
      "LOG: Epoch [104/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4191\n",
      "    Batch [2/2], Train Loss: 0.4183\n",
      "LOG: Epoch [104/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3883\n",
      "    Batch [2/2], Val Loss: 0.1467\n",
      "Epoch [104/2000], Avg Train Loss: 0.4187, Avg Val Loss: 0.2675\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [105/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4143\n",
      "LOG: Epoch [105/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3883\n",
      "    Batch [2/2], Val Loss: 0.1465\n",
      "Epoch [105/2000], Avg Train Loss: 0.4159, Avg Val Loss: 0.2674\n",
      "\n",
      "Validation loss improved from 0.2674 to 0.2674. Saving model...\n",
      "LOG: Epoch [106/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4230\n",
      "    Batch [2/2], Train Loss: 0.4143\n",
      "LOG: Epoch [106/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3885\n",
      "    Batch [2/2], Val Loss: 0.1462\n",
      "Epoch [106/2000], Avg Train Loss: 0.4187, Avg Val Loss: 0.2673\n",
      "\n",
      "Validation loss improved from 0.2674 to 0.2673. Saving model...\n",
      "LOG: Epoch [107/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4143\n",
      "LOG: Epoch [107/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3884\n",
      "    Batch [2/2], Val Loss: 0.1467\n",
      "Epoch [107/2000], Avg Train Loss: 0.4165, Avg Val Loss: 0.2675\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [108/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4189\n",
      "    Batch [2/2], Train Loss: 0.4183\n",
      "LOG: Epoch [108/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3885\n",
      "    Batch [2/2], Val Loss: 0.1463\n",
      "Epoch [108/2000], Avg Train Loss: 0.4186, Avg Val Loss: 0.2674\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [109/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4222\n",
      "LOG: Epoch [109/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3889\n",
      "    Batch [2/2], Val Loss: 0.1452\n",
      "Epoch [109/2000], Avg Train Loss: 0.4211, Avg Val Loss: 0.2670\n",
      "\n",
      "Validation loss improved from 0.2673 to 0.2670. Saving model...\n",
      "LOG: Epoch [110/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4159\n",
      "    Batch [2/2], Train Loss: 0.4143\n",
      "LOG: Epoch [110/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3887\n",
      "    Batch [2/2], Val Loss: 0.1455\n",
      "Epoch [110/2000], Avg Train Loss: 0.4151, Avg Val Loss: 0.2671\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [111/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4183\n",
      "LOG: Epoch [111/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3885\n",
      "    Batch [2/2], Val Loss: 0.1459\n",
      "Epoch [111/2000], Avg Train Loss: 0.4161, Avg Val Loss: 0.2672\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [112/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4101\n",
      "    Batch [2/2], Train Loss: 0.4110\n",
      "LOG: Epoch [112/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3885\n",
      "    Batch [2/2], Val Loss: 0.1460\n",
      "Epoch [112/2000], Avg Train Loss: 0.4105, Avg Val Loss: 0.2673\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [113/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4174\n",
      "LOG: Epoch [113/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3884\n",
      "    Batch [2/2], Val Loss: 0.1459\n",
      "Epoch [113/2000], Avg Train Loss: 0.4175, Avg Val Loss: 0.2672\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [114/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4120\n",
      "    Batch [2/2], Train Loss: 0.4201\n",
      "LOG: Epoch [114/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3882\n",
      "    Batch [2/2], Val Loss: 0.1464\n",
      "Epoch [114/2000], Avg Train Loss: 0.4161, Avg Val Loss: 0.2673\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [115/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4199\n",
      "LOG: Epoch [115/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3881\n",
      "    Batch [2/2], Val Loss: 0.1465\n",
      "Epoch [115/2000], Avg Train Loss: 0.4198, Avg Val Loss: 0.2673\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [116/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4192\n",
      "    Batch [2/2], Train Loss: 0.4168\n",
      "LOG: Epoch [116/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3876\n",
      "    Batch [2/2], Val Loss: 0.1469\n",
      "Epoch [116/2000], Avg Train Loss: 0.4180, Avg Val Loss: 0.2673\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [117/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4134\n",
      "LOG: Epoch [117/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3873\n",
      "    Batch [2/2], Val Loss: 0.1474\n",
      "Epoch [117/2000], Avg Train Loss: 0.4162, Avg Val Loss: 0.2674\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [118/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4155\n",
      "    Batch [2/2], Train Loss: 0.4161\n",
      "LOG: Epoch [118/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3871\n",
      "    Batch [2/2], Val Loss: 0.1477\n",
      "Epoch [118/2000], Avg Train Loss: 0.4158, Avg Val Loss: 0.2674\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [119/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4183\n",
      "LOG: Epoch [119/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3869\n",
      "    Batch [2/2], Val Loss: 0.1478\n",
      "Epoch [119/2000], Avg Train Loss: 0.4164, Avg Val Loss: 0.2674\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [120/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4161\n",
      "    Batch [2/2], Train Loss: 0.4163\n",
      "LOG: Epoch [120/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3870\n",
      "    Batch [2/2], Val Loss: 0.1479\n",
      "Epoch [120/2000], Avg Train Loss: 0.4162, Avg Val Loss: 0.2674\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [121/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4112\n",
      "LOG: Epoch [121/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3870\n",
      "    Batch [2/2], Val Loss: 0.1473\n",
      "Epoch [121/2000], Avg Train Loss: 0.4128, Avg Val Loss: 0.2672\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [122/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4117\n",
      "    Batch [2/2], Train Loss: 0.4128\n",
      "LOG: Epoch [122/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3871\n",
      "    Batch [2/2], Val Loss: 0.1473\n",
      "Epoch [122/2000], Avg Train Loss: 0.4122, Avg Val Loss: 0.2672\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [123/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4135\n",
      "    Batch [2/2], Train Loss: 0.4150\n",
      "LOG: Epoch [123/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3870\n",
      "    Batch [2/2], Val Loss: 0.1472\n",
      "Epoch [123/2000], Avg Train Loss: 0.4143, Avg Val Loss: 0.2671\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [124/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4177\n",
      "LOG: Epoch [124/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3871\n",
      "    Batch [2/2], Val Loss: 0.1470\n",
      "Epoch [124/2000], Avg Train Loss: 0.4197, Avg Val Loss: 0.2670\n",
      "\n",
      "Validation loss improved from 0.2670 to 0.2670. Saving model...\n",
      "LOG: Epoch [125/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4169\n",
      "    Batch [2/2], Train Loss: 0.4130\n",
      "LOG: Epoch [125/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3873\n",
      "    Batch [2/2], Val Loss: 0.1464\n",
      "Epoch [125/2000], Avg Train Loss: 0.4150, Avg Val Loss: 0.2669\n",
      "\n",
      "Validation loss improved from 0.2670 to 0.2669. Saving model...\n",
      "LOG: Epoch [126/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4146\n",
      "LOG: Epoch [126/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3873\n",
      "    Batch [2/2], Val Loss: 0.1470\n",
      "Epoch [126/2000], Avg Train Loss: 0.4140, Avg Val Loss: 0.2671\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [127/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4177\n",
      "    Batch [2/2], Train Loss: 0.4110\n",
      "LOG: Epoch [127/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3874\n",
      "    Batch [2/2], Val Loss: 0.1467\n",
      "Epoch [127/2000], Avg Train Loss: 0.4143, Avg Val Loss: 0.2671\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [128/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4176\n",
      "LOG: Epoch [128/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3874\n",
      "    Batch [2/2], Val Loss: 0.1465\n",
      "Epoch [128/2000], Avg Train Loss: 0.4180, Avg Val Loss: 0.2670\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [129/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4167\n",
      "    Batch [2/2], Train Loss: 0.4131\n",
      "LOG: Epoch [129/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3871\n",
      "    Batch [2/2], Val Loss: 0.1467\n",
      "Epoch [129/2000], Avg Train Loss: 0.4149, Avg Val Loss: 0.2669\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [130/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4058\n",
      "LOG: Epoch [130/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3869\n",
      "    Batch [2/2], Val Loss: 0.1474\n",
      "Epoch [130/2000], Avg Train Loss: 0.4089, Avg Val Loss: 0.2671\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [131/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4178\n",
      "    Batch [2/2], Train Loss: 0.4107\n",
      "LOG: Epoch [131/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3867\n",
      "    Batch [2/2], Val Loss: 0.1473\n",
      "Epoch [131/2000], Avg Train Loss: 0.4143, Avg Val Loss: 0.2670\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [132/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4159\n",
      "LOG: Epoch [132/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3866\n",
      "    Batch [2/2], Val Loss: 0.1474\n",
      "Epoch [132/2000], Avg Train Loss: 0.4115, Avg Val Loss: 0.2670\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [133/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4153\n",
      "    Batch [2/2], Train Loss: 0.4117\n",
      "LOG: Epoch [133/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3866\n",
      "    Batch [2/2], Val Loss: 0.1472\n",
      "Epoch [133/2000], Avg Train Loss: 0.4135, Avg Val Loss: 0.2669\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [134/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4139\n",
      "LOG: Epoch [134/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3865\n",
      "    Batch [2/2], Val Loss: 0.1468\n",
      "Epoch [134/2000], Avg Train Loss: 0.4153, Avg Val Loss: 0.2667\n",
      "\n",
      "Validation loss improved from 0.2669 to 0.2667. Saving model...\n",
      "LOG: Epoch [135/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4129\n",
      "LOG: Epoch [135/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3865\n",
      "    Batch [2/2], Val Loss: 0.1463\n",
      "Epoch [135/2000], Avg Train Loss: 0.4152, Avg Val Loss: 0.2664\n",
      "\n",
      "Validation loss improved from 0.2667 to 0.2664. Saving model...\n",
      "LOG: Epoch [136/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4168\n",
      "LOG: Epoch [136/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3867\n",
      "    Batch [2/2], Val Loss: 0.1455\n",
      "Epoch [136/2000], Avg Train Loss: 0.4148, Avg Val Loss: 0.2661\n",
      "\n",
      "Validation loss improved from 0.2664 to 0.2661. Saving model...\n",
      "LOG: Epoch [137/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4119\n",
      "LOG: Epoch [137/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3867\n",
      "    Batch [2/2], Val Loss: 0.1453\n",
      "Epoch [137/2000], Avg Train Loss: 0.4124, Avg Val Loss: 0.2660\n",
      "\n",
      "Validation loss improved from 0.2661 to 0.2660. Saving model...\n",
      "LOG: Epoch [138/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4177\n",
      "LOG: Epoch [138/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3867\n",
      "    Batch [2/2], Val Loss: 0.1445\n",
      "Epoch [138/2000], Avg Train Loss: 0.4163, Avg Val Loss: 0.2656\n",
      "\n",
      "Validation loss improved from 0.2660 to 0.2656. Saving model...\n",
      "LOG: Epoch [139/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4145\n",
      "LOG: Epoch [139/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3866\n",
      "    Batch [2/2], Val Loss: 0.1443\n",
      "Epoch [139/2000], Avg Train Loss: 0.4137, Avg Val Loss: 0.2654\n",
      "\n",
      "Validation loss improved from 0.2656 to 0.2654. Saving model...\n",
      "LOG: Epoch [140/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4075\n",
      "LOG: Epoch [140/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3865\n",
      "    Batch [2/2], Val Loss: 0.1444\n",
      "Epoch [140/2000], Avg Train Loss: 0.4099, Avg Val Loss: 0.2655\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [141/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4086\n",
      "LOG: Epoch [141/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3866\n",
      "    Batch [2/2], Val Loss: 0.1440\n",
      "Epoch [141/2000], Avg Train Loss: 0.4109, Avg Val Loss: 0.2653\n",
      "\n",
      "Validation loss improved from 0.2654 to 0.2653. Saving model...\n",
      "LOG: Epoch [142/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4216\n",
      "LOG: Epoch [142/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3864\n",
      "    Batch [2/2], Val Loss: 0.1436\n",
      "Epoch [142/2000], Avg Train Loss: 0.4163, Avg Val Loss: 0.2650\n",
      "\n",
      "Validation loss improved from 0.2653 to 0.2650. Saving model...\n",
      "LOG: Epoch [143/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4147\n",
      "LOG: Epoch [143/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3862\n",
      "    Batch [2/2], Val Loss: 0.1435\n",
      "Epoch [143/2000], Avg Train Loss: 0.4151, Avg Val Loss: 0.2649\n",
      "\n",
      "Validation loss improved from 0.2650 to 0.2649. Saving model...\n",
      "LOG: Epoch [144/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4120\n",
      "LOG: Epoch [144/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3860\n",
      "    Batch [2/2], Val Loss: 0.1430\n",
      "Epoch [144/2000], Avg Train Loss: 0.4118, Avg Val Loss: 0.2645\n",
      "\n",
      "Validation loss improved from 0.2649 to 0.2645. Saving model...\n",
      "LOG: Epoch [145/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4148\n",
      "LOG: Epoch [145/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3857\n",
      "    Batch [2/2], Val Loss: 0.1436\n",
      "Epoch [145/2000], Avg Train Loss: 0.4152, Avg Val Loss: 0.2647\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [146/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4077\n",
      "    Batch [2/2], Train Loss: 0.4184\n",
      "LOG: Epoch [146/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3853\n",
      "    Batch [2/2], Val Loss: 0.1445\n",
      "Epoch [146/2000], Avg Train Loss: 0.4130, Avg Val Loss: 0.2649\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [147/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4144\n",
      "LOG: Epoch [147/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3853\n",
      "    Batch [2/2], Val Loss: 0.1438\n",
      "Epoch [147/2000], Avg Train Loss: 0.4147, Avg Val Loss: 0.2645\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [148/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4117\n",
      "LOG: Epoch [148/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3852\n",
      "    Batch [2/2], Val Loss: 0.1440\n",
      "Epoch [148/2000], Avg Train Loss: 0.4127, Avg Val Loss: 0.2646\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [149/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4137\n",
      "    Batch [2/2], Train Loss: 0.4083\n",
      "LOG: Epoch [149/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3852\n",
      "    Batch [2/2], Val Loss: 0.1443\n",
      "Epoch [149/2000], Avg Train Loss: 0.4110, Avg Val Loss: 0.2648\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [150/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4133\n",
      "    Batch [2/2], Train Loss: 0.4108\n",
      "LOG: Epoch [150/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3850\n",
      "    Batch [2/2], Val Loss: 0.1443\n",
      "Epoch [150/2000], Avg Train Loss: 0.4120, Avg Val Loss: 0.2646\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [151/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4143\n",
      "    Batch [2/2], Train Loss: 0.4090\n",
      "LOG: Epoch [151/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3848\n",
      "    Batch [2/2], Val Loss: 0.1442\n",
      "Epoch [151/2000], Avg Train Loss: 0.4117, Avg Val Loss: 0.2645\n",
      "\n",
      "Validation loss improved from 0.2645 to 0.2645. Saving model...\n",
      "LOG: Epoch [152/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4161\n",
      "LOG: Epoch [152/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3845\n",
      "    Batch [2/2], Val Loss: 0.1444\n",
      "Epoch [152/2000], Avg Train Loss: 0.4144, Avg Val Loss: 0.2644\n",
      "\n",
      "Validation loss improved from 0.2645 to 0.2644. Saving model...\n",
      "LOG: Epoch [153/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4115\n",
      "LOG: Epoch [153/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3840\n",
      "    Batch [2/2], Val Loss: 0.1446\n",
      "Epoch [153/2000], Avg Train Loss: 0.4107, Avg Val Loss: 0.2643\n",
      "\n",
      "Validation loss improved from 0.2644 to 0.2643. Saving model...\n",
      "LOG: Epoch [154/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4111\n",
      "    Batch [2/2], Train Loss: 0.4116\n",
      "LOG: Epoch [154/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3837\n",
      "    Batch [2/2], Val Loss: 0.1443\n",
      "Epoch [154/2000], Avg Train Loss: 0.4113, Avg Val Loss: 0.2640\n",
      "\n",
      "Validation loss improved from 0.2643 to 0.2640. Saving model...\n",
      "LOG: Epoch [155/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4150\n",
      "LOG: Epoch [155/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3837\n",
      "    Batch [2/2], Val Loss: 0.1439\n",
      "Epoch [155/2000], Avg Train Loss: 0.4160, Avg Val Loss: 0.2638\n",
      "\n",
      "Validation loss improved from 0.2640 to 0.2638. Saving model...\n",
      "LOG: Epoch [156/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4122\n",
      "    Batch [2/2], Train Loss: 0.4185\n",
      "LOG: Epoch [156/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3837\n",
      "    Batch [2/2], Val Loss: 0.1436\n",
      "Epoch [156/2000], Avg Train Loss: 0.4154, Avg Val Loss: 0.2636\n",
      "\n",
      "Validation loss improved from 0.2638 to 0.2636. Saving model...\n",
      "LOG: Epoch [157/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4092\n",
      "    Batch [2/2], Train Loss: 0.4109\n",
      "LOG: Epoch [157/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3837\n",
      "    Batch [2/2], Val Loss: 0.1433\n",
      "Epoch [157/2000], Avg Train Loss: 0.4101, Avg Val Loss: 0.2635\n",
      "\n",
      "Validation loss improved from 0.2636 to 0.2635. Saving model...\n",
      "LOG: Epoch [158/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4147\n",
      "LOG: Epoch [158/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3838\n",
      "    Batch [2/2], Val Loss: 0.1433\n",
      "Epoch [158/2000], Avg Train Loss: 0.4124, Avg Val Loss: 0.2636\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [159/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4140\n",
      "    Batch [2/2], Train Loss: 0.4128\n",
      "LOG: Epoch [159/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3840\n",
      "    Batch [2/2], Val Loss: 0.1431\n",
      "Epoch [159/2000], Avg Train Loss: 0.4134, Avg Val Loss: 0.2635\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [160/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4134\n",
      "    Batch [2/2], Train Loss: 0.4157\n",
      "LOG: Epoch [160/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3840\n",
      "    Batch [2/2], Val Loss: 0.1431\n",
      "Epoch [160/2000], Avg Train Loss: 0.4146, Avg Val Loss: 0.2635\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [161/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4128\n",
      "    Batch [2/2], Train Loss: 0.4131\n",
      "LOG: Epoch [161/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3839\n",
      "    Batch [2/2], Val Loss: 0.1436\n",
      "Epoch [161/2000], Avg Train Loss: 0.4130, Avg Val Loss: 0.2637\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [162/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4101\n",
      "LOG: Epoch [162/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3841\n",
      "    Batch [2/2], Val Loss: 0.1434\n",
      "Epoch [162/2000], Avg Train Loss: 0.4134, Avg Val Loss: 0.2637\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [163/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4158\n",
      "    Batch [2/2], Train Loss: 0.4097\n",
      "LOG: Epoch [163/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3842\n",
      "    Batch [2/2], Val Loss: 0.1433\n",
      "Epoch [163/2000], Avg Train Loss: 0.4128, Avg Val Loss: 0.2637\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [164/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4126\n",
      "    Batch [2/2], Train Loss: 0.4075\n",
      "LOG: Epoch [164/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3842\n",
      "    Batch [2/2], Val Loss: 0.1434\n",
      "Epoch [164/2000], Avg Train Loss: 0.4101, Avg Val Loss: 0.2638\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [165/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4081\n",
      "    Batch [2/2], Train Loss: 0.4082\n",
      "LOG: Epoch [165/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3841\n",
      "    Batch [2/2], Val Loss: 0.1437\n",
      "Epoch [165/2000], Avg Train Loss: 0.4082, Avg Val Loss: 0.2639\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [166/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4134\n",
      "    Batch [2/2], Train Loss: 0.4149\n",
      "LOG: Epoch [166/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3843\n",
      "    Batch [2/2], Val Loss: 0.1433\n",
      "Epoch [166/2000], Avg Train Loss: 0.4141, Avg Val Loss: 0.2638\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [167/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4104\n",
      "LOG: Epoch [167/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3842\n",
      "    Batch [2/2], Val Loss: 0.1431\n",
      "Epoch [167/2000], Avg Train Loss: 0.4147, Avg Val Loss: 0.2636\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [168/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4168\n",
      "    Batch [2/2], Train Loss: 0.4064\n",
      "LOG: Epoch [168/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3843\n",
      "    Batch [2/2], Val Loss: 0.1430\n",
      "Epoch [168/2000], Avg Train Loss: 0.4116, Avg Val Loss: 0.2637\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [169/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4146\n",
      "LOG: Epoch [169/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3843\n",
      "    Batch [2/2], Val Loss: 0.1429\n",
      "Epoch [169/2000], Avg Train Loss: 0.4127, Avg Val Loss: 0.2636\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [170/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4110\n",
      "LOG: Epoch [170/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3844\n",
      "    Batch [2/2], Val Loss: 0.1424\n",
      "Epoch [170/2000], Avg Train Loss: 0.4118, Avg Val Loss: 0.2634\n",
      "\n",
      "Validation loss improved from 0.2635 to 0.2634. Saving model...\n",
      "LOG: Epoch [171/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4061\n",
      "    Batch [2/2], Train Loss: 0.4135\n",
      "LOG: Epoch [171/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3844\n",
      "    Batch [2/2], Val Loss: 0.1428\n",
      "Epoch [171/2000], Avg Train Loss: 0.4098, Avg Val Loss: 0.2636\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [172/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4130\n",
      "LOG: Epoch [172/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3844\n",
      "    Batch [2/2], Val Loss: 0.1429\n",
      "Epoch [172/2000], Avg Train Loss: 0.4123, Avg Val Loss: 0.2636\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [173/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4157\n",
      "    Batch [2/2], Train Loss: 0.4063\n",
      "LOG: Epoch [173/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3844\n",
      "    Batch [2/2], Val Loss: 0.1431\n",
      "Epoch [173/2000], Avg Train Loss: 0.4110, Avg Val Loss: 0.2637\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [174/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4118\n",
      "    Batch [2/2], Train Loss: 0.4087\n",
      "LOG: Epoch [174/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3844\n",
      "    Batch [2/2], Val Loss: 0.1424\n",
      "Epoch [174/2000], Avg Train Loss: 0.4103, Avg Val Loss: 0.2634\n",
      "\n",
      "Validation loss improved from 0.2634 to 0.2634. Saving model...\n",
      "LOG: Epoch [175/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4101\n",
      "LOG: Epoch [175/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3844\n",
      "    Batch [2/2], Val Loss: 0.1423\n",
      "Epoch [175/2000], Avg Train Loss: 0.4083, Avg Val Loss: 0.2634\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [176/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4081\n",
      "    Batch [2/2], Train Loss: 0.4077\n",
      "LOG: Epoch [176/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3844\n",
      "    Batch [2/2], Val Loss: 0.1420\n",
      "Epoch [176/2000], Avg Train Loss: 0.4079, Avg Val Loss: 0.2632\n",
      "\n",
      "Validation loss improved from 0.2634 to 0.2632. Saving model...\n",
      "LOG: Epoch [177/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4111\n",
      "LOG: Epoch [177/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3842\n",
      "    Batch [2/2], Val Loss: 0.1416\n",
      "Epoch [177/2000], Avg Train Loss: 0.4097, Avg Val Loss: 0.2629\n",
      "\n",
      "Validation loss improved from 0.2632 to 0.2629. Saving model...\n",
      "LOG: Epoch [178/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4085\n",
      "    Batch [2/2], Train Loss: 0.4088\n",
      "LOG: Epoch [178/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3838\n",
      "    Batch [2/2], Val Loss: 0.1418\n",
      "Epoch [178/2000], Avg Train Loss: 0.4086, Avg Val Loss: 0.2628\n",
      "\n",
      "Validation loss improved from 0.2629 to 0.2628. Saving model...\n",
      "LOG: Epoch [179/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4142\n",
      "    Batch [2/2], Train Loss: 0.4105\n",
      "LOG: Epoch [179/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3835\n",
      "    Batch [2/2], Val Loss: 0.1417\n",
      "Epoch [179/2000], Avg Train Loss: 0.4124, Avg Val Loss: 0.2626\n",
      "\n",
      "Validation loss improved from 0.2628 to 0.2626. Saving model...\n",
      "LOG: Epoch [180/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4090\n",
      "LOG: Epoch [180/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3833\n",
      "    Batch [2/2], Val Loss: 0.1417\n",
      "Epoch [180/2000], Avg Train Loss: 0.4078, Avg Val Loss: 0.2625\n",
      "\n",
      "Validation loss improved from 0.2626 to 0.2625. Saving model...\n",
      "LOG: Epoch [181/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4108\n",
      "    Batch [2/2], Train Loss: 0.4105\n",
      "LOG: Epoch [181/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3830\n",
      "    Batch [2/2], Val Loss: 0.1418\n",
      "Epoch [181/2000], Avg Train Loss: 0.4107, Avg Val Loss: 0.2624\n",
      "\n",
      "Validation loss improved from 0.2625 to 0.2624. Saving model...\n",
      "LOG: Epoch [182/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4129\n",
      "    Batch [2/2], Train Loss: 0.4104\n",
      "LOG: Epoch [182/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3830\n",
      "    Batch [2/2], Val Loss: 0.1411\n",
      "Epoch [182/2000], Avg Train Loss: 0.4117, Avg Val Loss: 0.2620\n",
      "\n",
      "Validation loss improved from 0.2624 to 0.2620. Saving model...\n",
      "LOG: Epoch [183/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4120\n",
      "    Batch [2/2], Train Loss: 0.4113\n",
      "LOG: Epoch [183/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3828\n",
      "    Batch [2/2], Val Loss: 0.1409\n",
      "Epoch [183/2000], Avg Train Loss: 0.4116, Avg Val Loss: 0.2619\n",
      "\n",
      "Validation loss improved from 0.2620 to 0.2619. Saving model...\n",
      "LOG: Epoch [184/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4128\n",
      "LOG: Epoch [184/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3825\n",
      "    Batch [2/2], Val Loss: 0.1408\n",
      "Epoch [184/2000], Avg Train Loss: 0.4150, Avg Val Loss: 0.2616\n",
      "\n",
      "Validation loss improved from 0.2619 to 0.2616. Saving model...\n",
      "LOG: Epoch [185/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4043\n",
      "    Batch [2/2], Train Loss: 0.4128\n",
      "LOG: Epoch [185/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3822\n",
      "    Batch [2/2], Val Loss: 0.1409\n",
      "Epoch [185/2000], Avg Train Loss: 0.4086, Avg Val Loss: 0.2616\n",
      "\n",
      "Validation loss improved from 0.2616 to 0.2616. Saving model...\n",
      "LOG: Epoch [186/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4077\n",
      "LOG: Epoch [186/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3821\n",
      "    Batch [2/2], Val Loss: 0.1408\n",
      "Epoch [186/2000], Avg Train Loss: 0.4117, Avg Val Loss: 0.2614\n",
      "\n",
      "Validation loss improved from 0.2616 to 0.2614. Saving model...\n",
      "LOG: Epoch [187/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4154\n",
      "    Batch [2/2], Train Loss: 0.4137\n",
      "LOG: Epoch [187/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3818\n",
      "    Batch [2/2], Val Loss: 0.1410\n",
      "Epoch [187/2000], Avg Train Loss: 0.4145, Avg Val Loss: 0.2614\n",
      "\n",
      "Validation loss improved from 0.2614 to 0.2614. Saving model...\n",
      "LOG: Epoch [188/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4097\n",
      "    Batch [2/2], Train Loss: 0.4115\n",
      "LOG: Epoch [188/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3819\n",
      "    Batch [2/2], Val Loss: 0.1402\n",
      "Epoch [188/2000], Avg Train Loss: 0.4106, Avg Val Loss: 0.2611\n",
      "\n",
      "Validation loss improved from 0.2614 to 0.2611. Saving model...\n",
      "LOG: Epoch [189/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4119\n",
      "    Batch [2/2], Train Loss: 0.4063\n",
      "LOG: Epoch [189/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3818\n",
      "    Batch [2/2], Val Loss: 0.1401\n",
      "Epoch [189/2000], Avg Train Loss: 0.4091, Avg Val Loss: 0.2609\n",
      "\n",
      "Validation loss improved from 0.2611 to 0.2609. Saving model...\n",
      "LOG: Epoch [190/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4097\n",
      "LOG: Epoch [190/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3816\n",
      "    Batch [2/2], Val Loss: 0.1408\n",
      "Epoch [190/2000], Avg Train Loss: 0.4090, Avg Val Loss: 0.2612\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [191/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4075\n",
      "    Batch [2/2], Train Loss: 0.4079\n",
      "LOG: Epoch [191/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3815\n",
      "    Batch [2/2], Val Loss: 0.1405\n",
      "Epoch [191/2000], Avg Train Loss: 0.4077, Avg Val Loss: 0.2610\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [192/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4148\n",
      "LOG: Epoch [192/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3815\n",
      "    Batch [2/2], Val Loss: 0.1407\n",
      "Epoch [192/2000], Avg Train Loss: 0.4125, Avg Val Loss: 0.2611\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [193/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4098\n",
      "    Batch [2/2], Train Loss: 0.4077\n",
      "LOG: Epoch [193/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3817\n",
      "    Batch [2/2], Val Loss: 0.1405\n",
      "Epoch [193/2000], Avg Train Loss: 0.4088, Avg Val Loss: 0.2611\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [194/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4059\n",
      "LOG: Epoch [194/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3817\n",
      "    Batch [2/2], Val Loss: 0.1402\n",
      "Epoch [194/2000], Avg Train Loss: 0.4068, Avg Val Loss: 0.2609\n",
      "\n",
      "Validation loss improved from 0.2609 to 0.2609. Saving model...\n",
      "LOG: Epoch [195/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4077\n",
      "    Batch [2/2], Train Loss: 0.4091\n",
      "LOG: Epoch [195/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3815\n",
      "    Batch [2/2], Val Loss: 0.1401\n",
      "Epoch [195/2000], Avg Train Loss: 0.4084, Avg Val Loss: 0.2608\n",
      "\n",
      "Validation loss improved from 0.2609 to 0.2608. Saving model...\n",
      "LOG: Epoch [196/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4116\n",
      "    Batch [2/2], Train Loss: 0.4142\n",
      "LOG: Epoch [196/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3813\n",
      "    Batch [2/2], Val Loss: 0.1403\n",
      "Epoch [196/2000], Avg Train Loss: 0.4129, Avg Val Loss: 0.2608\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [197/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4088\n",
      "    Batch [2/2], Train Loss: 0.4186\n",
      "LOG: Epoch [197/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3810\n",
      "    Batch [2/2], Val Loss: 0.1401\n",
      "Epoch [197/2000], Avg Train Loss: 0.4137, Avg Val Loss: 0.2606\n",
      "\n",
      "Validation loss improved from 0.2608 to 0.2606. Saving model...\n",
      "LOG: Epoch [198/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4063\n",
      "LOG: Epoch [198/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3808\n",
      "    Batch [2/2], Val Loss: 0.1398\n",
      "Epoch [198/2000], Avg Train Loss: 0.4071, Avg Val Loss: 0.2603\n",
      "\n",
      "Validation loss improved from 0.2606 to 0.2603. Saving model...\n",
      "LOG: Epoch [199/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4064\n",
      "    Batch [2/2], Train Loss: 0.4090\n",
      "LOG: Epoch [199/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.1400\n",
      "Epoch [199/2000], Avg Train Loss: 0.4077, Avg Val Loss: 0.2603\n",
      "\n",
      "Validation loss improved from 0.2603 to 0.2603. Saving model...\n",
      "LOG: Epoch [200/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4069\n",
      "LOG: Epoch [200/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3805\n",
      "    Batch [2/2], Val Loss: 0.1401\n",
      "Epoch [200/2000], Avg Train Loss: 0.4082, Avg Val Loss: 0.2603\n",
      "\n",
      "Validation loss improved from 0.2603 to 0.2603. Saving model...\n",
      "LOG: Epoch [201/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4088\n",
      "    Batch [2/2], Train Loss: 0.4078\n",
      "LOG: Epoch [201/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3805\n",
      "    Batch [2/2], Val Loss: 0.1402\n",
      "Epoch [201/2000], Avg Train Loss: 0.4083, Avg Val Loss: 0.2603\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [202/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4066\n",
      "LOG: Epoch [202/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3803\n",
      "    Batch [2/2], Val Loss: 0.1408\n",
      "Epoch [202/2000], Avg Train Loss: 0.4073, Avg Val Loss: 0.2605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [203/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4082\n",
      "LOG: Epoch [203/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3802\n",
      "    Batch [2/2], Val Loss: 0.1407\n",
      "Epoch [203/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [204/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4062\n",
      "    Batch [2/2], Train Loss: 0.4046\n",
      "LOG: Epoch [204/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3803\n",
      "    Batch [2/2], Val Loss: 0.1406\n",
      "Epoch [204/2000], Avg Train Loss: 0.4054, Avg Val Loss: 0.2604\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [205/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4097\n",
      "LOG: Epoch [205/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3802\n",
      "    Batch [2/2], Val Loss: 0.1401\n",
      "Epoch [205/2000], Avg Train Loss: 0.4073, Avg Val Loss: 0.2602\n",
      "\n",
      "Validation loss improved from 0.2603 to 0.2602. Saving model...\n",
      "LOG: Epoch [206/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4040\n",
      "    Batch [2/2], Train Loss: 0.4087\n",
      "LOG: Epoch [206/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3803\n",
      "    Batch [2/2], Val Loss: 0.1401\n",
      "Epoch [206/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [207/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4088\n",
      "LOG: Epoch [207/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3806\n",
      "    Batch [2/2], Val Loss: 0.1397\n",
      "Epoch [207/2000], Avg Train Loss: 0.4103, Avg Val Loss: 0.2602\n",
      "\n",
      "Validation loss improved from 0.2602 to 0.2602. Saving model...\n",
      "LOG: Epoch [208/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4100\n",
      "    Batch [2/2], Train Loss: 0.4090\n",
      "LOG: Epoch [208/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.1393\n",
      "Epoch [208/2000], Avg Train Loss: 0.4095, Avg Val Loss: 0.2600\n",
      "\n",
      "Validation loss improved from 0.2602 to 0.2600. Saving model...\n",
      "LOG: Epoch [209/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4051\n",
      "LOG: Epoch [209/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3806\n",
      "    Batch [2/2], Val Loss: 0.1391\n",
      "Epoch [209/2000], Avg Train Loss: 0.4075, Avg Val Loss: 0.2598\n",
      "\n",
      "Validation loss improved from 0.2600 to 0.2598. Saving model...\n",
      "LOG: Epoch [210/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4029\n",
      "    Batch [2/2], Train Loss: 0.4025\n",
      "LOG: Epoch [210/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3804\n",
      "    Batch [2/2], Val Loss: 0.1392\n",
      "Epoch [210/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2598\n",
      "\n",
      "Validation loss improved from 0.2598 to 0.2598. Saving model...\n",
      "LOG: Epoch [211/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4063\n",
      "LOG: Epoch [211/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3805\n",
      "    Batch [2/2], Val Loss: 0.1390\n",
      "Epoch [211/2000], Avg Train Loss: 0.4085, Avg Val Loss: 0.2598\n",
      "\n",
      "Validation loss improved from 0.2598 to 0.2598. Saving model...\n",
      "LOG: Epoch [212/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4089\n",
      "LOG: Epoch [212/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3804\n",
      "    Batch [2/2], Val Loss: 0.1389\n",
      "Epoch [212/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2597\n",
      "\n",
      "Validation loss improved from 0.2598 to 0.2597. Saving model...\n",
      "LOG: Epoch [213/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4101\n",
      "    Batch [2/2], Train Loss: 0.4000\n",
      "LOG: Epoch [213/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3801\n",
      "    Batch [2/2], Val Loss: 0.1396\n",
      "Epoch [213/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2599\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [214/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4059\n",
      "LOG: Epoch [214/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3802\n",
      "    Batch [2/2], Val Loss: 0.1391\n",
      "Epoch [214/2000], Avg Train Loss: 0.4059, Avg Val Loss: 0.2596\n",
      "\n",
      "Validation loss improved from 0.2597 to 0.2596. Saving model...\n",
      "LOG: Epoch [215/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4080\n",
      "    Batch [2/2], Train Loss: 0.4090\n",
      "LOG: Epoch [215/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3802\n",
      "    Batch [2/2], Val Loss: 0.1391\n",
      "Epoch [215/2000], Avg Train Loss: 0.4085, Avg Val Loss: 0.2596\n",
      "\n",
      "Validation loss improved from 0.2596 to 0.2596. Saving model...\n",
      "LOG: Epoch [216/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4061\n",
      "LOG: Epoch [216/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3801\n",
      "    Batch [2/2], Val Loss: 0.1387\n",
      "Epoch [216/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2594\n",
      "\n",
      "Validation loss improved from 0.2596 to 0.2594. Saving model...\n",
      "LOG: Epoch [217/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4115\n",
      "    Batch [2/2], Train Loss: 0.4059\n",
      "LOG: Epoch [217/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3799\n",
      "    Batch [2/2], Val Loss: 0.1388\n",
      "Epoch [217/2000], Avg Train Loss: 0.4087, Avg Val Loss: 0.2593\n",
      "\n",
      "Validation loss improved from 0.2594 to 0.2593. Saving model...\n",
      "LOG: Epoch [218/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4107\n",
      "LOG: Epoch [218/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3797\n",
      "    Batch [2/2], Val Loss: 0.1388\n",
      "Epoch [218/2000], Avg Train Loss: 0.4079, Avg Val Loss: 0.2592\n",
      "\n",
      "Validation loss improved from 0.2593 to 0.2592. Saving model...\n",
      "LOG: Epoch [219/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4038\n",
      "    Batch [2/2], Train Loss: 0.4081\n",
      "LOG: Epoch [219/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3794\n",
      "    Batch [2/2], Val Loss: 0.1386\n",
      "Epoch [219/2000], Avg Train Loss: 0.4060, Avg Val Loss: 0.2590\n",
      "\n",
      "Validation loss improved from 0.2592 to 0.2590. Saving model...\n",
      "LOG: Epoch [220/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4129\n",
      "LOG: Epoch [220/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3794\n",
      "    Batch [2/2], Val Loss: 0.1385\n",
      "Epoch [220/2000], Avg Train Loss: 0.4097, Avg Val Loss: 0.2589\n",
      "\n",
      "Validation loss improved from 0.2590 to 0.2589. Saving model...\n",
      "LOG: Epoch [221/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4093\n",
      "    Batch [2/2], Train Loss: 0.4031\n",
      "LOG: Epoch [221/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3793\n",
      "    Batch [2/2], Val Loss: 0.1386\n",
      "Epoch [221/2000], Avg Train Loss: 0.4062, Avg Val Loss: 0.2589\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [222/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4026\n",
      "LOG: Epoch [222/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3793\n",
      "    Batch [2/2], Val Loss: 0.1386\n",
      "Epoch [222/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2590\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [223/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4121\n",
      "    Batch [2/2], Train Loss: 0.4048\n",
      "LOG: Epoch [223/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3792\n",
      "    Batch [2/2], Val Loss: 0.1383\n",
      "Epoch [223/2000], Avg Train Loss: 0.4084, Avg Val Loss: 0.2588\n",
      "\n",
      "Validation loss improved from 0.2589 to 0.2588. Saving model...\n",
      "LOG: Epoch [224/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3980\n",
      "LOG: Epoch [224/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3788\n",
      "    Batch [2/2], Val Loss: 0.1393\n",
      "Epoch [224/2000], Avg Train Loss: 0.4022, Avg Val Loss: 0.2591\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [225/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4040\n",
      "    Batch [2/2], Train Loss: 0.4077\n",
      "LOG: Epoch [225/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3787\n",
      "    Batch [2/2], Val Loss: 0.1392\n",
      "Epoch [225/2000], Avg Train Loss: 0.4058, Avg Val Loss: 0.2590\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [226/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3999\n",
      "LOG: Epoch [226/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3787\n",
      "    Batch [2/2], Val Loss: 0.1388\n",
      "Epoch [226/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2587\n",
      "\n",
      "Validation loss improved from 0.2588 to 0.2587. Saving model...\n",
      "LOG: Epoch [227/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4089\n",
      "    Batch [2/2], Train Loss: 0.4060\n",
      "LOG: Epoch [227/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3786\n",
      "    Batch [2/2], Val Loss: 0.1384\n",
      "Epoch [227/2000], Avg Train Loss: 0.4074, Avg Val Loss: 0.2585\n",
      "\n",
      "Validation loss improved from 0.2587 to 0.2585. Saving model...\n",
      "LOG: Epoch [228/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4083\n",
      "LOG: Epoch [228/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3787\n",
      "    Batch [2/2], Val Loss: 0.1386\n",
      "Epoch [228/2000], Avg Train Loss: 0.4056, Avg Val Loss: 0.2586\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [229/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4063\n",
      "    Batch [2/2], Train Loss: 0.4034\n",
      "LOG: Epoch [229/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3783\n",
      "    Batch [2/2], Val Loss: 0.1390\n",
      "Epoch [229/2000], Avg Train Loss: 0.4048, Avg Val Loss: 0.2587\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [230/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4017\n",
      "LOG: Epoch [230/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3785\n",
      "    Batch [2/2], Val Loss: 0.1386\n",
      "Epoch [230/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2586\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [231/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4096\n",
      "    Batch [2/2], Train Loss: 0.4010\n",
      "LOG: Epoch [231/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3786\n",
      "    Batch [2/2], Val Loss: 0.1382\n",
      "Epoch [231/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2584\n",
      "\n",
      "Validation loss improved from 0.2585 to 0.2584. Saving model...\n",
      "LOG: Epoch [232/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4009\n",
      "LOG: Epoch [232/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3785\n",
      "    Batch [2/2], Val Loss: 0.1382\n",
      "Epoch [232/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2583\n",
      "\n",
      "Validation loss improved from 0.2584 to 0.2583. Saving model...\n",
      "LOG: Epoch [233/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4058\n",
      "    Batch [2/2], Train Loss: 0.3990\n",
      "LOG: Epoch [233/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3786\n",
      "    Batch [2/2], Val Loss: 0.1379\n",
      "Epoch [233/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2583\n",
      "\n",
      "Validation loss improved from 0.2583 to 0.2583. Saving model...\n",
      "LOG: Epoch [234/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4151\n",
      "LOG: Epoch [234/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3785\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [234/2000], Avg Train Loss: 0.4095, Avg Val Loss: 0.2579\n",
      "\n",
      "Validation loss improved from 0.2583 to 0.2579. Saving model...\n",
      "LOG: Epoch [235/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4049\n",
      "    Batch [2/2], Train Loss: 0.4103\n",
      "LOG: Epoch [235/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3785\n",
      "    Batch [2/2], Val Loss: 0.1367\n",
      "Epoch [235/2000], Avg Train Loss: 0.4076, Avg Val Loss: 0.2576\n",
      "\n",
      "Validation loss improved from 0.2579 to 0.2576. Saving model...\n",
      "LOG: Epoch [236/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4053\n",
      "LOG: Epoch [236/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3785\n",
      "    Batch [2/2], Val Loss: 0.1366\n",
      "Epoch [236/2000], Avg Train Loss: 0.4080, Avg Val Loss: 0.2575\n",
      "\n",
      "Validation loss improved from 0.2576 to 0.2575. Saving model...\n",
      "LOG: Epoch [237/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4116\n",
      "    Batch [2/2], Train Loss: 0.4088\n",
      "LOG: Epoch [237/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3783\n",
      "    Batch [2/2], Val Loss: 0.1367\n",
      "Epoch [237/2000], Avg Train Loss: 0.4102, Avg Val Loss: 0.2575\n",
      "\n",
      "Validation loss improved from 0.2575 to 0.2575. Saving model...\n",
      "LOG: Epoch [238/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4064\n",
      "    Batch [2/2], Train Loss: 0.4091\n",
      "LOG: Epoch [238/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3782\n",
      "    Batch [2/2], Val Loss: 0.1363\n",
      "Epoch [238/2000], Avg Train Loss: 0.4078, Avg Val Loss: 0.2572\n",
      "\n",
      "Validation loss improved from 0.2575 to 0.2572. Saving model...\n",
      "LOG: Epoch [239/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4080\n",
      "LOG: Epoch [239/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3779\n",
      "    Batch [2/2], Val Loss: 0.1367\n",
      "Epoch [239/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2573\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [240/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4042\n",
      "    Batch [2/2], Train Loss: 0.4028\n",
      "LOG: Epoch [240/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3777\n",
      "    Batch [2/2], Val Loss: 0.1372\n",
      "Epoch [240/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2575\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [241/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3996\n",
      "LOG: Epoch [241/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3774\n",
      "    Batch [2/2], Val Loss: 0.1374\n",
      "Epoch [241/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2574\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [242/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4049\n",
      "    Batch [2/2], Train Loss: 0.3987\n",
      "LOG: Epoch [242/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3772\n",
      "    Batch [2/2], Val Loss: 0.1376\n",
      "Epoch [242/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2574\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [243/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4100\n",
      "LOG: Epoch [243/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3771\n",
      "    Batch [2/2], Val Loss: 0.1376\n",
      "Epoch [243/2000], Avg Train Loss: 0.4072, Avg Val Loss: 0.2573\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [244/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4047\n",
      "    Batch [2/2], Train Loss: 0.3990\n",
      "LOG: Epoch [244/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3770\n",
      "    Batch [2/2], Val Loss: 0.1380\n",
      "Epoch [244/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2575\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [245/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4044\n",
      "LOG: Epoch [245/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3771\n",
      "    Batch [2/2], Val Loss: 0.1375\n",
      "Epoch [245/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2573\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [246/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4071\n",
      "    Batch [2/2], Train Loss: 0.4016\n",
      "LOG: Epoch [246/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3768\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [246/2000], Avg Train Loss: 0.4044, Avg Val Loss: 0.2569\n",
      "\n",
      "Validation loss improved from 0.2572 to 0.2569. Saving model...\n",
      "LOG: Epoch [247/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4032\n",
      "LOG: Epoch [247/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3767\n",
      "    Batch [2/2], Val Loss: 0.1369\n",
      "Epoch [247/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2568\n",
      "\n",
      "Validation loss improved from 0.2569 to 0.2568. Saving model...\n",
      "LOG: Epoch [248/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4029\n",
      "    Batch [2/2], Train Loss: 0.3986\n",
      "LOG: Epoch [248/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.1366\n",
      "Epoch [248/2000], Avg Train Loss: 0.4007, Avg Val Loss: 0.2565\n",
      "\n",
      "Validation loss improved from 0.2568 to 0.2565. Saving model...\n",
      "LOG: Epoch [249/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4101\n",
      "LOG: Epoch [249/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3763\n",
      "    Batch [2/2], Val Loss: 0.1367\n",
      "Epoch [249/2000], Avg Train Loss: 0.4054, Avg Val Loss: 0.2565\n",
      "\n",
      "Validation loss improved from 0.2565 to 0.2565. Saving model...\n",
      "LOG: Epoch [250/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4048\n",
      "    Batch [2/2], Train Loss: 0.4034\n",
      "LOG: Epoch [250/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3763\n",
      "    Batch [2/2], Val Loss: 0.1364\n",
      "Epoch [250/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2564\n",
      "\n",
      "Validation loss improved from 0.2565 to 0.2564. Saving model...\n",
      "LOG: Epoch [251/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4052\n",
      "LOG: Epoch [251/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3762\n",
      "    Batch [2/2], Val Loss: 0.1363\n",
      "Epoch [251/2000], Avg Train Loss: 0.4074, Avg Val Loss: 0.2563\n",
      "\n",
      "Validation loss improved from 0.2564 to 0.2563. Saving model...\n",
      "LOG: Epoch [252/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4064\n",
      "    Batch [2/2], Train Loss: 0.4045\n",
      "LOG: Epoch [252/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.1355\n",
      "Epoch [252/2000], Avg Train Loss: 0.4054, Avg Val Loss: 0.2560\n",
      "\n",
      "Validation loss improved from 0.2563 to 0.2560. Saving model...\n",
      "LOG: Epoch [253/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4023\n",
      "LOG: Epoch [253/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3762\n",
      "    Batch [2/2], Val Loss: 0.1359\n",
      "Epoch [253/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2561\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [254/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4060\n",
      "    Batch [2/2], Train Loss: 0.4059\n",
      "LOG: Epoch [254/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.1362\n",
      "Epoch [254/2000], Avg Train Loss: 0.4059, Avg Val Loss: 0.2562\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [255/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4028\n",
      "LOG: Epoch [255/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.1364\n",
      "Epoch [255/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2562\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [256/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4015\n",
      "    Batch [2/2], Train Loss: 0.3989\n",
      "LOG: Epoch [256/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.1363\n",
      "Epoch [256/2000], Avg Train Loss: 0.4002, Avg Val Loss: 0.2562\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [257/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4026\n",
      "LOG: Epoch [257/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3760\n",
      "    Batch [2/2], Val Loss: 0.1363\n",
      "Epoch [257/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2562\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [258/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4055\n",
      "    Batch [2/2], Train Loss: 0.4012\n",
      "LOG: Epoch [258/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3758\n",
      "    Batch [2/2], Val Loss: 0.1369\n",
      "Epoch [258/2000], Avg Train Loss: 0.4034, Avg Val Loss: 0.2564\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [259/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4081\n",
      "LOG: Epoch [259/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3757\n",
      "    Batch [2/2], Val Loss: 0.1372\n",
      "Epoch [259/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2564\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [260/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3972\n",
      "    Batch [2/2], Train Loss: 0.4061\n",
      "LOG: Epoch [260/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3756\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [260/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2562\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [261/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4022\n",
      "LOG: Epoch [261/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3755\n",
      "    Batch [2/2], Val Loss: 0.1366\n",
      "Epoch [261/2000], Avg Train Loss: 0.3996, Avg Val Loss: 0.2560\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [262/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3951\n",
      "    Batch [2/2], Train Loss: 0.4043\n",
      "LOG: Epoch [262/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3754\n",
      "    Batch [2/2], Val Loss: 0.1367\n",
      "Epoch [262/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2561\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [263/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4010\n",
      "LOG: Epoch [263/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3755\n",
      "    Batch [2/2], Val Loss: 0.1362\n",
      "Epoch [263/2000], Avg Train Loss: 0.4034, Avg Val Loss: 0.2558\n",
      "\n",
      "Validation loss improved from 0.2560 to 0.2558. Saving model...\n",
      "LOG: Epoch [264/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4000\n",
      "    Batch [2/2], Train Loss: 0.4035\n",
      "LOG: Epoch [264/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3757\n",
      "    Batch [2/2], Val Loss: 0.1361\n",
      "Epoch [264/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2559\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [265/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4053\n",
      "LOG: Epoch [265/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3756\n",
      "    Batch [2/2], Val Loss: 0.1363\n",
      "Epoch [265/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2560\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [266/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3999\n",
      "    Batch [2/2], Train Loss: 0.4030\n",
      "LOG: Epoch [266/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3757\n",
      "    Batch [2/2], Val Loss: 0.1357\n",
      "Epoch [266/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2557\n",
      "\n",
      "Validation loss improved from 0.2558 to 0.2557. Saving model...\n",
      "LOG: Epoch [267/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4021\n",
      "LOG: Epoch [267/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3757\n",
      "    Batch [2/2], Val Loss: 0.1350\n",
      "Epoch [267/2000], Avg Train Loss: 0.4026, Avg Val Loss: 0.2553\n",
      "\n",
      "Validation loss improved from 0.2557 to 0.2553. Saving model...\n",
      "LOG: Epoch [268/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3974\n",
      "    Batch [2/2], Train Loss: 0.4072\n",
      "LOG: Epoch [268/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3754\n",
      "    Batch [2/2], Val Loss: 0.1348\n",
      "Epoch [268/2000], Avg Train Loss: 0.4023, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2553 to 0.2551. Saving model...\n",
      "LOG: Epoch [269/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4019\n",
      "LOG: Epoch [269/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3751\n",
      "    Batch [2/2], Val Loss: 0.1354\n",
      "Epoch [269/2000], Avg Train Loss: 0.3996, Avg Val Loss: 0.2552\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [270/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4007\n",
      "    Batch [2/2], Train Loss: 0.4026\n",
      "LOG: Epoch [270/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3749\n",
      "    Batch [2/2], Val Loss: 0.1355\n",
      "Epoch [270/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2552\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [271/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3972\n",
      "LOG: Epoch [271/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3747\n",
      "    Batch [2/2], Val Loss: 0.1348\n",
      "Epoch [271/2000], Avg Train Loss: 0.3977, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2547. Saving model...\n",
      "LOG: Epoch [272/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4045\n",
      "    Batch [2/2], Train Loss: 0.4042\n",
      "LOG: Epoch [272/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3744\n",
      "    Batch [2/2], Val Loss: 0.1346\n",
      "Epoch [272/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2545. Saving model...\n",
      "LOG: Epoch [273/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4025\n",
      "LOG: Epoch [273/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3744\n",
      "    Batch [2/2], Val Loss: 0.1338\n",
      "Epoch [273/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2541. Saving model...\n",
      "LOG: Epoch [274/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4039\n",
      "    Batch [2/2], Train Loss: 0.4015\n",
      "LOG: Epoch [274/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3743\n",
      "    Batch [2/2], Val Loss: 0.1337\n",
      "Epoch [274/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2540. Saving model...\n",
      "LOG: Epoch [275/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4000\n",
      "LOG: Epoch [275/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3741\n",
      "    Batch [2/2], Val Loss: 0.1340\n",
      "Epoch [275/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [276/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4005\n",
      "    Batch [2/2], Train Loss: 0.4013\n",
      "LOG: Epoch [276/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3740\n",
      "    Batch [2/2], Val Loss: 0.1342\n",
      "Epoch [276/2000], Avg Train Loss: 0.4009, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [277/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3989\n",
      "LOG: Epoch [277/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3738\n",
      "    Batch [2/2], Val Loss: 0.1344\n",
      "Epoch [277/2000], Avg Train Loss: 0.3986, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [278/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4002\n",
      "    Batch [2/2], Train Loss: 0.4070\n",
      "LOG: Epoch [278/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3739\n",
      "    Batch [2/2], Val Loss: 0.1344\n",
      "Epoch [278/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [279/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4022\n",
      "LOG: Epoch [279/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3741\n",
      "    Batch [2/2], Val Loss: 0.1341\n",
      "Epoch [279/2000], Avg Train Loss: 0.4038, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [280/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4029\n",
      "    Batch [2/2], Train Loss: 0.4051\n",
      "LOG: Epoch [280/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3740\n",
      "    Batch [2/2], Val Loss: 0.1341\n",
      "Epoch [280/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [281/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3994\n",
      "LOG: Epoch [281/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3743\n",
      "    Batch [2/2], Val Loss: 0.1335\n",
      "Epoch [281/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2539\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2539. Saving model...\n",
      "LOG: Epoch [282/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4018\n",
      "    Batch [2/2], Train Loss: 0.4004\n",
      "LOG: Epoch [282/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3740\n",
      "    Batch [2/2], Val Loss: 0.1338\n",
      "Epoch [282/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2539\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [283/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3978\n",
      "LOG: Epoch [283/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3741\n",
      "    Batch [2/2], Val Loss: 0.1337\n",
      "Epoch [283/2000], Avg Train Loss: 0.4020, Avg Val Loss: 0.2539\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [284/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4022\n",
      "    Batch [2/2], Train Loss: 0.4042\n",
      "LOG: Epoch [284/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3741\n",
      "    Batch [2/2], Val Loss: 0.1332\n",
      "Epoch [284/2000], Avg Train Loss: 0.4032, Avg Val Loss: 0.2536\n",
      "\n",
      "Validation loss improved from 0.2539 to 0.2536. Saving model...\n",
      "LOG: Epoch [285/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3955\n",
      "LOG: Epoch [285/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3740\n",
      "    Batch [2/2], Val Loss: 0.1333\n",
      "Epoch [285/2000], Avg Train Loss: 0.3985, Avg Val Loss: 0.2537\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [286/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4016\n",
      "    Batch [2/2], Train Loss: 0.4078\n",
      "LOG: Epoch [286/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3740\n",
      "    Batch [2/2], Val Loss: 0.1333\n",
      "Epoch [286/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2536\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [287/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3956\n",
      "LOG: Epoch [287/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3738\n",
      "    Batch [2/2], Val Loss: 0.1333\n",
      "Epoch [287/2000], Avg Train Loss: 0.3974, Avg Val Loss: 0.2536\n",
      "\n",
      "Validation loss improved from 0.2536 to 0.2536. Saving model...\n",
      "LOG: Epoch [288/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3982\n",
      "    Batch [2/2], Train Loss: 0.3962\n",
      "LOG: Epoch [288/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3735\n",
      "    Batch [2/2], Val Loss: 0.1336\n",
      "Epoch [288/2000], Avg Train Loss: 0.3972, Avg Val Loss: 0.2535\n",
      "\n",
      "Validation loss improved from 0.2536 to 0.2535. Saving model...\n",
      "LOG: Epoch [289/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4027\n",
      "LOG: Epoch [289/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3734\n",
      "    Batch [2/2], Val Loss: 0.1336\n",
      "Epoch [289/2000], Avg Train Loss: 0.4013, Avg Val Loss: 0.2535\n",
      "\n",
      "Validation loss improved from 0.2535 to 0.2535. Saving model...\n",
      "LOG: Epoch [290/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4012\n",
      "    Batch [2/2], Train Loss: 0.4023\n",
      "LOG: Epoch [290/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3732\n",
      "    Batch [2/2], Val Loss: 0.1331\n",
      "Epoch [290/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2531\n",
      "\n",
      "Validation loss improved from 0.2535 to 0.2531. Saving model...\n",
      "LOG: Epoch [291/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4028\n",
      "LOG: Epoch [291/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3730\n",
      "    Batch [2/2], Val Loss: 0.1329\n",
      "Epoch [291/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2530\n",
      "\n",
      "Validation loss improved from 0.2531 to 0.2530. Saving model...\n",
      "LOG: Epoch [292/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4016\n",
      "    Batch [2/2], Train Loss: 0.4018\n",
      "LOG: Epoch [292/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3731\n",
      "    Batch [2/2], Val Loss: 0.1327\n",
      "Epoch [292/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2529\n",
      "\n",
      "Validation loss improved from 0.2530 to 0.2529. Saving model...\n",
      "LOG: Epoch [293/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3964\n",
      "LOG: Epoch [293/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3730\n",
      "    Batch [2/2], Val Loss: 0.1326\n",
      "Epoch [293/2000], Avg Train Loss: 0.3954, Avg Val Loss: 0.2528\n",
      "\n",
      "Validation loss improved from 0.2529 to 0.2528. Saving model...\n",
      "LOG: Epoch [294/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4003\n",
      "    Batch [2/2], Train Loss: 0.4029\n",
      "LOG: Epoch [294/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3730\n",
      "    Batch [2/2], Val Loss: 0.1324\n",
      "Epoch [294/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2527\n",
      "\n",
      "Validation loss improved from 0.2528 to 0.2527. Saving model...\n",
      "LOG: Epoch [295/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3955\n",
      "LOG: Epoch [295/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3731\n",
      "    Batch [2/2], Val Loss: 0.1320\n",
      "Epoch [295/2000], Avg Train Loss: 0.3980, Avg Val Loss: 0.2525\n",
      "\n",
      "Validation loss improved from 0.2527 to 0.2525. Saving model...\n",
      "LOG: Epoch [296/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3976\n",
      "    Batch [2/2], Train Loss: 0.3933\n",
      "LOG: Epoch [296/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3729\n",
      "    Batch [2/2], Val Loss: 0.1320\n",
      "Epoch [296/2000], Avg Train Loss: 0.3955, Avg Val Loss: 0.2525\n",
      "\n",
      "Validation loss improved from 0.2525 to 0.2525. Saving model...\n",
      "LOG: Epoch [297/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3994\n",
      "LOG: Epoch [297/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3727\n",
      "    Batch [2/2], Val Loss: 0.1324\n",
      "Epoch [297/2000], Avg Train Loss: 0.4008, Avg Val Loss: 0.2526\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [298/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3975\n",
      "    Batch [2/2], Train Loss: 0.3983\n",
      "LOG: Epoch [298/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3725\n",
      "    Batch [2/2], Val Loss: 0.1328\n",
      "Epoch [298/2000], Avg Train Loss: 0.3979, Avg Val Loss: 0.2526\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [299/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3983\n",
      "LOG: Epoch [299/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3725\n",
      "    Batch [2/2], Val Loss: 0.1325\n",
      "Epoch [299/2000], Avg Train Loss: 0.3965, Avg Val Loss: 0.2525\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [300/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3993\n",
      "    Batch [2/2], Train Loss: 0.3968\n",
      "LOG: Epoch [300/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3725\n",
      "    Batch [2/2], Val Loss: 0.1326\n",
      "Epoch [300/2000], Avg Train Loss: 0.3981, Avg Val Loss: 0.2526\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [301/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4020\n",
      "LOG: Epoch [301/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3723\n",
      "    Batch [2/2], Val Loss: 0.1329\n",
      "Epoch [301/2000], Avg Train Loss: 0.3977, Avg Val Loss: 0.2526\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [302/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3996\n",
      "    Batch [2/2], Train Loss: 0.3907\n",
      "LOG: Epoch [302/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3722\n",
      "    Batch [2/2], Val Loss: 0.1330\n",
      "Epoch [302/2000], Avg Train Loss: 0.3952, Avg Val Loss: 0.2526\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [303/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3979\n",
      "LOG: Epoch [303/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3721\n",
      "    Batch [2/2], Val Loss: 0.1327\n",
      "Epoch [303/2000], Avg Train Loss: 0.3986, Avg Val Loss: 0.2524\n",
      "\n",
      "Validation loss improved from 0.2525 to 0.2524. Saving model...\n",
      "LOG: Epoch [304/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4014\n",
      "    Batch [2/2], Train Loss: 0.4043\n",
      "LOG: Epoch [304/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3719\n",
      "    Batch [2/2], Val Loss: 0.1327\n",
      "Epoch [304/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2523\n",
      "\n",
      "Validation loss improved from 0.2524 to 0.2523. Saving model...\n",
      "LOG: Epoch [305/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3967\n",
      "LOG: Epoch [305/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3717\n",
      "    Batch [2/2], Val Loss: 0.1333\n",
      "Epoch [305/2000], Avg Train Loss: 0.3978, Avg Val Loss: 0.2525\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [306/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3977\n",
      "    Batch [2/2], Train Loss: 0.3952\n",
      "LOG: Epoch [306/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3715\n",
      "    Batch [2/2], Val Loss: 0.1332\n",
      "Epoch [306/2000], Avg Train Loss: 0.3965, Avg Val Loss: 0.2524\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [307/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3934\n",
      "LOG: Epoch [307/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3715\n",
      "    Batch [2/2], Val Loss: 0.1330\n",
      "Epoch [307/2000], Avg Train Loss: 0.3957, Avg Val Loss: 0.2523\n",
      "\n",
      "Validation loss improved from 0.2523 to 0.2523. Saving model...\n",
      "LOG: Epoch [308/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3923\n",
      "    Batch [2/2], Train Loss: 0.4070\n",
      "LOG: Epoch [308/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3714\n",
      "    Batch [2/2], Val Loss: 0.1330\n",
      "Epoch [308/2000], Avg Train Loss: 0.3996, Avg Val Loss: 0.2522\n",
      "\n",
      "Validation loss improved from 0.2523 to 0.2522. Saving model...\n",
      "LOG: Epoch [309/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4024\n",
      "LOG: Epoch [309/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3713\n",
      "    Batch [2/2], Val Loss: 0.1333\n",
      "Epoch [309/2000], Avg Train Loss: 0.3980, Avg Val Loss: 0.2523\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [310/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3977\n",
      "    Batch [2/2], Train Loss: 0.3967\n",
      "LOG: Epoch [310/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3713\n",
      "    Batch [2/2], Val Loss: 0.1341\n",
      "Epoch [310/2000], Avg Train Loss: 0.3972, Avg Val Loss: 0.2527\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [311/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3941\n",
      "LOG: Epoch [311/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3711\n",
      "    Batch [2/2], Val Loss: 0.1341\n",
      "Epoch [311/2000], Avg Train Loss: 0.3956, Avg Val Loss: 0.2526\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [312/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3983\n",
      "    Batch [2/2], Train Loss: 0.4012\n",
      "LOG: Epoch [312/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3712\n",
      "    Batch [2/2], Val Loss: 0.1341\n",
      "Epoch [312/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2526\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [313/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3951\n",
      "LOG: Epoch [313/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3712\n",
      "    Batch [2/2], Val Loss: 0.1340\n",
      "Epoch [313/2000], Avg Train Loss: 0.3940, Avg Val Loss: 0.2526\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [314/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3991\n",
      "    Batch [2/2], Train Loss: 0.3992\n",
      "LOG: Epoch [314/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3713\n",
      "    Batch [2/2], Val Loss: 0.1336\n",
      "Epoch [314/2000], Avg Train Loss: 0.3992, Avg Val Loss: 0.2524\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [315/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3994\n",
      "LOG: Epoch [315/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3713\n",
      "    Batch [2/2], Val Loss: 0.1340\n",
      "Epoch [315/2000], Avg Train Loss: 0.3970, Avg Val Loss: 0.2526\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [316/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3939\n",
      "    Batch [2/2], Train Loss: 0.3913\n",
      "LOG: Epoch [316/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3714\n",
      "    Batch [2/2], Val Loss: 0.1339\n",
      "Epoch [316/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2526\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [317/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3949\n",
      "LOG: Epoch [317/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3715\n",
      "    Batch [2/2], Val Loss: 0.1332\n",
      "Epoch [317/2000], Avg Train Loss: 0.3953, Avg Val Loss: 0.2524\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [318/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3998\n",
      "    Batch [2/2], Train Loss: 0.3996\n",
      "LOG: Epoch [318/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3714\n",
      "    Batch [2/2], Val Loss: 0.1330\n",
      "Epoch [318/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2522\n",
      "\n",
      "Validation loss improved from 0.2522 to 0.2522. Saving model...\n",
      "LOG: Epoch [319/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3945\n",
      "LOG: Epoch [319/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3713\n",
      "    Batch [2/2], Val Loss: 0.1328\n",
      "Epoch [319/2000], Avg Train Loss: 0.3973, Avg Val Loss: 0.2521\n",
      "\n",
      "Validation loss improved from 0.2522 to 0.2521. Saving model...\n",
      "LOG: Epoch [320/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3973\n",
      "    Batch [2/2], Train Loss: 0.3948\n",
      "LOG: Epoch [320/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3711\n",
      "    Batch [2/2], Val Loss: 0.1328\n",
      "Epoch [320/2000], Avg Train Loss: 0.3960, Avg Val Loss: 0.2519\n",
      "\n",
      "Validation loss improved from 0.2521 to 0.2519. Saving model...\n",
      "LOG: Epoch [321/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3938\n",
      "LOG: Epoch [321/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3707\n",
      "    Batch [2/2], Val Loss: 0.1332\n",
      "Epoch [321/2000], Avg Train Loss: 0.3978, Avg Val Loss: 0.2520\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [322/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4046\n",
      "    Batch [2/2], Train Loss: 0.3988\n",
      "LOG: Epoch [322/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3703\n",
      "    Batch [2/2], Val Loss: 0.1330\n",
      "Epoch [322/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2517\n",
      "\n",
      "Validation loss improved from 0.2519 to 0.2517. Saving model...\n",
      "LOG: Epoch [323/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3975\n",
      "LOG: Epoch [323/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3704\n",
      "    Batch [2/2], Val Loss: 0.1324\n",
      "Epoch [323/2000], Avg Train Loss: 0.3957, Avg Val Loss: 0.2514\n",
      "\n",
      "Validation loss improved from 0.2517 to 0.2514. Saving model...\n",
      "LOG: Epoch [324/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3949\n",
      "LOG: Epoch [324/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3702\n",
      "    Batch [2/2], Val Loss: 0.1327\n",
      "Epoch [324/2000], Avg Train Loss: 0.3953, Avg Val Loss: 0.2515\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [325/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3981\n",
      "    Batch [2/2], Train Loss: 0.3943\n",
      "LOG: Epoch [325/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3700\n",
      "    Batch [2/2], Val Loss: 0.1326\n",
      "Epoch [325/2000], Avg Train Loss: 0.3962, Avg Val Loss: 0.2513\n",
      "\n",
      "Validation loss improved from 0.2514 to 0.2513. Saving model...\n",
      "LOG: Epoch [326/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3964\n",
      "LOG: Epoch [326/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3702\n",
      "    Batch [2/2], Val Loss: 0.1321\n",
      "Epoch [326/2000], Avg Train Loss: 0.3989, Avg Val Loss: 0.2511\n",
      "\n",
      "Validation loss improved from 0.2513 to 0.2511. Saving model...\n",
      "LOG: Epoch [327/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3949\n",
      "    Batch [2/2], Train Loss: 0.3948\n",
      "LOG: Epoch [327/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3702\n",
      "    Batch [2/2], Val Loss: 0.1316\n",
      "Epoch [327/2000], Avg Train Loss: 0.3949, Avg Val Loss: 0.2509\n",
      "\n",
      "Validation loss improved from 0.2511 to 0.2509. Saving model...\n",
      "LOG: Epoch [328/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4007\n",
      "LOG: Epoch [328/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3702\n",
      "    Batch [2/2], Val Loss: 0.1313\n",
      "Epoch [328/2000], Avg Train Loss: 0.3978, Avg Val Loss: 0.2507\n",
      "\n",
      "Validation loss improved from 0.2509 to 0.2507. Saving model...\n",
      "LOG: Epoch [329/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3991\n",
      "    Batch [2/2], Train Loss: 0.4012\n",
      "LOG: Epoch [329/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3701\n",
      "    Batch [2/2], Val Loss: 0.1310\n",
      "Epoch [329/2000], Avg Train Loss: 0.4001, Avg Val Loss: 0.2505\n",
      "\n",
      "Validation loss improved from 0.2507 to 0.2505. Saving model...\n",
      "LOG: Epoch [330/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3979\n",
      "LOG: Epoch [330/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3699\n",
      "    Batch [2/2], Val Loss: 0.1304\n",
      "Epoch [330/2000], Avg Train Loss: 0.3952, Avg Val Loss: 0.2501\n",
      "\n",
      "Validation loss improved from 0.2505 to 0.2501. Saving model...\n",
      "LOG: Epoch [331/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3985\n",
      "    Batch [2/2], Train Loss: 0.4006\n",
      "LOG: Epoch [331/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3698\n",
      "    Batch [2/2], Val Loss: 0.1304\n",
      "Epoch [331/2000], Avg Train Loss: 0.3996, Avg Val Loss: 0.2501\n",
      "\n",
      "Validation loss improved from 0.2501 to 0.2501. Saving model...\n",
      "LOG: Epoch [332/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3977\n",
      "LOG: Epoch [332/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3698\n",
      "    Batch [2/2], Val Loss: 0.1304\n",
      "Epoch [332/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2501\n",
      "\n",
      "Validation loss improved from 0.2501 to 0.2501. Saving model...\n",
      "LOG: Epoch [333/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3958\n",
      "    Batch [2/2], Train Loss: 0.4016\n",
      "LOG: Epoch [333/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3698\n",
      "    Batch [2/2], Val Loss: 0.1307\n",
      "Epoch [333/2000], Avg Train Loss: 0.3987, Avg Val Loss: 0.2503\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [334/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.4001\n",
      "LOG: Epoch [334/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3698\n",
      "    Batch [2/2], Val Loss: 0.1307\n",
      "Epoch [334/2000], Avg Train Loss: 0.3974, Avg Val Loss: 0.2503\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [335/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3932\n",
      "    Batch [2/2], Train Loss: 0.3943\n",
      "LOG: Epoch [335/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3698\n",
      "    Batch [2/2], Val Loss: 0.1309\n",
      "Epoch [335/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2503\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [336/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3948\n",
      "LOG: Epoch [336/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3699\n",
      "    Batch [2/2], Val Loss: 0.1309\n",
      "Epoch [336/2000], Avg Train Loss: 0.3968, Avg Val Loss: 0.2504\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [337/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3946\n",
      "    Batch [2/2], Train Loss: 0.3900\n",
      "LOG: Epoch [337/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3700\n",
      "    Batch [2/2], Val Loss: 0.1316\n",
      "Epoch [337/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2508\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [338/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3954\n",
      "LOG: Epoch [338/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3701\n",
      "    Batch [2/2], Val Loss: 0.1317\n",
      "Epoch [338/2000], Avg Train Loss: 0.3949, Avg Val Loss: 0.2509\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [339/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3872\n",
      "    Batch [2/2], Train Loss: 0.3967\n",
      "LOG: Epoch [339/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3702\n",
      "    Batch [2/2], Val Loss: 0.1313\n",
      "Epoch [339/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2508\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [340/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3946\n",
      "LOG: Epoch [340/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3703\n",
      "    Batch [2/2], Val Loss: 0.1316\n",
      "Epoch [340/2000], Avg Train Loss: 0.3981, Avg Val Loss: 0.2510\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [341/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4002\n",
      "    Batch [2/2], Train Loss: 0.3947\n",
      "LOG: Epoch [341/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3704\n",
      "    Batch [2/2], Val Loss: 0.1311\n",
      "Epoch [341/2000], Avg Train Loss: 0.3975, Avg Val Loss: 0.2507\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [342/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3977\n",
      "LOG: Epoch [342/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3707\n",
      "    Batch [2/2], Val Loss: 0.1308\n",
      "Epoch [342/2000], Avg Train Loss: 0.3972, Avg Val Loss: 0.2508\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [343/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3951\n",
      "    Batch [2/2], Train Loss: 0.3945\n",
      "LOG: Epoch [343/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3708\n",
      "    Batch [2/2], Val Loss: 0.1305\n",
      "Epoch [343/2000], Avg Train Loss: 0.3948, Avg Val Loss: 0.2506\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [344/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3988\n",
      "LOG: Epoch [344/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3704\n",
      "    Batch [2/2], Val Loss: 0.1306\n",
      "Epoch [344/2000], Avg Train Loss: 0.3975, Avg Val Loss: 0.2505\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [345/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3930\n",
      "    Batch [2/2], Train Loss: 0.3924\n",
      "LOG: Epoch [345/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3700\n",
      "    Batch [2/2], Val Loss: 0.1309\n",
      "Epoch [345/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2505\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [346/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3939\n",
      "    Batch [2/2], Train Loss: 0.3883\n",
      "LOG: Epoch [346/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3698\n",
      "    Batch [2/2], Val Loss: 0.1308\n",
      "Epoch [346/2000], Avg Train Loss: 0.3911, Avg Val Loss: 0.2503\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [347/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3942\n",
      "LOG: Epoch [347/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3695\n",
      "    Batch [2/2], Val Loss: 0.1308\n",
      "Epoch [347/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2501\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [348/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3957\n",
      "    Batch [2/2], Train Loss: 0.3963\n",
      "LOG: Epoch [348/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3693\n",
      "    Batch [2/2], Val Loss: 0.1308\n",
      "Epoch [348/2000], Avg Train Loss: 0.3960, Avg Val Loss: 0.2500\n",
      "\n",
      "Validation loss improved from 0.2501 to 0.2500. Saving model...\n",
      "LOG: Epoch [349/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3957\n",
      "LOG: Epoch [349/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3692\n",
      "    Batch [2/2], Val Loss: 0.1303\n",
      "Epoch [349/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2498\n",
      "\n",
      "Validation loss improved from 0.2500 to 0.2498. Saving model...\n",
      "LOG: Epoch [350/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3917\n",
      "    Batch [2/2], Train Loss: 0.3931\n",
      "LOG: Epoch [350/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3691\n",
      "    Batch [2/2], Val Loss: 0.1296\n",
      "Epoch [350/2000], Avg Train Loss: 0.3924, Avg Val Loss: 0.2494\n",
      "\n",
      "Validation loss improved from 0.2498 to 0.2494. Saving model...\n",
      "LOG: Epoch [351/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3960\n",
      "    Batch [2/2], Train Loss: 0.3921\n",
      "LOG: Epoch [351/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3689\n",
      "    Batch [2/2], Val Loss: 0.1296\n",
      "Epoch [351/2000], Avg Train Loss: 0.3940, Avg Val Loss: 0.2493\n",
      "\n",
      "Validation loss improved from 0.2494 to 0.2493. Saving model...\n",
      "LOG: Epoch [352/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3963\n",
      "    Batch [2/2], Train Loss: 0.3928\n",
      "LOG: Epoch [352/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3686\n",
      "    Batch [2/2], Val Loss: 0.1296\n",
      "Epoch [352/2000], Avg Train Loss: 0.3945, Avg Val Loss: 0.2491\n",
      "\n",
      "Validation loss improved from 0.2493 to 0.2491. Saving model...\n",
      "LOG: Epoch [353/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.4015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3977\n",
      "LOG: Epoch [353/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3685\n",
      "    Batch [2/2], Val Loss: 0.1294\n",
      "Epoch [353/2000], Avg Train Loss: 0.3996, Avg Val Loss: 0.2489\n",
      "\n",
      "Validation loss improved from 0.2491 to 0.2489. Saving model...\n",
      "LOG: Epoch [354/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3940\n",
      "    Batch [2/2], Train Loss: 0.3934\n",
      "LOG: Epoch [354/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3685\n",
      "    Batch [2/2], Val Loss: 0.1290\n",
      "Epoch [354/2000], Avg Train Loss: 0.3937, Avg Val Loss: 0.2487\n",
      "\n",
      "Validation loss improved from 0.2489 to 0.2487. Saving model...\n",
      "LOG: Epoch [355/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.4022\n",
      "    Batch [2/2], Train Loss: 0.3937\n",
      "LOG: Epoch [355/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3683\n",
      "    Batch [2/2], Val Loss: 0.1288\n",
      "Epoch [355/2000], Avg Train Loss: 0.3979, Avg Val Loss: 0.2486\n",
      "\n",
      "Validation loss improved from 0.2487 to 0.2486. Saving model...\n",
      "LOG: Epoch [356/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3864\n",
      "LOG: Epoch [356/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3684\n",
      "    Batch [2/2], Val Loss: 0.1286\n",
      "Epoch [356/2000], Avg Train Loss: 0.3887, Avg Val Loss: 0.2485\n",
      "\n",
      "Validation loss improved from 0.2486 to 0.2485. Saving model...\n",
      "LOG: Epoch [357/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3922\n",
      "    Batch [2/2], Train Loss: 0.3914\n",
      "LOG: Epoch [357/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3684\n",
      "    Batch [2/2], Val Loss: 0.1285\n",
      "Epoch [357/2000], Avg Train Loss: 0.3918, Avg Val Loss: 0.2485\n",
      "\n",
      "Validation loss improved from 0.2485 to 0.2485. Saving model...\n",
      "LOG: Epoch [358/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3901\n",
      "LOG: Epoch [358/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3683\n",
      "    Batch [2/2], Val Loss: 0.1289\n",
      "Epoch [358/2000], Avg Train Loss: 0.3886, Avg Val Loss: 0.2486\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [359/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3965\n",
      "    Batch [2/2], Train Loss: 0.3831\n",
      "LOG: Epoch [359/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3680\n",
      "    Batch [2/2], Val Loss: 0.1294\n",
      "Epoch [359/2000], Avg Train Loss: 0.3898, Avg Val Loss: 0.2487\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [360/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3921\n",
      "LOG: Epoch [360/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3680\n",
      "    Batch [2/2], Val Loss: 0.1291\n",
      "Epoch [360/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2485\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [361/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3927\n",
      "    Batch [2/2], Train Loss: 0.3932\n",
      "LOG: Epoch [361/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3678\n",
      "    Batch [2/2], Val Loss: 0.1295\n",
      "Epoch [361/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2487\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [362/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3936\n",
      "LOG: Epoch [362/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3678\n",
      "    Batch [2/2], Val Loss: 0.1294\n",
      "Epoch [362/2000], Avg Train Loss: 0.3947, Avg Val Loss: 0.2486\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [363/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3916\n",
      "    Batch [2/2], Train Loss: 0.3870\n",
      "LOG: Epoch [363/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3677\n",
      "    Batch [2/2], Val Loss: 0.1291\n",
      "Epoch [363/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2484\n",
      "\n",
      "Validation loss improved from 0.2485 to 0.2484. Saving model...\n",
      "LOG: Epoch [364/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3930\n",
      "    Batch [2/2], Train Loss: 0.4003\n",
      "LOG: Epoch [364/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3678\n",
      "    Batch [2/2], Val Loss: 0.1289\n",
      "Epoch [364/2000], Avg Train Loss: 0.3967, Avg Val Loss: 0.2483\n",
      "\n",
      "Validation loss improved from 0.2484 to 0.2483. Saving model...\n",
      "LOG: Epoch [365/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3930\n",
      "LOG: Epoch [365/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3676\n",
      "    Batch [2/2], Val Loss: 0.1292\n",
      "Epoch [365/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2484\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [366/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3948\n",
      "    Batch [2/2], Train Loss: 0.3908\n",
      "LOG: Epoch [366/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3678\n",
      "    Batch [2/2], Val Loss: 0.1285\n",
      "Epoch [366/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2482\n",
      "\n",
      "Validation loss improved from 0.2483 to 0.2482. Saving model...\n",
      "LOG: Epoch [367/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3909\n",
      "LOG: Epoch [367/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3677\n",
      "    Batch [2/2], Val Loss: 0.1290\n",
      "Epoch [367/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2484\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [368/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3860\n",
      "    Batch [2/2], Train Loss: 0.3977\n",
      "LOG: Epoch [368/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3678\n",
      "    Batch [2/2], Val Loss: 0.1291\n",
      "Epoch [368/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2484\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [369/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3973\n",
      "LOG: Epoch [369/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3678\n",
      "    Batch [2/2], Val Loss: 0.1294\n",
      "Epoch [369/2000], Avg Train Loss: 0.3964, Avg Val Loss: 0.2486\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [370/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3934\n",
      "LOG: Epoch [370/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3679\n",
      "    Batch [2/2], Val Loss: 0.1301\n",
      "Epoch [370/2000], Avg Train Loss: 0.3954, Avg Val Loss: 0.2490\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [371/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3940\n",
      "    Batch [2/2], Train Loss: 0.3829\n",
      "LOG: Epoch [371/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3679\n",
      "    Batch [2/2], Val Loss: 0.1299\n",
      "Epoch [371/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2489\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [372/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3997\n",
      "LOG: Epoch [372/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3679\n",
      "    Batch [2/2], Val Loss: 0.1294\n",
      "Epoch [372/2000], Avg Train Loss: 0.3940, Avg Val Loss: 0.2487\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [373/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3953\n",
      "    Batch [2/2], Train Loss: 0.3914\n",
      "LOG: Epoch [373/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3679\n",
      "    Batch [2/2], Val Loss: 0.1292\n",
      "Epoch [373/2000], Avg Train Loss: 0.3934, Avg Val Loss: 0.2486\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [374/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3871\n",
      "LOG: Epoch [374/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3678\n",
      "    Batch [2/2], Val Loss: 0.1293\n",
      "Epoch [374/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2485\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [375/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3907\n",
      "LOG: Epoch [375/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3675\n",
      "    Batch [2/2], Val Loss: 0.1295\n",
      "Epoch [375/2000], Avg Train Loss: 0.3924, Avg Val Loss: 0.2485\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [376/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3869\n",
      "    Batch [2/2], Train Loss: 0.3915\n",
      "LOG: Epoch [376/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3672\n",
      "    Batch [2/2], Val Loss: 0.1293\n",
      "Epoch [376/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2483\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [377/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3935\n",
      "LOG: Epoch [377/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3671\n",
      "    Batch [2/2], Val Loss: 0.1292\n",
      "Epoch [377/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2482\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [378/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3868\n",
      "    Batch [2/2], Train Loss: 0.3904\n",
      "LOG: Epoch [378/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3671\n",
      "    Batch [2/2], Val Loss: 0.1285\n",
      "Epoch [378/2000], Avg Train Loss: 0.3886, Avg Val Loss: 0.2478\n",
      "\n",
      "Validation loss improved from 0.2482 to 0.2478. Saving model...\n",
      "LOG: Epoch [379/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3904\n",
      "LOG: Epoch [379/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3669\n",
      "    Batch [2/2], Val Loss: 0.1288\n",
      "Epoch [379/2000], Avg Train Loss: 0.3903, Avg Val Loss: 0.2479\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [380/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3879\n",
      "LOG: Epoch [380/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3668\n",
      "    Batch [2/2], Val Loss: 0.1290\n",
      "Epoch [380/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2479\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [381/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3890\n",
      "    Batch [2/2], Train Loss: 0.3863\n",
      "LOG: Epoch [381/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3666\n",
      "    Batch [2/2], Val Loss: 0.1289\n",
      "Epoch [381/2000], Avg Train Loss: 0.3876, Avg Val Loss: 0.2477\n",
      "\n",
      "Validation loss improved from 0.2478 to 0.2477. Saving model...\n",
      "LOG: Epoch [382/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3888\n",
      "LOG: Epoch [382/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3666\n",
      "    Batch [2/2], Val Loss: 0.1284\n",
      "Epoch [382/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2475\n",
      "\n",
      "Validation loss improved from 0.2477 to 0.2475. Saving model...\n",
      "LOG: Epoch [383/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3984\n",
      "    Batch [2/2], Train Loss: 0.3878\n",
      "LOG: Epoch [383/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3664\n",
      "    Batch [2/2], Val Loss: 0.1288\n",
      "Epoch [383/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2476\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [384/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3919\n",
      "    Batch [2/2], Train Loss: 0.3960\n",
      "LOG: Epoch [384/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3665\n",
      "    Batch [2/2], Val Loss: 0.1280\n",
      "Epoch [384/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2473\n",
      "\n",
      "Validation loss improved from 0.2475 to 0.2473. Saving model...\n",
      "LOG: Epoch [385/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3882\n",
      "LOG: Epoch [385/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3664\n",
      "    Batch [2/2], Val Loss: 0.1280\n",
      "Epoch [385/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2472\n",
      "\n",
      "Validation loss improved from 0.2473 to 0.2472. Saving model...\n",
      "LOG: Epoch [386/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3904\n",
      "LOG: Epoch [386/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3663\n",
      "    Batch [2/2], Val Loss: 0.1284\n",
      "Epoch [386/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2474\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [387/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3932\n",
      "    Batch [2/2], Train Loss: 0.3854\n",
      "LOG: Epoch [387/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3665\n",
      "    Batch [2/2], Val Loss: 0.1282\n",
      "Epoch [387/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2473\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [388/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3877\n",
      "LOG: Epoch [388/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3664\n",
      "    Batch [2/2], Val Loss: 0.1290\n",
      "Epoch [388/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2477\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [389/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3912\n",
      "LOG: Epoch [389/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3663\n",
      "    Batch [2/2], Val Loss: 0.1289\n",
      "Epoch [389/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2476\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [390/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3937\n",
      "    Batch [2/2], Train Loss: 0.3893\n",
      "LOG: Epoch [390/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3662\n",
      "    Batch [2/2], Val Loss: 0.1291\n",
      "Epoch [390/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2477\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [391/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3878\n",
      "LOG: Epoch [391/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3662\n",
      "    Batch [2/2], Val Loss: 0.1287\n",
      "Epoch [391/2000], Avg Train Loss: 0.3866, Avg Val Loss: 0.2475\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [392/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3870\n",
      "    Batch [2/2], Train Loss: 0.3868\n",
      "LOG: Epoch [392/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3661\n",
      "    Batch [2/2], Val Loss: 0.1289\n",
      "Epoch [392/2000], Avg Train Loss: 0.3869, Avg Val Loss: 0.2475\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [393/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3960\n",
      "    Batch [2/2], Train Loss: 0.3949\n",
      "LOG: Epoch [393/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3662\n",
      "    Batch [2/2], Val Loss: 0.1280\n",
      "Epoch [393/2000], Avg Train Loss: 0.3954, Avg Val Loss: 0.2471\n",
      "\n",
      "Validation loss improved from 0.2472 to 0.2471. Saving model...\n",
      "LOG: Epoch [394/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3940\n",
      "    Batch [2/2], Train Loss: 0.3853\n",
      "LOG: Epoch [394/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3662\n",
      "    Batch [2/2], Val Loss: 0.1277\n",
      "Epoch [394/2000], Avg Train Loss: 0.3897, Avg Val Loss: 0.2469\n",
      "\n",
      "Validation loss improved from 0.2471 to 0.2469. Saving model...\n",
      "LOG: Epoch [395/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3964\n",
      "LOG: Epoch [395/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3660\n",
      "    Batch [2/2], Val Loss: 0.1277\n",
      "Epoch [395/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2468\n",
      "\n",
      "Validation loss improved from 0.2469 to 0.2468. Saving model...\n",
      "LOG: Epoch [396/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3961\n",
      "    Batch [2/2], Train Loss: 0.3889\n",
      "LOG: Epoch [396/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3660\n",
      "    Batch [2/2], Val Loss: 0.1276\n",
      "Epoch [396/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2468\n",
      "\n",
      "Validation loss improved from 0.2468 to 0.2468. Saving model...\n",
      "LOG: Epoch [397/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3954\n",
      "LOG: Epoch [397/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3660\n",
      "    Batch [2/2], Val Loss: 0.1275\n",
      "Epoch [397/2000], Avg Train Loss: 0.3953, Avg Val Loss: 0.2467\n",
      "\n",
      "Validation loss improved from 0.2468 to 0.2467. Saving model...\n",
      "LOG: Epoch [398/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3819\n",
      "    Batch [2/2], Train Loss: 0.3899\n",
      "LOG: Epoch [398/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3661\n",
      "    Batch [2/2], Val Loss: 0.1269\n",
      "Epoch [398/2000], Avg Train Loss: 0.3859, Avg Val Loss: 0.2465\n",
      "\n",
      "Validation loss improved from 0.2467 to 0.2465. Saving model...\n",
      "LOG: Epoch [399/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3879\n",
      "LOG: Epoch [399/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3661\n",
      "    Batch [2/2], Val Loss: 0.1270\n",
      "Epoch [399/2000], Avg Train Loss: 0.3881, Avg Val Loss: 0.2466\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [400/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3901\n",
      "    Batch [2/2], Train Loss: 0.3917\n",
      "LOG: Epoch [400/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3661\n",
      "    Batch [2/2], Val Loss: 0.1272\n",
      "Epoch [400/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2466\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [401/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3946\n",
      "    Batch [2/2], Train Loss: 0.3898\n",
      "LOG: Epoch [401/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3661\n",
      "    Batch [2/2], Val Loss: 0.1269\n",
      "Epoch [401/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2465\n",
      "\n",
      "Validation loss improved from 0.2465 to 0.2465. Saving model...\n",
      "LOG: Epoch [402/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3910\n",
      "    Batch [2/2], Train Loss: 0.3869\n",
      "LOG: Epoch [402/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3658\n",
      "    Batch [2/2], Val Loss: 0.1273\n",
      "Epoch [402/2000], Avg Train Loss: 0.3889, Avg Val Loss: 0.2466\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [403/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3855\n",
      "LOG: Epoch [403/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3659\n",
      "    Batch [2/2], Val Loss: 0.1268\n",
      "Epoch [403/2000], Avg Train Loss: 0.3878, Avg Val Loss: 0.2464\n",
      "\n",
      "Validation loss improved from 0.2465 to 0.2464. Saving model...\n",
      "LOG: Epoch [404/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3917\n",
      "    Batch [2/2], Train Loss: 0.3935\n",
      "LOG: Epoch [404/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3658\n",
      "    Batch [2/2], Val Loss: 0.1267\n",
      "Epoch [404/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2463\n",
      "\n",
      "Validation loss improved from 0.2464 to 0.2463. Saving model...\n",
      "LOG: Epoch [405/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3901\n",
      "LOG: Epoch [405/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3658\n",
      "    Batch [2/2], Val Loss: 0.1264\n",
      "Epoch [405/2000], Avg Train Loss: 0.3894, Avg Val Loss: 0.2461\n",
      "\n",
      "Validation loss improved from 0.2463 to 0.2461. Saving model...\n",
      "LOG: Epoch [406/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3904\n",
      "    Batch [2/2], Train Loss: 0.3898\n",
      "LOG: Epoch [406/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3657\n",
      "    Batch [2/2], Val Loss: 0.1271\n",
      "Epoch [406/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2464\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [407/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3850\n",
      "LOG: Epoch [407/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3659\n",
      "    Batch [2/2], Val Loss: 0.1269\n",
      "Epoch [407/2000], Avg Train Loss: 0.3862, Avg Val Loss: 0.2464\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [408/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3854\n",
      "    Batch [2/2], Train Loss: 0.3893\n",
      "LOG: Epoch [408/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3657\n",
      "    Batch [2/2], Val Loss: 0.1265\n",
      "Epoch [408/2000], Avg Train Loss: 0.3874, Avg Val Loss: 0.2461\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [409/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3895\n",
      "LOG: Epoch [409/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3657\n",
      "    Batch [2/2], Val Loss: 0.1265\n",
      "Epoch [409/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2461\n",
      "\n",
      "Validation loss improved from 0.2461 to 0.2461. Saving model...\n",
      "LOG: Epoch [410/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3850\n",
      "    Batch [2/2], Train Loss: 0.3855\n",
      "LOG: Epoch [410/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3657\n",
      "    Batch [2/2], Val Loss: 0.1265\n",
      "Epoch [410/2000], Avg Train Loss: 0.3853, Avg Val Loss: 0.2461\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [411/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3853\n",
      "LOG: Epoch [411/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3655\n",
      "    Batch [2/2], Val Loss: 0.1266\n",
      "Epoch [411/2000], Avg Train Loss: 0.3891, Avg Val Loss: 0.2460\n",
      "\n",
      "Validation loss improved from 0.2461 to 0.2460. Saving model...\n",
      "LOG: Epoch [412/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3875\n",
      "    Batch [2/2], Train Loss: 0.3860\n",
      "LOG: Epoch [412/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3655\n",
      "    Batch [2/2], Val Loss: 0.1264\n",
      "Epoch [412/2000], Avg Train Loss: 0.3867, Avg Val Loss: 0.2459\n",
      "\n",
      "Validation loss improved from 0.2460 to 0.2459. Saving model...\n",
      "LOG: Epoch [413/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3816\n",
      "    Batch [2/2], Train Loss: 0.3895\n",
      "LOG: Epoch [413/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3653\n",
      "    Batch [2/2], Val Loss: 0.1261\n",
      "Epoch [413/2000], Avg Train Loss: 0.3855, Avg Val Loss: 0.2457\n",
      "\n",
      "Validation loss improved from 0.2459 to 0.2457. Saving model...\n",
      "LOG: Epoch [414/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3919\n",
      "LOG: Epoch [414/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3651\n",
      "    Batch [2/2], Val Loss: 0.1264\n",
      "Epoch [414/2000], Avg Train Loss: 0.3898, Avg Val Loss: 0.2457\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [415/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3892\n",
      "    Batch [2/2], Train Loss: 0.3862\n",
      "LOG: Epoch [415/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3650\n",
      "    Batch [2/2], Val Loss: 0.1261\n",
      "Epoch [415/2000], Avg Train Loss: 0.3877, Avg Val Loss: 0.2455\n",
      "\n",
      "Validation loss improved from 0.2457 to 0.2455. Saving model...\n",
      "LOG: Epoch [416/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3884\n",
      "LOG: Epoch [416/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3648\n",
      "    Batch [2/2], Val Loss: 0.1260\n",
      "Epoch [416/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2454\n",
      "\n",
      "Validation loss improved from 0.2455 to 0.2454. Saving model...\n",
      "LOG: Epoch [417/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3819\n",
      "    Batch [2/2], Train Loss: 0.3871\n",
      "LOG: Epoch [417/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3646\n",
      "    Batch [2/2], Val Loss: 0.1265\n",
      "Epoch [417/2000], Avg Train Loss: 0.3845, Avg Val Loss: 0.2455\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [418/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3870\n",
      "LOG: Epoch [418/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3644\n",
      "    Batch [2/2], Val Loss: 0.1270\n",
      "Epoch [418/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2457\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [419/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3840\n",
      "    Batch [2/2], Train Loss: 0.3940\n",
      "LOG: Epoch [419/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3643\n",
      "    Batch [2/2], Val Loss: 0.1269\n",
      "Epoch [419/2000], Avg Train Loss: 0.3890, Avg Val Loss: 0.2456\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [420/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3897\n",
      "LOG: Epoch [420/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3643\n",
      "    Batch [2/2], Val Loss: 0.1265\n",
      "Epoch [420/2000], Avg Train Loss: 0.3871, Avg Val Loss: 0.2454\n",
      "\n",
      "Validation loss improved from 0.2454 to 0.2454. Saving model...\n",
      "LOG: Epoch [421/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3884\n",
      "LOG: Epoch [421/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3643\n",
      "    Batch [2/2], Val Loss: 0.1264\n",
      "Epoch [421/2000], Avg Train Loss: 0.3874, Avg Val Loss: 0.2454\n",
      "\n",
      "Validation loss improved from 0.2454 to 0.2454. Saving model...\n",
      "LOG: Epoch [422/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3878\n",
      "    Batch [2/2], Train Loss: 0.3886\n",
      "LOG: Epoch [422/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3645\n",
      "    Batch [2/2], Val Loss: 0.1264\n",
      "Epoch [422/2000], Avg Train Loss: 0.3882, Avg Val Loss: 0.2454\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [423/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3835\n",
      "LOG: Epoch [423/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3643\n",
      "    Batch [2/2], Val Loss: 0.1265\n",
      "Epoch [423/2000], Avg Train Loss: 0.3854, Avg Val Loss: 0.2454\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [424/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3873\n",
      "LOG: Epoch [424/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3643\n",
      "    Batch [2/2], Val Loss: 0.1265\n",
      "Epoch [424/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2454\n",
      "\n",
      "Validation loss improved from 0.2454 to 0.2454. Saving model...\n",
      "LOG: Epoch [425/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3858\n",
      "    Batch [2/2], Train Loss: 0.3915\n",
      "LOG: Epoch [425/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3640\n",
      "    Batch [2/2], Val Loss: 0.1267\n",
      "Epoch [425/2000], Avg Train Loss: 0.3886, Avg Val Loss: 0.2454\n",
      "\n",
      "Validation loss improved from 0.2454 to 0.2454. Saving model...\n",
      "LOG: Epoch [426/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3876\n",
      "    Batch [2/2], Train Loss: 0.3857\n",
      "LOG: Epoch [426/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3637\n",
      "    Batch [2/2], Val Loss: 0.1271\n",
      "Epoch [426/2000], Avg Train Loss: 0.3867, Avg Val Loss: 0.2454\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [427/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3922\n",
      "LOG: Epoch [427/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3637\n",
      "    Batch [2/2], Val Loss: 0.1270\n",
      "Epoch [427/2000], Avg Train Loss: 0.3894, Avg Val Loss: 0.2454\n",
      "\n",
      "Validation loss improved from 0.2454 to 0.2454. Saving model...\n",
      "LOG: Epoch [428/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3855\n",
      "    Batch [2/2], Train Loss: 0.3854\n",
      "LOG: Epoch [428/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3637\n",
      "    Batch [2/2], Val Loss: 0.1273\n",
      "Epoch [428/2000], Avg Train Loss: 0.3854, Avg Val Loss: 0.2455\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [429/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3904\n",
      "LOG: Epoch [429/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3637\n",
      "    Batch [2/2], Val Loss: 0.1275\n",
      "Epoch [429/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2456\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [430/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3878\n",
      "    Batch [2/2], Train Loss: 0.3893\n",
      "LOG: Epoch [430/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3635\n",
      "    Batch [2/2], Val Loss: 0.1277\n",
      "Epoch [430/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2456\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [431/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3868\n",
      "LOG: Epoch [431/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3636\n",
      "    Batch [2/2], Val Loss: 0.1275\n",
      "Epoch [431/2000], Avg Train Loss: 0.3871, Avg Val Loss: 0.2456\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [432/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3886\n",
      "    Batch [2/2], Train Loss: 0.3843\n",
      "LOG: Epoch [432/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3636\n",
      "    Batch [2/2], Val Loss: 0.1271\n",
      "Epoch [432/2000], Avg Train Loss: 0.3864, Avg Val Loss: 0.2454\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [433/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3913\n",
      "LOG: Epoch [433/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3635\n",
      "    Batch [2/2], Val Loss: 0.1275\n",
      "Epoch [433/2000], Avg Train Loss: 0.3888, Avg Val Loss: 0.2455\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [434/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3894\n",
      "    Batch [2/2], Train Loss: 0.3906\n",
      "LOG: Epoch [434/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3637\n",
      "    Batch [2/2], Val Loss: 0.1270\n",
      "Epoch [434/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2453\n",
      "\n",
      "Validation loss improved from 0.2454 to 0.2453. Saving model...\n",
      "LOG: Epoch [435/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3846\n",
      "LOG: Epoch [435/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3636\n",
      "    Batch [2/2], Val Loss: 0.1272\n",
      "Epoch [435/2000], Avg Train Loss: 0.3844, Avg Val Loss: 0.2454\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [436/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3848\n",
      "    Batch [2/2], Train Loss: 0.3830\n",
      "LOG: Epoch [436/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3633\n",
      "    Batch [2/2], Val Loss: 0.1268\n",
      "Epoch [436/2000], Avg Train Loss: 0.3839, Avg Val Loss: 0.2450\n",
      "\n",
      "Validation loss improved from 0.2453 to 0.2450. Saving model...\n",
      "LOG: Epoch [437/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3869\n",
      "LOG: Epoch [437/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3632\n",
      "    Batch [2/2], Val Loss: 0.1264\n",
      "Epoch [437/2000], Avg Train Loss: 0.3862, Avg Val Loss: 0.2448\n",
      "\n",
      "Validation loss improved from 0.2450 to 0.2448. Saving model...\n",
      "LOG: Epoch [438/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3850\n",
      "    Batch [2/2], Train Loss: 0.3847\n",
      "LOG: Epoch [438/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3632\n",
      "    Batch [2/2], Val Loss: 0.1260\n",
      "Epoch [438/2000], Avg Train Loss: 0.3848, Avg Val Loss: 0.2446\n",
      "\n",
      "Validation loss improved from 0.2448 to 0.2446. Saving model...\n",
      "LOG: Epoch [439/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3791\n",
      "LOG: Epoch [439/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3630\n",
      "    Batch [2/2], Val Loss: 0.1260\n",
      "Epoch [439/2000], Avg Train Loss: 0.3851, Avg Val Loss: 0.2445\n",
      "\n",
      "Validation loss improved from 0.2446 to 0.2445. Saving model...\n",
      "LOG: Epoch [440/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3837\n",
      "    Batch [2/2], Train Loss: 0.3882\n",
      "LOG: Epoch [440/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3629\n",
      "    Batch [2/2], Val Loss: 0.1259\n",
      "Epoch [440/2000], Avg Train Loss: 0.3859, Avg Val Loss: 0.2444\n",
      "\n",
      "Validation loss improved from 0.2445 to 0.2444. Saving model...\n",
      "LOG: Epoch [441/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3814\n",
      "LOG: Epoch [441/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3628\n",
      "    Batch [2/2], Val Loss: 0.1260\n",
      "Epoch [441/2000], Avg Train Loss: 0.3846, Avg Val Loss: 0.2444\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [442/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3891\n",
      "    Batch [2/2], Train Loss: 0.3868\n",
      "LOG: Epoch [442/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3627\n",
      "    Batch [2/2], Val Loss: 0.1263\n",
      "Epoch [442/2000], Avg Train Loss: 0.3879, Avg Val Loss: 0.2445\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [443/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3855\n",
      "LOG: Epoch [443/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3628\n",
      "    Batch [2/2], Val Loss: 0.1270\n",
      "Epoch [443/2000], Avg Train Loss: 0.3871, Avg Val Loss: 0.2449\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [444/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3826\n",
      "    Batch [2/2], Train Loss: 0.3821\n",
      "LOG: Epoch [444/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3628\n",
      "    Batch [2/2], Val Loss: 0.1269\n",
      "Epoch [444/2000], Avg Train Loss: 0.3824, Avg Val Loss: 0.2449\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [445/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3829\n",
      "LOG: Epoch [445/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3625\n",
      "    Batch [2/2], Val Loss: 0.1269\n",
      "Epoch [445/2000], Avg Train Loss: 0.3846, Avg Val Loss: 0.2447\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [446/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3779\n",
      "    Batch [2/2], Train Loss: 0.3793\n",
      "LOG: Epoch [446/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3622\n",
      "    Batch [2/2], Val Loss: 0.1270\n",
      "Epoch [446/2000], Avg Train Loss: 0.3786, Avg Val Loss: 0.2446\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [447/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3844\n",
      "LOG: Epoch [447/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3620\n",
      "    Batch [2/2], Val Loss: 0.1268\n",
      "Epoch [447/2000], Avg Train Loss: 0.3842, Avg Val Loss: 0.2444\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [448/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3861\n",
      "    Batch [2/2], Train Loss: 0.3887\n",
      "LOG: Epoch [448/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3620\n",
      "    Batch [2/2], Val Loss: 0.1268\n",
      "Epoch [448/2000], Avg Train Loss: 0.3874, Avg Val Loss: 0.2444\n",
      "\n",
      "Validation loss improved from 0.2444 to 0.2444. Saving model...\n",
      "LOG: Epoch [449/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3899\n",
      "    Batch [2/2], Train Loss: 0.3862\n",
      "LOG: Epoch [449/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3619\n",
      "    Batch [2/2], Val Loss: 0.1267\n",
      "Epoch [449/2000], Avg Train Loss: 0.3880, Avg Val Loss: 0.2443\n",
      "\n",
      "Validation loss improved from 0.2444 to 0.2443. Saving model...\n",
      "LOG: Epoch [450/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3866\n",
      "LOG: Epoch [450/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3619\n",
      "    Batch [2/2], Val Loss: 0.1263\n",
      "Epoch [450/2000], Avg Train Loss: 0.3857, Avg Val Loss: 0.2441\n",
      "\n",
      "Validation loss improved from 0.2443 to 0.2441. Saving model...\n",
      "LOG: Epoch [451/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3822\n",
      "    Batch [2/2], Train Loss: 0.3837\n",
      "LOG: Epoch [451/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3619\n",
      "    Batch [2/2], Val Loss: 0.1261\n",
      "Epoch [451/2000], Avg Train Loss: 0.3830, Avg Val Loss: 0.2440\n",
      "\n",
      "Validation loss improved from 0.2441 to 0.2440. Saving model...\n",
      "LOG: Epoch [452/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3896\n",
      "LOG: Epoch [452/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3619\n",
      "    Batch [2/2], Val Loss: 0.1258\n",
      "Epoch [452/2000], Avg Train Loss: 0.3884, Avg Val Loss: 0.2439\n",
      "\n",
      "Validation loss improved from 0.2440 to 0.2439. Saving model...\n",
      "LOG: Epoch [453/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3927\n",
      "    Batch [2/2], Train Loss: 0.3831\n",
      "LOG: Epoch [453/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3620\n",
      "    Batch [2/2], Val Loss: 0.1258\n",
      "Epoch [453/2000], Avg Train Loss: 0.3879, Avg Val Loss: 0.2439\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [454/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3831\n",
      "LOG: Epoch [454/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3620\n",
      "    Batch [2/2], Val Loss: 0.1255\n",
      "Epoch [454/2000], Avg Train Loss: 0.3857, Avg Val Loss: 0.2438\n",
      "\n",
      "Validation loss improved from 0.2439 to 0.2438. Saving model...\n",
      "LOG: Epoch [455/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3851\n",
      "    Batch [2/2], Train Loss: 0.3844\n",
      "LOG: Epoch [455/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3619\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [455/2000], Avg Train Loss: 0.3848, Avg Val Loss: 0.2438\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [456/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3819\n",
      "LOG: Epoch [456/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3619\n",
      "    Batch [2/2], Val Loss: 0.1253\n",
      "Epoch [456/2000], Avg Train Loss: 0.3846, Avg Val Loss: 0.2436\n",
      "\n",
      "Validation loss improved from 0.2438 to 0.2436. Saving model...\n",
      "LOG: Epoch [457/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3793\n",
      "    Batch [2/2], Train Loss: 0.3777\n",
      "LOG: Epoch [457/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3617\n",
      "    Batch [2/2], Val Loss: 0.1250\n",
      "Epoch [457/2000], Avg Train Loss: 0.3785, Avg Val Loss: 0.2433\n",
      "\n",
      "Validation loss improved from 0.2436 to 0.2433. Saving model...\n",
      "LOG: Epoch [458/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3861\n",
      "LOG: Epoch [458/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3617\n",
      "    Batch [2/2], Val Loss: 0.1249\n",
      "Epoch [458/2000], Avg Train Loss: 0.3853, Avg Val Loss: 0.2433\n",
      "\n",
      "Validation loss improved from 0.2433 to 0.2433. Saving model...\n",
      "LOG: Epoch [459/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3884\n",
      "    Batch [2/2], Train Loss: 0.3885\n",
      "LOG: Epoch [459/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3615\n",
      "    Batch [2/2], Val Loss: 0.1253\n",
      "Epoch [459/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2434\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [460/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3815\n",
      "LOG: Epoch [460/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3614\n",
      "    Batch [2/2], Val Loss: 0.1255\n",
      "Epoch [460/2000], Avg Train Loss: 0.3850, Avg Val Loss: 0.2434\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [461/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3828\n",
      "LOG: Epoch [461/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3612\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [461/2000], Avg Train Loss: 0.3836, Avg Val Loss: 0.2434\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [462/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3870\n",
      "    Batch [2/2], Train Loss: 0.3851\n",
      "LOG: Epoch [462/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [462/2000], Avg Train Loss: 0.3861, Avg Val Loss: 0.2433\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [463/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3828\n",
      "    Batch [2/2], Train Loss: 0.3840\n",
      "LOG: Epoch [463/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [463/2000], Avg Train Loss: 0.3834, Avg Val Loss: 0.2433\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [464/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3846\n",
      "LOG: Epoch [464/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.1254\n",
      "Epoch [464/2000], Avg Train Loss: 0.3838, Avg Val Loss: 0.2432\n",
      "\n",
      "Validation loss improved from 0.2433 to 0.2432. Saving model...\n",
      "LOG: Epoch [465/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3852\n",
      "    Batch [2/2], Train Loss: 0.3798\n",
      "LOG: Epoch [465/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.1258\n",
      "Epoch [465/2000], Avg Train Loss: 0.3825, Avg Val Loss: 0.2434\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [466/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3834\n",
      "LOG: Epoch [466/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.1260\n",
      "Epoch [466/2000], Avg Train Loss: 0.3832, Avg Val Loss: 0.2435\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [467/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3763\n",
      "    Batch [2/2], Train Loss: 0.3821\n",
      "LOG: Epoch [467/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.1259\n",
      "Epoch [467/2000], Avg Train Loss: 0.3792, Avg Val Loss: 0.2435\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [468/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3796\n",
      "LOG: Epoch [468/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.1261\n",
      "Epoch [468/2000], Avg Train Loss: 0.3807, Avg Val Loss: 0.2436\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [469/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3797\n",
      "    Batch [2/2], Train Loss: 0.3883\n",
      "LOG: Epoch [469/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3612\n",
      "    Batch [2/2], Val Loss: 0.1257\n",
      "Epoch [469/2000], Avg Train Loss: 0.3840, Avg Val Loss: 0.2434\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [470/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3812\n",
      "LOG: Epoch [470/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.1261\n",
      "Epoch [470/2000], Avg Train Loss: 0.3810, Avg Val Loss: 0.2436\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [471/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3845\n",
      "    Batch [2/2], Train Loss: 0.3767\n",
      "LOG: Epoch [471/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.1261\n",
      "Epoch [471/2000], Avg Train Loss: 0.3806, Avg Val Loss: 0.2435\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [472/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3851\n",
      "    Batch [2/2], Train Loss: 0.3766\n",
      "LOG: Epoch [472/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.1263\n",
      "Epoch [472/2000], Avg Train Loss: 0.3809, Avg Val Loss: 0.2435\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [473/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3843\n",
      "LOG: Epoch [473/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.1264\n",
      "Epoch [473/2000], Avg Train Loss: 0.3820, Avg Val Loss: 0.2436\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [474/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3816\n",
      "    Batch [2/2], Train Loss: 0.3781\n",
      "LOG: Epoch [474/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.1265\n",
      "Epoch [474/2000], Avg Train Loss: 0.3798, Avg Val Loss: 0.2437\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [475/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3813\n",
      "LOG: Epoch [475/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.1266\n",
      "Epoch [475/2000], Avg Train Loss: 0.3812, Avg Val Loss: 0.2438\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [476/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3881\n",
      "LOG: Epoch [476/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.1267\n",
      "Epoch [476/2000], Avg Train Loss: 0.3826, Avg Val Loss: 0.2440\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [477/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3820\n",
      "    Batch [2/2], Train Loss: 0.3814\n",
      "LOG: Epoch [477/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.1267\n",
      "Epoch [477/2000], Avg Train Loss: 0.3817, Avg Val Loss: 0.2440\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [478/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3828\n",
      "    Batch [2/2], Train Loss: 0.3888\n",
      "LOG: Epoch [478/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3612\n",
      "    Batch [2/2], Val Loss: 0.1258\n",
      "Epoch [478/2000], Avg Train Loss: 0.3858, Avg Val Loss: 0.2435\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [479/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3874\n",
      "LOG: Epoch [479/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.1254\n",
      "Epoch [479/2000], Avg Train Loss: 0.3880, Avg Val Loss: 0.2432\n",
      "\n",
      "Validation loss improved from 0.2432 to 0.2432. Saving model...\n",
      "LOG: Epoch [480/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3810\n",
      "    Batch [2/2], Train Loss: 0.3798\n",
      "LOG: Epoch [480/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.1250\n",
      "Epoch [480/2000], Avg Train Loss: 0.3804, Avg Val Loss: 0.2428\n",
      "\n",
      "Validation loss improved from 0.2432 to 0.2428. Saving model...\n",
      "LOG: Epoch [481/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3807\n",
      "LOG: Epoch [481/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.1248\n",
      "Epoch [481/2000], Avg Train Loss: 0.3835, Avg Val Loss: 0.2426\n",
      "\n",
      "Validation loss improved from 0.2428 to 0.2426. Saving model...\n",
      "LOG: Epoch [482/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3837\n",
      "LOG: Epoch [482/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.1245\n",
      "Epoch [482/2000], Avg Train Loss: 0.3826, Avg Val Loss: 0.2424\n",
      "\n",
      "Validation loss improved from 0.2426 to 0.2424. Saving model...\n",
      "LOG: Epoch [483/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3801\n",
      "LOG: Epoch [483/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3600\n",
      "    Batch [2/2], Val Loss: 0.1244\n",
      "Epoch [483/2000], Avg Train Loss: 0.3817, Avg Val Loss: 0.2422\n",
      "\n",
      "Validation loss improved from 0.2424 to 0.2422. Saving model...\n",
      "LOG: Epoch [484/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3767\n",
      "    Batch [2/2], Train Loss: 0.3826\n",
      "LOG: Epoch [484/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3597\n",
      "    Batch [2/2], Val Loss: 0.1239\n",
      "Epoch [484/2000], Avg Train Loss: 0.3797, Avg Val Loss: 0.2418\n",
      "\n",
      "Validation loss improved from 0.2422 to 0.2418. Saving model...\n",
      "LOG: Epoch [485/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3855\n",
      "LOG: Epoch [485/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3596\n",
      "    Batch [2/2], Val Loss: 0.1236\n",
      "Epoch [485/2000], Avg Train Loss: 0.3842, Avg Val Loss: 0.2416\n",
      "\n",
      "Validation loss improved from 0.2418 to 0.2416. Saving model...\n",
      "LOG: Epoch [486/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3750\n",
      "LOG: Epoch [486/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3596\n",
      "    Batch [2/2], Val Loss: 0.1233\n",
      "Epoch [486/2000], Avg Train Loss: 0.3764, Avg Val Loss: 0.2414\n",
      "\n",
      "Validation loss improved from 0.2416 to 0.2414. Saving model...\n",
      "LOG: Epoch [487/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3796\n",
      "    Batch [2/2], Train Loss: 0.3805\n",
      "LOG: Epoch [487/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3594\n",
      "    Batch [2/2], Val Loss: 0.1231\n",
      "Epoch [487/2000], Avg Train Loss: 0.3801, Avg Val Loss: 0.2413\n",
      "\n",
      "Validation loss improved from 0.2414 to 0.2413. Saving model...\n",
      "LOG: Epoch [488/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3797\n",
      "    Batch [2/2], Train Loss: 0.3858\n",
      "LOG: Epoch [488/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3594\n",
      "    Batch [2/2], Val Loss: 0.1230\n",
      "Epoch [488/2000], Avg Train Loss: 0.3828, Avg Val Loss: 0.2412\n",
      "\n",
      "Validation loss improved from 0.2413 to 0.2412. Saving model...\n",
      "LOG: Epoch [489/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3785\n",
      "LOG: Epoch [489/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3594\n",
      "    Batch [2/2], Val Loss: 0.1230\n",
      "Epoch [489/2000], Avg Train Loss: 0.3813, Avg Val Loss: 0.2412\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [490/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3852\n",
      "    Batch [2/2], Train Loss: 0.3836\n",
      "LOG: Epoch [490/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3597\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [490/2000], Avg Train Loss: 0.3844, Avg Val Loss: 0.2412\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [491/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3775\n",
      "    Batch [2/2], Train Loss: 0.3822\n",
      "LOG: Epoch [491/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3597\n",
      "    Batch [2/2], Val Loss: 0.1230\n",
      "Epoch [491/2000], Avg Train Loss: 0.3799, Avg Val Loss: 0.2413\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [492/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3805\n",
      "    Batch [2/2], Train Loss: 0.3837\n",
      "LOG: Epoch [492/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3596\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [492/2000], Avg Train Loss: 0.3821, Avg Val Loss: 0.2413\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [493/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3859\n",
      "LOG: Epoch [493/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3596\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [493/2000], Avg Train Loss: 0.3793, Avg Val Loss: 0.2412\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [494/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3798\n",
      "    Batch [2/2], Train Loss: 0.3781\n",
      "LOG: Epoch [494/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1232\n",
      "Epoch [494/2000], Avg Train Loss: 0.3789, Avg Val Loss: 0.2414\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [495/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3797\n",
      "LOG: Epoch [495/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3593\n",
      "    Batch [2/2], Val Loss: 0.1232\n",
      "Epoch [495/2000], Avg Train Loss: 0.3788, Avg Val Loss: 0.2412\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [496/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3863\n",
      "    Batch [2/2], Train Loss: 0.3787\n",
      "LOG: Epoch [496/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3592\n",
      "    Batch [2/2], Val Loss: 0.1234\n",
      "Epoch [496/2000], Avg Train Loss: 0.3825, Avg Val Loss: 0.2413\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [497/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3742\n",
      "LOG: Epoch [497/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3590\n",
      "    Batch [2/2], Val Loss: 0.1230\n",
      "Epoch [497/2000], Avg Train Loss: 0.3776, Avg Val Loss: 0.2410\n",
      "\n",
      "Validation loss improved from 0.2412 to 0.2410. Saving model...\n",
      "LOG: Epoch [498/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3826\n",
      "LOG: Epoch [498/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3591\n",
      "    Batch [2/2], Val Loss: 0.1224\n",
      "Epoch [498/2000], Avg Train Loss: 0.3805, Avg Val Loss: 0.2407\n",
      "\n",
      "Validation loss improved from 0.2410 to 0.2407. Saving model...\n",
      "LOG: Epoch [499/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3773\n",
      "    Batch [2/2], Train Loss: 0.3812\n",
      "LOG: Epoch [499/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3588\n",
      "    Batch [2/2], Val Loss: 0.1232\n",
      "Epoch [499/2000], Avg Train Loss: 0.3792, Avg Val Loss: 0.2410\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [500/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3812\n",
      "    Batch [2/2], Train Loss: 0.3766\n",
      "LOG: Epoch [500/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3588\n",
      "    Batch [2/2], Val Loss: 0.1231\n",
      "Epoch [500/2000], Avg Train Loss: 0.3789, Avg Val Loss: 0.2409\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [501/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3787\n",
      "LOG: Epoch [501/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3587\n",
      "    Batch [2/2], Val Loss: 0.1238\n",
      "Epoch [501/2000], Avg Train Loss: 0.3810, Avg Val Loss: 0.2413\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [502/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3790\n",
      "LOG: Epoch [502/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3584\n",
      "    Batch [2/2], Val Loss: 0.1245\n",
      "Epoch [502/2000], Avg Train Loss: 0.3797, Avg Val Loss: 0.2415\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [503/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3823\n",
      "LOG: Epoch [503/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3581\n",
      "    Batch [2/2], Val Loss: 0.1251\n",
      "Epoch [503/2000], Avg Train Loss: 0.3812, Avg Val Loss: 0.2416\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [504/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3906\n",
      "    Batch [2/2], Train Loss: 0.3847\n",
      "LOG: Epoch [504/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3580\n",
      "    Batch [2/2], Val Loss: 0.1257\n",
      "Epoch [504/2000], Avg Train Loss: 0.3876, Avg Val Loss: 0.2418\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [505/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3832\n",
      "LOG: Epoch [505/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3580\n",
      "    Batch [2/2], Val Loss: 0.1247\n",
      "Epoch [505/2000], Avg Train Loss: 0.3813, Avg Val Loss: 0.2414\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [506/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3834\n",
      "    Batch [2/2], Train Loss: 0.3868\n",
      "LOG: Epoch [506/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3580\n",
      "    Batch [2/2], Val Loss: 0.1246\n",
      "Epoch [506/2000], Avg Train Loss: 0.3851, Avg Val Loss: 0.2413\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [507/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3783\n",
      "LOG: Epoch [507/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3580\n",
      "    Batch [2/2], Val Loss: 0.1245\n",
      "Epoch [507/2000], Avg Train Loss: 0.3783, Avg Val Loss: 0.2412\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [508/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3768\n",
      "    Batch [2/2], Train Loss: 0.3776\n",
      "LOG: Epoch [508/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3579\n",
      "    Batch [2/2], Val Loss: 0.1246\n",
      "Epoch [508/2000], Avg Train Loss: 0.3772, Avg Val Loss: 0.2412\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [509/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3849\n",
      "LOG: Epoch [509/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3579\n",
      "    Batch [2/2], Val Loss: 0.1241\n",
      "Epoch [509/2000], Avg Train Loss: 0.3816, Avg Val Loss: 0.2410\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [510/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3833\n",
      "    Batch [2/2], Train Loss: 0.3791\n",
      "LOG: Epoch [510/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3577\n",
      "    Batch [2/2], Val Loss: 0.1237\n",
      "Epoch [510/2000], Avg Train Loss: 0.3812, Avg Val Loss: 0.2407\n",
      "\n",
      "Validation loss improved from 0.2407 to 0.2407. Saving model...\n",
      "LOG: Epoch [511/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3763\n",
      "    Batch [2/2], Train Loss: 0.3766\n",
      "LOG: Epoch [511/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3577\n",
      "    Batch [2/2], Val Loss: 0.1231\n",
      "Epoch [511/2000], Avg Train Loss: 0.3764, Avg Val Loss: 0.2404\n",
      "\n",
      "Validation loss improved from 0.2407 to 0.2404. Saving model...\n",
      "LOG: Epoch [512/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3802\n",
      "LOG: Epoch [512/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3576\n",
      "    Batch [2/2], Val Loss: 0.1232\n",
      "Epoch [512/2000], Avg Train Loss: 0.3794, Avg Val Loss: 0.2404\n",
      "\n",
      "Validation loss improved from 0.2404 to 0.2404. Saving model...\n",
      "LOG: Epoch [513/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3749\n",
      "LOG: Epoch [513/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3577\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [513/2000], Avg Train Loss: 0.3793, Avg Val Loss: 0.2403\n",
      "\n",
      "Validation loss improved from 0.2404 to 0.2403. Saving model...\n",
      "LOG: Epoch [514/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3819\n",
      "    Batch [2/2], Train Loss: 0.3770\n",
      "LOG: Epoch [514/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3576\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [514/2000], Avg Train Loss: 0.3795, Avg Val Loss: 0.2402\n",
      "\n",
      "Validation loss improved from 0.2403 to 0.2402. Saving model...\n",
      "LOG: Epoch [515/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3761\n",
      "    Batch [2/2], Train Loss: 0.3805\n",
      "LOG: Epoch [515/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3577\n",
      "    Batch [2/2], Val Loss: 0.1222\n",
      "Epoch [515/2000], Avg Train Loss: 0.3783, Avg Val Loss: 0.2400\n",
      "\n",
      "Validation loss improved from 0.2402 to 0.2400. Saving model...\n",
      "LOG: Epoch [516/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3766\n",
      "    Batch [2/2], Train Loss: 0.3812\n",
      "LOG: Epoch [516/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3577\n",
      "    Batch [2/2], Val Loss: 0.1223\n",
      "Epoch [516/2000], Avg Train Loss: 0.3789, Avg Val Loss: 0.2400\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [517/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3828\n",
      "    Batch [2/2], Train Loss: 0.3804\n",
      "LOG: Epoch [517/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3575\n",
      "    Batch [2/2], Val Loss: 0.1223\n",
      "Epoch [517/2000], Avg Train Loss: 0.3816, Avg Val Loss: 0.2399\n",
      "\n",
      "Validation loss improved from 0.2400 to 0.2399. Saving model...\n",
      "LOG: Epoch [518/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3802\n",
      "    Batch [2/2], Train Loss: 0.3798\n",
      "LOG: Epoch [518/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3575\n",
      "    Batch [2/2], Val Loss: 0.1218\n",
      "Epoch [518/2000], Avg Train Loss: 0.3800, Avg Val Loss: 0.2396\n",
      "\n",
      "Validation loss improved from 0.2399 to 0.2396. Saving model...\n",
      "LOG: Epoch [519/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3771\n",
      "LOG: Epoch [519/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3573\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [519/2000], Avg Train Loss: 0.3767, Avg Val Loss: 0.2400\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [520/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3807\n",
      "LOG: Epoch [520/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3572\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [520/2000], Avg Train Loss: 0.3804, Avg Val Loss: 0.2400\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [521/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3836\n",
      "    Batch [2/2], Train Loss: 0.3779\n",
      "LOG: Epoch [521/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3570\n",
      "    Batch [2/2], Val Loss: 0.1233\n",
      "Epoch [521/2000], Avg Train Loss: 0.3808, Avg Val Loss: 0.2401\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [522/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3833\n",
      "    Batch [2/2], Train Loss: 0.3812\n",
      "LOG: Epoch [522/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3571\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [522/2000], Avg Train Loss: 0.3823, Avg Val Loss: 0.2400\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [523/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3798\n",
      "    Batch [2/2], Train Loss: 0.3820\n",
      "LOG: Epoch [523/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3571\n",
      "    Batch [2/2], Val Loss: 0.1225\n",
      "Epoch [523/2000], Avg Train Loss: 0.3809, Avg Val Loss: 0.2398\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [524/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3767\n",
      "    Batch [2/2], Train Loss: 0.3791\n",
      "LOG: Epoch [524/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3570\n",
      "    Batch [2/2], Val Loss: 0.1225\n",
      "Epoch [524/2000], Avg Train Loss: 0.3779, Avg Val Loss: 0.2398\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [525/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3764\n",
      "    Batch [2/2], Train Loss: 0.3762\n",
      "LOG: Epoch [525/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3571\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [525/2000], Avg Train Loss: 0.3763, Avg Val Loss: 0.2399\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [526/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3755\n",
      "LOG: Epoch [526/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3570\n",
      "    Batch [2/2], Val Loss: 0.1231\n",
      "Epoch [526/2000], Avg Train Loss: 0.3761, Avg Val Loss: 0.2401\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [527/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3811\n",
      "    Batch [2/2], Train Loss: 0.3788\n",
      "LOG: Epoch [527/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3569\n",
      "    Batch [2/2], Val Loss: 0.1230\n",
      "Epoch [527/2000], Avg Train Loss: 0.3800, Avg Val Loss: 0.2399\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [528/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3795\n",
      "LOG: Epoch [528/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3567\n",
      "    Batch [2/2], Val Loss: 0.1237\n",
      "Epoch [528/2000], Avg Train Loss: 0.3795, Avg Val Loss: 0.2402\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [529/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3771\n",
      "LOG: Epoch [529/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3565\n",
      "    Batch [2/2], Val Loss: 0.1237\n",
      "Epoch [529/2000], Avg Train Loss: 0.3760, Avg Val Loss: 0.2401\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [530/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3766\n",
      "LOG: Epoch [530/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3563\n",
      "    Batch [2/2], Val Loss: 0.1239\n",
      "Epoch [530/2000], Avg Train Loss: 0.3767, Avg Val Loss: 0.2401\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [531/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3809\n",
      "LOG: Epoch [531/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3561\n",
      "    Batch [2/2], Val Loss: 0.1239\n",
      "Epoch [531/2000], Avg Train Loss: 0.3806, Avg Val Loss: 0.2400\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [532/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3784\n",
      "    Batch [2/2], Train Loss: 0.3784\n",
      "LOG: Epoch [532/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3557\n",
      "    Batch [2/2], Val Loss: 0.1241\n",
      "Epoch [532/2000], Avg Train Loss: 0.3784, Avg Val Loss: 0.2399\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [533/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3744\n",
      "    Batch [2/2], Train Loss: 0.3803\n",
      "LOG: Epoch [533/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3555\n",
      "    Batch [2/2], Val Loss: 0.1239\n",
      "Epoch [533/2000], Avg Train Loss: 0.3773, Avg Val Loss: 0.2397\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [534/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3756\n",
      "LOG: Epoch [534/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3553\n",
      "    Batch [2/2], Val Loss: 0.1242\n",
      "Epoch [534/2000], Avg Train Loss: 0.3762, Avg Val Loss: 0.2398\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [535/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3824\n",
      "    Batch [2/2], Train Loss: 0.3802\n",
      "LOG: Epoch [535/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3552\n",
      "    Batch [2/2], Val Loss: 0.1240\n",
      "Epoch [535/2000], Avg Train Loss: 0.3813, Avg Val Loss: 0.2396\n",
      "\n",
      "Validation loss improved from 0.2396 to 0.2396. Saving model...\n",
      "LOG: Epoch [536/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3764\n",
      "    Batch [2/2], Train Loss: 0.3782\n",
      "LOG: Epoch [536/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3550\n",
      "    Batch [2/2], Val Loss: 0.1236\n",
      "Epoch [536/2000], Avg Train Loss: 0.3773, Avg Val Loss: 0.2393\n",
      "\n",
      "Validation loss improved from 0.2396 to 0.2393. Saving model...\n",
      "LOG: Epoch [537/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3816\n",
      "LOG: Epoch [537/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3551\n",
      "    Batch [2/2], Val Loss: 0.1239\n",
      "Epoch [537/2000], Avg Train Loss: 0.3792, Avg Val Loss: 0.2395\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [538/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3806\n",
      "LOG: Epoch [538/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3551\n",
      "    Batch [2/2], Val Loss: 0.1232\n",
      "Epoch [538/2000], Avg Train Loss: 0.3770, Avg Val Loss: 0.2392\n",
      "\n",
      "Validation loss improved from 0.2393 to 0.2392. Saving model...\n",
      "LOG: Epoch [539/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3749\n",
      "LOG: Epoch [539/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3551\n",
      "    Batch [2/2], Val Loss: 0.1233\n",
      "Epoch [539/2000], Avg Train Loss: 0.3737, Avg Val Loss: 0.2392\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [540/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3765\n",
      "    Batch [2/2], Train Loss: 0.3760\n",
      "LOG: Epoch [540/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3551\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [540/2000], Avg Train Loss: 0.3762, Avg Val Loss: 0.2389\n",
      "\n",
      "Validation loss improved from 0.2392 to 0.2389. Saving model...\n",
      "LOG: Epoch [541/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3752\n",
      "LOG: Epoch [541/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3551\n",
      "    Batch [2/2], Val Loss: 0.1220\n",
      "Epoch [541/2000], Avg Train Loss: 0.3746, Avg Val Loss: 0.2385\n",
      "\n",
      "Validation loss improved from 0.2389 to 0.2385. Saving model...\n",
      "LOG: Epoch [542/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3766\n",
      "LOG: Epoch [542/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3551\n",
      "    Batch [2/2], Val Loss: 0.1215\n",
      "Epoch [542/2000], Avg Train Loss: 0.3747, Avg Val Loss: 0.2383\n",
      "\n",
      "Validation loss improved from 0.2385 to 0.2383. Saving model...\n",
      "LOG: Epoch [543/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3707\n",
      "    Batch [2/2], Train Loss: 0.3758\n",
      "LOG: Epoch [543/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3548\n",
      "    Batch [2/2], Val Loss: 0.1212\n",
      "Epoch [543/2000], Avg Train Loss: 0.3733, Avg Val Loss: 0.2380\n",
      "\n",
      "Validation loss improved from 0.2383 to 0.2380. Saving model...\n",
      "LOG: Epoch [544/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3824\n",
      "    Batch [2/2], Train Loss: 0.3774\n",
      "LOG: Epoch [544/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3544\n",
      "    Batch [2/2], Val Loss: 0.1216\n",
      "Epoch [544/2000], Avg Train Loss: 0.3799, Avg Val Loss: 0.2380\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [545/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3758\n",
      "    Batch [2/2], Train Loss: 0.3758\n",
      "LOG: Epoch [545/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3542\n",
      "    Batch [2/2], Val Loss: 0.1218\n",
      "Epoch [545/2000], Avg Train Loss: 0.3758, Avg Val Loss: 0.2380\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [546/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3763\n",
      "LOG: Epoch [546/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3542\n",
      "    Batch [2/2], Val Loss: 0.1219\n",
      "Epoch [546/2000], Avg Train Loss: 0.3759, Avg Val Loss: 0.2381\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [547/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3715\n",
      "    Batch [2/2], Train Loss: 0.3803\n",
      "LOG: Epoch [547/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3540\n",
      "    Batch [2/2], Val Loss: 0.1224\n",
      "Epoch [547/2000], Avg Train Loss: 0.3759, Avg Val Loss: 0.2382\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [548/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3776\n",
      "    Batch [2/2], Train Loss: 0.3738\n",
      "LOG: Epoch [548/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3542\n",
      "    Batch [2/2], Val Loss: 0.1213\n",
      "Epoch [548/2000], Avg Train Loss: 0.3757, Avg Val Loss: 0.2377\n",
      "\n",
      "Validation loss improved from 0.2380 to 0.2377. Saving model...\n",
      "LOG: Epoch [549/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3727\n",
      "    Batch [2/2], Train Loss: 0.3731\n",
      "LOG: Epoch [549/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3541\n",
      "    Batch [2/2], Val Loss: 0.1218\n",
      "Epoch [549/2000], Avg Train Loss: 0.3729, Avg Val Loss: 0.2380\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [550/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3717\n",
      "LOG: Epoch [550/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3541\n",
      "    Batch [2/2], Val Loss: 0.1219\n",
      "Epoch [550/2000], Avg Train Loss: 0.3753, Avg Val Loss: 0.2380\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [551/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3775\n",
      "    Batch [2/2], Train Loss: 0.3757\n",
      "LOG: Epoch [551/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3542\n",
      "    Batch [2/2], Val Loss: 0.1218\n",
      "Epoch [551/2000], Avg Train Loss: 0.3766, Avg Val Loss: 0.2380\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [552/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3801\n",
      "    Batch [2/2], Train Loss: 0.3804\n",
      "LOG: Epoch [552/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3543\n",
      "    Batch [2/2], Val Loss: 0.1213\n",
      "Epoch [552/2000], Avg Train Loss: 0.3803, Avg Val Loss: 0.2378\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [553/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3757\n",
      "LOG: Epoch [553/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3542\n",
      "    Batch [2/2], Val Loss: 0.1216\n",
      "Epoch [553/2000], Avg Train Loss: 0.3775, Avg Val Loss: 0.2379\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [554/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3801\n",
      "    Batch [2/2], Train Loss: 0.3783\n",
      "LOG: Epoch [554/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3544\n",
      "    Batch [2/2], Val Loss: 0.1213\n",
      "Epoch [554/2000], Avg Train Loss: 0.3792, Avg Val Loss: 0.2378\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [555/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3759\n",
      "LOG: Epoch [555/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3545\n",
      "    Batch [2/2], Val Loss: 0.1210\n",
      "Epoch [555/2000], Avg Train Loss: 0.3757, Avg Val Loss: 0.2378\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [556/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3778\n",
      "LOG: Epoch [556/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3545\n",
      "    Batch [2/2], Val Loss: 0.1216\n",
      "Epoch [556/2000], Avg Train Loss: 0.3755, Avg Val Loss: 0.2381\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [557/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3779\n",
      "LOG: Epoch [557/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3544\n",
      "    Batch [2/2], Val Loss: 0.1215\n",
      "Epoch [557/2000], Avg Train Loss: 0.3776, Avg Val Loss: 0.2379\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [558/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3740\n",
      "LOG: Epoch [558/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3546\n",
      "    Batch [2/2], Val Loss: 0.1217\n",
      "Epoch [558/2000], Avg Train Loss: 0.3751, Avg Val Loss: 0.2381\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [559/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3718\n",
      "LOG: Epoch [559/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3549\n",
      "    Batch [2/2], Val Loss: 0.1209\n",
      "Epoch [559/2000], Avg Train Loss: 0.3734, Avg Val Loss: 0.2379\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [560/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3770\n",
      "    Batch [2/2], Train Loss: 0.3770\n",
      "LOG: Epoch [560/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3549\n",
      "    Batch [2/2], Val Loss: 0.1209\n",
      "Epoch [560/2000], Avg Train Loss: 0.3770, Avg Val Loss: 0.2379\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [561/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3770\n",
      "    Batch [2/2], Train Loss: 0.3740\n",
      "LOG: Epoch [561/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3550\n",
      "    Batch [2/2], Val Loss: 0.1210\n",
      "Epoch [561/2000], Avg Train Loss: 0.3755, Avg Val Loss: 0.2380\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [562/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3731\n",
      "    Batch [2/2], Train Loss: 0.3795\n",
      "LOG: Epoch [562/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3552\n",
      "    Batch [2/2], Val Loss: 0.1211\n",
      "Epoch [562/2000], Avg Train Loss: 0.3763, Avg Val Loss: 0.2381\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [563/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3695\n",
      "LOG: Epoch [563/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3555\n",
      "    Batch [2/2], Val Loss: 0.1209\n",
      "Epoch [563/2000], Avg Train Loss: 0.3713, Avg Val Loss: 0.2382\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [564/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3744\n",
      "    Batch [2/2], Train Loss: 0.3744\n",
      "LOG: Epoch [564/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3553\n",
      "    Batch [2/2], Val Loss: 0.1210\n",
      "Epoch [564/2000], Avg Train Loss: 0.3744, Avg Val Loss: 0.2382\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [565/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3726\n",
      "    Batch [2/2], Train Loss: 0.3778\n",
      "LOG: Epoch [565/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3553\n",
      "    Batch [2/2], Val Loss: 0.1201\n",
      "Epoch [565/2000], Avg Train Loss: 0.3752, Avg Val Loss: 0.2377\n",
      "\n",
      "Validation loss improved from 0.2377 to 0.2377. Saving model...\n",
      "LOG: Epoch [566/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3758\n",
      "    Batch [2/2], Train Loss: 0.3679\n",
      "LOG: Epoch [566/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3552\n",
      "    Batch [2/2], Val Loss: 0.1193\n",
      "Epoch [566/2000], Avg Train Loss: 0.3718, Avg Val Loss: 0.2373\n",
      "\n",
      "Validation loss improved from 0.2377 to 0.2373. Saving model...\n",
      "LOG: Epoch [567/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3731\n",
      "    Batch [2/2], Train Loss: 0.3809\n",
      "LOG: Epoch [567/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3555\n",
      "    Batch [2/2], Val Loss: 0.1192\n",
      "Epoch [567/2000], Avg Train Loss: 0.3770, Avg Val Loss: 0.2373\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [568/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3765\n",
      "LOG: Epoch [568/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3557\n",
      "    Batch [2/2], Val Loss: 0.1180\n",
      "Epoch [568/2000], Avg Train Loss: 0.3781, Avg Val Loss: 0.2369\n",
      "\n",
      "Validation loss improved from 0.2373 to 0.2369. Saving model...\n",
      "LOG: Epoch [569/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3734\n",
      "    Batch [2/2], Train Loss: 0.3743\n",
      "LOG: Epoch [569/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3556\n",
      "    Batch [2/2], Val Loss: 0.1180\n",
      "Epoch [569/2000], Avg Train Loss: 0.3739, Avg Val Loss: 0.2368\n",
      "\n",
      "Validation loss improved from 0.2369 to 0.2368. Saving model...\n",
      "LOG: Epoch [570/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3765\n",
      "    Batch [2/2], Train Loss: 0.3773\n",
      "LOG: Epoch [570/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3552\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [570/2000], Avg Train Loss: 0.3769, Avg Val Loss: 0.2365\n",
      "\n",
      "Validation loss improved from 0.2368 to 0.2365. Saving model...\n",
      "LOG: Epoch [571/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3764\n",
      "LOG: Epoch [571/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3551\n",
      "    Batch [2/2], Val Loss: 0.1178\n",
      "Epoch [571/2000], Avg Train Loss: 0.3731, Avg Val Loss: 0.2364\n",
      "\n",
      "Validation loss improved from 0.2365 to 0.2364. Saving model...\n",
      "LOG: Epoch [572/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3696\n",
      "LOG: Epoch [572/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3550\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [572/2000], Avg Train Loss: 0.3745, Avg Val Loss: 0.2366\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [573/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3745\n",
      "LOG: Epoch [573/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3547\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [573/2000], Avg Train Loss: 0.3735, Avg Val Loss: 0.2365\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [574/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3829\n",
      "    Batch [2/2], Train Loss: 0.3743\n",
      "LOG: Epoch [574/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3546\n",
      "    Batch [2/2], Val Loss: 0.1187\n",
      "Epoch [574/2000], Avg Train Loss: 0.3786, Avg Val Loss: 0.2366\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [575/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3722\n",
      "LOG: Epoch [575/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3546\n",
      "    Batch [2/2], Val Loss: 0.1190\n",
      "Epoch [575/2000], Avg Train Loss: 0.3742, Avg Val Loss: 0.2368\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [576/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3746\n",
      "    Batch [2/2], Train Loss: 0.3801\n",
      "LOG: Epoch [576/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3544\n",
      "    Batch [2/2], Val Loss: 0.1190\n",
      "Epoch [576/2000], Avg Train Loss: 0.3773, Avg Val Loss: 0.2367\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [577/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3721\n",
      "LOG: Epoch [577/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3541\n",
      "    Batch [2/2], Val Loss: 0.1197\n",
      "Epoch [577/2000], Avg Train Loss: 0.3752, Avg Val Loss: 0.2369\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [578/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3700\n",
      "    Batch [2/2], Train Loss: 0.3757\n",
      "LOG: Epoch [578/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3539\n",
      "    Batch [2/2], Val Loss: 0.1194\n",
      "Epoch [578/2000], Avg Train Loss: 0.3729, Avg Val Loss: 0.2367\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [579/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3771\n",
      "    Batch [2/2], Train Loss: 0.3766\n",
      "LOG: Epoch [579/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3540\n",
      "    Batch [2/2], Val Loss: 0.1188\n",
      "Epoch [579/2000], Avg Train Loss: 0.3768, Avg Val Loss: 0.2364\n",
      "\n",
      "Validation loss improved from 0.2364 to 0.2364. Saving model...\n",
      "LOG: Epoch [580/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3685\n",
      "LOG: Epoch [580/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3538\n",
      "    Batch [2/2], Val Loss: 0.1190\n",
      "Epoch [580/2000], Avg Train Loss: 0.3709, Avg Val Loss: 0.2364\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [581/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3817\n",
      "LOG: Epoch [581/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3537\n",
      "    Batch [2/2], Val Loss: 0.1193\n",
      "Epoch [581/2000], Avg Train Loss: 0.3765, Avg Val Loss: 0.2365\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [582/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3719\n",
      "    Batch [2/2], Train Loss: 0.3786\n",
      "LOG: Epoch [582/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3539\n",
      "    Batch [2/2], Val Loss: 0.1191\n",
      "Epoch [582/2000], Avg Train Loss: 0.3753, Avg Val Loss: 0.2365\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [583/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3722\n",
      "LOG: Epoch [583/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3541\n",
      "    Batch [2/2], Val Loss: 0.1192\n",
      "Epoch [583/2000], Avg Train Loss: 0.3734, Avg Val Loss: 0.2367\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [584/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3753\n",
      "LOG: Epoch [584/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3540\n",
      "    Batch [2/2], Val Loss: 0.1195\n",
      "Epoch [584/2000], Avg Train Loss: 0.3712, Avg Val Loss: 0.2368\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [585/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3688\n",
      "    Batch [2/2], Train Loss: 0.3730\n",
      "LOG: Epoch [585/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3543\n",
      "    Batch [2/2], Val Loss: 0.1191\n",
      "Epoch [585/2000], Avg Train Loss: 0.3709, Avg Val Loss: 0.2367\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [586/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3686\n",
      "    Batch [2/2], Train Loss: 0.3710\n",
      "LOG: Epoch [586/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3545\n",
      "    Batch [2/2], Val Loss: 0.1193\n",
      "Epoch [586/2000], Avg Train Loss: 0.3698, Avg Val Loss: 0.2369\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [587/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3699\n",
      "LOG: Epoch [587/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3544\n",
      "    Batch [2/2], Val Loss: 0.1192\n",
      "Epoch [587/2000], Avg Train Loss: 0.3711, Avg Val Loss: 0.2368\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [588/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3790\n",
      "LOG: Epoch [588/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3542\n",
      "    Batch [2/2], Val Loss: 0.1191\n",
      "Epoch [588/2000], Avg Train Loss: 0.3769, Avg Val Loss: 0.2367\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [589/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3702\n",
      "    Batch [2/2], Train Loss: 0.3714\n",
      "LOG: Epoch [589/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3539\n",
      "    Batch [2/2], Val Loss: 0.1192\n",
      "Epoch [589/2000], Avg Train Loss: 0.3708, Avg Val Loss: 0.2365\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [590/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3685\n",
      "LOG: Epoch [590/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3534\n",
      "    Batch [2/2], Val Loss: 0.1196\n",
      "Epoch [590/2000], Avg Train Loss: 0.3713, Avg Val Loss: 0.2365\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [591/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3707\n",
      "    Batch [2/2], Train Loss: 0.3731\n",
      "LOG: Epoch [591/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3529\n",
      "    Batch [2/2], Val Loss: 0.1202\n",
      "Epoch [591/2000], Avg Train Loss: 0.3719, Avg Val Loss: 0.2366\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [592/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3698\n",
      "LOG: Epoch [592/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3524\n",
      "    Batch [2/2], Val Loss: 0.1202\n",
      "Epoch [592/2000], Avg Train Loss: 0.3679, Avg Val Loss: 0.2363\n",
      "\n",
      "Validation loss improved from 0.2364 to 0.2363. Saving model...\n",
      "LOG: Epoch [593/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3703\n",
      "    Batch [2/2], Train Loss: 0.3753\n",
      "LOG: Epoch [593/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3523\n",
      "    Batch [2/2], Val Loss: 0.1200\n",
      "Epoch [593/2000], Avg Train Loss: 0.3728, Avg Val Loss: 0.2362\n",
      "\n",
      "Validation loss improved from 0.2363 to 0.2362. Saving model...\n",
      "LOG: Epoch [594/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3720\n",
      "LOG: Epoch [594/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3520\n",
      "    Batch [2/2], Val Loss: 0.1202\n",
      "Epoch [594/2000], Avg Train Loss: 0.3699, Avg Val Loss: 0.2361\n",
      "\n",
      "Validation loss improved from 0.2362 to 0.2361. Saving model...\n",
      "LOG: Epoch [595/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3734\n",
      "    Batch [2/2], Train Loss: 0.3686\n",
      "LOG: Epoch [595/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3518\n",
      "    Batch [2/2], Val Loss: 0.1200\n",
      "Epoch [595/2000], Avg Train Loss: 0.3710, Avg Val Loss: 0.2359\n",
      "\n",
      "Validation loss improved from 0.2361 to 0.2359. Saving model...\n",
      "LOG: Epoch [596/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3711\n",
      "LOG: Epoch [596/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3516\n",
      "    Batch [2/2], Val Loss: 0.1213\n",
      "Epoch [596/2000], Avg Train Loss: 0.3717, Avg Val Loss: 0.2364\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [597/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3712\n",
      "    Batch [2/2], Train Loss: 0.3731\n",
      "LOG: Epoch [597/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3514\n",
      "    Batch [2/2], Val Loss: 0.1220\n",
      "Epoch [597/2000], Avg Train Loss: 0.3722, Avg Val Loss: 0.2367\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [598/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3646\n",
      "LOG: Epoch [598/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3516\n",
      "    Batch [2/2], Val Loss: 0.1218\n",
      "Epoch [598/2000], Avg Train Loss: 0.3697, Avg Val Loss: 0.2367\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [599/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3711\n",
      "LOG: Epoch [599/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3518\n",
      "    Batch [2/2], Val Loss: 0.1214\n",
      "Epoch [599/2000], Avg Train Loss: 0.3697, Avg Val Loss: 0.2366\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [600/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3747\n",
      "    Batch [2/2], Train Loss: 0.3732\n",
      "LOG: Epoch [600/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3519\n",
      "    Batch [2/2], Val Loss: 0.1211\n",
      "Epoch [600/2000], Avg Train Loss: 0.3739, Avg Val Loss: 0.2365\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [601/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3642\n",
      "    Batch [2/2], Train Loss: 0.3772\n",
      "LOG: Epoch [601/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3520\n",
      "    Batch [2/2], Val Loss: 0.1210\n",
      "Epoch [601/2000], Avg Train Loss: 0.3707, Avg Val Loss: 0.2365\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [602/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3692\n",
      "    Batch [2/2], Train Loss: 0.3744\n",
      "LOG: Epoch [602/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3521\n",
      "    Batch [2/2], Val Loss: 0.1208\n",
      "Epoch [602/2000], Avg Train Loss: 0.3718, Avg Val Loss: 0.2364\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [603/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3668\n",
      "    Batch [2/2], Train Loss: 0.3718\n",
      "LOG: Epoch [603/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3519\n",
      "    Batch [2/2], Val Loss: 0.1211\n",
      "Epoch [603/2000], Avg Train Loss: 0.3693, Avg Val Loss: 0.2365\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [604/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3703\n",
      "LOG: Epoch [604/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3519\n",
      "    Batch [2/2], Val Loss: 0.1214\n",
      "Epoch [604/2000], Avg Train Loss: 0.3674, Avg Val Loss: 0.2367\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [605/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3693\n",
      "    Batch [2/2], Train Loss: 0.3726\n",
      "LOG: Epoch [605/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3519\n",
      "    Batch [2/2], Val Loss: 0.1214\n",
      "Epoch [605/2000], Avg Train Loss: 0.3709, Avg Val Loss: 0.2367\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [606/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3736\n",
      "LOG: Epoch [606/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3520\n",
      "    Batch [2/2], Val Loss: 0.1205\n",
      "Epoch [606/2000], Avg Train Loss: 0.3733, Avg Val Loss: 0.2363\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [607/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3741\n",
      "    Batch [2/2], Train Loss: 0.3722\n",
      "LOG: Epoch [607/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3520\n",
      "    Batch [2/2], Val Loss: 0.1202\n",
      "Epoch [607/2000], Avg Train Loss: 0.3731, Avg Val Loss: 0.2361\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [608/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3773\n",
      "LOG: Epoch [608/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3519\n",
      "    Batch [2/2], Val Loss: 0.1200\n",
      "Epoch [608/2000], Avg Train Loss: 0.3735, Avg Val Loss: 0.2359\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [609/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3719\n",
      "    Batch [2/2], Train Loss: 0.3741\n",
      "LOG: Epoch [609/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3516\n",
      "    Batch [2/2], Val Loss: 0.1202\n",
      "Epoch [609/2000], Avg Train Loss: 0.3730, Avg Val Loss: 0.2359\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [610/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3699\n",
      "LOG: Epoch [610/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3514\n",
      "    Batch [2/2], Val Loss: 0.1201\n",
      "Epoch [610/2000], Avg Train Loss: 0.3704, Avg Val Loss: 0.2357\n",
      "\n",
      "Validation loss improved from 0.2359 to 0.2357. Saving model...\n",
      "LOG: Epoch [611/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3713\n",
      "    Batch [2/2], Train Loss: 0.3785\n",
      "LOG: Epoch [611/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3512\n",
      "    Batch [2/2], Val Loss: 0.1201\n",
      "Epoch [611/2000], Avg Train Loss: 0.3749, Avg Val Loss: 0.2356\n",
      "\n",
      "Validation loss improved from 0.2357 to 0.2356. Saving model...\n",
      "LOG: Epoch [612/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3732\n",
      "    Batch [2/2], Train Loss: 0.3712\n",
      "LOG: Epoch [612/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3508\n",
      "    Batch [2/2], Val Loss: 0.1200\n",
      "Epoch [612/2000], Avg Train Loss: 0.3722, Avg Val Loss: 0.2354\n",
      "\n",
      "Validation loss improved from 0.2356 to 0.2354. Saving model...\n",
      "LOG: Epoch [613/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3731\n",
      "    Batch [2/2], Train Loss: 0.3662\n",
      "LOG: Epoch [613/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3506\n",
      "    Batch [2/2], Val Loss: 0.1197\n",
      "Epoch [613/2000], Avg Train Loss: 0.3697, Avg Val Loss: 0.2351\n",
      "\n",
      "Validation loss improved from 0.2354 to 0.2351. Saving model...\n",
      "LOG: Epoch [614/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3736\n",
      "    Batch [2/2], Train Loss: 0.3732\n",
      "LOG: Epoch [614/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3505\n",
      "    Batch [2/2], Val Loss: 0.1197\n",
      "Epoch [614/2000], Avg Train Loss: 0.3734, Avg Val Loss: 0.2351\n",
      "\n",
      "Validation loss improved from 0.2351 to 0.2351. Saving model...\n",
      "LOG: Epoch [615/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3750\n",
      "LOG: Epoch [615/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3505\n",
      "    Batch [2/2], Val Loss: 0.1194\n",
      "Epoch [615/2000], Avg Train Loss: 0.3715, Avg Val Loss: 0.2350\n",
      "\n",
      "Validation loss improved from 0.2351 to 0.2350. Saving model...\n",
      "LOG: Epoch [616/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3683\n",
      "    Batch [2/2], Train Loss: 0.3696\n",
      "LOG: Epoch [616/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3505\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [616/2000], Avg Train Loss: 0.3689, Avg Val Loss: 0.2347\n",
      "\n",
      "Validation loss improved from 0.2350 to 0.2347. Saving model...\n",
      "LOG: Epoch [617/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3699\n",
      "    Batch [2/2], Train Loss: 0.3686\n",
      "LOG: Epoch [617/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3505\n",
      "    Batch [2/2], Val Loss: 0.1183\n",
      "Epoch [617/2000], Avg Train Loss: 0.3692, Avg Val Loss: 0.2344\n",
      "\n",
      "Validation loss improved from 0.2347 to 0.2344. Saving model...\n",
      "LOG: Epoch [618/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3673\n",
      "    Batch [2/2], Train Loss: 0.3628\n",
      "LOG: Epoch [618/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3505\n",
      "    Batch [2/2], Val Loss: 0.1183\n",
      "Epoch [618/2000], Avg Train Loss: 0.3651, Avg Val Loss: 0.2344\n",
      "\n",
      "Validation loss improved from 0.2344 to 0.2344. Saving model...\n",
      "LOG: Epoch [619/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3697\n",
      "LOG: Epoch [619/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3504\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [619/2000], Avg Train Loss: 0.3706, Avg Val Loss: 0.2341\n",
      "\n",
      "Validation loss improved from 0.2344 to 0.2341. Saving model...\n",
      "LOG: Epoch [620/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3776\n",
      "    Batch [2/2], Train Loss: 0.3717\n",
      "LOG: Epoch [620/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3504\n",
      "    Batch [2/2], Val Loss: 0.1176\n",
      "Epoch [620/2000], Avg Train Loss: 0.3747, Avg Val Loss: 0.2340\n",
      "\n",
      "Validation loss improved from 0.2341 to 0.2340. Saving model...\n",
      "LOG: Epoch [621/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3772\n",
      "    Batch [2/2], Train Loss: 0.3695\n",
      "LOG: Epoch [621/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3505\n",
      "    Batch [2/2], Val Loss: 0.1176\n",
      "Epoch [621/2000], Avg Train Loss: 0.3734, Avg Val Loss: 0.2341\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [622/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3684\n",
      "    Batch [2/2], Train Loss: 0.3732\n",
      "LOG: Epoch [622/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3507\n",
      "    Batch [2/2], Val Loss: 0.1175\n",
      "Epoch [622/2000], Avg Train Loss: 0.3708, Avg Val Loss: 0.2341\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [623/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3668\n",
      "    Batch [2/2], Train Loss: 0.3634\n",
      "LOG: Epoch [623/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3507\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [623/2000], Avg Train Loss: 0.3651, Avg Val Loss: 0.2344\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [624/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3722\n",
      "    Batch [2/2], Train Loss: 0.3718\n",
      "LOG: Epoch [624/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3507\n",
      "    Batch [2/2], Val Loss: 0.1174\n",
      "Epoch [624/2000], Avg Train Loss: 0.3720, Avg Val Loss: 0.2340\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [625/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3661\n",
      "LOG: Epoch [625/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3507\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [625/2000], Avg Train Loss: 0.3655, Avg Val Loss: 0.2342\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [626/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3744\n",
      "    Batch [2/2], Train Loss: 0.3697\n",
      "LOG: Epoch [626/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3507\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [626/2000], Avg Train Loss: 0.3720, Avg Val Loss: 0.2344\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [627/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3683\n",
      "    Batch [2/2], Train Loss: 0.3706\n",
      "LOG: Epoch [627/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3510\n",
      "    Batch [2/2], Val Loss: 0.1174\n",
      "Epoch [627/2000], Avg Train Loss: 0.3694, Avg Val Loss: 0.2342\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [628/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3620\n",
      "    Batch [2/2], Train Loss: 0.3728\n",
      "LOG: Epoch [628/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3514\n",
      "    Batch [2/2], Val Loss: 0.1178\n",
      "Epoch [628/2000], Avg Train Loss: 0.3674, Avg Val Loss: 0.2346\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [629/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3704\n",
      "LOG: Epoch [629/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3514\n",
      "    Batch [2/2], Val Loss: 0.1183\n",
      "Epoch [629/2000], Avg Train Loss: 0.3686, Avg Val Loss: 0.2348\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [630/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3614\n",
      "LOG: Epoch [630/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3516\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [630/2000], Avg Train Loss: 0.3669, Avg Val Loss: 0.2349\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [631/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3649\n",
      "    Batch [2/2], Train Loss: 0.3639\n",
      "LOG: Epoch [631/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3514\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [631/2000], Avg Train Loss: 0.3644, Avg Val Loss: 0.2350\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [632/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3628\n",
      "    Batch [2/2], Train Loss: 0.3642\n",
      "LOG: Epoch [632/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3512\n",
      "    Batch [2/2], Val Loss: 0.1187\n",
      "Epoch [632/2000], Avg Train Loss: 0.3635, Avg Val Loss: 0.2349\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [633/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3695\n",
      "LOG: Epoch [633/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3512\n",
      "    Batch [2/2], Val Loss: 0.1185\n",
      "Epoch [633/2000], Avg Train Loss: 0.3706, Avg Val Loss: 0.2349\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [634/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3608\n",
      "    Batch [2/2], Train Loss: 0.3685\n",
      "LOG: Epoch [634/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3511\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [634/2000], Avg Train Loss: 0.3646, Avg Val Loss: 0.2350\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [635/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3668\n",
      "LOG: Epoch [635/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3509\n",
      "    Batch [2/2], Val Loss: 0.1194\n",
      "Epoch [635/2000], Avg Train Loss: 0.3668, Avg Val Loss: 0.2351\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [636/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3681\n",
      "    Batch [2/2], Train Loss: 0.3570\n",
      "LOG: Epoch [636/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3508\n",
      "    Batch [2/2], Val Loss: 0.1201\n",
      "Epoch [636/2000], Avg Train Loss: 0.3626, Avg Val Loss: 0.2354\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [637/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3726\n",
      "LOG: Epoch [637/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3508\n",
      "    Batch [2/2], Val Loss: 0.1196\n",
      "Epoch [637/2000], Avg Train Loss: 0.3719, Avg Val Loss: 0.2352\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [638/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3563\n",
      "    Batch [2/2], Train Loss: 0.3696\n",
      "LOG: Epoch [638/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3508\n",
      "    Batch [2/2], Val Loss: 0.1191\n",
      "Epoch [638/2000], Avg Train Loss: 0.3629, Avg Val Loss: 0.2350\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [639/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3715\n",
      "LOG: Epoch [639/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3508\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [639/2000], Avg Train Loss: 0.3672, Avg Val Loss: 0.2349\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [640/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3706\n",
      "    Batch [2/2], Train Loss: 0.3681\n",
      "LOG: Epoch [640/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3510\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [640/2000], Avg Train Loss: 0.3693, Avg Val Loss: 0.2346\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [641/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3731\n",
      "    Batch [2/2], Train Loss: 0.3657\n",
      "LOG: Epoch [641/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3507\n",
      "    Batch [2/2], Val Loss: 0.1187\n",
      "Epoch [641/2000], Avg Train Loss: 0.3694, Avg Val Loss: 0.2347\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [642/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3673\n",
      "    Batch [2/2], Train Loss: 0.3672\n",
      "LOG: Epoch [642/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3507\n",
      "    Batch [2/2], Val Loss: 0.1185\n",
      "Epoch [642/2000], Avg Train Loss: 0.3672, Avg Val Loss: 0.2346\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [643/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3726\n",
      "    Batch [2/2], Train Loss: 0.3746\n",
      "LOG: Epoch [643/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3506\n",
      "    Batch [2/2], Val Loss: 0.1187\n",
      "Epoch [643/2000], Avg Train Loss: 0.3736, Avg Val Loss: 0.2347\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [644/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3610\n",
      "LOG: Epoch [644/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3506\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [644/2000], Avg Train Loss: 0.3668, Avg Val Loss: 0.2347\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [645/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3687\n",
      "    Batch [2/2], Train Loss: 0.3669\n",
      "LOG: Epoch [645/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3506\n",
      "    Batch [2/2], Val Loss: 0.1187\n",
      "Epoch [645/2000], Avg Train Loss: 0.3678, Avg Val Loss: 0.2346\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [646/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3630\n",
      "LOG: Epoch [646/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3503\n",
      "    Batch [2/2], Val Loss: 0.1190\n",
      "Epoch [646/2000], Avg Train Loss: 0.3633, Avg Val Loss: 0.2347\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [647/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3696\n",
      "    Batch [2/2], Train Loss: 0.3705\n",
      "LOG: Epoch [647/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3500\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [647/2000], Avg Train Loss: 0.3700, Avg Val Loss: 0.2345\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [648/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3581\n",
      "LOG: Epoch [648/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3497\n",
      "    Batch [2/2], Val Loss: 0.1190\n",
      "Epoch [648/2000], Avg Train Loss: 0.3635, Avg Val Loss: 0.2343\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [649/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3641\n",
      "LOG: Epoch [649/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3495\n",
      "    Batch [2/2], Val Loss: 0.1191\n",
      "Epoch [649/2000], Avg Train Loss: 0.3670, Avg Val Loss: 0.2343\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [650/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3678\n",
      "    Batch [2/2], Train Loss: 0.3618\n",
      "LOG: Epoch [650/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3493\n",
      "    Batch [2/2], Val Loss: 0.1188\n",
      "Epoch [650/2000], Avg Train Loss: 0.3648, Avg Val Loss: 0.2341\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [651/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3646\n",
      "    Batch [2/2], Train Loss: 0.3678\n",
      "LOG: Epoch [651/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3491\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [651/2000], Avg Train Loss: 0.3662, Avg Val Loss: 0.2340\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [652/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3660\n",
      "LOG: Epoch [652/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3491\n",
      "    Batch [2/2], Val Loss: 0.1184\n",
      "Epoch [652/2000], Avg Train Loss: 0.3680, Avg Val Loss: 0.2338\n",
      "\n",
      "Validation loss improved from 0.2340 to 0.2338. Saving model...\n",
      "LOG: Epoch [653/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3662\n",
      "    Batch [2/2], Train Loss: 0.3623\n",
      "LOG: Epoch [653/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3492\n",
      "    Batch [2/2], Val Loss: 0.1185\n",
      "Epoch [653/2000], Avg Train Loss: 0.3642, Avg Val Loss: 0.2338\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [654/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3733\n",
      "    Batch [2/2], Train Loss: 0.3683\n",
      "LOG: Epoch [654/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3490\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [654/2000], Avg Train Loss: 0.3708, Avg Val Loss: 0.2338\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [655/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3684\n",
      "LOG: Epoch [655/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3490\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [655/2000], Avg Train Loss: 0.3671, Avg Val Loss: 0.2338\n",
      "\n",
      "Validation loss improved from 0.2338 to 0.2338. Saving model...\n",
      "LOG: Epoch [656/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3685\n",
      "    Batch [2/2], Train Loss: 0.3687\n",
      "LOG: Epoch [656/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3489\n",
      "    Batch [2/2], Val Loss: 0.1192\n",
      "Epoch [656/2000], Avg Train Loss: 0.3686, Avg Val Loss: 0.2340\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [657/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3621\n",
      "LOG: Epoch [657/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3489\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [657/2000], Avg Train Loss: 0.3654, Avg Val Loss: 0.2339\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [658/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3630\n",
      "    Batch [2/2], Train Loss: 0.3675\n",
      "LOG: Epoch [658/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1193\n",
      "Epoch [658/2000], Avg Train Loss: 0.3652, Avg Val Loss: 0.2340\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [659/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3662\n",
      "    Batch [2/2], Train Loss: 0.3663\n",
      "LOG: Epoch [659/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1191\n",
      "Epoch [659/2000], Avg Train Loss: 0.3663, Avg Val Loss: 0.2339\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [660/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3652\n",
      "LOG: Epoch [660/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1190\n",
      "Epoch [660/2000], Avg Train Loss: 0.3653, Avg Val Loss: 0.2339\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [661/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3634\n",
      "    Batch [2/2], Train Loss: 0.3728\n",
      "LOG: Epoch [661/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1191\n",
      "Epoch [661/2000], Avg Train Loss: 0.3681, Avg Val Loss: 0.2339\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [662/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3684\n",
      "LOG: Epoch [662/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1191\n",
      "Epoch [662/2000], Avg Train Loss: 0.3689, Avg Val Loss: 0.2339\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [663/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3646\n",
      "    Batch [2/2], Train Loss: 0.3688\n",
      "LOG: Epoch [663/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1192\n",
      "Epoch [663/2000], Avg Train Loss: 0.3667, Avg Val Loss: 0.2340\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [664/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3672\n",
      "LOG: Epoch [664/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [664/2000], Avg Train Loss: 0.3694, Avg Val Loss: 0.2339\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [665/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3679\n",
      "LOG: Epoch [665/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1191\n",
      "Epoch [665/2000], Avg Train Loss: 0.3690, Avg Val Loss: 0.2339\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [666/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3700\n",
      "    Batch [2/2], Train Loss: 0.3659\n",
      "LOG: Epoch [666/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [666/2000], Avg Train Loss: 0.3679, Avg Val Loss: 0.2337\n",
      "\n",
      "Validation loss improved from 0.2338 to 0.2337. Saving model...\n",
      "LOG: Epoch [667/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3649\n",
      "LOG: Epoch [667/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1188\n",
      "Epoch [667/2000], Avg Train Loss: 0.3669, Avg Val Loss: 0.2338\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [668/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3700\n",
      "    Batch [2/2], Train Loss: 0.3645\n",
      "LOG: Epoch [668/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [668/2000], Avg Train Loss: 0.3673, Avg Val Loss: 0.2338\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [669/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3693\n",
      "LOG: Epoch [669/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [669/2000], Avg Train Loss: 0.3693, Avg Val Loss: 0.2339\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [670/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3683\n",
      "LOG: Epoch [670/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3490\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [670/2000], Avg Train Loss: 0.3667, Avg Val Loss: 0.2339\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [671/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3640\n",
      "    Batch [2/2], Train Loss: 0.3684\n",
      "LOG: Epoch [671/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3489\n",
      "    Batch [2/2], Val Loss: 0.1191\n",
      "Epoch [671/2000], Avg Train Loss: 0.3662, Avg Val Loss: 0.2340\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [672/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3693\n",
      "LOG: Epoch [672/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1193\n",
      "Epoch [672/2000], Avg Train Loss: 0.3650, Avg Val Loss: 0.2340\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [673/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3693\n",
      "    Batch [2/2], Train Loss: 0.3633\n",
      "LOG: Epoch [673/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1194\n",
      "Epoch [673/2000], Avg Train Loss: 0.3663, Avg Val Loss: 0.2341\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [674/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3710\n",
      "    Batch [2/2], Train Loss: 0.3653\n",
      "LOG: Epoch [674/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1192\n",
      "Epoch [674/2000], Avg Train Loss: 0.3682, Avg Val Loss: 0.2340\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [675/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3591\n",
      "LOG: Epoch [675/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1191\n",
      "Epoch [675/2000], Avg Train Loss: 0.3619, Avg Val Loss: 0.2339\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [676/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3604\n",
      "LOG: Epoch [676/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3489\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [676/2000], Avg Train Loss: 0.3624, Avg Val Loss: 0.2339\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [677/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3694\n",
      "    Batch [2/2], Train Loss: 0.3675\n",
      "LOG: Epoch [677/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1184\n",
      "Epoch [677/2000], Avg Train Loss: 0.3684, Avg Val Loss: 0.2336\n",
      "\n",
      "Validation loss improved from 0.2337 to 0.2336. Saving model...\n",
      "LOG: Epoch [678/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3650\n",
      "LOG: Epoch [678/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1187\n",
      "Epoch [678/2000], Avg Train Loss: 0.3651, Avg Val Loss: 0.2337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [679/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3685\n",
      "    Batch [2/2], Train Loss: 0.3614\n",
      "LOG: Epoch [679/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1185\n",
      "Epoch [679/2000], Avg Train Loss: 0.3650, Avg Val Loss: 0.2337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [680/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3660\n",
      "    Batch [2/2], Train Loss: 0.3665\n",
      "LOG: Epoch [680/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [680/2000], Avg Train Loss: 0.3662, Avg Val Loss: 0.2338\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [681/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3710\n",
      "LOG: Epoch [681/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1192\n",
      "Epoch [681/2000], Avg Train Loss: 0.3693, Avg Val Loss: 0.2338\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [682/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3707\n",
      "    Batch [2/2], Train Loss: 0.3667\n",
      "LOG: Epoch [682/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [682/2000], Avg Train Loss: 0.3687, Avg Val Loss: 0.2337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [683/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3630\n",
      "    Batch [2/2], Train Loss: 0.3644\n",
      "LOG: Epoch [683/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1183\n",
      "Epoch [683/2000], Avg Train Loss: 0.3637, Avg Val Loss: 0.2334\n",
      "\n",
      "Validation loss improved from 0.2336 to 0.2334. Saving model...\n",
      "LOG: Epoch [684/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3726\n",
      "LOG: Epoch [684/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [684/2000], Avg Train Loss: 0.3698, Avg Val Loss: 0.2334\n",
      "\n",
      "Validation loss improved from 0.2334 to 0.2334. Saving model...\n",
      "LOG: Epoch [685/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3656\n",
      "LOG: Epoch [685/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1187\n",
      "Epoch [685/2000], Avg Train Loss: 0.3664, Avg Val Loss: 0.2336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [686/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3726\n",
      "    Batch [2/2], Train Loss: 0.3638\n",
      "LOG: Epoch [686/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [686/2000], Avg Train Loss: 0.3682, Avg Val Loss: 0.2335\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [687/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3677\n",
      "LOG: Epoch [687/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1190\n",
      "Epoch [687/2000], Avg Train Loss: 0.3676, Avg Val Loss: 0.2337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [688/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3602\n",
      "    Batch [2/2], Train Loss: 0.3632\n",
      "LOG: Epoch [688/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1193\n",
      "Epoch [688/2000], Avg Train Loss: 0.3617, Avg Val Loss: 0.2339\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [689/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3716\n",
      "LOG: Epoch [689/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1192\n",
      "Epoch [689/2000], Avg Train Loss: 0.3709, Avg Val Loss: 0.2337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [690/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3652\n",
      "LOG: Epoch [690/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3482\n",
      "    Batch [2/2], Val Loss: 0.1191\n",
      "Epoch [690/2000], Avg Train Loss: 0.3698, Avg Val Loss: 0.2336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [691/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3667\n",
      "    Batch [2/2], Train Loss: 0.3633\n",
      "LOG: Epoch [691/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1190\n",
      "Epoch [691/2000], Avg Train Loss: 0.3650, Avg Val Loss: 0.2337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [692/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3672\n",
      "    Batch [2/2], Train Loss: 0.3643\n",
      "LOG: Epoch [692/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1187\n",
      "Epoch [692/2000], Avg Train Loss: 0.3658, Avg Val Loss: 0.2336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [693/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3696\n",
      "    Batch [2/2], Train Loss: 0.3684\n",
      "LOG: Epoch [693/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [693/2000], Avg Train Loss: 0.3690, Avg Val Loss: 0.2334\n",
      "\n",
      "Validation loss improved from 0.2334 to 0.2334. Saving model...\n",
      "LOG: Epoch [694/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3689\n",
      "LOG: Epoch [694/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1179\n",
      "Epoch [694/2000], Avg Train Loss: 0.3710, Avg Val Loss: 0.2333\n",
      "\n",
      "Validation loss improved from 0.2334 to 0.2333. Saving model...\n",
      "LOG: Epoch [695/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3645\n",
      "    Batch [2/2], Train Loss: 0.3621\n",
      "LOG: Epoch [695/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1178\n",
      "Epoch [695/2000], Avg Train Loss: 0.3633, Avg Val Loss: 0.2333\n",
      "\n",
      "Validation loss improved from 0.2333 to 0.2333. Saving model...\n",
      "LOG: Epoch [696/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3620\n",
      "LOG: Epoch [696/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3489\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [696/2000], Avg Train Loss: 0.3662, Avg Val Loss: 0.2335\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [697/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3618\n",
      "    Batch [2/2], Train Loss: 0.3706\n",
      "LOG: Epoch [697/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3489\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [697/2000], Avg Train Loss: 0.3662, Avg Val Loss: 0.2335\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [698/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3711\n",
      "LOG: Epoch [698/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3489\n",
      "    Batch [2/2], Val Loss: 0.1180\n",
      "Epoch [698/2000], Avg Train Loss: 0.3696, Avg Val Loss: 0.2334\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [699/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3651\n",
      "LOG: Epoch [699/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [699/2000], Avg Train Loss: 0.3686, Avg Val Loss: 0.2336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [700/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3643\n",
      "    Batch [2/2], Train Loss: 0.3671\n",
      "LOG: Epoch [700/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [700/2000], Avg Train Loss: 0.3657, Avg Val Loss: 0.2334\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [701/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3668\n",
      "    Batch [2/2], Train Loss: 0.3690\n",
      "LOG: Epoch [701/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1176\n",
      "Epoch [701/2000], Avg Train Loss: 0.3679, Avg Val Loss: 0.2332\n",
      "\n",
      "Validation loss improved from 0.2333 to 0.2332. Saving model...\n",
      "LOG: Epoch [702/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3622\n",
      "LOG: Epoch [702/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1175\n",
      "Epoch [702/2000], Avg Train Loss: 0.3658, Avg Val Loss: 0.2332\n",
      "\n",
      "Validation loss improved from 0.2332 to 0.2332. Saving model...\n",
      "LOG: Epoch [703/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3683\n",
      "    Batch [2/2], Train Loss: 0.3709\n",
      "LOG: Epoch [703/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1178\n",
      "Epoch [703/2000], Avg Train Loss: 0.3696, Avg Val Loss: 0.2333\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [704/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3702\n",
      "LOG: Epoch [704/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [704/2000], Avg Train Loss: 0.3702, Avg Val Loss: 0.2332\n",
      "\n",
      "Validation loss improved from 0.2332 to 0.2332. Saving model...\n",
      "LOG: Epoch [705/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3724\n",
      "LOG: Epoch [705/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1171\n",
      "Epoch [705/2000], Avg Train Loss: 0.3683, Avg Val Loss: 0.2329\n",
      "\n",
      "Validation loss improved from 0.2332 to 0.2329. Saving model...\n",
      "LOG: Epoch [706/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3663\n",
      "    Batch [2/2], Train Loss: 0.3680\n",
      "LOG: Epoch [706/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1172\n",
      "Epoch [706/2000], Avg Train Loss: 0.3672, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [707/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3618\n",
      "    Batch [2/2], Train Loss: 0.3652\n",
      "LOG: Epoch [707/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1179\n",
      "Epoch [707/2000], Avg Train Loss: 0.3635, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [708/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3669\n",
      "LOG: Epoch [708/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1180\n",
      "Epoch [708/2000], Avg Train Loss: 0.3657, Avg Val Loss: 0.2333\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [709/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3676\n",
      "    Batch [2/2], Train Loss: 0.3591\n",
      "LOG: Epoch [709/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [709/2000], Avg Train Loss: 0.3633, Avg Val Loss: 0.2334\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [710/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3675\n",
      "LOG: Epoch [710/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1188\n",
      "Epoch [710/2000], Avg Train Loss: 0.3676, Avg Val Loss: 0.2337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [711/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3649\n",
      "LOG: Epoch [711/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [711/2000], Avg Train Loss: 0.3675, Avg Val Loss: 0.2336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [712/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3686\n",
      "    Batch [2/2], Train Loss: 0.3630\n",
      "LOG: Epoch [712/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [712/2000], Avg Train Loss: 0.3658, Avg Val Loss: 0.2337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [713/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3709\n",
      "LOG: Epoch [713/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [713/2000], Avg Train Loss: 0.3675, Avg Val Loss: 0.2335\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [714/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3656\n",
      "LOG: Epoch [714/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [714/2000], Avg Train Loss: 0.3695, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [715/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3695\n",
      "    Batch [2/2], Train Loss: 0.3689\n",
      "LOG: Epoch [715/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1184\n",
      "Epoch [715/2000], Avg Train Loss: 0.3692, Avg Val Loss: 0.2333\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [716/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3666\n",
      "LOG: Epoch [716/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1179\n",
      "Epoch [716/2000], Avg Train Loss: 0.3691, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [717/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3690\n",
      "    Batch [2/2], Train Loss: 0.3695\n",
      "LOG: Epoch [717/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1179\n",
      "Epoch [717/2000], Avg Train Loss: 0.3692, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [718/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3743\n",
      "    Batch [2/2], Train Loss: 0.3718\n",
      "LOG: Epoch [718/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1174\n",
      "Epoch [718/2000], Avg Train Loss: 0.3730, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [719/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3615\n",
      "LOG: Epoch [719/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [719/2000], Avg Train Loss: 0.3643, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [720/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3652\n",
      "    Batch [2/2], Train Loss: 0.3686\n",
      "LOG: Epoch [720/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1179\n",
      "Epoch [720/2000], Avg Train Loss: 0.3669, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [721/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3656\n",
      "    Batch [2/2], Train Loss: 0.3660\n",
      "LOG: Epoch [721/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [721/2000], Avg Train Loss: 0.3658, Avg Val Loss: 0.2334\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [722/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3652\n",
      "    Batch [2/2], Train Loss: 0.3712\n",
      "LOG: Epoch [722/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [722/2000], Avg Train Loss: 0.3682, Avg Val Loss: 0.2333\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [723/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3686\n",
      "LOG: Epoch [723/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1179\n",
      "Epoch [723/2000], Avg Train Loss: 0.3680, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [724/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3625\n",
      "    Batch [2/2], Train Loss: 0.3702\n",
      "LOG: Epoch [724/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1172\n",
      "Epoch [724/2000], Avg Train Loss: 0.3663, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [725/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3625\n",
      "LOG: Epoch [725/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1176\n",
      "Epoch [725/2000], Avg Train Loss: 0.3612, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [726/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3637\n",
      "    Batch [2/2], Train Loss: 0.3654\n",
      "LOG: Epoch [726/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1173\n",
      "Epoch [726/2000], Avg Train Loss: 0.3646, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [727/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3670\n",
      "LOG: Epoch [727/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1170\n",
      "Epoch [727/2000], Avg Train Loss: 0.3679, Avg Val Loss: 0.2328\n",
      "\n",
      "Validation loss improved from 0.2329 to 0.2328. Saving model...\n",
      "LOG: Epoch [728/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3612\n",
      "    Batch [2/2], Train Loss: 0.3769\n",
      "LOG: Epoch [728/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1168\n",
      "Epoch [728/2000], Avg Train Loss: 0.3691, Avg Val Loss: 0.2327\n",
      "\n",
      "Validation loss improved from 0.2328 to 0.2327. Saving model...\n",
      "LOG: Epoch [729/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3692\n",
      "LOG: Epoch [729/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1170\n",
      "Epoch [729/2000], Avg Train Loss: 0.3675, Avg Val Loss: 0.2328\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [730/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3672\n",
      "    Batch [2/2], Train Loss: 0.3682\n",
      "LOG: Epoch [730/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1175\n",
      "Epoch [730/2000], Avg Train Loss: 0.3677, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [731/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3720\n",
      "LOG: Epoch [731/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1176\n",
      "Epoch [731/2000], Avg Train Loss: 0.3715, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [732/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3704\n",
      "    Batch [2/2], Train Loss: 0.3674\n",
      "LOG: Epoch [732/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1172\n",
      "Epoch [732/2000], Avg Train Loss: 0.3689, Avg Val Loss: 0.2328\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [733/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3691\n",
      "    Batch [2/2], Train Loss: 0.3586\n",
      "LOG: Epoch [733/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1168\n",
      "Epoch [733/2000], Avg Train Loss: 0.3639, Avg Val Loss: 0.2327\n",
      "\n",
      "Validation loss improved from 0.2327 to 0.2327. Saving model...\n",
      "LOG: Epoch [734/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3612\n",
      "LOG: Epoch [734/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1172\n",
      "Epoch [734/2000], Avg Train Loss: 0.3671, Avg Val Loss: 0.2328\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [735/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3688\n",
      "    Batch [2/2], Train Loss: 0.3690\n",
      "LOG: Epoch [735/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1174\n",
      "Epoch [735/2000], Avg Train Loss: 0.3689, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [736/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3628\n",
      "LOG: Epoch [736/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1175\n",
      "Epoch [736/2000], Avg Train Loss: 0.3672, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [737/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3691\n",
      "    Batch [2/2], Train Loss: 0.3594\n",
      "LOG: Epoch [737/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1178\n",
      "Epoch [737/2000], Avg Train Loss: 0.3643, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [738/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3621\n",
      "LOG: Epoch [738/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1172\n",
      "Epoch [738/2000], Avg Train Loss: 0.3635, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [739/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3732\n",
      "    Batch [2/2], Train Loss: 0.3605\n",
      "LOG: Epoch [739/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1174\n",
      "Epoch [739/2000], Avg Train Loss: 0.3669, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [740/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3618\n",
      "LOG: Epoch [740/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [740/2000], Avg Train Loss: 0.3649, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [741/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3758\n",
      "    Batch [2/2], Train Loss: 0.3662\n",
      "LOG: Epoch [741/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [741/2000], Avg Train Loss: 0.3710, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [742/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3670\n",
      "LOG: Epoch [742/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1179\n",
      "Epoch [742/2000], Avg Train Loss: 0.3672, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [743/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3636\n",
      "    Batch [2/2], Train Loss: 0.3671\n",
      "LOG: Epoch [743/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [743/2000], Avg Train Loss: 0.3653, Avg Val Loss: 0.2333\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [744/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3655\n",
      "LOG: Epoch [744/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [744/2000], Avg Train Loss: 0.3613, Avg Val Loss: 0.2334\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [745/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3628\n",
      "    Batch [2/2], Train Loss: 0.3635\n",
      "LOG: Epoch [745/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [745/2000], Avg Train Loss: 0.3632, Avg Val Loss: 0.2334\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [746/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3661\n",
      "LOG: Epoch [746/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1183\n",
      "Epoch [746/2000], Avg Train Loss: 0.3680, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [747/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3658\n",
      "    Batch [2/2], Train Loss: 0.3600\n",
      "LOG: Epoch [747/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3482\n",
      "    Batch [2/2], Val Loss: 0.1180\n",
      "Epoch [747/2000], Avg Train Loss: 0.3629, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [748/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3679\n",
      "LOG: Epoch [748/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1179\n",
      "Epoch [748/2000], Avg Train Loss: 0.3639, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [749/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3705\n",
      "    Batch [2/2], Train Loss: 0.3616\n",
      "LOG: Epoch [749/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1176\n",
      "Epoch [749/2000], Avg Train Loss: 0.3661, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [750/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3675\n",
      "LOG: Epoch [750/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1176\n",
      "Epoch [750/2000], Avg Train Loss: 0.3688, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [751/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3710\n",
      "    Batch [2/2], Train Loss: 0.3700\n",
      "LOG: Epoch [751/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [751/2000], Avg Train Loss: 0.3705, Avg Val Loss: 0.2333\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [752/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3689\n",
      "LOG: Epoch [752/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1184\n",
      "Epoch [752/2000], Avg Train Loss: 0.3628, Avg Val Loss: 0.2334\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [753/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3722\n",
      "    Batch [2/2], Train Loss: 0.3614\n",
      "LOG: Epoch [753/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [753/2000], Avg Train Loss: 0.3668, Avg Val Loss: 0.2333\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [754/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3706\n",
      "LOG: Epoch [754/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [754/2000], Avg Train Loss: 0.3686, Avg Val Loss: 0.2334\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [755/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3676\n",
      "    Batch [2/2], Train Loss: 0.3731\n",
      "LOG: Epoch [755/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [755/2000], Avg Train Loss: 0.3704, Avg Val Loss: 0.2335\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [756/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3628\n",
      "LOG: Epoch [756/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [756/2000], Avg Train Loss: 0.3662, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [757/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3632\n",
      "    Batch [2/2], Train Loss: 0.3621\n",
      "LOG: Epoch [757/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [757/2000], Avg Train Loss: 0.3627, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [758/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3672\n",
      "LOG: Epoch [758/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1178\n",
      "Epoch [758/2000], Avg Train Loss: 0.3641, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [759/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3625\n",
      "    Batch [2/2], Train Loss: 0.3635\n",
      "LOG: Epoch [759/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1176\n",
      "Epoch [759/2000], Avg Train Loss: 0.3630, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [760/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3638\n",
      "LOG: Epoch [760/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [760/2000], Avg Train Loss: 0.3654, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [761/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3736\n",
      "    Batch [2/2], Train Loss: 0.3611\n",
      "LOG: Epoch [761/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3479\n",
      "    Batch [2/2], Val Loss: 0.1183\n",
      "Epoch [761/2000], Avg Train Loss: 0.3674, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [762/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3651\n",
      "    Batch [2/2], Train Loss: 0.3611\n",
      "LOG: Epoch [762/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3477\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [762/2000], Avg Train Loss: 0.3631, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [763/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3702\n",
      "LOG: Epoch [763/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3479\n",
      "    Batch [2/2], Val Loss: 0.1179\n",
      "Epoch [763/2000], Avg Train Loss: 0.3705, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [764/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3658\n",
      "    Batch [2/2], Train Loss: 0.3646\n",
      "LOG: Epoch [764/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [764/2000], Avg Train Loss: 0.3652, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [765/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3680\n",
      "LOG: Epoch [765/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3482\n",
      "    Batch [2/2], Val Loss: 0.1175\n",
      "Epoch [765/2000], Avg Train Loss: 0.3657, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [766/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3714\n",
      "    Batch [2/2], Train Loss: 0.3656\n",
      "LOG: Epoch [766/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1171\n",
      "Epoch [766/2000], Avg Train Loss: 0.3685, Avg Val Loss: 0.2328\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [767/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3660\n",
      "LOG: Epoch [767/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1169\n",
      "Epoch [767/2000], Avg Train Loss: 0.3679, Avg Val Loss: 0.2326\n",
      "\n",
      "Validation loss improved from 0.2327 to 0.2326. Saving model...\n",
      "LOG: Epoch [768/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3730\n",
      "    Batch [2/2], Train Loss: 0.3658\n",
      "LOG: Epoch [768/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1170\n",
      "Epoch [768/2000], Avg Train Loss: 0.3694, Avg Val Loss: 0.2327\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [769/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3730\n",
      "LOG: Epoch [769/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1171\n",
      "Epoch [769/2000], Avg Train Loss: 0.3723, Avg Val Loss: 0.2328\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [770/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3605\n",
      "    Batch [2/2], Train Loss: 0.3678\n",
      "LOG: Epoch [770/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1174\n",
      "Epoch [770/2000], Avg Train Loss: 0.3642, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [771/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3647\n",
      "LOG: Epoch [771/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3482\n",
      "    Batch [2/2], Val Loss: 0.1180\n",
      "Epoch [771/2000], Avg Train Loss: 0.3651, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [772/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3671\n",
      "    Batch [2/2], Train Loss: 0.3711\n",
      "LOG: Epoch [772/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [772/2000], Avg Train Loss: 0.3691, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [773/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3656\n",
      "LOG: Epoch [773/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3478\n",
      "    Batch [2/2], Val Loss: 0.1188\n",
      "Epoch [773/2000], Avg Train Loss: 0.3662, Avg Val Loss: 0.2333\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [774/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3683\n",
      "    Batch [2/2], Train Loss: 0.3656\n",
      "LOG: Epoch [774/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3479\n",
      "    Batch [2/2], Val Loss: 0.1185\n",
      "Epoch [774/2000], Avg Train Loss: 0.3669, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [775/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3674\n",
      "LOG: Epoch [775/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [775/2000], Avg Train Loss: 0.3662, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [776/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3716\n",
      "    Batch [2/2], Train Loss: 0.3699\n",
      "LOG: Epoch [776/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3479\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [776/2000], Avg Train Loss: 0.3708, Avg Val Loss: 0.2333\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [777/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3645\n",
      "LOG: Epoch [777/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [777/2000], Avg Train Loss: 0.3648, Avg Val Loss: 0.2333\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [778/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3645\n",
      "    Batch [2/2], Train Loss: 0.3708\n",
      "LOG: Epoch [778/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1183\n",
      "Epoch [778/2000], Avg Train Loss: 0.3677, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [779/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3616\n",
      "LOG: Epoch [779/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1188\n",
      "Epoch [779/2000], Avg Train Loss: 0.3631, Avg Val Loss: 0.2334\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [780/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3619\n",
      "    Batch [2/2], Train Loss: 0.3703\n",
      "LOG: Epoch [780/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [780/2000], Avg Train Loss: 0.3661, Avg Val Loss: 0.2333\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [781/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3636\n",
      "LOG: Epoch [781/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1185\n",
      "Epoch [781/2000], Avg Train Loss: 0.3690, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [782/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3683\n",
      "    Batch [2/2], Train Loss: 0.3656\n",
      "LOG: Epoch [782/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [782/2000], Avg Train Loss: 0.3670, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [783/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3643\n",
      "    Batch [2/2], Train Loss: 0.3539\n",
      "LOG: Epoch [783/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1183\n",
      "Epoch [783/2000], Avg Train Loss: 0.3591, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [784/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3704\n",
      "LOG: Epoch [784/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [784/2000], Avg Train Loss: 0.3719, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [785/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3687\n",
      "    Batch [2/2], Train Loss: 0.3657\n",
      "LOG: Epoch [785/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3482\n",
      "    Batch [2/2], Val Loss: 0.1183\n",
      "Epoch [785/2000], Avg Train Loss: 0.3672, Avg Val Loss: 0.2333\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [786/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3677\n",
      "LOG: Epoch [786/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3482\n",
      "    Batch [2/2], Val Loss: 0.1180\n",
      "Epoch [786/2000], Avg Train Loss: 0.3685, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [787/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3681\n",
      "    Batch [2/2], Train Loss: 0.3645\n",
      "LOG: Epoch [787/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3482\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [787/2000], Avg Train Loss: 0.3663, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [788/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3609\n",
      "LOG: Epoch [788/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3482\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [788/2000], Avg Train Loss: 0.3659, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [789/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3661\n",
      "    Batch [2/2], Train Loss: 0.3636\n",
      "LOG: Epoch [789/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [789/2000], Avg Train Loss: 0.3649, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [790/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3704\n",
      "LOG: Epoch [790/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1183\n",
      "Epoch [790/2000], Avg Train Loss: 0.3664, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [791/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3695\n",
      "    Batch [2/2], Train Loss: 0.3659\n",
      "LOG: Epoch [791/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [791/2000], Avg Train Loss: 0.3677, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [792/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3708\n",
      "    Batch [2/2], Train Loss: 0.3665\n",
      "LOG: Epoch [792/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1176\n",
      "Epoch [792/2000], Avg Train Loss: 0.3687, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [793/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3693\n",
      "LOG: Epoch [793/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1176\n",
      "Epoch [793/2000], Avg Train Loss: 0.3675, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [794/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3676\n",
      "    Batch [2/2], Train Loss: 0.3691\n",
      "LOG: Epoch [794/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [794/2000], Avg Train Loss: 0.3683, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [795/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3670\n",
      "LOG: Epoch [795/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [795/2000], Avg Train Loss: 0.3642, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [796/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3619\n",
      "    Batch [2/2], Train Loss: 0.3716\n",
      "LOG: Epoch [796/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1183\n",
      "Epoch [796/2000], Avg Train Loss: 0.3667, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [797/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3679\n",
      "LOG: Epoch [797/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [797/2000], Avg Train Loss: 0.3698, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [798/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3691\n",
      "    Batch [2/2], Train Loss: 0.3619\n",
      "LOG: Epoch [798/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3482\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [798/2000], Avg Train Loss: 0.3655, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [799/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3666\n",
      "LOG: Epoch [799/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1183\n",
      "Epoch [799/2000], Avg Train Loss: 0.3669, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [800/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3675\n",
      "    Batch [2/2], Train Loss: 0.3729\n",
      "LOG: Epoch [800/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [800/2000], Avg Train Loss: 0.3702, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [801/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3688\n",
      "LOG: Epoch [801/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1176\n",
      "Epoch [801/2000], Avg Train Loss: 0.3667, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [802/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3664\n",
      "    Batch [2/2], Train Loss: 0.3685\n",
      "LOG: Epoch [802/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [802/2000], Avg Train Loss: 0.3675, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [803/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3699\n",
      "LOG: Epoch [803/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [803/2000], Avg Train Loss: 0.3674, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [804/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3653\n",
      "    Batch [2/2], Train Loss: 0.3699\n",
      "LOG: Epoch [804/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [804/2000], Avg Train Loss: 0.3676, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [805/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3623\n",
      "LOG: Epoch [805/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3482\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [805/2000], Avg Train Loss: 0.3689, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [806/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3635\n",
      "    Batch [2/2], Train Loss: 0.3705\n",
      "LOG: Epoch [806/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1176\n",
      "Epoch [806/2000], Avg Train Loss: 0.3670, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [807/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3717\n",
      "LOG: Epoch [807/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1170\n",
      "Epoch [807/2000], Avg Train Loss: 0.3688, Avg Val Loss: 0.2327\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [808/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3631\n",
      "    Batch [2/2], Train Loss: 0.3730\n",
      "LOG: Epoch [808/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1171\n",
      "Epoch [808/2000], Avg Train Loss: 0.3680, Avg Val Loss: 0.2327\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [809/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3668\n",
      "    Batch [2/2], Train Loss: 0.3725\n",
      "LOG: Epoch [809/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1174\n",
      "Epoch [809/2000], Avg Train Loss: 0.3696, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [810/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3631\n",
      "LOG: Epoch [810/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [810/2000], Avg Train Loss: 0.3606, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [811/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3677\n",
      "LOG: Epoch [811/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1174\n",
      "Epoch [811/2000], Avg Train Loss: 0.3684, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [812/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3671\n",
      "    Batch [2/2], Train Loss: 0.3677\n",
      "LOG: Epoch [812/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1179\n",
      "Epoch [812/2000], Avg Train Loss: 0.3674, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [813/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3641\n",
      "LOG: Epoch [813/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1178\n",
      "Epoch [813/2000], Avg Train Loss: 0.3629, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [814/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3649\n",
      "    Batch [2/2], Train Loss: 0.3694\n",
      "LOG: Epoch [814/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1183\n",
      "Epoch [814/2000], Avg Train Loss: 0.3672, Avg Val Loss: 0.2333\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [815/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3645\n",
      "LOG: Epoch [815/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1184\n",
      "Epoch [815/2000], Avg Train Loss: 0.3648, Avg Val Loss: 0.2334\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [816/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3661\n",
      "    Batch [2/2], Train Loss: 0.3633\n",
      "LOG: Epoch [816/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [816/2000], Avg Train Loss: 0.3647, Avg Val Loss: 0.2334\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "LOG: Epoch [817/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3684\n",
      "LOG: Epoch [817/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1179\n",
      "Epoch [817/2000], Avg Train Loss: 0.3668, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "LOG: Epoch [818/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3658\n",
      "    Batch [2/2], Train Loss: 0.3675\n",
      "LOG: Epoch [818/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1173\n",
      "Epoch [818/2000], Avg Train Loss: 0.3666, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "LOG: Epoch [819/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3661\n",
      "LOG: Epoch [819/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1174\n",
      "Epoch [819/2000], Avg Train Loss: 0.3644, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "LOG: Epoch [820/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3643\n",
      "    Batch [2/2], Train Loss: 0.3693\n",
      "LOG: Epoch [820/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1167\n",
      "Epoch [820/2000], Avg Train Loss: 0.3668, Avg Val Loss: 0.2328\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "LOG: Epoch [821/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3626\n",
      "LOG: Epoch [821/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1172\n",
      "Epoch [821/2000], Avg Train Loss: 0.3637, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "LOG: Epoch [822/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3682\n",
      "    Batch [2/2], Train Loss: 0.3667\n",
      "LOG: Epoch [822/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1175\n",
      "Epoch [822/2000], Avg Train Loss: 0.3674, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "LOG: Epoch [823/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3648\n",
      "LOG: Epoch [823/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1175\n",
      "Epoch [823/2000], Avg Train Loss: 0.3679, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "LOG: Epoch [824/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3671\n",
      "    Batch [2/2], Train Loss: 0.3595\n",
      "LOG: Epoch [824/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [824/2000], Avg Train Loss: 0.3633, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "LOG: Epoch [825/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3693\n",
      "LOG: Epoch [825/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [825/2000], Avg Train Loss: 0.3657, Avg Val Loss: 0.2333\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "LOG: Epoch [826/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3671\n",
      "    Batch [2/2], Train Loss: 0.3677\n",
      "LOG: Epoch [826/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1183\n",
      "Epoch [826/2000], Avg Train Loss: 0.3674, Avg Val Loss: 0.2334\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "LOG: Epoch [827/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3646\n",
      "LOG: Epoch [827/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1184\n",
      "Epoch [827/2000], Avg Train Loss: 0.3660, Avg Val Loss: 0.2334\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "LOG: Epoch [828/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3695\n",
      "    Batch [2/2], Train Loss: 0.3649\n",
      "LOG: Epoch [828/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [828/2000], Avg Train Loss: 0.3672, Avg Val Loss: 0.2335\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "LOG: Epoch [829/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3676\n",
      "    Batch [2/2], Train Loss: 0.3753\n",
      "LOG: Epoch [829/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [829/2000], Avg Train Loss: 0.3714, Avg Val Loss: 0.2335\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "LOG: Epoch [830/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3711\n",
      "    Batch [2/2], Train Loss: 0.3692\n",
      "LOG: Epoch [830/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1188\n",
      "Epoch [830/2000], Avg Train Loss: 0.3702, Avg Val Loss: 0.2335\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "LOG: Epoch [831/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3661\n",
      "LOG: Epoch [831/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3482\n",
      "    Batch [2/2], Val Loss: 0.1188\n",
      "Epoch [831/2000], Avg Train Loss: 0.3696, Avg Val Loss: 0.2335\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "LOG: Epoch [832/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3624\n",
      "    Batch [2/2], Train Loss: 0.3665\n",
      "LOG: Epoch [832/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3482\n",
      "    Batch [2/2], Val Loss: 0.1191\n",
      "Epoch [832/2000], Avg Train Loss: 0.3644, Avg Val Loss: 0.2337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "LOG: Epoch [833/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3721\n",
      "LOG: Epoch [833/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [833/2000], Avg Train Loss: 0.3703, Avg Val Loss: 0.2335\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "LOG: Epoch [834/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3657\n",
      "    Batch [2/2], Train Loss: 0.3724\n",
      "LOG: Epoch [834/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1193\n",
      "Epoch [834/2000], Avg Train Loss: 0.3690, Avg Val Loss: 0.2337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "LOG: Epoch [835/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3696\n",
      "    Batch [2/2], Train Loss: 0.3628\n",
      "LOG: Epoch [835/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1192\n",
      "Epoch [835/2000], Avg Train Loss: 0.3662, Avg Val Loss: 0.2336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "LOG: Epoch [836/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3659\n",
      "    Batch [2/2], Train Loss: 0.3714\n",
      "LOG: Epoch [836/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3479\n",
      "    Batch [2/2], Val Loss: 0.1193\n",
      "Epoch [836/2000], Avg Train Loss: 0.3686, Avg Val Loss: 0.2336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "LOG: Epoch [837/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3642\n",
      "LOG: Epoch [837/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3478\n",
      "    Batch [2/2], Val Loss: 0.1195\n",
      "Epoch [837/2000], Avg Train Loss: 0.3669, Avg Val Loss: 0.2337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "LOG: Epoch [838/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3644\n",
      "    Batch [2/2], Train Loss: 0.3710\n",
      "LOG: Epoch [838/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3478\n",
      "    Batch [2/2], Val Loss: 0.1194\n",
      "Epoch [838/2000], Avg Train Loss: 0.3677, Avg Val Loss: 0.2336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "LOG: Epoch [839/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3699\n",
      "LOG: Epoch [839/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3479\n",
      "    Batch [2/2], Val Loss: 0.1184\n",
      "Epoch [839/2000], Avg Train Loss: 0.3681, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "LOG: Epoch [840/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3712\n",
      "    Batch [2/2], Train Loss: 0.3663\n",
      "LOG: Epoch [840/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1179\n",
      "Epoch [840/2000], Avg Train Loss: 0.3687, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "LOG: Epoch [841/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3709\n",
      "LOG: Epoch [841/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [841/2000], Avg Train Loss: 0.3701, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "LOG: Epoch [842/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3652\n",
      "    Batch [2/2], Train Loss: 0.3706\n",
      "LOG: Epoch [842/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3482\n",
      "    Batch [2/2], Val Loss: 0.1188\n",
      "Epoch [842/2000], Avg Train Loss: 0.3679, Avg Val Loss: 0.2335\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "LOG: Epoch [843/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3699\n",
      "LOG: Epoch [843/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1190\n",
      "Epoch [843/2000], Avg Train Loss: 0.3674, Avg Val Loss: 0.2335\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "LOG: Epoch [844/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3666\n",
      "    Batch [2/2], Train Loss: 0.3647\n",
      "LOG: Epoch [844/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1184\n",
      "Epoch [844/2000], Avg Train Loss: 0.3656, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "LOG: Epoch [845/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3649\n",
      "LOG: Epoch [845/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [845/2000], Avg Train Loss: 0.3635, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "LOG: Epoch [846/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3660\n",
      "    Batch [2/2], Train Loss: 0.3731\n",
      "LOG: Epoch [846/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3482\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [846/2000], Avg Train Loss: 0.3695, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "LOG: Epoch [847/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3566\n",
      "LOG: Epoch [847/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [847/2000], Avg Train Loss: 0.3601, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "LOG: Epoch [848/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3674\n",
      "    Batch [2/2], Train Loss: 0.3718\n",
      "LOG: Epoch [848/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1183\n",
      "Epoch [848/2000], Avg Train Loss: 0.3696, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "LOG: Epoch [849/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3707\n",
      "LOG: Epoch [849/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3479\n",
      "    Batch [2/2], Val Loss: 0.1184\n",
      "Epoch [849/2000], Avg Train Loss: 0.3692, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "LOG: Epoch [850/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3691\n",
      "    Batch [2/2], Train Loss: 0.3640\n",
      "LOG: Epoch [850/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1179\n",
      "Epoch [850/2000], Avg Train Loss: 0.3665, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "LOG: Epoch [851/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3643\n",
      "LOG: Epoch [851/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [851/2000], Avg Train Loss: 0.3656, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "LOG: Epoch [852/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3657\n",
      "    Batch [2/2], Train Loss: 0.3696\n",
      "LOG: Epoch [852/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3479\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [852/2000], Avg Train Loss: 0.3676, Avg Val Loss: 0.2334\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "LOG: Epoch [853/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3662\n",
      "LOG: Epoch [853/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1184\n",
      "Epoch [853/2000], Avg Train Loss: 0.3691, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "LOG: Epoch [854/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3668\n",
      "    Batch [2/2], Train Loss: 0.3658\n",
      "LOG: Epoch [854/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1174\n",
      "Epoch [854/2000], Avg Train Loss: 0.3663, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "LOG: Epoch [855/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3703\n",
      "LOG: Epoch [855/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1176\n",
      "Epoch [855/2000], Avg Train Loss: 0.3644, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "LOG: Epoch [856/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3715\n",
      "    Batch [2/2], Train Loss: 0.3700\n",
      "LOG: Epoch [856/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1179\n",
      "Epoch [856/2000], Avg Train Loss: 0.3708, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "LOG: Epoch [857/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3688\n",
      "LOG: Epoch [857/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [857/2000], Avg Train Loss: 0.3673, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "LOG: Epoch [858/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3601\n",
      "    Batch [2/2], Train Loss: 0.3661\n",
      "LOG: Epoch [858/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1179\n",
      "Epoch [858/2000], Avg Train Loss: 0.3631, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "LOG: Epoch [859/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3679\n",
      "LOG: Epoch [859/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3482\n",
      "    Batch [2/2], Val Loss: 0.1183\n",
      "Epoch [859/2000], Avg Train Loss: 0.3667, Avg Val Loss: 0.2333\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "LOG: Epoch [860/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3659\n",
      "    Batch [2/2], Train Loss: 0.3721\n",
      "LOG: Epoch [860/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3482\n",
      "    Batch [2/2], Val Loss: 0.1185\n",
      "Epoch [860/2000], Avg Train Loss: 0.3690, Avg Val Loss: 0.2333\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "LOG: Epoch [861/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3689\n",
      "LOG: Epoch [861/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [861/2000], Avg Train Loss: 0.3681, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "LOG: Epoch [862/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3713\n",
      "    Batch [2/2], Train Loss: 0.3674\n",
      "LOG: Epoch [862/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [862/2000], Avg Train Loss: 0.3693, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "LOG: Epoch [863/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3739\n",
      "LOG: Epoch [863/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1179\n",
      "Epoch [863/2000], Avg Train Loss: 0.3721, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "LOG: Epoch [864/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3579\n",
      "    Batch [2/2], Train Loss: 0.3610\n",
      "LOG: Epoch [864/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [864/2000], Avg Train Loss: 0.3594, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "LOG: Epoch [865/2000] - Training\n",
      "    Batch [1/2], Train Loss: 0.3649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [2/2], Train Loss: 0.3629\n",
      "LOG: Epoch [865/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1176\n",
      "Epoch [865/2000], Avg Train Loss: 0.3639, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "LOG: Epoch [866/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3675\n",
      "    Batch [2/2], Train Loss: 0.3611\n",
      "LOG: Epoch [866/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [866/2000], Avg Train Loss: 0.3643, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "LOG: Epoch [867/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Train Loss: 0.3669\n",
      "    Batch [2/2], Train Loss: 0.3645\n",
      "LOG: Epoch [867/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [867/2000], Avg Train Loss: 0.3657, Avg Val Loss: 0.2332\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 867!!\n",
      "No improvement for 100 epochs\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_model = SupConNet().to(device)\n",
    "sclsdl_criterion = SilhouetteDistanceLoss()\n",
    "sclsdl_optimizer = optim.AdamW(sclsdl_model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "sclsdl_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    sclsdl_optimizer, \n",
    "    mode='min',\n",
    "    patience=25,\n",
    "    factor=0.1\n",
    ")\n",
    "\n",
    "sclsdl_num_epochs = 2000\n",
    "\n",
    "sclsdl_patience = 100\n",
    "sclsdl_best_val_loss = float('inf')\n",
    "sclsdl_epochs_without_improvement = 0\n",
    "\n",
    "sclsdl_train_loss_history = []\n",
    "sclsdl_val_loss_history = []\n",
    "\n",
    "for sclsdl_epoch in range(sclsdl_num_epochs):\n",
    "    # Training\n",
    "    sclsdl_model.train()\n",
    "    sclsdl_running_train_loss = 0.0\n",
    "    \n",
    "    print(f\"LOG: Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}] - Training\")\n",
    "    for batch_idx, (vectors, labels) in enumerate(sclsdl_train_loader):\n",
    "\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        sclsdl_train_projections = sclsdl_model(vectors)\n",
    "\n",
    "        sclsdl_loss = sclsdl_criterion(sclsdl_train_projections, labels)\n",
    "\n",
    "        # Backprop and optimize\n",
    "        sclsdl_optimizer.zero_grad()\n",
    "        sclsdl_loss.backward()\n",
    "        sclsdl_optimizer.step()\n",
    "\n",
    "        sclsdl_running_train_loss += sclsdl_loss.item()\n",
    "        print(f\"    Batch [{batch_idx+1}/{len(sclsdl_train_loader)}], Train Loss: {sclsdl_loss.item():.4f}\")\n",
    "\n",
    "    sclsdl_train_epoch_loss = sclsdl_running_train_loss / len(sclsdl_train_loader)\n",
    "    sclsdl_train_loss_history.append(sclsdl_train_epoch_loss)\n",
    "\n",
    "    # Validation\n",
    "    sclsdl_model.eval()\n",
    "    sclsdl_running_val_loss = 0.0\n",
    "    print(f\"LOG: Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}] - Validation\")\n",
    "    with torch.no_grad():\n",
    "        for val_batch_idx, (vectors, labels) in enumerate(sclsdl_val_loader):\n",
    "\n",
    "            vectors = vectors.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            sclsdl_val_projections = sclsdl_model(vectors)\n",
    "            sclsdl_val_batch_loss = sclsdl_criterion(sclsdl_val_projections, labels).item()\n",
    "            sclsdl_running_val_loss += sclsdl_val_batch_loss\n",
    "            print(f\"    Batch [{val_batch_idx+1}/{len(sclsdl_val_loader)}], Val Loss: {sclsdl_val_batch_loss:.4f}\")\n",
    "\n",
    "    sclsdl_val_epoch_loss = sclsdl_running_val_loss / len(sclsdl_val_loader)\n",
    "    sclsdl_val_loss_history.append(sclsdl_val_epoch_loss)\n",
    "    \n",
    "    sclsdl_scheduler.step(sclsdl_val_epoch_loss)\n",
    "\n",
    "    print(f\"Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}], \"\n",
    "          f\"Avg Train Loss: {sclsdl_train_epoch_loss:.4f}, \"\n",
    "          f\"Avg Val Loss: {sclsdl_val_epoch_loss:.4f}\\n\")\n",
    "    \n",
    "    #early stopping logic\n",
    "    if sclsdl_val_epoch_loss < sclsdl_best_val_loss:\n",
    "        print(f\"Validation loss improved from {sclsdl_best_val_loss:.4f} to {sclsdl_val_epoch_loss:.4f}. Saving model...\")\n",
    "        sclsdl_best_val_loss = sclsdl_val_epoch_loss\n",
    "        sclsdl_epochs_without_improvement = 0\n",
    "    else:\n",
    "        sclsdl_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! Patience: {sclsdl_epochs_without_improvement}/{sclsdl_patience}\")\n",
    "\n",
    "    #stop training if val loss not improving\n",
    "    if sclsdl_epochs_without_improvement >= sclsdl_patience:\n",
    "        print(f\"!! Early stopping triggered at epoch {sclsdl_epoch + 1}!!\\nNo improvement for {sclsdl_patience} epochs\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sclsdl_num_epochs_run = len(sclsdl_train_loss_history)\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_train_loss_history, label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_val_loss_history, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Silhouette Distance Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:50:41.366386Z",
     "iopub.status.busy": "2025-05-08T19:50:41.365386Z",
     "iopub.status.idle": "2025-05-08T19:50:41.593584Z",
     "shell.execute_reply": "2025-05-08T19:50:41.593584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [10/41], Loss: 0.2320\n",
      "Test Batch [20/41], Loss: 0.2090\n",
      "Test Batch [30/41], Loss: 0.5003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [40/41], Loss: 0.1459\n",
      "\n",
      "Test Loss: 0.2595\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "sclsdl_model.eval()\n",
    "sclsdl_total_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (vectors, labels) in enumerate(sclsdl_test_loader):\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        projections = sclsdl_model(vectors)\n",
    "        loss = sclsdl_criterion(projections, labels)\n",
    "        sclsdl_total_test_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Test Batch [{batch_idx + 1}/{len(sclsdl_test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "sclsdl_avg_test_loss = sclsdl_total_test_loss / len(sclsdl_test_loader)\n",
    "print(f\"\\nTest Loss: {sclsdl_avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sclsdl_num_epochs_run = len(sclsdl_train_loss_history)\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_train_loss_history, label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_val_loss_history, label='Val Loss')\n",
    "# test loss = horizontal dashed line\n",
    "plt.axhline(y=sclsdl_avg_test_loss, color='r', linestyle='--', label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the representations learnt by SCL w/ SDL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:50:41.596377Z",
     "iopub.status.busy": "2025-05-08T19:50:41.596377Z",
     "iopub.status.idle": "2025-05-08T19:50:41.899315Z",
     "shell.execute_reply": "2025-05-08T19:50:41.899315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL_SDL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'sclsdl_representations\\train'.\n",
      "\n",
      "Extracting SCL_SDL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'sclsdl_representations\\val'.\n",
      "\n",
      "Extracting SCL_SDL representations for the test dataset...\n",
      "  Processed batch 10/41 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 20/41 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 30/41 for test dataset.\n",
      "  Processed batch 40/41 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'sclsdl_representations\\test'.\n",
      "SCL representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the SCL representations\n",
    "sclsdl_rep_dir = \"sclsdl_representations\"\n",
    "os.makedirs(sclsdl_rep_dir, exist_ok=True)\n",
    "\n",
    "sclsdl_loaders = {\n",
    "    'train': sclsdl_train_loader,\n",
    "    'val': sclsdl_val_loader,\n",
    "    'test': sclsdl_test_loader\n",
    "}\n",
    "\n",
    "sclsdl_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sclsdl_split_name, sclsdl_loader in sclsdl_loaders.items():\n",
    "        print(f\"\\nExtracting SCL_SDL representations for the {sclsdl_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        sclsdl_split_dir = os.path.join(sclsdl_rep_dir, sclsdl_split_name)\n",
    "        os.makedirs(sclsdl_split_dir, exist_ok=True)\n",
    "        \n",
    "        # processing the data batch-wise\n",
    "        for sclsdl_batch_idx, (sclsdl_vectors, sclsdl_labels) in enumerate(sclsdl_loader):\n",
    "            sclsdl_vectors = sclsdl_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            sclsdl_projections = sclsdl_model(sclsdl_vectors)\n",
    "            \n",
    "            # converting projections and labels to np arrays\n",
    "            sclsdl_projections_np = sclsdl_projections.cpu().numpy()\n",
    "            sclsdl_labels_np = sclsdl_labels.cpu().numpy()\n",
    "            \n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(sclsdl_split_dir, f\"scl_encoded_batch_{sclsdl_batch_idx}.npy\"), sclsdl_projections_np)\n",
    "            np.save(os.path.join(sclsdl_split_dir, f\"scl_labels_batch_{sclsdl_batch_idx}.npy\"), sclsdl_labels_np)\n",
    "            \n",
    "            if (sclsdl_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {sclsdl_batch_idx + 1}/{len(sclsdl_loader)} for {sclsdl_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {sclsdl_split_name} dataset. Representations saved in '{sclsdl_split_dir}'.\")\n",
    "\n",
    "print(\"SCL representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the representations learnt by SCL w/ SDL Model with LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:50:41.901352Z",
     "iopub.status.busy": "2025-05-08T19:50:41.901352Z",
     "iopub.status.idle": "2025-05-08T19:50:41.905427Z",
     "shell.execute_reply": "2025-05-08T19:50:41.905427Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_sclsdl_reps_and_labels(split_dir):\n",
    "    #gather all the scl_encoded_batch npy files in sorted order\n",
    "    sclsdl_rep_files = sorted(glob.glob(os.path.join(split_dir, \"scl_encoded_batch_*.npy\")))\n",
    "\n",
    "    sclsdl_all_reps = []\n",
    "    sclsdl_all_labels = []\n",
    "\n",
    "    for sclsdl_rep_file in sclsdl_rep_files:\n",
    "        #deriving label filenames\n",
    "        sclsdl_label_file = sclsdl_rep_file.replace(\"scl_encoded_batch_\", \"scl_labels_batch_\")\n",
    "\n",
    "        sclsdl_reps = np.load(sclsdl_rep_file)\n",
    "        sclsdl_labels = np.load(sclsdl_label_file)\n",
    "\n",
    "        sclsdl_all_reps.append(sclsdl_reps)\n",
    "        sclsdl_all_labels.append(sclsdl_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    sclsdl_all_reps = np.concatenate(sclsdl_all_reps, axis = 0)\n",
    "    sclsdl_all_labels = np.concatenate(sclsdl_all_labels, axis = 0)\n",
    "\n",
    "    return sclsdl_all_reps, sclsdl_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:50:41.907947Z",
     "iopub.status.busy": "2025-05-08T19:50:41.906938Z",
     "iopub.status.idle": "2025-05-08T19:50:42.421193Z",
     "shell.execute_reply": "2025-05-08T19:50:42.421193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (560, 128)\n",
      "Train labels shape: (560,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2618, 128)\n",
      "Test labels shape: (2618,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_lrm_train_dir = os.path.join(\"sclsdl_representations\", \"train\")\n",
    "sclsdl_lrm_val_dir   = os.path.join(\"sclsdl_representations\", \"val\")\n",
    "sclsdl_lrm_test_dir  = os.path.join(\"sclsdl_representations\", \"test\")\n",
    "\n",
    "sclsdl_lrm_train_reps, sclsdl_lrm_train_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_train_dir)\n",
    "sclsdl_lrm_val_reps, sclsdl_lrm_val_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_val_dir)\n",
    "sclsdl_lrm_test_reps, sclsdl_lrm_test_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", sclsdl_lrm_train_reps.shape)\n",
    "print(\"Train labels shape:\", sclsdl_lrm_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", sclsdl_lrm_val_reps.shape)\n",
    "print(\"Val labels shape:\", sclsdl_lrm_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", sclsdl_lrm_test_reps.shape)\n",
    "print(\"Test labels shape:\", sclsdl_lrm_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:50:42.423703Z",
     "iopub.status.busy": "2025-05-08T19:50:42.423703Z",
     "iopub.status.idle": "2025-05-08T19:50:42.471421Z",
     "shell.execute_reply": "2025-05-08T19:50:42.471421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Training Logistic Regression model on SCL SDL representations...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 92.86%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       1.00      1.00      1.00         5\n",
      "           4       0.80      0.80      0.80         5\n",
      "           5       0.75      0.60      0.67         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      0.80      0.89         5\n",
      "           8       0.83      1.00      0.91         5\n",
      "           9       0.71      1.00      0.83         5\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      0.80      0.89         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.93        70\n",
      "   macro avg       0.94      0.93      0.93        70\n",
      "weighted avg       0.94      0.93      0.93        70\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 90.60%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99       225\n",
      "           1       0.80      1.00      0.89        56\n",
      "           2       0.97      0.97      0.97       206\n",
      "           3       0.84      0.99      0.91       170\n",
      "           4       0.78      0.83      0.80       224\n",
      "           5       0.81      0.65      0.72       224\n",
      "           6       0.97      0.98      0.97       214\n",
      "           7       0.93      0.91      0.92       158\n",
      "           8       0.87      0.83      0.85       269\n",
      "           9       0.88      0.95      0.91       203\n",
      "          10       0.98      0.94      0.96       260\n",
      "          11       0.92      0.97      0.94       136\n",
      "          12       0.94      0.91      0.92       223\n",
      "          13       1.00      0.98      0.99        50\n",
      "\n",
      "    accuracy                           0.91      2618\n",
      "   macro avg       0.91      0.92      0.91      2618\n",
      "weighted avg       0.91      0.91      0.90      2618\n",
      "\n",
      "Saved SCL_SDL+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression Model on the SCLSDL representations\n",
    "print(\"\\nLOG: Training Logistic Regression model on SCL SDL representations...\")\n",
    "sclsdl_logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced')\n",
    "sclsdl_logistic_clf.fit(sclsdl_lrm_train_reps, sclsdl_lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "# Evaluate on Validation Set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "sclsdl_lrm_val_predictions = sclsdl_logistic_clf.predict(sclsdl_lrm_val_reps)\n",
    "sclsdl_lrm_val_accuracy = accuracy_score(sclsdl_lrm_val_labels, sclsdl_lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {sclsdl_lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(sclsdl_lrm_val_labels, sclsdl_lrm_val_predictions))\n",
    "\n",
    "# Evaluate on Test Set\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "sclsdl_lrm_test_predictions = sclsdl_logistic_clf.predict(sclsdl_lrm_test_reps)\n",
    "sclsdl_lrm_test_accuracy = accuracy_score(sclsdl_lrm_test_labels, sclsdl_lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {sclsdl_lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(sclsdl_lrm_test_labels, sclsdl_lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_lrm_predictions.npy'), sclsdl_lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_lrm_true_labels.npy'), sclsdl_lrm_test_labels)\n",
    "print(f\"Saved SCL_SDL+LRM predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the representations learnt by SCL w/ SDL Model with MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:50:42.474428Z",
     "iopub.status.busy": "2025-05-08T19:50:42.474428Z",
     "iopub.status.idle": "2025-05-08T19:50:42.490008Z",
     "shell.execute_reply": "2025-05-08T19:50:42.490008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (560, 128)\n",
      "Train labels shape: (560,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2618, 128)\n",
      "Test labels shape: (2618,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_mlp_train_dir = os.path.join(\"sclsdl_representations\", \"train\")\n",
    "sclsdl_mlp_val_dir   = os.path.join(\"sclsdl_representations\", \"val\")\n",
    "sclsdl_mlp_test_dir  = os.path.join(\"sclsdl_representations\", \"test\")\n",
    "\n",
    "sclsdl_mlp_train_reps, sclsdl_mlp_train_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_train_dir)\n",
    "sclsdl_mlp_val_reps, sclsdl_mlp_val_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_val_dir)\n",
    "sclsdl_mlp_test_reps, sclsdl_mlp_test_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", sclsdl_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", sclsdl_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", sclsdl_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", sclsdl_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", sclsdl_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", sclsdl_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:50:42.493013Z",
     "iopub.status.busy": "2025-05-08T19:50:42.492013Z",
     "iopub.status.idle": "2025-05-08T19:50:42.497267Z",
     "shell.execute_reply": "2025-05-08T19:50:42.497267Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "sclsdl_mlp_train_embeddings_torch = torch.tensor(sclsdl_mlp_train_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_train_labels_torch = torch.tensor(sclsdl_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "sclsdl_mlp_val_embeddings_torch = torch.tensor(sclsdl_mlp_val_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_val_labels_torch = torch.tensor(sclsdl_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "sclsdl_mlp_test_embeddings_torch = torch.tensor(sclsdl_mlp_test_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_test_labels_torch = torch.tensor(sclsdl_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "sclsdl_mlp_train_dataset = TensorDataset(sclsdl_mlp_train_embeddings_torch, sclsdl_mlp_train_labels_torch)\n",
    "sclsdl_mlp_val_dataset = TensorDataset(sclsdl_mlp_val_embeddings_torch, sclsdl_mlp_val_labels_torch)\n",
    "sclsdl_mlp_test_dataset = TensorDataset(sclsdl_mlp_test_embeddings_torch, sclsdl_mlp_test_labels_torch)\n",
    "\n",
    "sclsdl_mlp_batch_size = 64\n",
    "sclsdl_mlp_train_loader = DataLoader(sclsdl_mlp_train_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=True)\n",
    "sclsdl_mlp_val_loader = DataLoader(sclsdl_mlp_val_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=False)\n",
    "sclsdl_mlp_test_loader = DataLoader(sclsdl_mlp_test_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:50:42.499276Z",
     "iopub.status.busy": "2025-05-08T19:50:42.499276Z",
     "iopub.status.idle": "2025-05-08T19:50:50.303533Z",
     "shell.execute_reply": "2025-05-08T19:50:50.303533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.6285  |  Val Loss: 2.5976\n",
      "Validation loss improved from inf to 2.5976.\n",
      "[Epoch 2/1000] Train Loss: 2.5708  |  Val Loss: 2.5486\n",
      "Validation loss improved from 2.5976 to 2.5486.\n",
      "[Epoch 3/1000] Train Loss: 2.5204  |  Val Loss: 2.5020\n",
      "Validation loss improved from 2.5486 to 2.5020.\n",
      "[Epoch 4/1000] Train Loss: 2.4705  |  Val Loss: 2.4594\n",
      "Validation loss improved from 2.5020 to 2.4594.\n",
      "[Epoch 5/1000] Train Loss: 2.4251  |  Val Loss: 2.4199\n",
      "Validation loss improved from 2.4594 to 2.4199.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/1000] Train Loss: 2.3857  |  Val Loss: 2.3813\n",
      "Validation loss improved from 2.4199 to 2.3813.\n",
      "[Epoch 7/1000] Train Loss: 2.3436  |  Val Loss: 2.3450\n",
      "Validation loss improved from 2.3813 to 2.3450.\n",
      "[Epoch 8/1000] Train Loss: 2.3058  |  Val Loss: 2.3082\n",
      "Validation loss improved from 2.3450 to 2.3082.\n",
      "[Epoch 9/1000] Train Loss: 2.2667  |  Val Loss: 2.2716\n",
      "Validation loss improved from 2.3082 to 2.2716.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/1000] Train Loss: 2.2293  |  Val Loss: 2.2347\n",
      "Validation loss improved from 2.2716 to 2.2347.\n",
      "[Epoch 11/1000] Train Loss: 2.1896  |  Val Loss: 2.1981\n",
      "Validation loss improved from 2.2347 to 2.1981.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/1000] Train Loss: 2.1510  |  Val Loss: 2.1611\n",
      "Validation loss improved from 2.1981 to 2.1611.\n",
      "[Epoch 13/1000] Train Loss: 2.1120  |  Val Loss: 2.1245\n",
      "Validation loss improved from 2.1611 to 2.1245.\n",
      "[Epoch 14/1000] Train Loss: 2.0738  |  Val Loss: 2.0872\n",
      "Validation loss improved from 2.1245 to 2.0872.\n",
      "[Epoch 15/1000] Train Loss: 2.0355  |  Val Loss: 2.0503\n",
      "Validation loss improved from 2.0872 to 2.0503.\n",
      "[Epoch 16/1000] Train Loss: 1.9981  |  Val Loss: 2.0132\n",
      "Validation loss improved from 2.0503 to 2.0132.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/1000] Train Loss: 1.9598  |  Val Loss: 1.9763\n",
      "Validation loss improved from 2.0132 to 1.9763.\n",
      "[Epoch 18/1000] Train Loss: 1.9215  |  Val Loss: 1.9398\n",
      "Validation loss improved from 1.9763 to 1.9398.\n",
      "[Epoch 19/1000] Train Loss: 1.8833  |  Val Loss: 1.9036\n",
      "Validation loss improved from 1.9398 to 1.9036.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/1000] Train Loss: 1.8459  |  Val Loss: 1.8676\n",
      "Validation loss improved from 1.9036 to 1.8676.\n",
      "[Epoch 21/1000] Train Loss: 1.8080  |  Val Loss: 1.8321\n",
      "Validation loss improved from 1.8676 to 1.8321.\n",
      "[Epoch 22/1000] Train Loss: 1.7708  |  Val Loss: 1.7966\n",
      "Validation loss improved from 1.8321 to 1.7966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23/1000] Train Loss: 1.7336  |  Val Loss: 1.7615\n",
      "Validation loss improved from 1.7966 to 1.7615.\n",
      "[Epoch 24/1000] Train Loss: 1.6964  |  Val Loss: 1.7267\n",
      "Validation loss improved from 1.7615 to 1.7267.\n",
      "[Epoch 25/1000] Train Loss: 1.6597  |  Val Loss: 1.6921\n",
      "Validation loss improved from 1.7267 to 1.6921.\n",
      "[Epoch 26/1000] Train Loss: 1.6228  |  Val Loss: 1.6583\n",
      "Validation loss improved from 1.6921 to 1.6583.\n",
      "[Epoch 27/1000] Train Loss: 1.5858  |  Val Loss: 1.6249\n",
      "Validation loss improved from 1.6583 to 1.6249.\n",
      "[Epoch 28/1000] Train Loss: 1.5488  |  Val Loss: 1.5920\n",
      "Validation loss improved from 1.6249 to 1.5920.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29/1000] Train Loss: 1.5121  |  Val Loss: 1.5591\n",
      "Validation loss improved from 1.5920 to 1.5591.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/1000] Train Loss: 1.4748  |  Val Loss: 1.5261\n",
      "Validation loss improved from 1.5591 to 1.5261.\n",
      "[Epoch 31/1000] Train Loss: 1.4383  |  Val Loss: 1.4937\n",
      "Validation loss improved from 1.5261 to 1.4937.\n",
      "[Epoch 32/1000] Train Loss: 1.4026  |  Val Loss: 1.4625\n",
      "Validation loss improved from 1.4937 to 1.4625.\n",
      "[Epoch 33/1000] Train Loss: 1.3672  |  Val Loss: 1.4322\n",
      "Validation loss improved from 1.4625 to 1.4322.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/1000] Train Loss: 1.3330  |  Val Loss: 1.4016\n",
      "Validation loss improved from 1.4322 to 1.4016.\n",
      "[Epoch 35/1000] Train Loss: 1.2987  |  Val Loss: 1.3710\n",
      "Validation loss improved from 1.4016 to 1.3710.\n",
      "[Epoch 36/1000] Train Loss: 1.2647  |  Val Loss: 1.3411\n",
      "Validation loss improved from 1.3710 to 1.3411.\n",
      "[Epoch 37/1000] Train Loss: 1.2313  |  Val Loss: 1.3113\n",
      "Validation loss improved from 1.3411 to 1.3113.\n",
      "[Epoch 38/1000] Train Loss: 1.1978  |  Val Loss: 1.2826\n",
      "Validation loss improved from 1.3113 to 1.2826.\n",
      "[Epoch 39/1000] Train Loss: 1.1654  |  Val Loss: 1.2529\n",
      "Validation loss improved from 1.2826 to 1.2529.\n",
      "[Epoch 40/1000] Train Loss: 1.1323  |  Val Loss: 1.2236\n",
      "Validation loss improved from 1.2529 to 1.2236.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41/1000] Train Loss: 1.0995  |  Val Loss: 1.1942\n",
      "Validation loss improved from 1.2236 to 1.1942.\n",
      "[Epoch 42/1000] Train Loss: 1.0671  |  Val Loss: 1.1661\n",
      "Validation loss improved from 1.1942 to 1.1661.\n",
      "[Epoch 43/1000] Train Loss: 1.0351  |  Val Loss: 1.1376\n",
      "Validation loss improved from 1.1661 to 1.1376.\n",
      "[Epoch 44/1000] Train Loss: 1.0042  |  Val Loss: 1.1094\n",
      "Validation loss improved from 1.1376 to 1.1094.\n",
      "[Epoch 45/1000] Train Loss: 0.9726  |  Val Loss: 1.0820\n",
      "Validation loss improved from 1.1094 to 1.0820.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 46/1000] Train Loss: 0.9417  |  Val Loss: 1.0549\n",
      "Validation loss improved from 1.0820 to 1.0549.\n",
      "[Epoch 47/1000] Train Loss: 0.9114  |  Val Loss: 1.0280\n",
      "Validation loss improved from 1.0549 to 1.0280.\n",
      "[Epoch 48/1000] Train Loss: 0.8820  |  Val Loss: 1.0013\n",
      "Validation loss improved from 1.0280 to 1.0013.\n",
      "[Epoch 49/1000] Train Loss: 0.8524  |  Val Loss: 0.9753\n",
      "Validation loss improved from 1.0013 to 0.9753.\n",
      "[Epoch 50/1000] Train Loss: 0.8242  |  Val Loss: 0.9498\n",
      "Validation loss improved from 0.9753 to 0.9498.\n",
      "[Epoch 51/1000] Train Loss: 0.7971  |  Val Loss: 0.9257\n",
      "Validation loss improved from 0.9498 to 0.9257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 52/1000] Train Loss: 0.7699  |  Val Loss: 0.9007\n",
      "Validation loss improved from 0.9257 to 0.9007.\n",
      "[Epoch 53/1000] Train Loss: 0.7432  |  Val Loss: 0.8773\n",
      "Validation loss improved from 0.9007 to 0.8773.\n",
      "[Epoch 54/1000] Train Loss: 0.7181  |  Val Loss: 0.8539\n",
      "Validation loss improved from 0.8773 to 0.8539.\n",
      "[Epoch 55/1000] Train Loss: 0.6937  |  Val Loss: 0.8310\n",
      "Validation loss improved from 0.8539 to 0.8310.\n",
      "[Epoch 56/1000] Train Loss: 0.6700  |  Val Loss: 0.8087\n",
      "Validation loss improved from 0.8310 to 0.8087.\n",
      "[Epoch 57/1000] Train Loss: 0.6471  |  Val Loss: 0.7886\n",
      "Validation loss improved from 0.8087 to 0.7886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 58/1000] Train Loss: 0.6249  |  Val Loss: 0.7689\n",
      "Validation loss improved from 0.7886 to 0.7689.\n",
      "[Epoch 59/1000] Train Loss: 0.6034  |  Val Loss: 0.7494\n",
      "Validation loss improved from 0.7689 to 0.7494.\n",
      "[Epoch 60/1000] Train Loss: 0.5836  |  Val Loss: 0.7302\n",
      "Validation loss improved from 0.7494 to 0.7302.\n",
      "[Epoch 61/1000] Train Loss: 0.5642  |  Val Loss: 0.7129\n",
      "Validation loss improved from 0.7302 to 0.7129.\n",
      "[Epoch 62/1000] Train Loss: 0.5451  |  Val Loss: 0.6957\n",
      "Validation loss improved from 0.7129 to 0.6957.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 63/1000] Train Loss: 0.5272  |  Val Loss: 0.6802\n",
      "Validation loss improved from 0.6957 to 0.6802.\n",
      "[Epoch 64/1000] Train Loss: 0.5103  |  Val Loss: 0.6651\n",
      "Validation loss improved from 0.6802 to 0.6651.\n",
      "[Epoch 65/1000] Train Loss: 0.4941  |  Val Loss: 0.6502\n",
      "Validation loss improved from 0.6651 to 0.6502.\n",
      "[Epoch 66/1000] Train Loss: 0.4787  |  Val Loss: 0.6359\n",
      "Validation loss improved from 0.6502 to 0.6359.\n",
      "[Epoch 67/1000] Train Loss: 0.4637  |  Val Loss: 0.6231\n",
      "Validation loss improved from 0.6359 to 0.6231.\n",
      "[Epoch 68/1000] Train Loss: 0.4497  |  Val Loss: 0.6108\n",
      "Validation loss improved from 0.6231 to 0.6108.\n",
      "[Epoch 69/1000] Train Loss: 0.4361  |  Val Loss: 0.5992\n",
      "Validation loss improved from 0.6108 to 0.5992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 70/1000] Train Loss: 0.4236  |  Val Loss: 0.5871\n",
      "Validation loss improved from 0.5992 to 0.5871.\n",
      "[Epoch 71/1000] Train Loss: 0.4116  |  Val Loss: 0.5752\n",
      "Validation loss improved from 0.5871 to 0.5752.\n",
      "[Epoch 72/1000] Train Loss: 0.4001  |  Val Loss: 0.5649\n",
      "Validation loss improved from 0.5752 to 0.5649.\n",
      "[Epoch 73/1000] Train Loss: 0.3886  |  Val Loss: 0.5551\n",
      "Validation loss improved from 0.5649 to 0.5551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 74/1000] Train Loss: 0.3782  |  Val Loss: 0.5447\n",
      "Validation loss improved from 0.5551 to 0.5447.\n",
      "[Epoch 75/1000] Train Loss: 0.3681  |  Val Loss: 0.5365\n",
      "Validation loss improved from 0.5447 to 0.5365.\n",
      "[Epoch 76/1000] Train Loss: 0.3578  |  Val Loss: 0.5265\n",
      "Validation loss improved from 0.5365 to 0.5265.\n",
      "[Epoch 77/1000] Train Loss: 0.3481  |  Val Loss: 0.5184\n",
      "Validation loss improved from 0.5265 to 0.5184.\n",
      "[Epoch 78/1000] Train Loss: 0.3391  |  Val Loss: 0.5093\n",
      "Validation loss improved from 0.5184 to 0.5093.\n",
      "[Epoch 79/1000] Train Loss: 0.3304  |  Val Loss: 0.5014\n",
      "Validation loss improved from 0.5093 to 0.5014.\n",
      "[Epoch 80/1000] Train Loss: 0.3219  |  Val Loss: 0.4934\n",
      "Validation loss improved from 0.5014 to 0.4934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 81/1000] Train Loss: 0.3139  |  Val Loss: 0.4864\n",
      "Validation loss improved from 0.4934 to 0.4864.\n",
      "[Epoch 82/1000] Train Loss: 0.3062  |  Val Loss: 0.4803\n",
      "Validation loss improved from 0.4864 to 0.4803.\n",
      "[Epoch 83/1000] Train Loss: 0.2991  |  Val Loss: 0.4733\n",
      "Validation loss improved from 0.4803 to 0.4733.\n",
      "[Epoch 84/1000] Train Loss: 0.2923  |  Val Loss: 0.4664\n",
      "Validation loss improved from 0.4733 to 0.4664.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 85/1000] Train Loss: 0.2864  |  Val Loss: 0.4614\n",
      "Validation loss improved from 0.4664 to 0.4614.\n",
      "[Epoch 86/1000] Train Loss: 0.2792  |  Val Loss: 0.4548\n",
      "Validation loss improved from 0.4614 to 0.4548.\n",
      "[Epoch 87/1000] Train Loss: 0.2731  |  Val Loss: 0.4486\n",
      "Validation loss improved from 0.4548 to 0.4486.\n",
      "[Epoch 88/1000] Train Loss: 0.2670  |  Val Loss: 0.4432\n",
      "Validation loss improved from 0.4486 to 0.4432.\n",
      "[Epoch 89/1000] Train Loss: 0.2616  |  Val Loss: 0.4381\n",
      "Validation loss improved from 0.4432 to 0.4381.\n",
      "[Epoch 90/1000] Train Loss: 0.2564  |  Val Loss: 0.4342\n",
      "Validation loss improved from 0.4381 to 0.4342.\n",
      "[Epoch 91/1000] Train Loss: 0.2509  |  Val Loss: 0.4300\n",
      "Validation loss improved from 0.4342 to 0.4300.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 92/1000] Train Loss: 0.2457  |  Val Loss: 0.4244\n",
      "Validation loss improved from 0.4300 to 0.4244.\n",
      "[Epoch 93/1000] Train Loss: 0.2409  |  Val Loss: 0.4197\n",
      "Validation loss improved from 0.4244 to 0.4197.\n",
      "[Epoch 94/1000] Train Loss: 0.2361  |  Val Loss: 0.4162\n",
      "Validation loss improved from 0.4197 to 0.4162.\n",
      "[Epoch 95/1000] Train Loss: 0.2314  |  Val Loss: 0.4113\n",
      "Validation loss improved from 0.4162 to 0.4113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 96/1000] Train Loss: 0.2269  |  Val Loss: 0.4074\n",
      "Validation loss improved from 0.4113 to 0.4074.\n",
      "[Epoch 97/1000] Train Loss: 0.2226  |  Val Loss: 0.4028\n",
      "Validation loss improved from 0.4074 to 0.4028.\n",
      "[Epoch 98/1000] Train Loss: 0.2180  |  Val Loss: 0.3982\n",
      "Validation loss improved from 0.4028 to 0.3982.\n",
      "[Epoch 99/1000] Train Loss: 0.2137  |  Val Loss: 0.3955\n",
      "Validation loss improved from 0.3982 to 0.3955.\n",
      "[Epoch 100/1000] Train Loss: 0.2096  |  Val Loss: 0.3915\n",
      "Validation loss improved from 0.3955 to 0.3915.\n",
      "[Epoch 101/1000] Train Loss: 0.2053  |  Val Loss: 0.3876\n",
      "Validation loss improved from 0.3915 to 0.3876.\n",
      "[Epoch 102/1000] Train Loss: 0.2017  |  Val Loss: 0.3833\n",
      "Validation loss improved from 0.3876 to 0.3833.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 103/1000] Train Loss: 0.1980  |  Val Loss: 0.3798\n",
      "Validation loss improved from 0.3833 to 0.3798.\n",
      "[Epoch 104/1000] Train Loss: 0.1944  |  Val Loss: 0.3765\n",
      "Validation loss improved from 0.3798 to 0.3765.\n",
      "[Epoch 105/1000] Train Loss: 0.1913  |  Val Loss: 0.3741\n",
      "Validation loss improved from 0.3765 to 0.3741.\n",
      "[Epoch 106/1000] Train Loss: 0.1881  |  Val Loss: 0.3697\n",
      "Validation loss improved from 0.3741 to 0.3697.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 107/1000] Train Loss: 0.1853  |  Val Loss: 0.3689\n",
      "Validation loss improved from 0.3697 to 0.3689.\n",
      "[Epoch 108/1000] Train Loss: 0.1820  |  Val Loss: 0.3652\n",
      "Validation loss improved from 0.3689 to 0.3652.\n",
      "[Epoch 109/1000] Train Loss: 0.1792  |  Val Loss: 0.3614\n",
      "Validation loss improved from 0.3652 to 0.3614.\n",
      "[Epoch 110/1000] Train Loss: 0.1760  |  Val Loss: 0.3592\n",
      "Validation loss improved from 0.3614 to 0.3592.\n",
      "[Epoch 111/1000] Train Loss: 0.1733  |  Val Loss: 0.3570\n",
      "Validation loss improved from 0.3592 to 0.3570.\n",
      "[Epoch 112/1000] Train Loss: 0.1704  |  Val Loss: 0.3539\n",
      "Validation loss improved from 0.3570 to 0.3539.\n",
      "[Epoch 113/1000] Train Loss: 0.1683  |  Val Loss: 0.3512\n",
      "Validation loss improved from 0.3539 to 0.3512.\n",
      "[Epoch 114/1000] Train Loss: 0.1656  |  Val Loss: 0.3471\n",
      "Validation loss improved from 0.3512 to 0.3471.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 115/1000] Train Loss: 0.1629  |  Val Loss: 0.3458\n",
      "Validation loss improved from 0.3471 to 0.3458.\n",
      "[Epoch 116/1000] Train Loss: 0.1607  |  Val Loss: 0.3441\n",
      "Validation loss improved from 0.3458 to 0.3441.\n",
      "[Epoch 117/1000] Train Loss: 0.1584  |  Val Loss: 0.3429\n",
      "Validation loss improved from 0.3441 to 0.3429.\n",
      "[Epoch 118/1000] Train Loss: 0.1562  |  Val Loss: 0.3400\n",
      "Validation loss improved from 0.3429 to 0.3400.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 119/1000] Train Loss: 0.1537  |  Val Loss: 0.3360\n",
      "Validation loss improved from 0.3400 to 0.3360.\n",
      "[Epoch 120/1000] Train Loss: 0.1518  |  Val Loss: 0.3347\n",
      "Validation loss improved from 0.3360 to 0.3347.\n",
      "[Epoch 121/1000] Train Loss: 0.1500  |  Val Loss: 0.3323\n",
      "Validation loss improved from 0.3347 to 0.3323.\n",
      "[Epoch 122/1000] Train Loss: 0.1475  |  Val Loss: 0.3311\n",
      "Validation loss improved from 0.3323 to 0.3311.\n",
      "[Epoch 123/1000] Train Loss: 0.1456  |  Val Loss: 0.3296\n",
      "Validation loss improved from 0.3311 to 0.3296.\n",
      "[Epoch 124/1000] Train Loss: 0.1438  |  Val Loss: 0.3267\n",
      "Validation loss improved from 0.3296 to 0.3267.\n",
      "[Epoch 125/1000] Train Loss: 0.1416  |  Val Loss: 0.3243\n",
      "Validation loss improved from 0.3267 to 0.3243.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 126/1000] Train Loss: 0.1402  |  Val Loss: 0.3226\n",
      "Validation loss improved from 0.3243 to 0.3226.\n",
      "[Epoch 127/1000] Train Loss: 0.1382  |  Val Loss: 0.3221\n",
      "Validation loss improved from 0.3226 to 0.3221.\n",
      "[Epoch 128/1000] Train Loss: 0.1364  |  Val Loss: 0.3200\n",
      "Validation loss improved from 0.3221 to 0.3200.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 129/1000] Train Loss: 0.1349  |  Val Loss: 0.3181\n",
      "Validation loss improved from 0.3200 to 0.3181.\n",
      "[Epoch 130/1000] Train Loss: 0.1331  |  Val Loss: 0.3168\n",
      "Validation loss improved from 0.3181 to 0.3168.\n",
      "[Epoch 131/1000] Train Loss: 0.1314  |  Val Loss: 0.3144\n",
      "Validation loss improved from 0.3168 to 0.3144.\n",
      "[Epoch 132/1000] Train Loss: 0.1302  |  Val Loss: 0.3134\n",
      "Validation loss improved from 0.3144 to 0.3134.\n",
      "[Epoch 133/1000] Train Loss: 0.1285  |  Val Loss: 0.3111\n",
      "Validation loss improved from 0.3134 to 0.3111.\n",
      "[Epoch 134/1000] Train Loss: 0.1269  |  Val Loss: 0.3093\n",
      "Validation loss improved from 0.3111 to 0.3093.\n",
      "[Epoch 135/1000] Train Loss: 0.1253  |  Val Loss: 0.3079\n",
      "Validation loss improved from 0.3093 to 0.3079.\n",
      "[Epoch 136/1000] Train Loss: 0.1238  |  Val Loss: 0.3068\n",
      "Validation loss improved from 0.3079 to 0.3068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 137/1000] Train Loss: 0.1228  |  Val Loss: 0.3051\n",
      "Validation loss improved from 0.3068 to 0.3051.\n",
      "[Epoch 138/1000] Train Loss: 0.1211  |  Val Loss: 0.3048\n",
      "Validation loss improved from 0.3051 to 0.3048.\n",
      "[Epoch 139/1000] Train Loss: 0.1196  |  Val Loss: 0.3034\n",
      "Validation loss improved from 0.3048 to 0.3034.\n",
      "[Epoch 140/1000] Train Loss: 0.1181  |  Val Loss: 0.3014\n",
      "Validation loss improved from 0.3034 to 0.3014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 141/1000] Train Loss: 0.1172  |  Val Loss: 0.2998\n",
      "Validation loss improved from 0.3014 to 0.2998.\n",
      "[Epoch 142/1000] Train Loss: 0.1157  |  Val Loss: 0.2984\n",
      "Validation loss improved from 0.2998 to 0.2984.\n",
      "[Epoch 143/1000] Train Loss: 0.1142  |  Val Loss: 0.2981\n",
      "Validation loss improved from 0.2984 to 0.2981.\n",
      "[Epoch 144/1000] Train Loss: 0.1130  |  Val Loss: 0.2974\n",
      "Validation loss improved from 0.2981 to 0.2974.\n",
      "[Epoch 145/1000] Train Loss: 0.1118  |  Val Loss: 0.2964\n",
      "Validation loss improved from 0.2974 to 0.2964.\n",
      "[Epoch 146/1000] Train Loss: 0.1105  |  Val Loss: 0.2942\n",
      "Validation loss improved from 0.2964 to 0.2942.\n",
      "[Epoch 147/1000] Train Loss: 0.1097  |  Val Loss: 0.2926\n",
      "Validation loss improved from 0.2942 to 0.2926.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 148/1000] Train Loss: 0.1081  |  Val Loss: 0.2922\n",
      "Validation loss improved from 0.2926 to 0.2922.\n",
      "[Epoch 149/1000] Train Loss: 0.1073  |  Val Loss: 0.2910\n",
      "Validation loss improved from 0.2922 to 0.2910.\n",
      "[Epoch 150/1000] Train Loss: 0.1058  |  Val Loss: 0.2906\n",
      "Validation loss improved from 0.2910 to 0.2906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 151/1000] Train Loss: 0.1047  |  Val Loss: 0.2877\n",
      "Validation loss improved from 0.2906 to 0.2877.\n",
      "[Epoch 152/1000] Train Loss: 0.1038  |  Val Loss: 0.2883\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 153/1000] Train Loss: 0.1026  |  Val Loss: 0.2887\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 154/1000] Train Loss: 0.1013  |  Val Loss: 0.2858\n",
      "Validation loss improved from 0.2877 to 0.2858.\n",
      "[Epoch 155/1000] Train Loss: 0.1003  |  Val Loss: 0.2843\n",
      "Validation loss improved from 0.2858 to 0.2843.\n",
      "[Epoch 156/1000] Train Loss: 0.0995  |  Val Loss: 0.2851\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 157/1000] Train Loss: 0.0981  |  Val Loss: 0.2829\n",
      "Validation loss improved from 0.2843 to 0.2829.\n",
      "[Epoch 158/1000] Train Loss: 0.0972  |  Val Loss: 0.2822\n",
      "Validation loss improved from 0.2829 to 0.2822.\n",
      "[Epoch 159/1000] Train Loss: 0.0961  |  Val Loss: 0.2825\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 160/1000] Train Loss: 0.0950  |  Val Loss: 0.2815\n",
      "Validation loss improved from 0.2822 to 0.2815.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 161/1000] Train Loss: 0.0943  |  Val Loss: 0.2807\n",
      "Validation loss improved from 0.2815 to 0.2807.\n",
      "[Epoch 162/1000] Train Loss: 0.0932  |  Val Loss: 0.2773\n",
      "Validation loss improved from 0.2807 to 0.2773.\n",
      "[Epoch 163/1000] Train Loss: 0.0922  |  Val Loss: 0.2772\n",
      "Validation loss improved from 0.2773 to 0.2772.\n",
      "[Epoch 164/1000] Train Loss: 0.0913  |  Val Loss: 0.2773\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 165/1000] Train Loss: 0.0901  |  Val Loss: 0.2757\n",
      "Validation loss improved from 0.2772 to 0.2757.\n",
      "[Epoch 166/1000] Train Loss: 0.0895  |  Val Loss: 0.2741\n",
      "Validation loss improved from 0.2757 to 0.2741.\n",
      "[Epoch 167/1000] Train Loss: 0.0885  |  Val Loss: 0.2757\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 168/1000] Train Loss: 0.0877  |  Val Loss: 0.2745\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 169/1000] Train Loss: 0.0868  |  Val Loss: 0.2727\n",
      "Validation loss improved from 0.2741 to 0.2727.\n",
      "[Epoch 170/1000] Train Loss: 0.0860  |  Val Loss: 0.2728\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 171/1000] Train Loss: 0.0850  |  Val Loss: 0.2725\n",
      "Validation loss improved from 0.2727 to 0.2725.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 172/1000] Train Loss: 0.0841  |  Val Loss: 0.2695\n",
      "Validation loss improved from 0.2725 to 0.2695.\n",
      "[Epoch 173/1000] Train Loss: 0.0832  |  Val Loss: 0.2701\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 174/1000] Train Loss: 0.0824  |  Val Loss: 0.2705\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 175/1000] Train Loss: 0.0816  |  Val Loss: 0.2692\n",
      "Validation loss improved from 0.2695 to 0.2692.\n",
      "[Epoch 176/1000] Train Loss: 0.0808  |  Val Loss: 0.2676\n",
      "Validation loss improved from 0.2692 to 0.2676.\n",
      "[Epoch 177/1000] Train Loss: 0.0801  |  Val Loss: 0.2660\n",
      "Validation loss improved from 0.2676 to 0.2660.\n",
      "[Epoch 178/1000] Train Loss: 0.0793  |  Val Loss: 0.2677\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 179/1000] Train Loss: 0.0783  |  Val Loss: 0.2654\n",
      "Validation loss improved from 0.2660 to 0.2654.\n",
      "[Epoch 180/1000] Train Loss: 0.0775  |  Val Loss: 0.2654\n",
      "Validation loss improved from 0.2654 to 0.2654.\n",
      "[Epoch 181/1000] Train Loss: 0.0767  |  Val Loss: 0.2646\n",
      "Validation loss improved from 0.2654 to 0.2646.\n",
      "[Epoch 182/1000] Train Loss: 0.0762  |  Val Loss: 0.2633\n",
      "Validation loss improved from 0.2646 to 0.2633.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 183/1000] Train Loss: 0.0751  |  Val Loss: 0.2630\n",
      "Validation loss improved from 0.2633 to 0.2630.\n",
      "[Epoch 184/1000] Train Loss: 0.0744  |  Val Loss: 0.2619\n",
      "Validation loss improved from 0.2630 to 0.2619.\n",
      "[Epoch 185/1000] Train Loss: 0.0738  |  Val Loss: 0.2624\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 186/1000] Train Loss: 0.0731  |  Val Loss: 0.2629\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 187/1000] Train Loss: 0.0723  |  Val Loss: 0.2597\n",
      "Validation loss improved from 0.2619 to 0.2597.\n",
      "[Epoch 188/1000] Train Loss: 0.0716  |  Val Loss: 0.2593\n",
      "Validation loss improved from 0.2597 to 0.2593.\n",
      "[Epoch 189/1000] Train Loss: 0.0708  |  Val Loss: 0.2589\n",
      "Validation loss improved from 0.2593 to 0.2589.\n",
      "[Epoch 190/1000] Train Loss: 0.0701  |  Val Loss: 0.2594\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 191/1000] Train Loss: 0.0693  |  Val Loss: 0.2588\n",
      "Validation loss improved from 0.2589 to 0.2588.\n",
      "[Epoch 192/1000] Train Loss: 0.0687  |  Val Loss: 0.2577\n",
      "Validation loss improved from 0.2588 to 0.2577.\n",
      "[Epoch 193/1000] Train Loss: 0.0680  |  Val Loss: 0.2572\n",
      "Validation loss improved from 0.2577 to 0.2572.\n",
      "[Epoch 194/1000] Train Loss: 0.0677  |  Val Loss: 0.2568\n",
      "Validation loss improved from 0.2572 to 0.2568.\n",
      "[Epoch 195/1000] Train Loss: 0.0668  |  Val Loss: 0.2578\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 196/1000] Train Loss: 0.0663  |  Val Loss: 0.2563\n",
      "Validation loss improved from 0.2568 to 0.2563.\n",
      "[Epoch 197/1000] Train Loss: 0.0654  |  Val Loss: 0.2553\n",
      "Validation loss improved from 0.2563 to 0.2553.\n",
      "[Epoch 198/1000] Train Loss: 0.0648  |  Val Loss: 0.2545\n",
      "Validation loss improved from 0.2553 to 0.2545.\n",
      "[Epoch 199/1000] Train Loss: 0.0642  |  Val Loss: 0.2558\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 200/1000] Train Loss: 0.0635  |  Val Loss: 0.2537\n",
      "Validation loss improved from 0.2545 to 0.2537.\n",
      "[Epoch 201/1000] Train Loss: 0.0631  |  Val Loss: 0.2532\n",
      "Validation loss improved from 0.2537 to 0.2532.\n",
      "[Epoch 202/1000] Train Loss: 0.0622  |  Val Loss: 0.2539\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 203/1000] Train Loss: 0.0620  |  Val Loss: 0.2524\n",
      "Validation loss improved from 0.2532 to 0.2524.\n",
      "[Epoch 204/1000] Train Loss: 0.0614  |  Val Loss: 0.2515\n",
      "Validation loss improved from 0.2524 to 0.2515.\n",
      "[Epoch 205/1000] Train Loss: 0.0606  |  Val Loss: 0.2507\n",
      "Validation loss improved from 0.2515 to 0.2507.\n",
      "[Epoch 206/1000] Train Loss: 0.0600  |  Val Loss: 0.2523\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 207/1000] Train Loss: 0.0594  |  Val Loss: 0.2519\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 208/1000] Train Loss: 0.0589  |  Val Loss: 0.2511\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 209/1000] Train Loss: 0.0583  |  Val Loss: 0.2490\n",
      "Validation loss improved from 0.2507 to 0.2490.\n",
      "[Epoch 210/1000] Train Loss: 0.0579  |  Val Loss: 0.2492\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 211/1000] Train Loss: 0.0572  |  Val Loss: 0.2492\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 212/1000] Train Loss: 0.0573  |  Val Loss: 0.2458\n",
      "Validation loss improved from 0.2490 to 0.2458.\n",
      "[Epoch 213/1000] Train Loss: 0.0562  |  Val Loss: 0.2482\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 214/1000] Train Loss: 0.0559  |  Val Loss: 0.2482\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 215/1000] Train Loss: 0.0553  |  Val Loss: 0.2480\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 216/1000] Train Loss: 0.0546  |  Val Loss: 0.2467\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 217/1000] Train Loss: 0.0542  |  Val Loss: 0.2483\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 218/1000] Train Loss: 0.0537  |  Val Loss: 0.2486\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 219/1000] Train Loss: 0.0531  |  Val Loss: 0.2461\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 220/1000] Train Loss: 0.0527  |  Val Loss: 0.2454\n",
      "Validation loss improved from 0.2458 to 0.2454.\n",
      "[Epoch 221/1000] Train Loss: 0.0520  |  Val Loss: 0.2455\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 222/1000] Train Loss: 0.0517  |  Val Loss: 0.2452\n",
      "Validation loss improved from 0.2454 to 0.2452.\n",
      "[Epoch 223/1000] Train Loss: 0.0510  |  Val Loss: 0.2455\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 224/1000] Train Loss: 0.0507  |  Val Loss: 0.2435\n",
      "Validation loss improved from 0.2452 to 0.2435.\n",
      "[Epoch 225/1000] Train Loss: 0.0502  |  Val Loss: 0.2448\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 226/1000] Train Loss: 0.0498  |  Val Loss: 0.2432\n",
      "Validation loss improved from 0.2435 to 0.2432.\n",
      "[Epoch 227/1000] Train Loss: 0.0491  |  Val Loss: 0.2430\n",
      "Validation loss improved from 0.2432 to 0.2430.\n",
      "[Epoch 228/1000] Train Loss: 0.0488  |  Val Loss: 0.2431\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 229/1000] Train Loss: 0.0483  |  Val Loss: 0.2430\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 230/1000] Train Loss: 0.0478  |  Val Loss: 0.2417\n",
      "Validation loss improved from 0.2430 to 0.2417.\n",
      "[Epoch 231/1000] Train Loss: 0.0475  |  Val Loss: 0.2412\n",
      "Validation loss improved from 0.2417 to 0.2412.\n",
      "[Epoch 232/1000] Train Loss: 0.0471  |  Val Loss: 0.2421\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 233/1000] Train Loss: 0.0467  |  Val Loss: 0.2439\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 234/1000] Train Loss: 0.0462  |  Val Loss: 0.2426\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 235/1000] Train Loss: 0.0458  |  Val Loss: 0.2413\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 236/1000] Train Loss: 0.0453  |  Val Loss: 0.2407\n",
      "Validation loss improved from 0.2412 to 0.2407.\n",
      "[Epoch 237/1000] Train Loss: 0.0447  |  Val Loss: 0.2423\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 238/1000] Train Loss: 0.0444  |  Val Loss: 0.2419\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 239/1000] Train Loss: 0.0442  |  Val Loss: 0.2406\n",
      "Validation loss improved from 0.2407 to 0.2406.\n",
      "[Epoch 240/1000] Train Loss: 0.0435  |  Val Loss: 0.2411\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 241/1000] Train Loss: 0.0431  |  Val Loss: 0.2411\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 242/1000] Train Loss: 0.0429  |  Val Loss: 0.2411\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 243/1000] Train Loss: 0.0425  |  Val Loss: 0.2400\n",
      "Validation loss improved from 0.2406 to 0.2400.\n",
      "[Epoch 244/1000] Train Loss: 0.0421  |  Val Loss: 0.2417\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 245/1000] Train Loss: 0.0418  |  Val Loss: 0.2403\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 246/1000] Train Loss: 0.0412  |  Val Loss: 0.2415\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 247/1000] Train Loss: 0.0409  |  Val Loss: 0.2412\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 248/1000] Train Loss: 0.0408  |  Val Loss: 0.2388\n",
      "Validation loss improved from 0.2400 to 0.2388.\n",
      "[Epoch 249/1000] Train Loss: 0.0403  |  Val Loss: 0.2404\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 250/1000] Train Loss: 0.0398  |  Val Loss: 0.2388\n",
      "Validation loss improved from 0.2388 to 0.2388.\n",
      "[Epoch 251/1000] Train Loss: 0.0396  |  Val Loss: 0.2381\n",
      "Validation loss improved from 0.2388 to 0.2381.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 252/1000] Train Loss: 0.0392  |  Val Loss: 0.2386\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 253/1000] Train Loss: 0.0387  |  Val Loss: 0.2379\n",
      "Validation loss improved from 0.2381 to 0.2379.\n",
      "[Epoch 254/1000] Train Loss: 0.0384  |  Val Loss: 0.2381\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 255/1000] Train Loss: 0.0380  |  Val Loss: 0.2377\n",
      "Validation loss improved from 0.2379 to 0.2377.\n",
      "[Epoch 256/1000] Train Loss: 0.0377  |  Val Loss: 0.2376\n",
      "Validation loss improved from 0.2377 to 0.2376.\n",
      "[Epoch 257/1000] Train Loss: 0.0373  |  Val Loss: 0.2374\n",
      "Validation loss improved from 0.2376 to 0.2374.\n",
      "[Epoch 258/1000] Train Loss: 0.0369  |  Val Loss: 0.2372\n",
      "Validation loss improved from 0.2374 to 0.2372.\n",
      "[Epoch 259/1000] Train Loss: 0.0367  |  Val Loss: 0.2383\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 260/1000] Train Loss: 0.0367  |  Val Loss: 0.2374\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 261/1000] Train Loss: 0.0361  |  Val Loss: 0.2366\n",
      "Validation loss improved from 0.2372 to 0.2366.\n",
      "[Epoch 262/1000] Train Loss: 0.0359  |  Val Loss: 0.2366\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 263/1000] Train Loss: 0.0353  |  Val Loss: 0.2353\n",
      "Validation loss improved from 0.2366 to 0.2353.\n",
      "[Epoch 264/1000] Train Loss: 0.0351  |  Val Loss: 0.2351\n",
      "Validation loss improved from 0.2353 to 0.2351.\n",
      "[Epoch 265/1000] Train Loss: 0.0349  |  Val Loss: 0.2381\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 266/1000] Train Loss: 0.0343  |  Val Loss: 0.2364\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 267/1000] Train Loss: 0.0341  |  Val Loss: 0.2358\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 268/1000] Train Loss: 0.0339  |  Val Loss: 0.2350\n",
      "Validation loss improved from 0.2351 to 0.2350.\n",
      "[Epoch 269/1000] Train Loss: 0.0336  |  Val Loss: 0.2379\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 270/1000] Train Loss: 0.0331  |  Val Loss: 0.2374\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 271/1000] Train Loss: 0.0328  |  Val Loss: 0.2360\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 272/1000] Train Loss: 0.0327  |  Val Loss: 0.2340\n",
      "Validation loss improved from 0.2350 to 0.2340.\n",
      "[Epoch 273/1000] Train Loss: 0.0322  |  Val Loss: 0.2362\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 274/1000] Train Loss: 0.0319  |  Val Loss: 0.2364\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 275/1000] Train Loss: 0.0316  |  Val Loss: 0.2359\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 276/1000] Train Loss: 0.0313  |  Val Loss: 0.2365\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 277/1000] Train Loss: 0.0309  |  Val Loss: 0.2350\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 278/1000] Train Loss: 0.0309  |  Val Loss: 0.2348\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 279/1000] Train Loss: 0.0304  |  Val Loss: 0.2346\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 280/1000] Train Loss: 0.0301  |  Val Loss: 0.2349\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 281/1000] Train Loss: 0.0300  |  Val Loss: 0.2367\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 282/1000] Train Loss: 0.0297  |  Val Loss: 0.2373\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 283/1000] Train Loss: 0.0294  |  Val Loss: 0.2365\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 284/1000] Train Loss: 0.0291  |  Val Loss: 0.2334\n",
      "Validation loss improved from 0.2340 to 0.2334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 285/1000] Train Loss: 0.0289  |  Val Loss: 0.2353\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 286/1000] Train Loss: 0.0285  |  Val Loss: 0.2349\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 287/1000] Train Loss: 0.0283  |  Val Loss: 0.2341\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 288/1000] Train Loss: 0.0280  |  Val Loss: 0.2345\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 289/1000] Train Loss: 0.0277  |  Val Loss: 0.2351\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 290/1000] Train Loss: 0.0275  |  Val Loss: 0.2341\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 291/1000] Train Loss: 0.0272  |  Val Loss: 0.2343\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 292/1000] Train Loss: 0.0273  |  Val Loss: 0.2352\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 293/1000] Train Loss: 0.0268  |  Val Loss: 0.2355\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 294/1000] Train Loss: 0.0264  |  Val Loss: 0.2348\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 295/1000] Train Loss: 0.0264  |  Val Loss: 0.2331\n",
      "Validation loss improved from 0.2334 to 0.2331.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 296/1000] Train Loss: 0.0260  |  Val Loss: 0.2341\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 297/1000] Train Loss: 0.0257  |  Val Loss: 0.2344\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 298/1000] Train Loss: 0.0254  |  Val Loss: 0.2342\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 299/1000] Train Loss: 0.0253  |  Val Loss: 0.2344\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 300/1000] Train Loss: 0.0250  |  Val Loss: 0.2352\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 301/1000] Train Loss: 0.0248  |  Val Loss: 0.2347\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 302/1000] Train Loss: 0.0246  |  Val Loss: 0.2347\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 303/1000] Train Loss: 0.0244  |  Val Loss: 0.2340\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 304/1000] Train Loss: 0.0242  |  Val Loss: 0.2360\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 305/1000] Train Loss: 0.0240  |  Val Loss: 0.2368\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 306/1000] Train Loss: 0.0237  |  Val Loss: 0.2357\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 307/1000] Train Loss: 0.0235  |  Val Loss: 0.2357\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 308/1000] Train Loss: 0.0233  |  Val Loss: 0.2365\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 309/1000] Train Loss: 0.0231  |  Val Loss: 0.2354\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 310/1000] Train Loss: 0.0231  |  Val Loss: 0.2339\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 311/1000] Train Loss: 0.0228  |  Val Loss: 0.2358\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 312/1000] Train Loss: 0.0225  |  Val Loss: 0.2349\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 313/1000] Train Loss: 0.0223  |  Val Loss: 0.2354\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 314/1000] Train Loss: 0.0221  |  Val Loss: 0.2351\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 315/1000] Train Loss: 0.0219  |  Val Loss: 0.2357\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 316/1000] Train Loss: 0.0217  |  Val Loss: 0.2355\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 317/1000] Train Loss: 0.0215  |  Val Loss: 0.2346\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 318/1000] Train Loss: 0.0214  |  Val Loss: 0.2350\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 319/1000] Train Loss: 0.0212  |  Val Loss: 0.2359\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 320/1000] Train Loss: 0.0211  |  Val Loss: 0.2364\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 321/1000] Train Loss: 0.0207  |  Val Loss: 0.2356\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 322/1000] Train Loss: 0.0207  |  Val Loss: 0.2356\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 323/1000] Train Loss: 0.0205  |  Val Loss: 0.2340\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 324/1000] Train Loss: 0.0203  |  Val Loss: 0.2336\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 325/1000] Train Loss: 0.0202  |  Val Loss: 0.2359\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 326/1000] Train Loss: 0.0199  |  Val Loss: 0.2358\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 327/1000] Train Loss: 0.0197  |  Val Loss: 0.2353\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 328/1000] Train Loss: 0.0196  |  Val Loss: 0.2360\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 329/1000] Train Loss: 0.0195  |  Val Loss: 0.2350\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 330/1000] Train Loss: 0.0193  |  Val Loss: 0.2343\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 331/1000] Train Loss: 0.0191  |  Val Loss: 0.2369\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 332/1000] Train Loss: 0.0189  |  Val Loss: 0.2363\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 333/1000] Train Loss: 0.0187  |  Val Loss: 0.2365\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 334/1000] Train Loss: 0.0186  |  Val Loss: 0.2362\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 335/1000] Train Loss: 0.0184  |  Val Loss: 0.2357\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 336/1000] Train Loss: 0.0183  |  Val Loss: 0.2358\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 337/1000] Train Loss: 0.0180  |  Val Loss: 0.2364\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 338/1000] Train Loss: 0.0179  |  Val Loss: 0.2366\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 339/1000] Train Loss: 0.0179  |  Val Loss: 0.2359\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 340/1000] Train Loss: 0.0177  |  Val Loss: 0.2363\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 341/1000] Train Loss: 0.0175  |  Val Loss: 0.2372\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 342/1000] Train Loss: 0.0173  |  Val Loss: 0.2376\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 343/1000] Train Loss: 0.0172  |  Val Loss: 0.2372\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 344/1000] Train Loss: 0.0170  |  Val Loss: 0.2372\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 345/1000] Train Loss: 0.0169  |  Val Loss: 0.2372\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 346/1000] Train Loss: 0.0167  |  Val Loss: 0.2381\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 347/1000] Train Loss: 0.0166  |  Val Loss: 0.2384\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 348/1000] Train Loss: 0.0164  |  Val Loss: 0.2385\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 349/1000] Train Loss: 0.0163  |  Val Loss: 0.2374\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 350/1000] Train Loss: 0.0162  |  Val Loss: 0.2383\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 351/1000] Train Loss: 0.0160  |  Val Loss: 0.2380\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 352/1000] Train Loss: 0.0159  |  Val Loss: 0.2389\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 353/1000] Train Loss: 0.0158  |  Val Loss: 0.2378\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 354/1000] Train Loss: 0.0156  |  Val Loss: 0.2382\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 355/1000] Train Loss: 0.0155  |  Val Loss: 0.2389\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 356/1000] Train Loss: 0.0153  |  Val Loss: 0.2398\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 357/1000] Train Loss: 0.0152  |  Val Loss: 0.2388\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 358/1000] Train Loss: 0.0150  |  Val Loss: 0.2391\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 359/1000] Train Loss: 0.0149  |  Val Loss: 0.2391\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 360/1000] Train Loss: 0.0149  |  Val Loss: 0.2393\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 361/1000] Train Loss: 0.0149  |  Val Loss: 0.2397\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 362/1000] Train Loss: 0.0147  |  Val Loss: 0.2397\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 363/1000] Train Loss: 0.0145  |  Val Loss: 0.2390\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 364/1000] Train Loss: 0.0143  |  Val Loss: 0.2387\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 365/1000] Train Loss: 0.0144  |  Val Loss: 0.2409\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 366/1000] Train Loss: 0.0141  |  Val Loss: 0.2418\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 367/1000] Train Loss: 0.0140  |  Val Loss: 0.2403\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 368/1000] Train Loss: 0.0138  |  Val Loss: 0.2406\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 369/1000] Train Loss: 0.0138  |  Val Loss: 0.2406\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 370/1000] Train Loss: 0.0136  |  Val Loss: 0.2406\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 371/1000] Train Loss: 0.0135  |  Val Loss: 0.2407\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "[Epoch 372/1000] Train Loss: 0.0134  |  Val Loss: 0.2415\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "[Epoch 373/1000] Train Loss: 0.0133  |  Val Loss: 0.2415\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 374/1000] Train Loss: 0.0132  |  Val Loss: 0.2412\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 375/1000] Train Loss: 0.0131  |  Val Loss: 0.2422\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 376/1000] Train Loss: 0.0130  |  Val Loss: 0.2409\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 377/1000] Train Loss: 0.0128  |  Val Loss: 0.2414\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 378/1000] Train Loss: 0.0127  |  Val Loss: 0.2425\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 379/1000] Train Loss: 0.0127  |  Val Loss: 0.2433\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "[Epoch 380/1000] Train Loss: 0.0125  |  Val Loss: 0.2442\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 381/1000] Train Loss: 0.0124  |  Val Loss: 0.2438\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 382/1000] Train Loss: 0.0123  |  Val Loss: 0.2432\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "[Epoch 383/1000] Train Loss: 0.0122  |  Val Loss: 0.2439\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 384/1000] Train Loss: 0.0122  |  Val Loss: 0.2423\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 385/1000] Train Loss: 0.0121  |  Val Loss: 0.2438\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 386/1000] Train Loss: 0.0119  |  Val Loss: 0.2440\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 387/1000] Train Loss: 0.0119  |  Val Loss: 0.2441\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 388/1000] Train Loss: 0.0118  |  Val Loss: 0.2437\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "[Epoch 389/1000] Train Loss: 0.0117  |  Val Loss: 0.2445\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "[Epoch 390/1000] Train Loss: 0.0115  |  Val Loss: 0.2451\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 391/1000] Train Loss: 0.0114  |  Val Loss: 0.2459\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 392/1000] Train Loss: 0.0113  |  Val Loss: 0.2453\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 393/1000] Train Loss: 0.0113  |  Val Loss: 0.2454\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "[Epoch 394/1000] Train Loss: 0.0112  |  Val Loss: 0.2466\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 395/1000] Train Loss: 0.0110  |  Val Loss: 0.2467\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 395 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_mlp_input_dim = sclsdl_mlp_train_reps.shape[1]\n",
    "sclsdl_mlp_num_classes = len(torch.unique(sclsdl_mlp_train_labels_torch))\n",
    "sclsdl_mlp_model = MLPClassifier(sclsdl_mlp_input_dim, sclsdl_mlp_num_classes).to(device)\n",
    "\n",
    "sclsdl_mlp_criterion = nn.CrossEntropyLoss()\n",
    "sclsdl_mlp_optimizer = optim.Adam(sclsdl_mlp_model.parameters(), lr=1e-4)\n",
    "\n",
    "sclsdl_mlp_num_epochs = 1000\n",
    "sclsdl_mlp_patience = 100\n",
    "\n",
    "sclsdl_mlp_train_losses = []\n",
    "sclsdl_mlp_val_losses = []\n",
    "\n",
    "sclsdl_mlp_best_val_loss = float('inf')\n",
    "sclsdl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for sclsdl_mlp_epoch in range(sclsdl_mlp_num_epochs):\n",
    "    # Training\n",
    "    sclsdl_mlp_model.train()\n",
    "    sclsdl_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for sclsdl_mlp_embeddings_batch, sclsdl_mlp_labels_batch in sclsdl_mlp_train_loader:\n",
    "        sclsdl_mlp_embeddings_batch = sclsdl_mlp_embeddings_batch.to(device)\n",
    "        sclsdl_mlp_labels_batch = sclsdl_mlp_labels_batch.to(device)\n",
    "        \n",
    "        sclsdl_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        sclsdl_mlp_outputs = sclsdl_mlp_model(sclsdl_mlp_embeddings_batch)\n",
    "        sclsdl_mlp_loss = sclsdl_mlp_criterion(sclsdl_mlp_outputs, sclsdl_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        sclsdl_mlp_loss.backward()\n",
    "        sclsdl_mlp_optimizer.step()\n",
    "        \n",
    "        sclsdl_mlp_train_running_loss += sclsdl_mlp_loss.item() * sclsdl_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    sclsdl_mlp_epoch_train_loss = sclsdl_mlp_train_running_loss / len(sclsdl_mlp_train_loader.dataset)\n",
    "    sclsdl_mlp_train_losses.append(sclsdl_mlp_epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    sclsdl_mlp_model.eval()\n",
    "    sclsdl_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sclsdl_mlp_val_embeddings_batch, sclsdl_mlp_val_labels_batch in sclsdl_mlp_val_loader:\n",
    "            sclsdl_mlp_val_embeddings_batch = sclsdl_mlp_val_embeddings_batch.to(device)\n",
    "            sclsdl_mlp_val_labels_batch = sclsdl_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            sclsdl_mlp_val_outputs = sclsdl_mlp_model(sclsdl_mlp_val_embeddings_batch)\n",
    "            sclsdl_mlp_val_loss = sclsdl_mlp_criterion(sclsdl_mlp_val_outputs, sclsdl_mlp_val_labels_batch)\n",
    "\n",
    "            sclsdl_mlp_val_running_loss += sclsdl_mlp_val_loss.item() * sclsdl_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    sclsdl_mlp_epoch_val_loss = sclsdl_mlp_val_running_loss / len(sclsdl_mlp_val_loader.dataset)\n",
    "    sclsdl_mlp_val_losses.append(sclsdl_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {sclsdl_mlp_epoch+1}/{sclsdl_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {sclsdl_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {sclsdl_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if sclsdl_mlp_epoch_val_loss < sclsdl_mlp_best_val_loss:\n",
    "        print(f\"Validation loss improved from {sclsdl_mlp_best_val_loss:.4f} to {sclsdl_mlp_epoch_val_loss:.4f}.\")\n",
    "        sclsdl_mlp_best_val_loss = sclsdl_mlp_epoch_val_loss\n",
    "        sclsdl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "\n",
    "    else:\n",
    "        sclsdl_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {sclsdl_mlp_epochs_without_improvement}/{sclsdl_mlp_patience}\")\n",
    "        \n",
    "        if sclsdl_mlp_epochs_without_improvement >= sclsdl_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {sclsdl_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {sclsdl_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(sclsdl_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(sclsdl_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:50:50.306538Z",
     "iopub.status.busy": "2025-05-08T19:50:50.305539Z",
     "iopub.status.idle": "2025-05-08T19:50:50.449330Z",
     "shell.execute_reply": "2025-05-08T19:50:50.449330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SCL_SDL+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.3427 | Test Accuracy: 89.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIhCAYAAAB5deq6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACEFUlEQVR4nOzdd3hUVf7H8ffMZNILSSANQqjSexMUAUGa2LCtDXUtyyruuuhPxV3Fsiuua1tXxXVXwC4q6KKi0ouC0ot0pJMECCW9zcz9/XGTCYFUSHJTPq/nmWdmzj135pvLGOeTc+65NsMwDERERERERKRUdqsLEBERERERqe0UnERERERERMqh4CQiIiIiIlIOBScREREREZFyKDiJiIiIiIiUQ8FJRERERESkHApOIiIiIiIi5VBwEhERERERKYeCk4iIiIiISDkUnEREKsFms1XotmTJkvN6n6eeegqbzXZO+y5ZsqRKaqjt7rjjDlq0aFHq9mPHjuHr68tvfvObUvukpaURGBjIlVdeWeH3nTFjBjabjX379lW4ltPZbDaeeuqpCr9focTERJ566ik2bNhw1rbz+bycrxYtWjBmzBhL3ltEpCb5WF2AiEhdsnLlymLPn332WRYvXsyiRYuKtXfs2PG83ufuu+9m5MiR57Rvz549Wbly5XnXUNc1adKEK6+8ki+//JKTJ08SHh5+Vp9PPvmE7Oxs7rrrrvN6ryeeeII//vGP5/Ua5UlMTOTpp5+mRYsWdO/evdi28/m8iIhIxSg4iYhUwoUXXljseZMmTbDb7We1nykrK4vAwMAKv0+zZs1o1qzZOdUYGhpabj0NxV133cWsWbP48MMPmTBhwlnbp02bRnR0NJdffvl5vU/r1q3Pa//zdT6fFxERqRhN1RMRqWKDBw+mc+fOLFu2jAEDBhAYGMhvf/tbAGbOnMnw4cOJjY0lICCADh068Nhjj5GZmVnsNUqaelU4Jeq7776jZ8+eBAQE0L59e6ZNm1asX0lT9e644w6Cg4PZvXs3o0ePJjg4mPj4eB566CFyc3OL7X/o0CGuu+46QkJCaNSoEbfccgurV6/GZrMxY8aMMn/2Y8eOcd9999GxY0eCg4OJiori0ksvZfny5cX67du3D5vNxosvvsjLL79My5YtCQ4Opn///vz0009nve6MGTNo164dfn5+dOjQgffee6/MOgqNGDGCZs2aMX369LO2bdu2jZ9//plx48bh4+PD/Pnzueqqq2jWrBn+/v60adOG3/3ud6SkpJT7PiVN1UtLS+Oee+4hMjKS4OBgRo4cyc6dO8/ad/fu3dx55520bduWwMBAmjZtyhVXXMHmzZu9fZYsWUKfPn0AuPPOO71TQgun/JX0efF4PLzwwgu0b98ePz8/oqKiGDduHIcOHSrWr/Dzunr1agYOHEhgYCCtWrXi+eefx+PxlPuzV0ROTg6TJk2iZcuW+Pr60rRpU+6//35OnTpVrN+iRYsYPHgwkZGRBAQE0Lx5c6699lqysrK8faZOnUq3bt0IDg4mJCSE9u3b8/jjj1dJnSIiZdGIk4hINUhKSuLWW2/lkUce4bnnnsNuN/9OtWvXLkaPHs2DDz5IUFAQ27dv5+9//zurVq06a7pfSTZu3MhDDz3EY489RnR0NP/973+56667aNOmDZdcckmZ++bn53PllVdy11138dBDD7Fs2TKeffZZwsLCePLJJwHIzMxkyJAhnDhxgr///e+0adOG7777jhtvvLFCP/eJEycAmDx5MjExMWRkZPDFF18wePBgFi5cyODBg4v1f+ONN2jfvj2vvvoqYE55Gz16NHv37iUsLAwwQ9Odd97JVVddxUsvvURqaipPPfUUubm53uNaGrvdzh133MFf//pXNm7cSLdu3bzbCsNUYaj99ddf6d+/P3fffTdhYWHs27ePl19+mYsvvpjNmzfjdDordAwADMPg6quvZsWKFTz55JP06dOHH3/8kVGjRp3VNzExkcjISJ5//nmaNGnCiRMnePfdd+nXrx/r16+nXbt29OzZk+nTp3PnnXfyl7/8xTtCVtYo0+9//3vefvttJkyYwJgxY9i3bx9PPPEES5YsYd26dTRu3NjbNzk5mVtuuYWHHnqIyZMn88UXXzBp0iTi4uIYN25chX/uso7FwoULmTRpEgMHDmTTpk1MnjyZlStXsnLlSvz8/Ni3bx+XX345AwcOZNq0aTRq1IjDhw/z3XffkZeXR2BgIJ988gn33XcfDzzwAC+++CJ2u53du3ezdevW86pRRKRCDBEROWe33367ERQUVKxt0KBBBmAsXLiwzH09Ho+Rn59vLF261ACMjRs3erdNnjzZOPNXdEJCguHv72/s37/f25adnW1EREQYv/vd77xtixcvNgBj8eLFxeoEjE8//bTYa44ePdpo166d9/kbb7xhAMa3335brN/vfvc7AzCmT59e5s90JpfLZeTn5xtDhw41rrnmGm/73r17DcDo0qWL4XK5vO2rVq0yAOPjjz82DMMw3G63ERcXZ/Ts2dPweDzefvv27TOcTqeRkJBQbg179uwxbDab8Yc//MHblp+fb8TExBgXXXRRifsU/tvs37/fAIz//e9/3m3Tp083AGPv3r3etttvv71YLd9++60BGP/85z+Lve7f/vY3AzAmT55car0ul8vIy8sz2rZta/zpT3/ytq9evbrUf4MzPy/btm0zAOO+++4r1u/nn382AOPxxx/3thV+Xn/++edifTt27GiMGDGi1DoLJSQkGJdffnmp27/77jsDMF544YVi7TNnzjQA4+233zYMwzA+//xzAzA2bNhQ6mtNmDDBaNSoUbk1iYhUB03VExGpBuHh4Vx66aVnte/Zs4ebb76ZmJgYHA4HTqeTQYMGAebUsfJ0796d5s2be5/7+/tzwQUXsH///nL3tdlsXHHFFcXaunbtWmzfpUuXEhISctZCAzfddFO5r1/orbfeomfPnvj7++Pj44PT6WThwoUl/nyXX345DoejWD2At6YdO3aQmJjIzTffXGwqWkJCAgMGDKhQPS1btmTIkCF8+OGH5OXlAfDtt9+SnJzsHW0COHr0KOPHjyc+Pt5bd0JCAlCxf5vTLV68GIBbbrmlWPvNN998Vl+Xy8Vzzz1Hx44d8fX1xcfHB19fX3bt2lXp9z3z/e+4445i7X379qVDhw4sXLiwWHtMTAx9+/Yt1nbmZ+NcFY6knlnL9ddfT1BQkLeW7t274+vry7333su7777Lnj17znqtvn37curUKW666Sb+97//VWgapYhIVVFwEhGpBrGxsWe1ZWRkMHDgQH7++Wf++te/smTJElavXs3s2bMByM7OLvd1IyMjz2rz8/Or0L6BgYH4+/uftW9OTo73+fHjx4mOjj5r35LaSvLyyy/z+9//nn79+jFr1ix++uknVq9ezciRI0us8cyfx8/PDyg6FsePHwfML/ZnKqmtNHfddRfHjx9nzpw5gDlNLzg4mBtuuAEwzwcaPnw4s2fP5pFHHmHhwoWsWrXKe75VRY7v6Y4fP46Pj89ZP19JNU+cOJEnnniCq6++mq+++oqff/6Z1atX061bt0q/7+nvDyV/DuPi4rzbC53P56oitfj4+NCkSZNi7TabjZiYGG8trVu3ZsGCBURFRXH//ffTunVrWrduzT//+U/vPrfddhvTpk1j//79XHvttURFRdGvXz/mz59/3nWKiJRH5ziJiFSDkq6ps2jRIhITE1myZIl3lAk46wR5K0VGRrJq1aqz2pOTkyu0/wcffMDgwYOZOnVqsfb09PRzrqe0969oTQBjx44lPDycadOmMWjQIL7++mvGjRtHcHAwAL/88gsbN25kxowZ3H777d79du/efc51u1wujh8/XiyUlFTzBx98wLhx43juueeKtaekpNCoUaNzfn8wz7U78zyoxMTEYuc3VbfCY3Hs2LFi4ckwDJKTk72LXgAMHDiQgQMH4na7WbNmDf/617948MEHiY6O9l6P68477+TOO+8kMzOTZcuWMXnyZMaMGcPOnTu9I4QiItVBI04iIjWkMEwVjqoU+ve//21FOSUaNGgQ6enpfPvtt8XaP/nkkwrtb7PZzvr5Nm3adNb1ryqqXbt2xMbG8vHHH2MYhrd9//79rFixosKv4+/vz80338y8efP4+9//Tn5+frFpelX9bzNkyBAAPvzww2LtH3300Vl9Szpm33zzDYcPHy7WduZoXFkKp4l+8MEHxdpXr17Ntm3bGDp0aLmvUVUK3+vMWmbNmkVmZmaJtTgcDvr168cbb7wBwLp1687qExQUxKhRo/jzn/9MXl4eW7ZsqYbqRUSKaMRJRKSGDBgwgPDwcMaPH8/kyZNxOp18+OGHbNy40erSvG6//XZeeeUVbr31Vv7617/Spk0bvv32W77//nuAclexGzNmDM8++yyTJ09m0KBB7Nixg2eeeYaWLVvicrkqXY/dbufZZ5/l7rvv5pprruGee+7h1KlTPPXUU5WaqgfmdL033niDl19+mfbt2xc7R6p9+/a0bt2axx57DMMwiIiI4KuvvjrnKWDDhw/nkksu4ZFHHiEzM5PevXvz448/8v7775/Vd8yYMcyYMYP27dvTtWtX1q5dyz/+8Y+zRopat25NQEAAH374IR06dCA4OJi4uDji4uLOes127dpx77338q9//Qu73c6oUaO8q+rFx8fzpz/96Zx+rtIkJyfz+eefn9XeokULLrvsMkaMGMGjjz5KWloaF110kXdVvR49enDbbbcB5rlxixYt4vLLL6d58+bk5OR4l9ofNmwYAPfccw8BAQFcdNFFxMbGkpyczJQpUwgLCys2ciUiUh0UnEREakhkZCTffPMNDz30ELfeeitBQUFcddVVzJw5k549e1pdHmD+FX/RokU8+OCDPPLII9hsNoYPH86bb77J6NGjy5069uc//5msrCzeeecdXnjhBTp27Mhbb73FF198Uey6UpVx1113AfD3v/+dsWPH0qJFCx5//HGWLl1aqdfs0aMHPXr0YP369cVGmwCcTidfffUVf/zjH/nd736Hj48Pw4YNY8GCBcUW46gou93OnDlzmDhxIi+88AJ5eXlcdNFFzJ07l/bt2xfr+89//hOn08mUKVPIyMigZ8+ezJ49m7/85S/F+gUGBjJt2jSefvpphg8fTn5+PpMnT/Zey+lMU6dOpXXr1rzzzju88cYbhIWFMXLkSKZMmVLiOU3nY+3atVx//fVntd9+++3MmDGDL7/8kqeeeorp06fzt7/9jcaNG3Pbbbfx3HPPeUfSunfvzrx585g8eTLJyckEBwfTuXNn5syZw/DhwwFzKt+MGTP49NNPOXnyJI0bN+biiy/mvffeO+scKhGRqmYzTp/7ICIiUoLnnnuOv/zlLxw4cKDMaweJiIjUVxpxEhGRYl5//XXAnL6Wn5/PokWLeO2117j11lsVmkREpMFScBIRkWICAwN55ZVX2LdvH7m5uTRv3pxHH330rKljIiIiDYmm6omIiIiIiJRDy5GLiIiIiIiUQ8FJRERERESkHApOIiIiIiIi5Whwi0N4PB4SExMJCQnxXileREREREQaHsMwSE9PJy4urtyLvDe44JSYmEh8fLzVZYiIiIiISC1x8ODBci+50eCCU0hICGAenNDQUIurERERERERq6SlpREfH+/NCGVpcMGpcHpeaGiogpOIiIiIiFToFB4tDiEiIiIiIlIOBScREREREZFyKDiJiIiIiIiUo8Gd4yQiIiIiUhbDMHC5XLjdbqtLkSrgdDpxOBzn/ToKTiIiIiIiBfLy8khKSiIrK8vqUqSK2Gw2mjVrRnBw8Hm9joKTiIiIiAjg8XjYu3cvDoeDuLg4fH19K7TamtRehmFw7NgxDh06RNu2bc9r5EnBSUREREQEc7TJ4/EQHx9PYGCg1eVIFWnSpAn79u0jPz//vIKTFocQERERETmN3a6vyPVJVY0a6lMhIiIiIiJSDgUnERERERGRcig4iYiIiIjIWQYPHsyDDz5odRm1hhaHEBERERGpw8o7h+f2229nxowZlX7d2bNn43Q6z7Eq0x133MGpU6f48ssvz+t1agMFJxERERGROiwpKcn7eObMmTz55JPs2LHD2xYQEFCsf35+foUCUURERNUVWQ9oqp6IiIiISCkMwyArz2XJzTCMCtUYExPjvYWFhWGz2bzPc3JyaNSoEZ9++imDBw/G39+fDz74gOPHj3PTTTfRrFkzAgMD6dKlCx9//HGx1z1zql6LFi147rnn+O1vf0tISAjNmzfn7bffPq/ju3TpUvr27Yufnx+xsbE89thjuFwu7/bPP/+cLl26EBAQQGRkJMOGDSMzMxOAJUuW0LdvX4KCgmjUqBEXXXQR+/fvP696yqIRJxERERGRUmTnu+n45PeWvPfWZ0YQ6Fs1X9cfffRRXnrpJaZPn46fnx85OTn06tWLRx99lNDQUL755htuu+02WrVqRb9+/Up9nZdeeolnn32Wxx9/nM8//5zf//73XHLJJbRv377SNR0+fJjRo0dzxx138N5777F9+3buuece/P39eeqpp0hKSuKmm27ihRde4JprriE9PZ3ly5djGAYul4urr76ae+65h48//pi8vDxWrVpVrRcsVnASEREREannHnzwQcaOHVus7eGHH/Y+fuCBB/juu+/47LPPygxOo0eP5r777gPMMPbKK6+wZMmScwpOb775JvHx8bz++uvYbDbat29PYmIijz76KE8++SRJSUm4XC7Gjh1LQkICAF26dAHgxIkTpKamMmbMGFq3bg1Ahw4dKl1DZSg4Wehoeg7r9p+icbAvvVtoDqmIiIhIbRPgdLD1mRGWvXdV6d27d7Hnbreb559/npkzZ3L48GFyc3PJzc0lKCiozNfp2rWr93HhlMCjR4+eU03btm2jf//+xUaJLrroIjIyMjh06BDdunVj6NChdOnShREjRjB8+HCuu+46wsPDiYiI4I477mDEiBFcdtllDBs2jBtuuIHY2NhzqqUidI6ThT5bc4jxH6zlvZXVNxdTRERERM6dzWYj0NfHkltVTjs7MxC99NJLvPLKKzzyyCMsWrSIDRs2MGLECPLy8sp8nTMXlbDZbHg8nnOqyTCMs37GwvO6bDYbDoeD+fPn8+2339KxY0f+9a9/0a5dO/bu3QvA9OnTWblyJQMGDGDmzJlccMEF/PTTT+dUS0UoOFmoY1woAFsSUy2uREREREQakuXLl3PVVVdx66230q1bN1q1asWuXbtqtIaOHTuyYsWKYotgrFixgpCQEJo2bQqYAeqiiy7i6aefZv369fj6+vLFF194+/fo0YNJkyaxYsUKOnfuzEcffVRt9WqqnoU6x4UBsCclk8xcF0F++ucQERERkerXpk0bZs2axYoVKwgPD+fll18mOTm5Ws4TSk1NZcOGDcXaIiIiuO+++3j11Vd54IEHmDBhAjt27GDy5MlMnDgRu93Ozz//zMKFCxk+fDhRUVH8/PPPHDt2jA4dOrB3717efvttrrzySuLi4tixYwc7d+5k3LhxVV5/IX1Tt1CTED+iQvw4mp7L9uQ0eiXoPCcRERERqX5PPPEEe/fuZcSIEQQGBnLvvfdy9dVXk5pa9TOhlixZQo8ePYq1FV6Ud+7cufzf//0f3bp1IyIigrvuuou//OUvAISGhrJs2TJeffVV0tLSSEhI4KWXXmLUqFEcOXKE7du38+6773L8+HFiY2OZMGECv/vd76q8/kI2o6ILxNcTaWlphIWFkZqaSmhoqLXFpB7iv++/y8JEJ6OuuIFx/VtYW4+IiIhIA5aTk8PevXtp2bIl/v7+VpcjVaSsf9fKZAONOFlpw8fcnfIC0Y4LWX7YmtVaRERERESkfFocwkrNLwSgt30nWw5rgQgRERERkdpKwclKTXth2H2ItZ0g4+he8lzntpSjiIiIiIhULwUnK/kGQmw3ALob29l5JN3igkREREREpCQKThazNe8PQB/7Dl3PSURERESkllJwstpp5zltOKjgJCIiIiJSGyk4WS2+HwAX2A6xa99Bi4sREREREZGSKDhZLTgKV3gr7DaDkOPrSM/Jt7oiERERERE5g4JTLeCTMACA3rYdbNR0PRERERGRWkfBqTZobk7X623fyboDJy0uRkREREQaosGDB/Pggw9aXUatpeBUGxSsrNfN9iub9h+xuBgRERERqUuuuOIKhg0bVuK2lStXYrPZWLdu3Xm/z4wZM2jUqNF5v05dpeBUG0S2weUfgb8tn9wD6/F4DKsrEhEREZE64q677mLRokXs37//rG3Tpk2je/fu9OzZ04LK6hdLg9OUKVPo06cPISEhREVFcfXVV7Njx44y91myZAk2m+2s2/bt22uo6mpgs2EvWJa8ff5W9qRkWlyQiIiIiABgGJCXac3NqNgf08eMGUNUVBQzZswo1p6VlcXMmTO56667OH78ODfddBPNmjUjMDCQLl268PHHH1fpoTpw4ABXXXUVwcHBhIaGcsMNN3DkSNFsqo0bNzJkyBBCQkIIDQ2lV69erFmzBoD9+/dzxRVXEB4eTlBQEJ06dWLu3LlVWt/58rHyzZcuXcr9999Pnz59cLlc/PnPf2b48OFs3bqVoKCgMvfdsWMHoaGh3udNmjSp7nKrlT2hP+ycSx/7DtYfOEmbqGCrSxIRERGR/Cx4Ls6a9348EXzL/k4M4OPjw7hx45gxYwZPPvkkNpsNgM8++4y8vDxuueUWsrKy6NWrF48++iihoaF888033HbbbbRq1Yp+/fqdd6mGYXD11VcTFBTE0qVLcblc3Hfffdx4440sWbIEgFtuuYUePXowdepUHA4HGzZswOl0AnD//feTl5fHsmXLCAoKYuvWrQQH167vw5YGp++++67Y8+nTpxMVFcXatWu55JJLytw3Kiqqfs2xLDjPqbd9B//Yf5Lre8dbXJCIiIiI1BW//e1v+cc//sGSJUsYMmQIYE7TGzt2LOHh4YSHh/Pwww97+z/wwAN89913fPbZZ1USnBYsWMCmTZvYu3cv8fHm99j333+fTp06sXr1avr06cOBAwf4v//7P9q3bw9A27ZtvfsfOHCAa6+9li5dugDQqlWr866pqlkanM6UmmouxR0REVFu3x49epCTk0PHjh35y1/+4v2AnCk3N5fc3Fzv87S0tKoptqrFdsNt9yPCk0HKvs1AV6srEhERERFnoDnyY9V7V1D79u0ZMGAA06ZNY8iQIfz6668sX76cefPmAeB2u3n++eeZOXMmhw8f9n5HLm+WV0Vt27aN+Ph4b2gC6NixI40aNWLbtm306dOHiRMncvfdd/P+++8zbNgwrr/+elq3bg3AH/7wB37/+98zb948hg0bxrXXXkvXrrXr+3CtWRzCMAwmTpzIxRdfTOfOnUvtFxsby9tvv82sWbOYPXs27dq1Y+jQoSxbtqzE/lOmTCEsLMx7O/0fs1bx8cXdtBcA0SdW60K4IiIiIrWBzWZOl7PiVjDlrqLuuusuZs2aRVpaGtOnTychIYGhQ4cC8NJLL/HKK6/wyCOPsGjRIjZs2MCIESPIy8urksNkGIZ3imBp7U899RRbtmzh8ssvZ9GiRXTs2JEvvvgCgLvvvps9e/Zw2223sXnzZnr37s2//vWvKqmtqtSa4DRhwgQ2bdpU7klq7dq145577qFnz57079+fN998k8svv5wXX3yxxP6TJk0iNTXVezt48GB1lF8lfNuYo2YD7Ft0IVwRERERqZQbbrgBh8PBRx99xLvvvsudd97pDS3Lly/nqquu4tZbb6Vbt260atWKXbt2Vdl7d+zYkQMHDhT7rr1161ZSU1Pp0KGDt+2CCy7gT3/6E/PmzWPs2LFMnz7duy0+Pp7x48cze/ZsHnroIf7zn/9UWX1VoVYEpwceeIA5c+awePFimjVrVun9L7zwwlL/4f38/AgNDS12q7VaDgKgv30r6/Yft7gYEREREalLgoODufHGG3n88cdJTEzkjjvu8G5r06YN8+fPZ8WKFWzbto3f/e53JCcnV/o93G43GzZsKHbbunUrw4YNo2vXrtxyyy2sW7eOVatWMW7cOAYNGkTv3r3Jzs5mwoQJLFmyhP379/Pjjz+yevVqb6h68MEH+f7779m7dy/r1q1j0aJFxQJXbWDpOU6GYfDAAw/wxRdfsGTJElq2bHlOr7N+/XpiY2OruDoLNO1JviOQcHcGx3evgWHtrK5IREREROqQu+66i3feeYfhw4fTvHlzb/sTTzzB3r17GTFiBIGBgdx7771cffXV3jUGKiojI4MePXoUa0tISGDfvn18+eWXPPDAA1xyySXY7XZGjhzpnW7ncDg4fvw448aN48iRIzRu3JixY8fy9NNPA2Ygu//++zl06BChoaGMHDmSV1555TyPRtWyGUYFF4ivBvfddx8fffQR//vf/2jXrigkhIWFERAQAJhT7Q4fPsx7770HwKuvvkqLFi3o1KkTeXl5fPDBBzz//PPMmjWLsWPHlvueaWlphIWFkZqaWitHn9LeuYbQg4t4mVt58MnXsdsrN7dVRERERM5NTk4Oe/fupWXLlvj7+1tdjlSRsv5dK5MNLB1xmjp1KgCDBw8u1j59+nTv0GJSUhIHDhzwbsvLy+Phhx/m8OHDBAQE0KlTJ7755htGjx5dU2VXq6D2Q+HgInq5N7H7WAYXRIdYXZKIiIiISINn+VS98px5BeRHHnmERx55pJoqsp6j9WCYD33sO/hid5KCk4iIiIhILVArFoeQ00R1JNMZSaAtl+PbllpdjYiIiIiIoOBU+9jtZDUfDED44WUVGpUTEREREZHqpeBUC4V1HQVAP/da9qRkWlyNiIiIiIgoONVCvm2H4sHOBfbDbN6yxepyREREREQaPAWn2igwgqSQzgDkbvvO4mJERERERETBqZZytxoKQPTR5TrPSURERETEYgpOtVRM7ysA6O3ZzLZDxyyuRkRERESkYVNwqqV8m/Ygzd6IYFsOu9YssLocEREREZEGTcGptrLbORYz0Hy4W8FJREREREpms9nKvN1xxx3n/NotWrTg1VdfrbJ+dZmP1QVI6cK6jIbEr2if/hPpOfmE+DutLklEREREapmkpCTv45kzZ/Lkk0+yY8cOb1tAQIAVZdU7GnGqxRp3G4kbO23th1m7abPV5YiIiIg0XJmZpd9ycireNzu7Yn0rISYmxnsLCwvDZrMVa1u2bBm9evXC39+fVq1a8fTTT+Nyubz7P/XUUzRv3hw/Pz/i4uL4wx/+AMDgwYPZv38/f/rTn7yjV+dq6tSptG7dGl9fX9q1a8f7779fbHtpNQC8+eabtG3bFn9/f6Kjo7nuuuvOuY7zoRGn2iwwgsNBnWieuZmTG7+Bvj2trkhERESkYQoOLn3b6NHwzTdFz6OiICur5L6DBsGSJUXPW7SAlJSz+1XRqsrff/89t956K6+99hoDBw7k119/5d577wVg8uTJfP7557zyyit88skndOrUieTkZDZu3AjA7Nmz6datG/feey/33HPPOdfwxRdf8Mc//pFXX32VYcOG8fXXX3PnnXfSrFkzhgwZUmYNa9as4Q9/+APvv/8+AwYM4MSJEyxfvvz8D8w5UHCq5VythsLmzUQlLwWesLocEREREalD/va3v/HYY49x++23A9CqVSueffZZHnnkESZPnsyBAweIiYlh2LBhOJ1OmjdvTt++fQGIiIjA4XAQEhJCTEzMOdfw4osvcscdd3DfffcBMHHiRH766SdefPFFhgwZUmYNBw4cICgoiDFjxhASEkJCQgI9evQ4z6NybjRVr5aL6XMNAD1dGzl0pIS/RoiIiIhI9cvIKP02a1bxvkePlt7322+L9923r+R+VWTt2rU888wzBAcHe2/33HMPSUlJZGVlcf3115OdnU2rVq245557+OKLL4pN46sK27Zt46KLLirWdtFFF7Ft2zaAMmu47LLLSEhIoFWrVtx22218+OGHZJU2mlfNFJxqucD4bhyzRxFgy2PPqrlWlyMiIiLSMAUFlX7z96943zMXaiitXxXxeDw8/fTTbNiwwXvbvHkzu3btwt/fn/j4eHbs2MEbb7xBQEAA9913H5dccgn5+flVVgNw1vlRhmF428qqISQkhHXr1vHxxx8TGxvLk08+Sbdu3Th16lSV1lcRCk61nc3GoejBADh2fWdtLSIiIiJSp/Ts2ZMdO3bQpk2bs252uxkFAgICuPLKK3nttddYsmQJK1euZPNmc2EyX19f3G73edXQoUMHfvjhh2JtK1asoEOHDt7nZdXg4+PDsGHDeOGFF9i0aRP79u1j0aJF51XTudA5TnVAYJcxkPQp7dJ+xON2Y3c4rC5JREREROqAJ598kjFjxhAfH8/111+P3W5n06ZNbN68mb/+9a/MmDEDt9tNv379CAwM5P333ycgIICEhATAvD7TsmXL+M1vfoOfnx+NGzcu9b0OHz7Mhg0birU1b96c//u//+OGG26gZ8+eDB06lK+++orZs2ezYIF5rdKyavj666/Zs2cPl1xyCeHh4cydOxePx0O7du2q7ZiVRiNOdUCr3iPIMAJozCn2bf6h/B1ERERERIARI0bw9ddfM3/+fPr06cOFF17Iyy+/7A1GjRo14j//+Q8XXXQRXbt2ZeHChXz11VdERkYC8Mwzz7Bv3z5at25NkyZNynyvF198kR49ehS7zZkzh6uvvpp//vOf/OMf/6BTp078+9//Zvr06QwePLjcGho1asTs2bO59NJL6dChA2+99RYff/wxnTp1qtbjVhKbYVTRWod1RFpaGmFhYaSmphIaGmp1ORW2+oUr6JO1jLXN76LXb1+2uhwRERGReicnJ4e9e/fSsmVL/M88b0nqrLL+XSuTDTTiVEfktBoBQOPEhRZXIiIiIiLS8Cg41RGtBlyDy7CT4NpHWuJuq8sREREREWlQFJzqiKZxTdni0xGAAz/NKqe3iIiIiIhUJQWnOuRY3KUA+O7+3uJKREREREQaFgWnOiSy51UAtMzagDvrlLXFiIiIiNRTDWzttHqvqv49FZzqkM5de/IrTXHi5sCqOVaXIyIiIlKvOJ1OALKysiyuRKpSXl4eAI7zvBaqLoBbhzgddn4Nv4TWJz8m55evYfA4q0sSERERqTccDgeNGjXi6NGjAAQGBmKz2SyuSs6Hx+Ph2LFjBAYG4uNzftFHwamOcXYcDT9+TPzxH8CdDw6n1SWJiIiI1BsxMTEA3vAkdZ/dbqd58+bnHYIVnOqYLv2GcfyHECJJ5+S2pYR3HmZ1SSIiIiL1hs1mIzY2lqioKPLz860uR6qAr68vdvv5n6Gk4FTHNA4NZKF/P4bmLuDo2i8UnERERESqgcPhOO9zYqR+0eIQdVBWy+EARBxcCFr1RURERESk2ik41UEt+40h13DSxJVEXvJWq8sREREREan3FJzqoI4Jcay2dwEg8ecvLK5GRERERKT+U3Cqg+x2G0dihgDg2PWtxdWIiIiIiNR/Ck51VHiPKwFomrkFMrRcpoiIiIhIdVJwqqP6dO3EZk9L7BikrJtjdTkiIiIiIvWaglMdFeLvZHvYxQBkbv7K4mpEREREROo3Bac6zNHhcgBiUlZCfrbF1YiIiIiI1F8KTnVY114Xc9iIxM/IJWfXYqvLERERERGptxSc6rDWUcH85NMXgONrvrS2GBERERGRekzBqQ6z2WykJ1wGQMiBBeDxWFyRiIiIiEj9pOBUx8X3GE66EUCo6zhG4nqryxERERERqZcUnOq4/u1iWW50A+Dkhv9ZXI2IiIiISP2k4FTHBfr6sD/yEgCM7d9aXI2IiIiISP2k4FQPBHUehduwEZmxE04dsLocEREREZF6R8GpHujfuS1rjHYA5G3VqJOIiIiISFVTcKoH2kQFs8bXXJY8fdMci6sREREREal/FJzqAZvNRm7rkQCEHfkJctIsrkhEREREpH5RcKonOnftxR5PDD6GC+PXRVaXIyIiIiJSryg41RMD2jRmkdELgIxNX1lcjYiIiIhI/aLgVE8E+/mQGD0YAOeeBeBxW1uQiIiIiEg9ouBUj8R2HsQpIwj//FNwcJXV5YiIiIiI1BsKTvXIoA5xLPZ0ByB/2zfWFiMiIiIiUo8oONUjbaOCWet3IQB5WxWcRERERESqioJTPWKz2fBpdxn5hoOgtD1w/FerSxIRERERqRcUnOqZ/h1b8pOng/lkx7fWFiMiIiIiUk8oONUzF7VpzBLMZcmzf/na4mpEREREROoHBad6JtjPh5S4SwHwS1oFWScsrkhEREREpO5TcKqHunTuynZPPHbDDbsXWF2OiIiIiEidp+BUDw1pH8UCT08A8rfNtbgaEREREZG6T8GpHmrVOIgtwQPMJ7vmgyvP2oJEREREROo4Bad6yGazEdPhIo4ZoThdGXBghdUliYiIiIjUaQpO9dSQDjEscpvT9Yztmq4nIiIiInI+FJzqqX6tIlhu7w0UnOdkGBZXJCIiIiJSdyk41VN+Pg6MVoPJNZz4ph+Eo9usLklEREREpM5ScKrHLu6YwA+ezuaTnd9aW4yIiIiISB2m4FSPDWkXxcLCZcm3fmNxNSIiIiIidZeCUz0WE+bPoSYDAfBJWgcZRy2uSERERESkblJwque6dezIJk9LbBiw83uryxERERERqZMUnOq5Ie2jWODuBYBnh85zEhERERE5FwpO9Vy3Zo1Y7dcXAGP3IsjPsbgiEREREZG6x9LgNGXKFPr06UNISAhRUVFcffXV7Nixo9z9li5dSq9evfD396dVq1a89dZbNVBt3eSw24i9oC+JRgQOdzbsXWZ1SSIiIiIidY6lwWnp0qXcf//9/PTTT8yfPx+Xy8Xw4cPJzMwsdZ+9e/cyevRoBg4cyPr163n88cf5wx/+wKxZs2qw8rplSIdoFrrN1fXYMdfaYkRERERE6iCbYRiG1UUUOnbsGFFRUSxdupRLLrmkxD6PPvooc+bMYdu2ogu6jh8/no0bN7Jy5cpy3yMtLY2wsDBSU1MJDQ2tstprs9TsfB786z+Y7vw7rqAYfB7eDjab1WWJiIiIiFiqMtmgVp3jlJqaCkBERESpfVauXMnw4cOLtY0YMYI1a9aQn59/Vv/c3FzS0tKK3RqasAAnefEXkWn44ZOZDEkbrC5JRERERKROqTXByTAMJk6cyMUXX0znzp1L7ZecnEx0dHSxtujoaFwuFykpKWf1nzJlCmFhYd5bfHx8lddeFwzs0Izlnq7mkx3fWVuMiIiIiEgdU2uC04QJE9i0aRMff/xxuX1tZ0wzK5xteGY7wKRJk0hNTfXeDh48WDUF1zGXto9igcc8z8mzXec5iYiIiIhUho/VBQA88MADzJkzh2XLltGsWbMy+8bExJCcnFys7ejRo/j4+BAZGXlWfz8/P/z8/Kq03rqobVQw24IvxJPzNvYjmyD1MIQ1tbosEREREZE6wdIRJ8MwmDBhArNnz2bRokW0bNmy3H369+/P/Pnzi7XNmzeP3r1743Q6q6vUOs9ms9GzwwWsM9qaDTt1MVwRERERkYqyNDjdf//9fPDBB3z00UeEhISQnJxMcnIy2dnZ3j6TJk1i3Lhx3ufjx49n//79TJw4kW3btjFt2jTeeecdHn74YSt+hDrl0vZR3mXJDZ3nJCIiIiJSYZYGp6lTp5KamsrgwYOJjY313mbOnOntk5SUxIEDB7zPW7Zsydy5c1myZAndu3fn2Wef5bXXXuPaa6+14keoU/q3jmSZvTcAxp6lkJthcUUiIiIiInWDpec4VeQSUjNmzDirbdCgQaxbt64aKqrf/J0OYlp1Y//eKBI4CnsWQ4crrC5LRERERKTWqzWr6knNGNIhmgWeXuaTHTrPSURERESkIhScGpghpy9LvvN78LgtrkhEREREpPZTcGpgmjYKIK1Jb9KMQOxZKXBojdUliYiIiIjUegpODdAlHeJY4ulmPtGy5CIiIiIi5VJwaoAubR/FArd5npOxXcFJRERERKQ8Ck4NUI/4Rqzz7YXLsGNL2Q4n9lhdkoiIiIhIrabg1AD5OOz0bNeSVZ72ZoMuhisiIiIiUiYFpwbq0vZRLCxYXY8dc60tRkRERESkllNwaqAGXdCEhQXXczL2r4CsExZXJCIiIiJSeyk4NVDhQb5ENm/PNk88NsMNu+ZZXZKIiIiISK2l4NSAXdo+inme3uaT7V9bW4yIiIiISC2m4NSADWkXxTy3GZyM3QshP9viikREREREaicFpwasQ2wIJ0Lac8hojC0/C35dbHVJIiIiIiK1koJTA2az2RjSIZr5BRfDZfs31hYkIiIiIlJLKTg1cJe2KzrPydgxF9wuiysSEREREal9FJwauAFtItlg78hJIxhb9gk4+JPVJYmIiIiI1DoKTg1coK8PfVuddjFcTdcTERERETmLgpOYy5IXnue07WswDGsLEhERERGpZRSchEvbR7HM05VswxdSD0DyZqtLEhERERGpVRSchPiIQJpFRbLM09Vs0HQ9EREREZFiFJwEKJyuZ66up+AkIiIiIlKcgpMAMKRdFAs9PXBhhyOb4eQ+q0sSEREREak1FJwEgN4twnH7h7PK3d5s0KiTiIiIiIiXgpMA4HTYueSCJt6L4So4iYiIiIgUUXASr6Hto5hfuCz5gZWQmWJtQSIiIiIitYSCk3gNaRdFkq0Jmz0twPDAjm+tLklEREREpFZQcBKv8CBfeiWEa3U9EREREZEzKDhJMcM6RBed5/TrIsjNsLYgEREREZFaQMFJihnaIZodRjz7jWhw58KvC60uSURERETEcgpOUkzrJkG0iAzie03XExERERHxUnCSYmw2G0M7RDOvcHW9nd+BK8/aokRERERELKbgJGcZ2iGKdcYFpNAIclJh3zKrSxIRERERsZSCk5ylT4sIgv19+d5VMOq0dY61BYmIiIiIWEzBSc7idNgZ3C6Kbz19zYbt34DHbW1RIiIiIiIWUnCSEg3tEMVPng6kEQxZKbB/hdUliYiIiIhYRsFJSjT4gigMu5PvXT3Nhm1fWVuQiIiIiIiFFJykRGGBTvq0CC+arrftK/B4rC1KRERERMQiCk5SqmEdovnB04VsWyCkJ8LhtVaXJCIiIiJiCQUnKdWwDtHk4WS+q7vZsO1/ltYjIiIiImIVBScpVYvGQbRuEsRcd8F0va1zwDCsLUpERERExAIKTlKmYR2iWerpSp7ND07th+RNVpckIiIiIlLjFJykTEM7RJONP8uM7maDLoYrIiIiIg2QgpOUqWfzRoQHOpmT19ts2KbgJCIiIiINj4KTlMnHYWdIuygWeXrgsjkhZScc3W51WSIiIiIiNUrBSco1tEM0GQSy2t7NbNCok4iIiIg0MApOUq5LLmiM02Fjdk5Ps0HnOYmIiIhIA6PgJOUK8XfSr2Uk89298NgccGQznNhjdVkiIiIiIjVGwUkqZFiHKE4Rwi/OrmbDli8trUdEREREpCYpOEmFDO0QDcAnWb3Mhi1fWFiNiIiIiEjNUnCSComPCKRddAjfunqb0/WSN8HxX60uS0RERESkRig4SYUN7RDFSULZHlCwSMSW2dYWJCIiIiJSQxScpMIKp+t9nFVwMdxfNF1PRERERBoGBSepsO7xjYgM8uV/OT3w2J1wdAsc22F1WSIiIiIi1U7BSSrMYbdxafso0ghmd0gfs1GLRIiIiIhIA6DgJJVSOF3vs+yC4PTLbDAMCysSEREREal+Ck5SKQPbNsbXYeeTtC547L6QsgOObrW6LBERERGRaqXgJJUS5OdD/9aRpBPI/vABZqOm64mIiIhIPafgJJU2rEMUAF/m9zMbNF1PREREROo5BSeptMLznKYduwDDxx9O/GpeEFdEREREpJ5ScJJKi2sUQMfYUNKNAA43GWg2arqeiIiIiNRjCk5yTgqn631r9DcbNF1PREREROoxBSc5J4XT9f6d2BrDGQin9kPiOourEhERERGpHgpOck66NA2jSYgfKXlOjsUOMRs1XU9ERERE6ikFJzkndrvNO11voeMis3HLl5quJyIiIiL1koKTnLOh7c3pem8ntsLwDYbUg3BotcVViYiIiIhUPQUnOWcXtWmMn4+dvake0hIuMxs1XU9ERERE6iEFJzlnAb4OLm7TGIDlvoXLkn8JHo91RYmIiIiIVAMFJzkvhavrzTjSGvzCID0RDv5kcVUiIiIiIlVLwUnOy9CCBSLWHs4kp81Is1HT9URERESknrE0OC1btowrrriCuLg4bDYbX375ZZn9lyxZgs1mO+u2ffv2milYzhId6k/XZmEYBqwKHGw2bv0feNyW1iUiIiIiUpUsDU6ZmZl069aN119/vVL77dixg6SkJO+tbdu21VShVETh6nofp7QE/0aQcQT2/2htUSIiIiIiVcjHyjcfNWoUo0aNqvR+UVFRNGrUqOoLknMytEMUryzYyZLdqbh6jsFn4wfmdL2Wl1hdmoiIiIhIlaiT5zj16NGD2NhYhg4dyuLFi8vsm5ubS1paWrGbVK1OcaHEhvmTne/ml/ChZuPWOeB2WVuYiIiIiEgVqVPBKTY2lrfffptZs2Yxe/Zs2rVrx9ChQ1m2bFmp+0yZMoWwsDDvLT4+vgYrbhhsNhuXtjcXiZh1oiUERkJWCuxdanFlIiIiIiJVw2YYhmF1EWB++f7iiy+4+uqrK7XfFVdcgc1mY86cOSVuz83NJTc31/s8LS2N+Ph4UlNTCQ0NPZ+S5TSLdxzlzumriQ3zZ0WXb7CteQe6/gbG/tvq0kRERERESpSWlkZYWFiFskGdGnEqyYUXXsiuXbtK3e7n50doaGixm1S9/q0iCfR1kJSaw564MWbjtq8gL9PawkREREREqkCdD07r168nNjbW6jIaPH+ng4vbNAbgq+NNIaIV5GfCtq8trkxERERE5PxZGpwyMjLYsGEDGzZsAGDv3r1s2LCBAwcOADBp0iTGjRvn7f/qq6/y5ZdfsmvXLrZs2cKkSZOYNWsWEyZMsKJ8OcOwDuay5Au3H4OuN5qNmz6xsCIRERERkaph6XLka9asYciQId7nEydOBOD2229nxowZJCUleUMUQF5eHg8//DCHDx8mICCATp068c033zB69Ogar13ONqR9FDYbbD6cSspVV9N4yRTYswTSkyEkxuryRERERETOWa1ZHKKmVOYEMKm8a978kfUHTvHcNV24+Ze74eDPMPyvMOABq0sTERERESmmQS0OIbWLd7retiNF0/U2zrSwIhERERGR86fgJFVqaAfzek4/7E4h+4KrwOELRzbDkS0WVyYiIiIicu4UnKRKtYsOoWmjAHJdHpYfckHb4eaGjVokQkRERETqLgUnqVI2m43LOprT9eZtPQLdfmNu2PwZeNwWViYiIiIicu4UnKTKjexsrqC3YNsRXK2GgX8jSE+CvcusLUxERERE5BwpOEmV69MigoggX05l5bPqYCZ0Hmtu2KRFIkRERESkblJwkirnsNsYVrBIxPdbkqFrwXS9rXMgL9PCykREREREzo2Ck1SLEZ3M6XrfbzmCp2kfCG8J+Zmw7WuLKxMRERERqTwFJ6kWF7VpTJCvg+S0HDYlphVd02mTVtcTERERkbpHwUmqhb/TweD2p0/Xu8HcsGcJpCdbV5iIiIiIyDk4p+B08OBBDh065H2+atUqHnzwQd5+++0qK0zqvqLpeskQ2Rqa9QXDYy5NLiIiIiJSh5xTcLr55ptZvHgxAMnJyVx22WWsWrWKxx9/nGeeeaZKC5S6a0i7Jvg67Ow5lsnuo+lF13TaqNX1RERERKRuOafg9Msvv9C3b18APv30Uzp37syKFSv46KOPmDFjRlXWJ3VYiL+TAW0iAfjul2TodA04fOHIZjiyxeLqREREREQq7pyCU35+Pn5+fgAsWLCAK6+8EoD27duTlJRUddVJnTfytNX1CIyAtsPNDRs/trAqEREREZHKOafg1KlTJ9566y2WL1/O/PnzGTlyJACJiYlERkZWaYFStw3rGI3dBpsPp3L4VDZ0v9ncsHEmuF3WFiciIiIiUkHnFJz+/ve/8+9//5vBgwdz00030a1bNwDmzJnjncInAtA42I/eCREAfP9LsjniFNgYMo/C7gUWVyciIiIiUjHnFJwGDx5MSkoKKSkpTJs2zdt+77338tZbb1VZcVI/DO8UDRSsrudwFl3TacMHFlYlIiIiIlJx5xScsrOzyc3NJTw8HID9+/fz6quvsmPHDqKioqq0QKn7CpclX73vBMczcoum6+34DjKPW1iZiIiIiEjFnFNwuuqqq3jvvfcAOHXqFP369eOll17i6quvZurUqVVaoNR98RGBdIoLxWPAwm1HIaYzxHYDT76u6SQiIiIidcI5Bad169YxcOBAAD7//HOio6PZv38/7733Hq+99lqVFij1Q+Go07e/FKy62P1W837DhxZVJCIiIiJScecUnLKysggJCQFg3rx5jB07FrvdzoUXXsj+/furtECpH0Z1NoPTD7tTSM3Ohy7Xmdd0St4EyZstrk5EREREpGznFJzatGnDl19+ycGDB/n+++8ZPty8Ns/Ro0cJDQ2t0gKlfmgbHULbqGDy3QYLtxVc06ndKHPjho+sLU5EREREpBznFJyefPJJHn74YVq0aEHfvn3p378/YI4+9ejRo0oLlPpjVJdYAOZuPmO63qaZ4MqzqCoRERERkfKdU3C67rrrOHDgAGvWrOH777/3tg8dOpRXXnmlyoqT+mV0F3O63rKdKaTn5EPrSyE4BrKOw67vy9lbRERERMQ65xScAGJiYujRoweJiYkcPnwYgL59+9K+ffsqK07ql3bRIbRqEkSe28Oi7UfB4QPdCq/ppOl6IiIiIlJ7nVNw8ng8PPPMM4SFhZGQkEDz5s1p1KgRzz77LB6Pp6prlHrCZrMxurM5Xe+bTYXT9W4x73d+DxlHLapMRERERKRs5xSc/vznP/P666/z/PPPs379etatW8dzzz3Hv/71L5544omqrlHqkdEF5zkt2XmMjFwXNGkHTXuD4YZNn1pcnYiIiIhIyc4pOL377rv897//5fe//z1du3alW7du3HffffznP/9hxowZVVyi1CcdYkNoERlInqtguh5Aj4JRpw0fgmFYV5yIiIiISCnOKTidOHGixHOZ2rdvz4kTJ867KKm/bDabd9Tp28LV9TqNBR9/OLoVkjZYV5yIiIiISCnOKTh169aN119//az2119/na5du553UVK/FQanxTuOkpXngoBG0H6MuXH9h9YVJiIiIiJSCp9z2emFF17g8ssvZ8GCBfTv3x+bzcaKFSs4ePAgc+fOreoapZ7pFBdKfEQAB09ks3j7MS7vGgvdb4ZfPofNn8Hwv4LT3+oyRURERES8zmnEadCgQezcuZNrrrmGU6dOceLECcaOHcuWLVuYPn16Vdco9czp0/Xm/lIwXa/VYAhtCjmnYOe3ltUmIiIiIlISm2FU3dn4GzdupGfPnrjd7qp6ySqXlpZGWFgYqamphIaGWl1Og7Xx4CmueuNHApwO1j1xGQG+Dlj4LCx/EdoMg1tnWV2iiIiIiNRzlckG53wBXJHz0bVZGE0bBZCd72bpzjNW19u9EFIPWVeciIiIiMgZFJzEEuZ0vRgAvtmcbDZGtIIWAwEDNnxkXXEiIiIiImdQcBLLFJ7ntGjbEXLyC6Z39rjNvF//Png8FlUmIiIiIlJcpVbVGzt2bJnbT506dT61SAPTPb4RcWH+JKbmsHTnMUZ0ioGOV8Lc/4NTB2DfMnPRCBERERERi1VqxCksLKzMW0JCAuPGjauuWqWesdlsjOx8xsVwnQHQ5Trz8br3LapMRERERKS4So04aalxqWqXd41h2o97WbDtKDn5bvydDuh5G6x5B7Z9BdknISDc6jJFREREpIHTOU5iqR7x4cSE+pOR6+KHXSlmY2x3iO4C7lzY9Jml9YmIiIiIgIKTWMxutzGys7m63tzC6Xo2mznqBLD+PYsqExEREREpouAklitcXW/+1tNW1+tyPTj8IHkzJG6wrjgRERERERScpBbonRBObJg/6bkuluw4ZjYGRkCHMebj9VokQkRERESspeAklrPbbYzpao46fbUxsWhD4TWdNn0G+dkWVCYiIiIiYlJwklrhim5xACzcfoSMXJfZ2HIQNGoOuamwdY6F1YmIiIhIQ6fgJLVCl6ZhtIgMJCffw4KtR8xGux2632o+1nQ9EREREbGQgpPUCjabjSsLRp3mnD5dr/vNgA32LYcTe6wpTkREREQaPAUnqTUKp+st23mMU1l5ZmOjeGh9qfl4/QcWVSYiIiIiDZ2Ck9QabaNDaB8Tgstj8O0vyUUbCq/ptOEjcLusKU5EREREGjQFJ6lVruxeMF1vw2nT9dqNhoAISE+CXxdaVJmIiIiINGQKTlKrXNHVDE4/7T3O0bQcs9HHD7r9xny87j2LKhMRERGRhkzBSWqV+IhAejRvhGHA15uSijb0HGfe7/gW0pJK3llEREREpJooOEmtU+LqelEdIP5CMNxaJEJEREREapyCk9Q6l3eJxW6DDQdPcfBEVtGG3r8179fOAI/bktpEREREpGFScJJaJyrUnwtbRQJnjDp1vAoCwiHtEOxeYFF1IiIiItIQKThJrVQ4Xe+r04OT0x+632I+XjPdgqpEREREpKFScJJaaWTnGJwOG9uT09l1JL1oQ687zPtd30PqIUtqExEREZGGR8FJaqVGgb5c0rYJcMZ0vcZtocVAMDxamlxEREREaoyCk9RahRfD/WpjIoZhFG3ofad5v+49cLssqExEREREGhoFJ6m1hnWIxt9pZ9/xLDYfTi3a0P4KCGwM6Umw8zvrChQRERGRBkPBSWqtID8fhnaIBmDOhtOm6/n4Qo9bzcdrtUiEiIiIiFQ/BSep1QpX1/t6UxIez2nT9Xrdbt7vXggn99V8YSIiIiLSoCg4Sa026IImhPj5kJyWw+p9J4o2RLSCVkMAA9a+a1l9IiIiItIwKDhJrebvdDCicwxwxup6AL1/a96vfx9ceTVcmYiIiIg0JApOUusVTtf79pdk8t2eog3tRkFwDGQeg21zLKpORERERBoCBSep9Qa0jiQyyJcTmXn8uDulaIPDWXRB3NX/taQ2EREREWkYFJyk1vNx2BndJRYoYbperzvA7gMHVkLy5povTkREREQaBAUnqRMKL4Y7b8sRcvLdRRtCY6HDlebjVf+xoDIRERERaQgUnKRO6NU8nNgwfzJyXSzZcbT4xr73mPebPoXskzVfnIiIiIjUe5YGp2XLlnHFFVcQFxeHzWbjyy+/LHefpUuX0qtXL/z9/WnVqhVvvfVW9RcqlrPbbVxRsEjEWdP1mveH6M7gyob1H1pQnYiIiIjUd5YGp8zMTLp168brr79eof579+5l9OjRDBw4kPXr1/P444/zhz/8gVmzZlVzpVIbFK6ut3DbUTJyXUUbbDboc7f5ePV/weMpYW8RERERkXPnY+Wbjxo1ilGjRlW4/1tvvUXz5s159dVXAejQoQNr1qzhxRdf5Nprr62mKqW26BQXSsvGQexNyWT+1mSu6dGsaGPXG2D+ZDi5F35dCG0vs65QEREREal36tQ5TitXrmT48OHF2kaMGMGaNWvIz88vcZ/c3FzS0tKK3aRustlOm6634Yzper5B0OMW87EWiRARERGRKlanglNycjLR0dHF2qKjo3G5XKSkpJS4z5QpUwgLC/Pe4uPja6JUqSZXdjOXJV++K4WTmXnFNxZO19s1D07sqeHKRERERKQ+q1PBCcxRh9MZhlFie6FJkyaRmprqvR08eLDaa5Tq0yYqhA6xobg8Bt/+klx8Y2RraDMMMGD1O5bUJyIiIiL1U50KTjExMSQnF/+yfPToUXx8fIiMjCxxHz8/P0JDQ4vdpG670ru63uGzN/YpWJp8/QeQl1WDVYmIiIhIfVanglP//v2ZP39+sbZ58+bRu3dvnE6nRVVJTRvT1Zyu9/PeExxJyym+se1l0CgBck7B5s9qvjgRERERqZcsDU4ZGRls2LCBDRs2AOZy4xs2bODAgQOAOc1u3Lhx3v7jx49n//79TJw4kW3btjFt2jTeeecdHn74YSvKF4vERwTSs3kjDKOERSLsjqIL4v40FQqmcoqIiIiInA9Lg9OaNWvo0aMHPXr0AGDixIn06NGDJ598EoCkpCRviAJo2bIlc+fOZcmSJXTv3p1nn32W1157TUuRN0DX9DSXIp+17tDZG3uOA98QOLYNdi+s4cpEREREpD6yGUbD+pN8WloaYWFhpKam6nynOuxUVh59/7aQPLeHuX8YSMe4M/4tv3scfnoDWg2Gcf+zpEYRERERqd0qkw3q1DlOIoUaBfoytEMUUMqoU7/fgc0Oe5ZA8uaaLU5ERERE6h0FJ6mzri2Yrve/DYdxuT3FN4YnQMerzMcr36jhykRERESkvlFwkjprULsmRAb5kpKRx7Jdx87u0P8B837z55CWVLPFiYiIiEi9ouAkdZbTYefK7uY1nWatK+GaTs16QfP+4MmHVW/XcHUiIiIiUp8oOEmdVjhdb/7WI6Rm5Z/dof8E837NNMjNqMHKRERERKQ+UXCSOq1TXCjtokPIc3n4ZnMJ0/HajYKIVuYFcde/X+P1iYiIiEj9oOAkdZrNZmNsz6ZAKavr2R0woOBcp5VvgLuEUSkRERERkXIoOEmdd3WPpthtsHb/SfalZJ7dodvNENQEUg/Cli9qvkARERERqfMUnKTOiw715+K2TQCYvb6ERSKc/tBvvPn4x39Cw7rms4iIiIhUAQUnqReuLZiuN3vdITyeEoJRn7vAGQRHfoFfF9ZwdSIiIiJS1yk4Sb0wvGMMwX4+HDqZzep9J87uEBAOve4wH//wak2WJiIiIiL1gIKT1AsBvg4u7xILwOdrS1gkAuDC34PdB/Yth8Nra7A6EREREanrFJyk3ri2l3lNp282J5GZ6zq7Q6N46Hyd+VijTiIiIiJSCQpOUm/0aRFOq8ZBZOW5+WZTCdd0Arjoj+b9tq/g2I6aK05ERERE6jQFJ6k3bDYb1/eOB2DmmoMld4ruCO0uBwz44ZWaK05ERERE6jQFJ6lXru3ZFIfdxtr9J9l9NL3kTpc8ZN5v+hRO7K254kRERESkzlJwknolKtSfIe3Mazp9tqaURSKa9oLWl4LhNq/rJCIiIiJSDgUnqXduKJiuN2vdIfLdnpI7DXzYvN/wIaQl1lBlIiIiIlJXKThJvTOkfRSNg/1Iychj0fajJXdqcRE07w/uPFjxes0WKCIiIiJ1joKT1DtOh51rezYF4LPSFomAolGntdMhM6UGKhMRERGRukrBSeqlwtX1Fu84xpG0nJI7tRkKsd0hPwtWatRJREREREqn4CT1UpuoYHonhOP2GHy6upRRJ5sNBj9mPv75bcg8XnMFioiIiEidouAk9datFyYA8NGqA7hKWyTigpEQ2w3yM2Hlv2qwOhERERGpSxScpN4a1SWGiCBfklJzWFjaIhE2Gww6bdQpPbnmChQRERGROkPBSeotPx+Hd2nyD37aX3rHdqOgaW9z1GnRX2uoOhERERGpSxScpF67pV9zbDZYviuFvSmZJXey2WDEc+bj9R9A8uaaK1BERERE6gQFJ6nX4iMCGdIuCoAPyxp1at4POl0DGPD942AYNVOgiIiIiNQJCk5S7916YXMAPlt7iJx8d+kdhz0NDj/Yuwx2fldD1YmIiIhIXaDgJPXeoAuiaBYeQGp2Pl9tTCy9Y3gCXPh78/G8v4A7v2YKFBEREZFaT8FJ6j2H3cYt/cylyctcJAJg4EMQ2BiO74Y102qgOhERERGpCxScpEG4oXczfB12Nh5KZdOhU6V39A+FS/9sPl4yBbJP1kh9IiIiIlK7KThJgxAZ7MfoLjFABUadeoyDJh3M0LT0HzVQnYiIiIjUdgpO0mDc1t+crve/DYmkZpVx/pLDB0b8zXy86m04/msNVCciIiIitZmCkzQYPZuH0z4mhFyXh8/WHiy7c5uh0OYy8OTD93+umQJFREREpNZScJIGw2azeUed3l25D7ennGs1jXgO7D6w81vYvaAGKhQRERGR2krBSRqUsT2aER7o5OCJbL7fklx25yYXQN/fmY+/e1zLk4uIiIg0YApO0qAE+Dq47UJz1OntZXswjHJGnQY9Yi5PnrIDfny1+gsUERERkVpJwUkanNv6t8DXx86Gg6dYu7+c5cYDGsHI583HS1+AYzuqvT4RERERqX0UnKTBaRLixzXdmwLwn+V7yt+hy3XQdgS48+B/E8DjruYKRURERKS2UXCSBunugS0BmLf1CPtSMsvubLPBmJfBNwQOrYLV/62BCkVERESkNlFwkgapbXQIg9s1wTBg2o97y98hrBlc9pT5eMHTcOpAtdYnIiIiIrWLgpM0WPcMbAXAZ2sOcTIzr/wdev0Wmg+A/Ez43/3g8VRzhSIiIiJSWyg4SYM1oHUkHWNDyc53M2PFvvJ3sNvhyn+BMxD2LoMfXq72GkVERESkdlBwkgbLZrNx35DWAMxYsY+MXFf5OzVuA6NfNB8vfg4O/FSNFYqIiIhIbaHgJA3aqM6xtGocRGp2Ph/9vL9iO3W/GbrcAIYbZt0NWSeqt0gRERERsZyCkzRoDruN8YPNUaf/LN9LTn4FlhovXGUvohWkHoQ5D0B5F9IVERERkTpNwUkavGt6NKVpowCOpefy2dpDFdvJLwSumwZ2J2z/WkuUi4iIiNRzCk7S4Dkddu69xFxh760lv5LvruBqeXE94LJnzMff/xmSN1dThSIiIiJiNQUnEeDGPvE0Dvbl8Kls5mxIrPiOF/4eLhgJ7lz47E7ITa++IkVERETEMgpOIoC/08FdF5ujTm8s3o2roqNONhtc9SaExMHxXTrfSURERKSeUnASKXBb/wTCA53sScnkf5UZdQqKhOtngN0HtnwBP71ZbTWKiIiIiDUUnEQKBPv5cO8l5gp7/1y4q+LnOgE07wcjnjMfz/sLbP+mGioUEREREasoOImc5vYBCTQO9uXAiSxmr6vgCnuF+t4LPceB4YHP74KDq6qnSBERERGpcQpOIqcJ9PVh/CBz1Om1hbvJc1Vi1Mlmg8tfgbYjwJUNH90IKburqVIRERERqUkKTiJnuPXCBKJC/Dh8KpuZaw5WbmeHD1w/HeJ6QvYJ+OAaSE+unkJFREREpMYoOImcwd/p4P4hbQB4Y9FucvLdlXsB3yC4+VMIbwmnDsB7V0FmSjVUKiIiIiI1RcFJpAS/6RtPXJg/yWk5vLdyX+VfILgJ3PYFhMTCse3w3tWQdaKqyxQRERGRGqLgJFICPx8HD152AQD/WriblIzcyr9IREu4/SsIioIjm+GDsZCTWsWVioiIiEhNUHASKcV1PZvRuWko6bkuXpq389xepHFbuH0OBEZC4nr44DrITa/aQkVERESk2ik4iZTCbrfx5JhOAMxcfYCtiWnn9kJRHeC2L8G/ERxaZa62l5dVZXWKiIiISPVTcBIpQ9+WEVzeNRaPAc98vQXDMM7thWK7wm2zwS8U9v8In9wE+TlVW6yIiIiIVBsFJ5FyTBrVHj8fOz/tOcH3W46c+ws17QW3fA7OINizBD69DVzncO6UiIiIiNQ4BSeRcjQLD+TeS1oB8NzcbeS6Krk8+ema94NbPgWfANg1Dz65GXIzqqhSEREREakuCk4iFTB+UGuiQvw4cCKL6T/uO78Xa3Ex3PSxGZ52L4D3roTM41VSp4iIiIhUDwUnkQoI8vPh0ZHtAXh90W6OpZ/nFLvWQ8ylygPC4fBamDYcTu6vgkpFREREpDooOIlU0DU9mtKtWRgZuS5e+G77+b9gfB/47fcQ2gyO74Z3LoN9P57/64qIiIhIlVNwEqkgu93Gk1eYy5N/tvYQK3annP+LNmkHd8+HqI6QcQTeHQPLXoRzXb1PRERERKqFgpNIJfRKCOe2CxMAmPTFZnLyz2OhiEKhcXDXfOh2ExgeWPQsfPUHcLvO/7VFREREpEooOIlU0iMj2xET6s/+41m8umBX1byoXzBc8xZc/hLY7LDuPfjwWkg/j+XPRURERKTKWB6c3nzzTVq2bIm/vz+9evVi+fLlpfZdsmQJNpvtrNv27VVwvolIBYX4O3n26s4A/Gf5Hn45nFp1L97nbrjxA3PFvT1L4K2LzHsRERERsZSlwWnmzJk8+OCD/PnPf2b9+vUMHDiQUaNGceDAgTL327FjB0lJSd5b27Zta6hiEdNlHaO5vGssbo/BY7M34XJ7qu7F218O9y6BqE6QeQzeHws//1vnPYmIiIhYyNLg9PLLL3PXXXdx991306FDB1599VXi4+OZOnVqmftFRUURExPjvTkcjhqqWKTIU1d0IizAyS+H03hzya9V++JR7eGeRdD1N2C44dtHYOatkHGsat9HRERERCrEsuCUl5fH2rVrGT58eLH24cOHs2LFijL37dGjB7GxsQwdOpTFixeX2Tc3N5e0tLRiN5Gq0CTEj6evNFfZ++fCXWw4eKpq38Dpb573NPxvYHfC9q/hzQth21dV+z4iIiIiUi7LglNKSgput5vo6Ohi7dHR0SQnJ5e4T2xsLG+//TazZs1i9uzZtGvXjqFDh7Js2bJS32fKlCmEhYV5b/Hx8VX6c0jDdlX3OK7oFofbY/DgJ+vJzK3ilfBsNhgwAe5dbE7dy0oxR56+GA/Zp6r2vURERESkVDbDsObEicTERJo2bcqKFSvo37+/t/1vf/sb77//foUXfLjiiiuw2WzMmTOnxO25ubnk5uZ6n6elpREfH09qaiqhoaHn90OIAKlZ+Yz65zISU3O4qW88U8Z2rZ43cuXCkinw4z/NZctDm5qr8F0w0gxYIiIiIlIpaWlphIWFVSgbWDbi1LhxYxwOx1mjS0ePHj1rFKosF154Ibt2lb4ktJ+fH6GhocVuIlUpLNDJizd0w2aDj1cd5PstJY+YnjcfPxj2FNz5HUS0grTD8PFv4N0rIPmX6nlPEREREQEsDE6+vr706tWL+fPnF2ufP38+AwYMqPDrrF+/ntjY2KouT6RSBrRuzL0DWwHw6KxNHDqZVX1v1rwfjP8BLv4TOPxg33L49yUw7wnIy6y+9xURERFpwCxdVW/ixIn897//Zdq0aWzbto0//elPHDhwgPHjxwMwadIkxo0b5+3/6quv8uWXX7Jr1y62bNnCpEmTmDVrFhMmTLDqRxDxmjj8Aro2C+NUVj73f7SeXJe7+t7MN8gcfXpgLXS40lx5b8Vr8EY/2DoHPFW4PLqIiIiI4GPlm994440cP36cZ555hqSkJDp37szcuXNJSEgAICkpqdg1nfLy8nj44Yc5fPgwAQEBdOrUiW+++YbRo0db9SOIePn5OHjj5p6M+dcPbDx4ir99s41nrupcvW/aKB5ufB92fg/fPAypB+DT26BxOxj4EHS5HuyWX+daREREpM6zbHEIq1TmBDCRc7Fo+xF+O2MNAP/8TXeu6t60Zt44LxOWv2xeLDcv3Wxr2gtG/h3i+9RMDSIiIiJ1SJ1YHEKkvrq0fTQThrQB4LFZm9l5JL1m3tg3CIY+ARO3wKVPgG8wHF4L7wyDWffA8Sq+SK+IiIhIA6LgJFIN/nTZBQxoHUl2vpu73l1NSkZu+TtVFf8wuORh8/yn7rcCNtj8KbzeGz67AxI31FwtIiIiIvWEgpNINXDYbbx+c08SIgM5eCKbe99bQ05+NS4WUZKQGLj6DbhnEbQdYV77acsX8PYgmDEGNnwMuRk1W5OIiIhIHaVznESq0a/HMrjmjR9Jy3Expmssr/2mB3a7RRerTf7FvHjuL7PMVfgAnIHQ4QroNx6a9rSmLhERERGLVCYbKDiJVLMVv6Yw7p1VuDwGD1zahoeGt7O2oFMHYONM2PgxnDjtvKe2w6H//dByENgsCnciIiIiNUjBqQwKTmKFT9cc5JHPNwHwxJiO3HVxS4srAgwDDq2B1f81z4EyCq79FNEaOl4FXa6D6E7W1igiIiJSjRScyqDgJFb554JdvLJgJwBTxnbhpr7NLa7oNMd/hZ+mmqNQeaed99RiIPS6A9qNBt9Ay8oTERERqQ4KTmVQcBKrGIbB899u59/L9mCzwcs3dOOaHs2sLqu4nDTYNc9cRGLHt6edCxVkjkD1vQdiulhbo4iIiEgVUXAqg4KTWMkwDCbP2cJ7K/fjsNt44+YejOwca3VZJUs9BGumw+bP4NT+ovb4ftDjVnM0KryFzocSERGROkvBqQwKTmI1j8fgkVmb+HztIZwOG2/f1psh7aOsLqt0hgH7V5jnQm2bAx5X0baIVtDlevPWuK11NYqIiIicAwWnMig4SW3g9hj84ZP1fLMpCT8fO2+P682gC5pYXVb50pNh3fvmdL7E9eDJL9oW290MUJ3HQmicZSWKiIiIVJSCUxkUnKS2yHd7+P0Ha1mw7ShOh42XbujOld3qUODIzYAdc82pfLsXFp0PhQ1aXGwGqLYjIKyppWWKiIiIlEbBqQwKTlKb5Lk8TPx0A19vSsJmg2eu6sxtFyZYXVblZabA1i9h8+dwYGXxbZFtzPOiOlwJbYaBw8eSEkVERETOpOBUBgUnqW3cHoOn5mzh/Z/MBRgmXnYBD1zaBltdXXTh1AH4ZRZsnwuHVgOn/YoJbAxhzaBRPLS/AtqNAn/9dygiIiLWUHAqg4KT1EaGYfDKgl28tnAXAHcMaMGTYzpit9fR8FQo64QZnvYsgY2fQPaJ4tsdftBmKLQaAnHdIbqzrhclIiIiNUbBqQwKTlKbTf9xL09/tRWAK7rF8Y/ruuLvdFhcVRVx5ULSRjNMJa4zrxWVsrN4H5sdojqaYartCHOKn6b2iYiISDVRcCqDgpPUdl+uP8zDn23E5THoHt+It8f1IirE3+qyqp5hwNGtsO1rOLwGEjdA5tHiffwbmedFXTACYrtBo+bgDLCiWhEREamHFJzKUCuDU2Zm6dscDvD3r1hfux0CAs6tb1aW+UW2JDYbBAaeW9/sbPB4Sq8jKOjc+ubkgNtdNX0DA4su4pqbCy5X1fQNCDCPM0BeHuTnV7jvT9uTeHDmRlKz84lr5M8bt/SkfUzB59Xf3/xcVOR1T++bn2/2L42fH/j4VL6vy2Uei9L4+oLTWX5fw4DcE5C4ylzufMf3kH7y7H5BTSAsHiKbQ2wnaDUIYrpDfhn/xk6nWQeYn7Hs7Krp6+NjHovC+rOyqqZvZf671++IkvvW898RFf7vvj79jjizr9tt/tuV5vT/livTV78jzq2vfkeYj/U7ovJ9LVapbGA0MKmpqQZgpKamWl1KEfPXR8m30aOL9w0MLL3voEHF+zZuXHrf3r2L901IKL1vx47F+3bsWHrfhITifXv3Lr1v48bF+w4aVHrfwMDifUePLvu4ne6668rum5FR1Pf228vue/RoUd/77iu77969RX0ffrjsvr/8UtR38uSy+65aVdT3hRfK7rt4cVHf118vu+/XXxf1nT697L6fflrU99NPy+47fXpR36+/Lrvv668X9V24oOy+w/wMY3KoeZsQV3bfyZOLXveXX8ru+/DDRX337i277333FfU9erTsvrffXtQ3I6PsvtddZxRTVl/9jjBv+h1RdGsovyMWLy677wsvFPVdtarsvvodYd70O6Lodjr9jjBV1+8Ii1UmG9hrIsmJSNVxucv4a1p9Yi/n3K4LRkKnayAgAnJSy+67fwXs/B6yT1ZdfSIiItKgaKpebaAh9sr3bUBD7C63h1cX7uSd5fsA6Nomitdu7UN0qH/tGGK3ehqO22VegHfzV3BqPxzfC6kHivd1AA4bYIPGHSCmFzS+AEKbmqv4BcdCREtzIQpNwym5r35HmI9r4e+Is9S2aThW/46obF9N1Tu3vvodYT7W74jK97WYznEqQ60MTiIV8N0vyTz82UYycl1EBvny/LVduaxjtNVl1U4ZR82FJ04dhNSDcHK/uSz6iV9L38fHH5q0h+hOEN4SwluYS6RHtC76n5GIiIjUKwpOZVBwkrpsz7EM7vtwHduT0wG4qW88f7m8I0F+teOvNrVexlE4sBIOr4PjuyE9GfIyzZGq/FL+uuvwg+BoiGgB0V0gprN5vanwFrp4r4iISB2n4FQGBSep63Jdbl6at5P/LN+DYUCLyEBeuK4bfVtGWF1a3eXxwMm9cOQXOLodTh0wrzGVvAlcZUzv8W8EjeKhUYK50l9AODj9zWXTI9tCZGstny4iIlKLKTiVQcFJ6osVv6bw8KcbSUw1v9j/pk88j41qT6NAX4srq0fc+ZCWCBlH4NgOM1gl/2JOA8w+UYEXsEFYM3N0qvAWGAG+weAMBL9gc3n10DgzdImIiEiNUnAqg4KT1Cep2fk8/+02Pl51EIDGwb48ProDV3dvit1us7i6ei43wzx/6tSBoltuOuRlwMl9kLILck5V/PWCYyCqg3kLjABnEIREm9MEfYMgJM58LiIiIlVGwakMCk5SH63ed4LHZ29m19EMANrHhDBpdAcGXdDE4soaMMOArONw/FczSJ3ca97npJrnVeVnQU4aZB6r4OgVENnGDFj5mZCfDYYH4npCQn9zmzPAXHI9ONpc6MLhrM6fUEREpM5TcCqDgpPUV3kuD//9YQ9TF/9Keq65vOk1PZryl8s7EBnsZ3F1UqacNHMq4LFt5n1huEpPhsyjkJcF6UlAJX5d250Q1NicFujOM6+LFdjYbAtqDHE9oM1lBVMEC17Xx19hS0REGhQFpzIoOEl9dyorj38u3MW7K/bhMSDEz4fxg1tz18Ut8XeWc1FZqb2yT8LBVeZIlTPQvLlyYf8PkLjBHM1y55kLVqQehNy0yr+HzV6wsEUb83ysrOOQlgT+YRDcxDwfK6gJBEWZ0wed/hDT1QxiIiIidZCCUxkUnKShWH/gJH/58he2JJpfoGPD/PnTZRdwTY+mOB26LlG95vFA2iHIOmGec+XwBY8LMlMgK8UMQ3sWw6E1VGoUqzSRbcz7vCxzGqEz8LQFMQquiRUQboY7T74ZtkLjzKDmFwoBjcwRMRERkRqm4FQGBSdpSDweg/9tPMyL3+/k8Cnz6vZNGwVw7yWtuKF3PAG++rLaoLnywHAXPLGZo1onfi06Lysw0gw4uenmuViZKQX3BdMHc1Lh+K4qKMRmBqvACPM9AyMhIAJsNnOErfB8rvi+0HyAef0sH38zoLnzCkbhAswQ5hcKDl3XTEREKkbBqQwKTtIQ5eS7eW/lPt5etoeUjDwAIoJ8uXNAC8b1b0FYoM5rkXOUccxcpt3Hr2gKYW66uRjGqf0FC2PsM0e/GiWYYShpkxnSDI85QlXVnEFmuPILBb8Qs56cU+Y5XmHNIKwphMSa0xrzMyH9CITGQnQn8A8Hu90878zuMPuFxIJvYNHrG4a5VL2Plv4XEanrFJzKoOAkDVlOvpvP1h7i7WW/cvCEOQIV5Ovg5n7NueviVsSE+VtcoTQ47nwzRGUdN8NV1vGiGxScSxUA+TmwZ4l5Da387IJblrmYReF2V3b11ekfZgYvZ4AZBAunQPqFmLfwlmbw8vEDj9sMhYER0HaEeS5Y4nqzZpvDDGQ+fhDa1AySJ/aawc6db057bNbbDHU2XVJAROqZ/Gxz5oLHDRjmpTac1n73UHAqg4KTCLjcHr7ZnMTUJb+yPTkdAKfDxtgezbh3UCtaNwm2uEKRc+DKM0eXclMLRpnSzHvfIDP4ZKaY536lHjYvapxzCnwCIDjKvA5Xyk7z+lwelzli5c43VzasjlGx8tid5ugdAIY5yoVhnhcWnmCeN5aZYi4QEtHSXKbex88Mdj5+5lTGwpszwBwxc+ebX1hSdsKpg+a5ZcExBdcLizGXsc85ZQZDMFdkDI0zp056XOb5ae58MxRiM9t9A83gl5cJjeLN/dKTzFPnfAPNZfEDI8xpne58cx8FQmloPO6KncdZ+JX89P9G8rPN1VYzj5mPw5oW/DfpNv+bKvxv88znbpf52O5j/oEp+6S5aFBwjPn7LfuU2ZZ90rwkRuEfr/IyimYP+Aaar5GbXnSx9vQjkJFc8PoF72cv/ANWlvm6OacK7lPN6dQOp/mHJpv97IWL7l5o/rHIQgpOZVBwEiliGAZLdh5j6pJfWbW36FpCl1zQhHEXJjCkfRQOXUhXGjLDMP9Hn55sfrHIyzSnHAY3MR/npptfEFJ2ml9uDLc5qmSzwfHd8OtiwDAXxAgIN0OH4TbPEUs7bH7ZiWhZsDKhDZI3m9Mc6xO/MDPMFj4OjTWnUbrzwJVjBjS/4KLRuMJ7u8P80mcruHfnQsZR898koJEZyALCzW12p/mlLjjK/HJ25Bc48LP5uhGtzNFC/zBzv7RE2P+j+e/nDDQDX2RbaNzWDNnJm81g7XaZ0zGdgeYXQncehMVDSIz5JdDuNM+nc7vMz8jxX83pqbnpgGGep9ekHbS8xPz3PrXf/Fx49/U193cVnKfnH2b+TIbntC/BBV9M3S6zvVG8OXXUlWu+Z06a2aeQ4Sm4nEGWWbtPgPnXfJ8A83ie2GN+LrNOmPsFR5sjpoZR8EeHNPNLeaPm5rRWu485yuvKNdsNo2ik1+Yw+7vzCn6egpvdaf4b5KWbteSkFv2b+fib+4XGmv8d+QaZ75u43vwCX7i/w6foNQu/lPuHmoH/8BqznsJA4O1/+j4O85i5ss2+hmEeX4eP+dyVYx53V4753J1r/hze44j5c+ZlFFzYPNM8tg6necwMo+D6ezbzfXNOmaEmqElRgMjLNP8Qk3Xc/ONL4TmYhrsg3LjMhXwKHxe2YysKLT7+5ufVey5qPVH434DNDrf/D5r2srQcBacyKDiJlGzt/hNMXbKHhduPeP/o1Sw8gFv6JXBjn3gignQ+h0iluXLNe59KXEstN8P8spmfBdiK//XZ44KUXeaS88HR5he5E3vML535OQVfBHOKvhAWTmvMyzT7BkaaQS28ZVEgTE82/4KccdQMMRGtzC+euemQeqjgC61v0Rd9m938Yp913Pxi2SjB/PJ96oBZa0icuX9OqhkWvGxUySqODZ3NUf++SEvZChfqcfiZ/03mpBYFRLuzIESWEB7tPgUhPM/8I4NvsPnfem66+Twg3JwWHBhZ8IeICPOPDa4c83dGXpb5ur7B5u+JtERzhDq0acHvg4IA7ck3f884A82A7N+o6A8VDr+i0WqP2/wjkX9YrRp5VnAqg4KTSNkOHM/ig5/3M3P1QVKzzb9k+vrYGd4xmmt7NWNgm8b4aDlzEQHzL+b2Mn4fZJ80v2w1am5+oTu51wxouWnmFyof36K/zBeOxnncRfced9Ff4+0+5jXEbAUrQGadMP/SbxjmF73UQ+YogMdljgy1GGiOJJzcZ/YvHP3wDYKEi81Rj9x0c3vKTkjZbT6P6WyGQYfT/MJZODJl94HUA+YUSXe+ua1wKpQz0AykEa3ML4Vg9ju0yrzOmjMAIlqbtReOJLnzzMeOglGtnFPmz+T9Muwo+AJc8IXYMMxRytNDk2/IGYuU2Mz39w0qWHEy2zw2+TnmsQhrZk6fDI4yXzPjiHnsbXZzH78Qs+7UQ+bP6s43+/sFm7XZ7GathSNhfqEFlzvIL5q65c4zPxd+IUVfng3D/PlcueZ+qYfM8F94/KI7mV/GPa6i6WaFx6fwS3lOqvnFvnk/8wu/9/3yKTY1rfCxw1kwXdXPPO45qeb2wjZH4ZRWX/Pe7lP8y7wzsGg01DfY/PfIzzFXFS2cqmqzFV0/z8ff3ObKNfv7Bpm3gHDzOOWcMj9fhf+ehcHmzJHVwkVz8rKKpuaFxNaqoFHfKDiVQcFJpGKy89x8tTGR937axy+Hi+YkNwnx4+rucVzbqxntY/TfkIhImfKyCr6YV8EfnFy5ZrApDDl1/fpn7oJphg6t7CrWUXAqg4KTSOUYhsEvh9OYte4Q/9twmJNZRfPpO8WFcm3PZlzZPY7GwZWYiiQiIiJSCyg4lUHBSeTc5bk8LNlxlFnrDrFo+1Hy3eavDx+7jcHtmnBtz2Zc2iEKP586/ldQERERaRAUnMqg4CRSNU5k5vHVxkRmrzvExkOp3vawACdXdIvl6u5N6dE8XKvyiYiISK2l4FQGBSeRqrfrSDqz1h3my/WHSU7L8bZHBvkypH0UwzpEcVGbxoT4ax67iIiI1B4KTmVQcBKpPm6PwYpfU5i97jALth0hPcfl3eaw2+jZvBED2zZhYNvGdG3WSKNRIiIiYikFpzIoOInUjHy3h9V7T7Bg21EWbT/CvuNZxbaH+vtwcdvGDGzbhIvbNCY+ItCiSkVERKShUnAqg4KTiDUOnshi+a4Ulu86xg+7U4qNRgG0bBzEha0i6J0QQd+WETQLD8Cm61aIiIhINVJwKoOCk4j1XG4Pmw6nsnynGaTWHzyF21P8V1F0qB99WkR4b+1iQjS1T0RERKqUglMZFJxEap+0nHx+3nOCNftOsHrfCTYfTvUudV4oxM+HngnhdGkaRqe4UDrFhREfoVEpEREROXcKTmVQcBKp/bLz3Gw8dIo1+06wat9J1u0/SUau66x+If4+dIw1Q1SnuFA6xoXSJioYp8NuQdUiIiJS1yg4lUHBSaTucXsMtiensW7/SbYkprElMY0dyenkuT1n9fX1sdMuOqRgVCqUjnFhdIgNIdDXx4LKRUREpDarTDbQNwkRqfUcdlvBqFKYty3f7WH30YyCIJXKlsQ0tiWmkZ7rYvPhVDYfLroor81mLj7hHZmKNUemYsP8NdVPREREKkQjTiJSb3g8BgdPZhULU1sS0ziWnlti/0BfB62aBNGqcTCtmgTRsnEQrZsE07JxEEF++ruSiIhIfaepemVQcBJpeI6m57AlMY2tBbdtSWkcOJGFy1P6r7+YUH9aNQmiReMgmkcEEh8eSPMI8xYW6KzB6kVERKS6KDiVQcFJRMCc6nfgRBa/Hs1gT0ome49lsiclgz3HMjmemVfmvqH+PjSPDCQhIoj4iKJA1TwikNhG/lqcQkREpI7QOU4iIuVwOuy0bhJM6ybBZ21Lzcrn14IQdeB4JgdOZBXcsknJyCUtx8Uvh9P45XDaWfs67DbiGvnTPCKQpo0CiCu4FT6ODfPH3+moiR9RREREqpCCk4jIGcICnfRsHk7P5uFnbcvKc3HwRLY3TB30hirzlufycPBENgdPZJf6+o2Dfb0hKibUn+gwf6JD/IkJ8yc61J/oUD9C/DUdUEREpDZRcBIRqYRAXx/axYTQLibkrG0ej8GxjFwzRB3PIik1m8Onsjl8KofEU9kknsomK89NSkYeKRl5bDqUWsI7mIJ8HSUGKm/QCvUnKsRP0wJFRERqiIKTiEgVsdttBQHHnz4tIs7abhgGqdn5HD6VTeKpHJJSs0lOzeFIWi5H0nJITsvhSGoO6bkuMvPc7DmWyZ5jmaW+n80GkUF+3kAVFepPkxA/ogpujUP8aBzkR2SwL4G+Di29LiIich4UnEREaojNZqNRoC+NAn2LXZPqTJm5Lm+QOpqWS3JaDsmpORxNz/EGraPpOeS7DVIycknJyGVL4tnnW53O32knMqgwTPkSGexLZLAfjYP9aBzsS2SQHxEF7eGBvvj6aCRLRETkdApOIiK1TJCfD62aBNOqhIUrCnk8Biey8k4LVGaYOpqey7H0XI6m53K8IFTl5HvIyfcUTBss/dyr04X4+xAZ5EvEabfwIF8ig8xgVRiwIoP8CA9yEuznoxEtERGp1xScRETqILvdVjBa5AeUPnoF5oIWKel5pGTmcjwjj+MZuRzPzONYunl/PKOgPTOXE5l5eAxIz3GRnuNi3/GsCtXj67ATHuQkIsiP8EAnYQFOGgU6CQ0oeBzg620LK2gLC3QSosAlIiJ1hIKTiEg9F+jrQ/NI89pT5fF4DE5l53MiM5cTmaXcZ5n3JzPzOZ5pjmjluT0F52rlVqo2u42iIBXgJCywIGAFFA9Y3rbAoiDm77QrdImISI1RcBIRES+73eadmldR2XluTmTlcaJg1Co1O5/U7HxOZRW/T8vO51R2nrct1+XBY8DJrHxOZuVXulZfh90bpIqFrYK2EH9zRCvIz4cgPwfBBY9Pv9e5XCIiUlEKTiIicl4CfB009TUv8lsZOfnugjBVPGClZueTmpVXFMC8bUXbXR6DPLeHYwXndJ0rX4edID9HsUAV5OdTELhKay85iAU6HdjtGgETEamvFJxERMQS/k4H/k4HUaH+ldrPMAwy89wFYSuvaDTrtGB1Kjuf9BwXmbkuMnLNe/Oxm4zcfHLyPQDkuT3kZXnOacTrTDYbBPmeEbh8C8OVg2D/gse+PmcEMgchBduCfIvaNRomIlK7KDiJiEidYrPZCC4IHpUd5SrkcnvIzHOfFqiKAlZGrrtY4MooFr7cJbZ7DDAMvG1w7qNghU4fDQsoCJkBTgf+vg4CnHYCnA4CfM1tgb4OAnwdBW3mc//CdmfRtsCC/gG+DpwOm84RExGpBAUnERFpcHwcdsIC7IQFOM/7tQzDICffU2KgyigIWyW3FwWx09tzXVU/GlYSh91GYEEQOzNg+Tsd+Drs+Dnt+PnY8fWx4+fjKLg/83HRdj+nHT/vfqX393FoNE1E6h4FJxERkfNgs9nMwOHroEmI33m/Xr7bQ1aum4w8Fxk5LrLyXGTnu8nN95Cd7yY7z01WvpucPDfZ+W6y8tzk5LsL+nnILuiflWf2LdyncD+3xwDA7TFIz3WRnus675ory26jeJhy2s2gVhC+zNDmOC2UFWwrIawVfw1H8dcr4TVOD3AacRORylBwEhERqUWcDjthgeaKgdUhz1UUwLILAlfOGUErN99DrttDbr6bPLfHfO7ykOfykOtyl/LYfO59XLBMfeFr5LsNbw0eA7OGfHe1/IwVZYa104JVKSNtpYevosclvobDjtPHjtNhx+mw4eswH/uc9tjcbsNpt2txEZFaTsFJRESkAfEt+JJfFdMUK8PtMcg7I3DllhS+TgtrhcGr1HBW4uuV/hqF0yAL5bnN7VVwSlqV8LHbikKWN3AVBCuH3dvmYz99e8E2bxAreu7jsOFjN/s4Cu597DZ8Cl7Dx1HYVti3oK3g3mG3ebebr2G+tsNe1LfwceE2uw2N5Em9peAkIiIi1c5hL5rSCDUb2goZhkG+2ygzfHkfe0NX0ehb2QHOXXykzeUm32WQXxDO8gtG3fJdHm9gM4zi9bk8Bi6Pm+zqOa2txpwepIpClhnATn/usNtP22bu47DbsNts3n6Fj+12Gw7b6dvxPvY5c3vB46I28xp1p7/e6e/j7Wun4PXs3sclv3fh+9sL9qX465SwX9F2SnxvqRssD05vvvkm//jHP0hKSqJTp068+uqrDBw4sNT+S5cuZeLEiWzZsoW4uDgeeeQRxo8fX4MVi4iISF1ks9nw9bHVmqXe3Z7TgpXLY16fzHVayDptW7HnhTeX4X3uchvFt7nN13J5zG0uj4HL7SG/4N58bwOXx+x7ZltJ+7g8Bm6PUbDNvIB1ScwAaJw1wielOz1cmcGKswJesUB5RuA7PbQV3vs4zty35NB2VvA8LWye3mbezHabjaLnNnOFTvtpbbbTfo7CfR0F+xW9HlzYKpJGgRW/4LrVLA1OM2fO5MEHH+TNN9/koosu4t///jejRo1i69atNG/e/Kz+e/fuZfTo0dxzzz188MEH/Pjjj9x33300adKEa6+91oKfQEREROTcmF+MzVUM6yJPQUBye8wgVRi8Cp8Xhq/CgOj2FIUx7+OCfm6PQb7HwFPQ320Y3tf3GAVt3seU0HbarWBfd2Hfs9pK2NfgrPc+vYbT+3oMztq/8N7lOX1fvO9XnsLXa2hm3zeAns3rTnCyGcaZA8U1p1+/fvTs2ZOpU6d62zp06MDVV1/NlClTzur/6KOPMmfOHLZt2+ZtGz9+PBs3bmTlypUlvkdubi65uUWTl9PS0oiPjyc1NZXQ0NAq/GlERERERM52emgrOehRFNjKDXqcEfqK9vMYZwa90t+7sK+5L2cFxtNf22OYYdW8Zp3hfewxDIzTtnk8BgZFAdNT+J4F+xW+r6cg/E4Z24W20SGW/tukpaURFhZWoWxg2YhTXl4ea9eu5bHHHivWPnz4cFasWFHiPitXrmT48OHF2kaMGME777xDfn4+TufZc6anTJnC008/XXWFi4iIiIhUgt1uw46NOjq4KAUsm+SbkpKC2+0mOjq6WHt0dDTJyckl7pOcnFxif5fLRUpKSon7TJo0idTUVO/t4MGDVfMDiIiIiIhIg2H54hBnLllpGEaZy1iW1L+k9kJ+fn74+Z3/BQlFRERERKThsmzEqXHjxjgcjrNGl44ePXrWqFKhmJiYEvv7+PgQGRlZbbWKiIiIiEjDZllw8vX1pVevXsyfP79Y+/z58xkwYECJ+/Tv3/+s/vPmzaN3794lnt8kIiIiIiJSFSy9kMHEiRP573//y7Rp09i2bRt/+tOfOHDggPe6TJMmTWLcuHHe/uPHj2f//v1MnDiRbdu2MW3aNN555x0efvhhq34EERERERFpACw9x+nGG2/k+PHjPPPMMyQlJdG5c2fmzp1LQkICAElJSRw4cMDbv2XLlsydO5c//elPvPHGG8TFxfHaa6/pGk4iIiIiIlKtLL2OkxUqs1a7iIiIiIjUX5XJBpZO1RMREREREakLFJxERERERETKoeAkIiIiIiJSDgUnERERERGRcig4iYiIiIiIlEPBSUREREREpBwKTiIiIiIiIuVQcBIRERERESmHgpOIiIiIiEg5FJxERERERETKoeAkIiIiIiJSDh+rC6hphmEAkJaWZnElIiIiIiJipcJMUJgRytLgglN6ejoA8fHxFlciIiIiIiK1QXp6OmFhYWX2sRkViVf1iMfjITExkZCQEGw2m2V1pKWlER8fz8GDBwkNDbWsjvpMx7hm6DhXPx3j6qdjXDN0nKufjnHN0HGufjV1jA3DID09nbi4OOz2ss9ianAjTna7nWbNmlldhldoaKj+g6tmOsY1Q8e5+ukYVz8d45qh41z9dIxrho5z9auJY1zeSFMhLQ4hIiIiIiJSDgUnERERERGRcig4WcTPz4/Jkyfj5+dndSn1lo5xzdBxrn46xtVPx7hm6DhXPx3jmqHjXP1q4zFucItDiIiIiIiIVJZGnERERERERMqh4CQiIiIiIlIOBScREREREZFyKDiJiIiIiIiUQ8HJAm+++SYtW7bE39+fXr16sXz5cqtLqrOeeuopbDZbsVtMTIx3u2EYPPXUU8TFxREQEMDgwYPZsmWLhRXXDcuWLeOKK64gLi4Om83Gl19+WWx7RY5rbm4uDzzwAI0bNyYoKIgrr7ySQ4cO1eBPUbuVd4zvuOOOsz7bF154YbE+OsZlmzJlCn369CEkJISoqCiuvvpqduzYUayPPsvnryLHWZ/n8zN16lS6du3qvRBo//79+fbbb73b9Tk+f+UdY32Gq96UKVOw2Ww8+OCD3rba/llWcKphM2fO5MEHH+TPf/4z69evZ+DAgYwaNYoDBw5YXVqd1alTJ5KSkry3zZs3e7e98MILvPzyy7z++uusXr2amJgYLrvsMtLT0y2suPbLzMykW7duvP766yVur8hxffDBB/niiy/45JNP+OGHH8jIyGDMmDG43e6a+jFqtfKOMcDIkSOLfbbnzp1bbLuOcdmWLl3K/fffz08//cT8+fNxuVwMHz6czMxMbx99ls9fRY4z6PN8Ppo1a8bzzz/PmjVrWLNmDZdeeilXXXWV9wulPsfnr7xjDPoMV6XVq1fz9ttv07Vr12Lttf6zbEiN6tu3rzF+/Phibe3btzcee+wxiyqq2yZPnmx069atxG0ej8eIiYkxnn/+eW9bTk6OERYWZrz11ls1VGHdBxhffPGF93lFjuupU6cMp9NpfPLJJ94+hw8fNux2u/Hdd9/VWO11xZnH2DAM4/bbbzeuuuqqUvfRMa68o0ePGoCxdOlSwzD0Wa4uZx5nw9DnuTqEh4cb//3vf/U5rkaFx9gw9BmuSunp6Ubbtm2N+fPnG4MGDTL++Mc/GoZRN34na8SpBuXl5bF27VqGDx9erH348OGsWLHCoqrqvl27dhEXF0fLli35zW9+w549ewDYu3cvycnJxY63n58fgwYN0vE+DxU5rmvXriU/P79Yn7i4ODp37qxjXwlLliwhKiqKCy64gHvuuYejR496t+kYV15qaioAERERgD7L1eXM41xIn+eq4Xa7+eSTT8jMzKR///76HFeDM49xIX2Gq8b999/P5ZdfzrBhw4q114XPsk+1v4N4paSk4Ha7iY6OLtYeHR1NcnKyRVXVbf369eO9997jggsu4MiRI/z1r39lwIABbNmyxXtMSzre+/fvt6LceqEixzU5ORlfX1/Cw8PP6qPPesWMGjWK66+/noSEBPbu3csTTzzBpZdeytq1a/Hz89MxriTDMJg4cSIXX3wxnTt3BvRZrg4lHWfQ57kqbN68mf79+5OTk0NwcDBffPEFHTt29H5Z1Of4/JV2jEGf4aryySefsG7dOlavXn3WtrrwO1nByQI2m63Yc8MwzmqTihk1apT3cZcuXejfvz+tW7fm3Xff9Z60qeNdPc7luOrYV9yNN97ofdy5c2d69+5NQkIC33zzDWPHji11Px3jkk2YMIFNmzbxww8/nLVNn+WqU9px1uf5/LVr144NGzZw6tQpZs2axe23387SpUu92/U5Pn+lHeOOHTvqM1wFDh48yB//+EfmzZuHv79/qf1q82dZU/VqUOPGjXE4HGcl4qNHj56VruXcBAUF0aVLF3bt2uVdXU/Hu2pV5LjGxMSQl5fHyZMnS+0jlRMbG0tCQgK7du0CdIwr44EHHmDOnDksXryYZs2aedv1Wa5apR3nkujzXHm+vr60adOG3r17M2XKFLp168Y///lPfY6rUGnHuCT6DFfe2rVrOXr0KL169cLHxwcfHx+WLl3Ka6+9ho+Pj/c41ebPsoJTDfL19aVXr17Mnz+/WPv8+fMZMGCARVXVL7m5uWzbto3Y2FhatmxJTExMseOdl5fH0qVLdbzPQ0WOa69evXA6ncX6JCUl8csvv+jYn6Pjx49z8OBBYmNjAR3jijAMgwkTJjB79mwWLVpEy5Yti23XZ7lqlHecS6LP8/kzDIPc3Fx9jqtR4TEuiT7DlTd06FA2b97Mhg0bvLfevXtzyy23sGHDBlq1alX7P8vVvvyEFPPJJ58YTqfTeOedd4ytW7caDz74oBEUFGTs27fP6tLqpIceeshYsmSJsWfPHuOnn34yxowZY4SEhHiP5/PPP2+EhYUZs2fPNjZv3mzcdNNNRmxsrJGWlmZx5bVbenq6sX79emP9+vUGYLz88svG+vXrjf379xuGUbHjOn78eKNZs2bGggULjHXr1hmXXnqp0a1bN8Plcln1Y9UqZR3j9PR046GHHjJWrFhh7N2711i8eLHRv39/o2nTpjrGlfD73//eCAsLM5YsWWIkJSV5b1lZWd4++iyfv/KOsz7P52/SpEnGsmXLjL179xqbNm0yHn/8ccNutxvz5s0zDEOf46pQ1jHWZ7j6nL6qnmHU/s+ygpMF3njjDSMhIcHw9fU1evbsWWzJVqmcG2+80YiNjTWcTqcRFxdnjB071tiyZYt3u8fjMSZPnmzExMQYfn5+xiWXXGJs3rzZworrhsWLFxvAWbfbb7/dMIyKHdfs7GxjwoQJRkREhBEQEGCMGTPGOHDggAU/Te1U1jHOysoyhg8fbjRp0sRwOp1G8+bNjdtvv/2s46djXLaSji9gTJ8+3dtHn+XzV95x1uf5/P32t7/1fm9o0qSJMXToUG9oMgx9jqtCWcdYn+Hqc2Zwqu2fZZthGEb1j2uJiIiIiIjUXTrHSUREREREpBwKTiIiIiIiIuVQcBIRERERESmHgpOIiIiIiEg5FJxERERERETKoeAkIiIiIiJSDgUnERERERGRcig4iYiIiIiIlEPBSUREpBJsNhtffvml1WWIiEgNU3ASEZE644477sBms511GzlypNWliYhIPedjdQEiIiKVMXLkSKZPn16szc/Pz6JqRESkodCIk4iI1Cl+fn7ExMQUu4WHhwPmNLqpU6cyatQoAgICaNmyJZ999lmx/Tdv3syll15KQEAAkZGR3HvvvWRkZBTrM23aNDp16oSfnx+xsbFMmDCh2PaUlBSuueYaAgMDadu2LXPmzKneH1pERCyn4CQiIvXKE088wbXXXsvGjRu59dZbuemmm9i2bRsAWVlZjBw5kvDwcFavXs1nn33GggULigWjqVOncv/993PvvfeyefNm5syZQ5s2bYq9x9NPP80NN9zApk2bGD16NLfccgsnTpyo0Z9TRERqls0wDMPqIkRERCrijjvu4IMPPsDf379Y+6OPPsoTTzyBzWZj/PjxTJ061bvtwgsvpGfPnrz55pv85z//4dFHH+XgwYMEBQUBMHfuXK644goSExOJjo6madOm3Hnnnfz1r38tsQabzcZf/vIXnn32Wfj/du6YJdUojuP494kcUp4lpGxr0nCwxQapRZrcAttCXCWQlnZ9BfUKHAWhoS1qaBTCyS19AxE1hqCLNVwQpMt97r1wuynfz3Sec57ncM7445z/A4xGI8Iw5ObmxlorSVpi1jhJkhZKsVicC0YA6+vrs3ahUJgbKxQK9Pt9AB4fH9nd3Z2FJoD9/X2m0ynD4ZAgCHh6euLw8PCXa8jlcrN2IpEgDENeXl7+dkuSpAVgcJIkLZREIvHp6lyUIAgAeH9/n7V/9s7a2tpvzReLxT59O51O/2hNkqTFYo2TJGmpPDw8fHre2dkBIJvN0u/3GY1Gs/Fut8vKygrpdJowDNne3ub+/v5L1yxJ+v48cZIkLZTJZMLz8/Nc3+rqKslkEoCrqyvy+TwHBwe02216vR6tVguAk5MTGo0G1WqVZrPJ6+sr9XqdSqXC5uYmAM1mk1qtxsbGBqVSibe3N7rdLvV6/Ws3Kkn6VgxOkqSFcnt7y9bW1lxfJpNhMBgAP/541+l0OD09JZVK0W63yWazAMTjce7u7jg7O2Nvb494PE65XObi4mI2V7VaZTwec3l5yfn5OclkkuPj46/boCTpW/KvepKkpREEAdfX1xwdHf3vpUiSlow1TpIkSZIUweAkSZIkSRGscZIkLQ1vn0uS/hVPnCRJkiQpgsFJkiRJkiIYnCRJkiQpgsFJkiRJkiIYnCRJkiQpgsFJkiRJkiIYnCRJkiQpgsFJkiRJkiJ8AKrEbSup+XNAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_mlp_model.eval()\n",
    "\n",
    "sclsdl_mlp_test_running_loss = 0.0\n",
    "sclsdl_mlp_test_correct = 0\n",
    "sclsdl_mlp_all_predictions = []\n",
    "sclsdl_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sclsdl_mlp_test_embeddings_batch, sclsdl_mlp_test_labels_batch in sclsdl_mlp_test_loader:\n",
    "        sclsdl_mlp_test_embeddings_batch = sclsdl_mlp_test_embeddings_batch.to(device)\n",
    "        sclsdl_mlp_test_labels_batch = sclsdl_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        sclsdl_mlp_test_outputs = sclsdl_mlp_model(sclsdl_mlp_test_embeddings_batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        sclsdl_mlp_test_loss_batch = sclsdl_mlp_criterion(sclsdl_mlp_test_outputs, sclsdl_mlp_test_labels_batch)\n",
    "        sclsdl_mlp_test_running_loss += sclsdl_mlp_test_loss_batch.item() * sclsdl_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, sclsdl_mlp_test_predicted = torch.max(sclsdl_mlp_test_outputs, dim=1)\n",
    "        sclsdl_mlp_test_correct += (sclsdl_mlp_test_predicted == sclsdl_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        sclsdl_mlp_all_predictions.extend(sclsdl_mlp_test_predicted.cpu().numpy())\n",
    "        sclsdl_mlp_all_true_labels.extend(sclsdl_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_mlp_predictions.npy'), np.array(sclsdl_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_mlp_true_labels.npy'), np.array(sclsdl_mlp_all_true_labels))\n",
    "print(f\"Saved SCL_SDL+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "sclsdl_mlp_epoch_test_loss = sclsdl_mlp_test_running_loss / len(sclsdl_mlp_test_loader.dataset)\n",
    "sclsdl_mlp_test_accuracy = sclsdl_mlp_test_correct / len(sclsdl_mlp_test_loader.dataset)\n",
    "\n",
    "sclsdl_mlp_test_accuracy_pct = sclsdl_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {sclsdl_mlp_epoch_test_loss:.4f} | Test Accuracy: {sclsdl_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "sclsdl_mlp_num_epochs_run = len(sclsdl_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         sclsdl_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         sclsdl_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         [sclsdl_mlp_epoch_test_loss]*sclsdl_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Results and Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:50:50.451852Z",
     "iopub.status.busy": "2025-05-08T19:50:50.451852Z",
     "iopub.status.idle": "2025-05-08T19:50:50.457153Z",
     "shell.execute_reply": "2025-05-08T19:50:50.457153Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_conf_matrix(model_name, class_names = None, cm_save_dir='confusion_matrices'):\n",
    "    os.makedirs(cm_save_dir, exist_ok = True)\n",
    "\n",
    "    #loading predictions and true labels\n",
    "    predictions_path = os.path.join(predictions_dir, f'{model_name}_predictions.npy')\n",
    "    true_labels_path = os.path.join(predictions_dir, f'{model_name}_true_labels.npy')\n",
    "\n",
    "    if not os.path.exists(predictions_path) or not os.path.exists(true_labels_path):\n",
    "        print(f\"Error: Files not found for model {model_name}\")\n",
    "        return\n",
    "    \n",
    "    cm_predictions = np.load(predictions_path)\n",
    "    cm_true_labels = np.load(true_labels_path)\n",
    "\n",
    "    conf_matrix = confusion_matrix(cm_true_labels, cm_predictions)\n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    conf_matrix_normalised = conf_matrix.astype('float') / conf_matrix.sum(axis = 1)[:, np.newaxis]\n",
    "    sns.heatmap(conf_matrix_normalised, annot=conf_matrix, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "    plt.title(f\"{model_name.upper()} Confusion Matrix\", fontsize=16)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    cm_save_path = os.path.join(cm_save_dir, f'{model_name}_confusion_matrix.png')\n",
    "    plt.savefig(cm_save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved confusion matrix to: {cm_save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "    print(f\"Classification Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:50:50.460158Z",
     "iopub.status.busy": "2025-05-08T19:50:50.459158Z",
     "iopub.status.idle": "2025-05-08T19:50:55.338882Z",
     "shell.execute_reply": "2025-05-08T19:50:55.338882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving confusion matrices to: confusion_matrices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\e2e_cnn_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 98.62%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\cae_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 79.03%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\cae_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 77.04%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\tscl_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 89.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\tscl_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAMWCAYAAABIgshOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADHkElEQVR4nOzdd1gUVxsF8LP0Ik1QBHvsiCJgQ7ErlmjsPWrsNfZGNHbFEnuNvfdEY4waazRqTOyJSpTEggWVJqj0Zb4//Ni4spSVZWeunt/zzJMwMztzuLOLd+++c1clSZIEIiIiIiJSHBO5AxARERERkW7srBMRERERKRQ760RERERECsXOOhERERGRQrGzTkRERESkUOysExEREREpFDvrREREREQKxc46EREREZFCsbNORERERKRQ7KwTESmEWq3GrFmzUKZMGVhYWEClUqFu3bpGzVCsWDGoVCrcv3/fqOf9GN2/fx8qlQrFihWTOwoRKRg76/RRU6lUei/vdp4uXLiAzz//HMWKFYOVlRXs7OxQsmRJBAQEYObMmfjzzz8zzXDo0CF0794dJUqUQJ48eWBtbY1ixYqhbdu22LlzJ5KTk7X2nzJlSq514n755Ret3zWr7N7e3pp9v/jiC61taR0RfTp+aR3Ftxdra2uUKFECvXr1ws2bN9/zNwPCw8Mxffp01KxZE66urrCwsICTkxOqVauGwMBA3Llz572PbSiTJk3ChAkTcP/+fXh6eqJmzZqoUKGC3LEU5+3nyahRozLdd/HixVrPJ0N48eIFpkyZgkWLFhnkeEREmTGTOwCRnGrWrJluXUxMDG7cuJHh9rc7T3PmzEFgYCAkSYKVlRWKFSsGe3t7PH78GMeOHcOxY8dw9epV7N27N91xwsPD0bFjR5w6dQoAYGdnh08++QTm5uYIDQ3F999/j++//x6lSpXC6dOn4ebmZqhfO9u2bt2KuXPn6tx28+ZNXLt2LVfOW6pUKeTPnx/Am45RSEgINmzYgO3bt2PPnj1o0aKFXsfbuHEjvvzyS7x69QrAm85e0aJFERMTgytXruCPP/7AvHnzMHPmTIwbN87gv092SJKEVatWQaVS4dy5c6hcubIsOUqUKAErKyuYm5vLcn59bd++HXPnzoWpqanO7Vu3bjX4OV+8eIGpU6eiaNGiGD58+Hsfx9zcHGXKlEHBggUNF46IPjwSEWk5deqUBEDK6uVx/vx5zX6BgYFSTEyM1vZ79+5Js2fPlkaOHJnusS9evJBKly4tAZBKlSol7d+/X0pKStLa5+LFi1KHDh0klUolXb16VbN+8uTJEgCpTp067/07ZiTtd3d3d5fs7OykggULSmq1Wue+48aNkwBIZcqUkQBIPXr00Np+7949Tfvcu3cvW+cvWrSoBEDasGGD1vqnT59KDRs2lABIzs7O0suXL7P9Oy1fvlwCIKlUKmnIkCHSw4cPtbZHR0dLK1eulAoWLCi1bNky28c1tGfPnkkApPz588uWQRRpz5O0596RI0d07vf3339r7Weof/LSnttFixY1yPGIiDLDMhii97Rp0yYAQMOGDTFr1izY29trbS9WrBjGjRuH+fPnp3vs4MGDcefOHXh4eOC3335Dy5Yt041kVq5cGbt27cJ3330HW1vb3PtFdLC2tkabNm3w+PFjzcj/2yRJwvbt22Fra4vWrVvneh5XV1ds2bIFlpaWiIyMxLFjx7L1uJs3b2LEiBEAgOXLl2Pp0qUoVKiQ1j6Ojo4YMGAAbt68iaZNmxo8e3bFx8cDeNP2lD2ff/45gIxHz7ds2QIA6Natm9EyEREZGjvrRO/p7t27AIBKlSrp9bh//vkHO3bsAACsW7cOzs7Ome7funVrlCpV6r0y5kRaRyitw/O2X375BQ8fPkTr1q2N9kaiQIECmnYICQnJ1mPmzJmDpKQkBAQEYODAgZnu6+DggP79+6dbHxoaioEDB6J48eKwtLSEi4sLmjZtisOHD+s8Tto9BVOmTEFMTAyGDx+OIkWKwNLSEiVLlsT06dORkpKi9Zi3bzJ88OCBVo31L7/8AgCoW7eu1s/v+uKLL6BSqbBx40at9SkpKVi8eDGqVq0KOzs7WFpawt3dHTVq1MDkyZPx4sULrf0zu8E0OTkZS5cuRdWqVWFvbw9bW1t4eXlh5syZiIuLS7f/uzdQbt26FZUrV4aNjQ3y5s2L9u3ba15H76NOnTooXLgw9u3bh9evX2ttkyQJ27Zt07zxzMjdu3cxZ84c1K1bF4ULF4alpSXy5cuHJk2a4Keffkq3/xdffIHixYsDSH+t3q6Jf/t5EB4ejiFDhqBYsWIwNzfX3N+R0Q2mffr0gUqlQqNGjSBJUroMkyZNgkqlQoUKFZCYmJjd5iIiQbGzTvSe0kbS//jjD70et3v3bqSmpsLb2xvVq1fPjWgGUb9+fRQsWBDff/99uo5Y2kimsUcsdXVcMpKSkoLvv/8ewJtPMt7H77//Di8vL6xatQrh4eGoUKECrK2tceTIETRr1gyTJk3K8LExMTHw8/PD8uXL4ezsDHd3d/z777+YNGlSujcONWvW1NSoW1paombNmprFwcHhvbKn6dSpE4YPH46LFy/C1dUVXl5eMDMzwx9//IFp06Zl++bf+Ph4NGnSBEOHDsXFixdRqFAhlCxZEjdu3MDEiRNRs2ZNREZGZvj4wMBAdOvWDREREShdujTi4uKwd+9e+Pv7IyIi4r1+N5VKha5du+L169fYt2+f1razZ8/i/v37aNWqFezs7DI8xqxZszB+/HhcvnwZNjY2qFixIszNzfHzzz+jefPmmDNnjtb+pUuXzvBa6brHJTw8HJUrV8aqVavg4OAADw+PDOvr0yxatAiffPIJjh8/jsWLF2tt+/333zFr1ixYWFhg69atsLS0zPRYRPQBkLcKh0h5sluzvmbNGs1+7du3l3755RcpMTExy+N/+umnEgBp+PDh75XPGDXrJUqUkCRJksaMGSMBkLZv367ZJz4+XrK3t5fc3NyklJQUafr06blesy5JkhQWFiZZWlpKAKTvvvsuy2NdvHhRU6seHR2drfO/7fXr11KRIkUkAFKHDh2k2NhYzbaNGzdKpqamEgDp0KFDWo9Luz7m5uZS7dq1pcePH2u2HThwQPO44OBgrcdlVQddp04dCYB06tQpndt79OiRru0uXbokAZAKFy4s3bp1S2v/mJgYac2aNVJoaKjW+rRr8O41GzVqlOZ+hsuXL2vWh4SESGXLltW0k67fyczMTLK3t9dqq7CwMKlixYoSAGncuHE6f6eMpGX89ddfpZs3b0oApICAAK19+vbtq7k+Dx8+zPA1fejQIenChQtSamqq1vozZ85Ibm5ukqmpqfTPP//o/L0yq1lPex6YmppKfn5+WvdKxMfHZ3mcc+fOSaamppKVlZV048YNSZLePCdLlSolAZDmzJmTaRsR0YeDI+tE7+mLL75As2bNAAB79uxB3bp1YWdnhypVqmD48OEZlis8fvwYADQfpStZ2sj526UwP/zwA2JjY9G5c+csRwgN5fnz5+jWrRsSExPh5OSERo0aZfmYtHZ2dHSEo6Oj3ufcvn07QkND4erqik2bNmmNzvbo0UNTMhMUFKTz8WZmZti2bRvc3d0161q0aIGWLVsCQIZlNIaUVi7Url07lCtXTmubvb09+vTpg8KFC2d5nNjYWKxcuRLAm9p/Hx8fzbaSJUti8+bNAN68Dv799990j09JScHkyZO17gkoUKAAZsyYASBnbeHh4QFvb2+cOHECYWFhAIDExETs2bMH+fPnz/K50rRpU1SrVi3dtI61atXC9OnToVarsWvXrvfOZ2Zmhr1792rdK2FlZZXl42rUqIGxY8ciISEBn3/+OZKSkjBy5EiEhISgdu3aGD169HtnIiKxsLNO9J7MzMxw4MABrF27FpUrV4ZKpUJSUhIuXbqExYsXo169evD398fDhw+1Hvfy5UsAMPpNo++jQoUKqFixIo4dO4bnz58DME4JzKxZs+Dv7w9/f394enqicOHCOH78OMzNzbFmzZpMyxrS5LSdjx49CgDo27evzs7VsGHDAADnz59PVy8NAE2aNEl3MysAVKlSBQByVKudXWkd8RMnTiAqKuq9j3P27FnExcWhSJEimjcbb6tSpQr8/PwgSVKGN//27t1b5+OAnLdFt27doFarNfeCHDx4EC9evEDnzp1hZpb1DMXh4eFYvHgxunTpgoYNG2qee2nzqF+/fv29szVs2FDrDZs+pk6dCm9vb1y7dg3NmzfHt99+C3t7e2zevBkmJvznm+hjwVc7UQ6Ympqid+/euHjxIsLDw3Hw4EF89dVXKF++PADg3LlzCAgI0LoJLK2jqauDp0Sff/45UlJSsGPHDkRERODIkSMoX7683jfW6iMkJATnzp3DuXPnEBISggIFCuDzzz/HH3/8gbZt22brGDlt57QvSfLw8NC5vVSpUrCwsIBardY5mlyiRAmdj0ubPz5tzvfc5Ofnh2rVquHPP/9E4cKF0apVKyxYsACXL1/Wq/4/rS3Kli2b4RcLpT3ndX25lIuLi87ae0O1RdqnPGmfAKX9N+0m6cwcPXoUpUqVwvDhw7Fjxw6cOHFC89xL+76FnLzRefcTDX2Ym5tj69atsLKy0rwJWrJkCYoWLfrexyQi8bCzTmQgzs7O+PTTTzFz5kz89ddfWLhwIQDg77//1vpSpLQvQLl3754sOfXVtWtXmJiYYOvWrdi5cydSUlJy/cbSDRs2QJIkSJKExMREPHjwAFu2bNHrDUJaO7948SLdjCfZkdaBTOtQvkulUiFfvnwA/hvFf1tGI/ppI6L6dJbfl4mJCQ4fPoxhw4bB2toaP/zwA0aNGoXKlSujePHi6WaOyUhWbQG8mV4TeL+2yKkCBQqgYcOGuHbtGs6cOYPDhw+jbNmyWX6x1IsXL9CpUyfExMSge/fuuHDhAqKjo6FWq7U+JXj3W4T1kdNP0EqWLIkiRYoAeDNjUXbfrBLRh4OddaJcoFKpMHz4cM3H/G/PGFOjRg0AwOnTp2XJpi93d3fUr18fly5dwrx582BiYoKuXbvKHStLXl5esLGxgSRJOHPmjN6Pz5MnDwBoyn/eJUkSwsPDASBbZTk5lTainVEnP6NPEJycnLBo0SKEh4fj6tWrmhKtBw8eoGfPnjq/XfddWbUFADx79gyAcdpCl7Q3kN26dUNSUlK23lAePnwY0dHR8PPzw8aNG1GtWjU4Ojpq3kS8W8ImhwkTJuDOnTswMTFBTEyM5nsDiOjjwc46US765JNPAABJSUmade3bt4eJiQmuXr2KCxcuyBVNL2nlBKGhoahTp47OWmylMTc318yvvWLFCr0fX7p0aQDArVu3dG4PCQlBUlISTE1NMyx5MaS0Edq0Nwjv+ueffzJ9vEqlQqVKlTB06FCcPHkS48ePBwCsWbMmy3OntUVwcHCGbxZu3rypta+xtW7dGnny5EFoaKhmSsespE1b6efnp7O8J6Na9YxKgQztzJkzWLBgAWxsbHDs2DE4Ojpi7dq1+PHHH41yfiJSBnbWid5TZqOMwJuPzi9evAgAWl9qVKpUKXTs2BHAm5vusqqH3b9/f7a/BCi3tG3bFgEBAWjQoAGGDh0qaxZ9jBs3TjNn9qpVqzLdNyYmBqtXr9b83LhxYwBvOrMJCQnp9l+yZAmAN3OkG+Nm4bQ3fmnPqbddunRJ75sg0+b4f/LkSZb7+vv7w8bGBg8fPsQPP/yg8/y//fab5ot85GBjY4NRo0ahQYMG6N+/f7bqutO+LTbtU4G3RUZGYt26dZk+Lu1bZ3NDbGwsevTogdTUVMybNw/169fH8uXLAbz50qSM3rQR0YeHnXWi99S/f3+0aNECP/74Y7p/tP/991907NgRd+/ehY2NDTp06KC1ffny5ShRogRu3bqF6tWr48CBA+nqYq9du4YuXbqgTZs2st+MmidPHvz88884fvw4WrVqJWsWfXh6emL+/PkAgEGDBmHo0KF49OiR1j4xMTFYu3YtPD09cejQIc36zp07o0iRInj27Bm++OILrZsgt27dim+//RYANCPUuS1t2sM1a9ZolVWFhISgR48eOmc92bZtG6ZPn57ui48iIyM1bzbenoYxI/b29povchoyZAiuXr2q2fbvv/+iR48eAIAOHToY5VOGjEyZMgXHjx/XTDOZlVq1agF480Vlx48f16wPCwtD27Zt033TbJp8+fLBzs4Oz58/R3BwcM6D6zB06FDcv38fAQEBGDRoEACgS5cu6NixI54/f45+/frlynmJSHmyntOKiDJ08OBBHDx4EObm5ihZsiTs7Ozw9OlTPHr0CKmpqbCyssKmTZvSlY04OTnh3Llz6NChA86cOYOWLVvCzs4On3zyCczMzPDw4UPNyH3ZsmU1N++97dy5c3Bxcckw24ABAzTzWMvNx8cnw5sJHRwcdM6mYihffvklbGxsMGzYMCxduhRLly7FJ598AhcXF8TExODu3btITk6GmZkZ/P39NY+zsbHB7t270bhxY+zatQsHDx5EuXLl8OzZM00t88SJE7XmDs9NTZo0QcOGDXH8+HH4+fmhVKlSMDc3x61bt+Dv749KlSph+/btWo8JDw/HpEmTMGnSJBQsWBDu7u6Ij4/HnTt3kJSUhIIFC2L69OnZOv/06dNx5coVnDp1Cj4+PvDw8IC5uTlu3LgBtVoNLy8vzcivKHx9fdGuXTvs3bsXjRo1QsmSJZEnTx7cuHED1tbWmD17NoYPH57ucSqVCu3bt8f69evh4+MDT09PzacrGX2/gj727duHTZs2wcnJCRs2bNDatnLlSvz666/Yv38/NmzYgJ49e+b4fESkbOysE72nTZs24dixYzh8+DCuXLmCJ0+eICQkRPOV5Q0aNMCgQYM05QvvcnV1xenTp3Hw4EHs3LkT58+fR0hICNRqNQoUKIC2bduiQ4cOaNOmjc5R05SUlEy/3t0YUwNmV3R0dIbbMhq9NKTevXujefPmWLVqFX7++WeEhIQgNDQUefLkgbe3Nxo0aIA+ffqku1bVqlXD9evXERQUhCNHjuDPP/+Era0tAgICMGzYMM2XYhmDSqXCvn37MHnyZOzevRv37t1DwYIFERgYiK+//lrzJU1va9u2LZKSknD8+HHcvn0bf/31F2xtbeHp6Yk2bdpg8ODB2f7CKGtra/z8889YuXIltmzZguDgYKSmpsLDwwMdO3bEiBEjYGNjY+DfOvdt27YN5cqVw5YtW/DgwQM4OzujXbt2mDJliuZLlnRZvHgx7Ozs8MMPP+D69es5mjHmbc+ePdOMmq9YsSLdHO1pHfgmTZpg2LBhqFevHooVK2aQcxORMqkkY8wfRkREREREemPNOhERERGRQrGzTkRERESkUKxZJ/pAzZo1S2t2k8y4ublhz549uZyIiIiI9MXOOtEH6s6dOzh37ly29s3OnNRERERkfLzBlIiIiIhIoVizTkRERESkUOysExEREREp1Adbs25dZaTcEbIl/Ox8uSNkycxUJXcEIiIiek9WCuvtWXsPkTuCRvzVZXJHyBJH1omIiIiIFIqddSIiIiIihVLYByNERERE9EFTcaxYH2wtIiIiIiKFYmediIiIiEihWAZDRERERMaj4ixz+uDIOhERERGRQrGzTkRERESkUCyDISIiIiLj4WwwemFrEREREREpFEfWiYiIiMh4eIOpXjiyTkRERESkUOysExEREREpFMtgiIiIiMh4eIOpXthaREREREQKxc46EREREZFCsQyGiIiIiIyHs8HohSPrREREREQK9VF31kd/0QBnNw3H819m4cHPU7F7Xk+UKppPs93M1AQzhjTHxR1jEHEmCHcPTcbaKZ3h5mKvdRwLc1MsGN0aD49NQ8SZIOyZ3wsF8zsY7ff4dsVS+FYsq7UE1PM32vn1sWvHNjQNqI8q3hXQqX0bXLl8Se5IOomQU4SMgBg5RcgIiJFThIyAGDlFyAiIkVOEjIA4OXNMZaKcRQBipMwltXxKYNWec6jTazGaD/kWpqYmOLi0P2ysLAAANlYWqFS2IGavOwq/bgvQaexGlCqSH3vm99Y6zryRrfBZ3QroPmELGvRZhjzWlvhuYR+YmBjvY54SJUrh55O/apZd3x0w2rmz68jhQ5g7Owh9+w3Err374ePji0H9+yLsyRO5o2kRIacIGQExcoqQERAjpwgZATFyipARECOnCBkBcXKS8akkSZLkDpEbrKuM1PsxLo62eHhsOhr2W4ZzV+/q3MfXozDObhqB0s2n4eGzF7C3tcLDY9PQe/J27D12DQDg5mKPkIOT0Gr4Ghy/cDvTc4afna93znd9u2Ipfjl1Ajv27M/xsXQxMzXMm46undqjnIcHJk6aqlnXqkVT1KvfEMNGjDLIOQxBhJwiZATEyClCRkCMnCJkBMTIKUJGQIycImQEcjenlcLuULSuPk7uCBrxF+bIHSFLH/XI+rvs81gDAKJj4zLZxwqpqal48SoeAOBdrhAszM20OuVhEbG4+e9TVK9YLFfzvi30wQM0blALLZo0QODYkXj06KHRzp0dyUlJCL51E341tMtz/GrUxPVrV2VKlZ4IOUXICIiRU4SMgBg5RcgIiJFThIyAGDlFyAiIk9NgVCrlLAJQ2Hstec0Z8RnOXb2LW/8+1bnd0sIM0wc3x66fr+Ll60QAQAFneyQmpeDFy3itfZ9HvYSrs72uwxicZwUvTJs5G0WKFkNUVCTWrV6JXt06Y/e+H+Ho6GSUDFmJfhENtVoNZ2dnrfXOzi6IiAiXKVV6IuQUISMgRk4RMgJi5BQhIyBGThEyAmLkFCEjIE5OkofiR9YfPnyIXr16ZbpPYmIiYmNjtRYpNUWv8ywc2wYVSrqjx8QtOrebmZpgy8xuMDFRYdicvVkeT6UCjFVhVLNWbTRo1BilSpdBteo1sHjZtwCAgwf2G+X8+lC98y5WkqR065RAhJwiZATEyClCRkCMnCJkBMTIKUJGQIycImQExMlJxqX4znpUVBQ2bdqU6T5BQUFwcHDQWlLCLmb7HAtGt0bz2uXReOAKPH4ek267makJtgX1QFF3ZzQfskozqg4ATyNjYWlhBkc7a63H5HOyw/Ool9nOYEjWNjYoWao0Qh88kOX8ujg5OsHU1BQRERFa66OiIuHs7CJTqvREyClCRkCMnCJkBMTIKUJGQIycImQExMgpQkZAnJwGI/cMMJwNRj8HDhzIdDl16lSWxwgMDERMTIzWYuZWJVvnXzimDVrWq4gmA1fiwZOodNvTOuolirjg08ErERWjXc9+NfgRkpJT0KBaac26As52KF+iAC78eT9bGQwtKSkJ9+7+C5d8+bLe2UjMLSxQzqM8Lpw/p7X+wvnz8KrkLVOq9ETIKUJGQIycImQExMgpQkZAjJwiZATEyClCRkCcnCQP2WvWW7VqBZVKlWnJSFYfAVlaWsLS0lL7MSZZ/2qLxrVFx8Y+aD96PV7FJcLV2Q4AEPMqAQmJyTA1NcH2OV/Au2xBtBmxDqamJpp9omLikJyiRuzrBGz84XfMHv4ZImPiEB0Th6DhLXDj3zCc/ONOlhkMYeE3c1C7bj0UKOCuqVl//foVWnzWyijnz65uPXpiwvix8PD0hJeXN77bswthYWFo37GT3NG0iJBThIyAGDlFyAiIkVOEjIAYOUXICIiRU4SMgDg5yfhk76y7ublh+fLlaNWqlc7t165dg6+vb66cu3+7mgCAY98O1lrfd+oObD14EQXzO6BFHU8AwB/bR2vtE9B/OX698i8AYOzCH6BWp2LrrO6wtjLHqYsh6Dd1HVJTjVOz/vz5M3w1bhReRL+AU14nVKjghY1bd8HNvaBRzp9dTZo2Q8yLaKxeuQLh4c9RslRpLF+1Gu7MqTcRMgJi5BQhIyBGThEyAmLkFCEjIEZOETIC4uQ0CNbh60X2edY/++wzVKpUCdOmTdO5/fr16/D29kZqaqpex32fedblYIh51nOboeZZJyIiIuNT3DzrNSfIHUEj/txMuSNkSfbLN2bMGLx+/TrD7SVLlsxW3ToRERERCUCQGzuVQvbOeq1atTLdbmtrizp16hgpDRERERGRcvCtDRERERGRQsk+sk5EREREHxHeYKoXjqwTERERESkUO+tERERERArFMhgiIiIiMh7OBqMXthYRERERkUKxs05EREREpFAsgyEiIiIi42EZjF7YWkRERERECsWRdSIiIiIyHhPOs64PjqwTERERESkUO+tERERERArFMhgiIiIiMh7eYKoXthYRERERkUKxs05EREREpFAsgyEiIiIi41FxNhh9cGSdiIiIiEih2FknIiIiIlKoD7YMJvq3BXJHyBangJlyR8hS9NEJckf4YKhTJbkjZEticqrcEbJkY2kqdwQiInofnA1GL2wtIiIiIiKF+mBH1omIiIhIgXiDqV44sk5EREREpFDsrBMRERERKRTLYIiIiIjIeHiDqV7YWkRERERECsXOOhERERGRQrEMhoiIiIiMh7PB6IUj60RERERECsWRdSIiIiIyHt5gqhe2FhERERGRQrGzTkRERESkUCyDISIiIiLj4Q2meuHIOhERERGRQrGzTkRERESkUCyDISIiIiLj4WwwemFrEREREREpFDvrREREREQKxc56NuzasQ1NA+qjincFdGrfBlcuX5I1z4QetRB/coLWcm/vMACAmakJZvSth4tr+yLipzG4u3so1o5vATfnPLJmTqO0tsyI0nNevnQRw4YMQED9WvCpUBanThyXO1I63+/Zic87tEKDWlXQoFYV9O3RGb+dOyN3LJ2Ufr3TiJBThIyAGDlFyAiIkVOEjIA4OXNMpVLOIgB21rNw5PAhzJ0dhL79BmLX3v3w8fHFoP59Efbkiay5bt57jmJtF2mWKr3XAABsrMxRqVQBzN5yFn4D1qHT5L0oVcgZe2Z0kDUvoNy2fJcIORPi41G6dFmM++pruaNkKF9+VwwaOgIbtu7Bhq174FulGsaOGIK7/4bIHU2LCNcbECOnCBkBMXKKkBEQI6cIGQFxcpLxqSRJkuQOkRsSUgxznK6d2qOchwcmTpqqWdeqRVPUq98Qw0aMyvHxnQJm6v2YCT1qoUXNMqjeb2229vct44azK3uhdKelePg8Vu/zRR+doPdjdMnttjSU3MypTjX8y82nQlnMX7QM9Ro0NNgxE5NTDXastwXUrY4hw8fgs1Ztc3wsG0tTAyTi89KQRMgIiJFThIyAGDlFyAjkbk4rhU0nYt18mdwRNOIPDpE7QpY4sp6J5KQkBN+6Cb8a/lrr/WrUxPVrV2VK9UbJgk64u3sogrcNxuaJrVDMzTHDfe1tLZGaKuHFqwTjBXyHktvybaLkFI1arcaxnw8hIT4eFSp6yR1HQ5TrLUJOETICYuQUISMgRk4RMgLi5CR5KOy9lrJEv4iGWq2Gs7Oz1npnZxdERITLlAq4GPwEfWYfQMijKOR3ssX4z/1xamkP+PZajajYeK19Lc1NMb1vfew6cQMv45JkSqzctnyXKDlF8U/IHfT7ojOSkpJgbW2D2fOXoPgnJeWOpSHK9RYhpwgZATFyipARECOnCBkBcXKSPBQxsh4fH4+zZ8/i1q1b6bYlJCRg8+bNmT4+MTERsbGxWktiYqLB8qneuQFBkqR064zp6B//Yv+vt3HzXjhOXbmP1l/tAgB8HlBBaz8zUxNs+bo1TExUGLb4iBxR01FaW2ZElJxKV7RYMWza8T3WbNqB1u07Yvqkr3Dv7j9yx0pHlOstQk4RMgJi5BQhIyBGThEyAuLkzDGViXIWAcie8s6dOyhXrhxq166NChUqoG7duggLC9Nsj4mJQc+ePTM9RlBQEBwcHLSWeXOCcpzNydEJpqamiIiI0FofFRUJZ2eXHB/fUOISknHz7nOUKJRXs87M1ATbJrdBUTdHNB+zXdZRdUCcthQlpyjMzS1QuEhRlPPwxKAvR6Jk6TLYtX2L3LE0RLneIuQUISMgRk4RMgJi5BQhIyBOTpKH7J31cePGoUKFCnj+/Dlu374Ne3t71KxZE6Ghodk+RmBgIGJiYrSWMeMCc5zN3MIC5TzK48L5c1rrL5w/D69K3jk+vqFYmJuibFEXPI18BeC/jnqJgk74dPT2dKUxchClLUXJKSpJkpCcnCx3DA1RrrcIOUXICIiRU4SMgBg5RcgIiJOT5CF7zfr58+dx/PhxuLi4wMXFBQcOHMDgwYNRq1YtnDp1Cra2tlkew9LSEpaWllrrDDUbTLcePTFh/Fh4eHrCy8sb3+3ZhbCwMLTv2MkwJ3gPQQMa4KfzIXj4PAb5HW0xrps/7Gwsse3onzA1UWH7lLbwLlUAbb7aBVMTFVyd3rRh1Mt4JKfkziwf2aHEttRFhJxxca/x8K03tI8fP8Ltv4Nh7+AANzd3GZP9Z+XShfCrWQuuBdzw+vVrHP/5EK5evoiFy1bLHU2LCNcbECOnCBkBMXKKkBEQI6cIGQFxchrEh1jak4tk76zHx8fDzEw7xvLly2FiYoI6depg+/btMiV7o0nTZoh5EY3VK1cgPPw5SpYqjeWrVsPdvaBsmQq62GHzxFZwdrBBREwc/rj1GHWGbETos1gUcXVAi5qlAQB/rO2r9biAEVvw6/Xsf2JhaEpsS11EyHnr5g3069VD8/OCebMBAC0+a4WpM2fLFUtLVFQkpn49HpER4ciTxw4lSpXGwmWrUbV6DbmjaRHhegNi5BQhIyBGThEyAmLkFCEjIE5OMj7Z51mvWrUqvvzyS3Tr1i3dtiFDhmDbtm2IjY2FWq3W67iGGlnPbe8zz7qxGWqedcqdedZzQ27Ns25IhppnnYjoQ6e4edY/Wyl3BI34AwPljpAl2WvWW7dujR07dujctmzZMnTu3Bkf6Pc2EREREX185J4BRrDZYGQfWc8tHFk3HI6sGw5H1g2HI+tERNmjuJH1lt/KHUEj/of+ckfIksIuHxERERF90HiDqV7EGP8nIiIiIvoIsbNORERERKRQLIMhIiIiIuMR5MZOpWBrEREREREpFDvrREREREQKxTIYIiIiIjIezgajF46sExEREREpFEfWiYiIiMhoVBxZ1wtH1omIiIiIFIqddSIiIiIihWIZDBEREREZDctg9MORdSIiIiIihWJnnYiIiIhIoVgGQ0RERETGwyoYvXBknYiIiIhIodhZJyIiIiJSKJbBEBEREZHRcDYY/bCzLrPooxPkjpAlJ/9xckfIlqhf58gdIUumJmL8gbKxNJU7AlE6ySmpckfIkrkZP7AmIsNiZ52IiIiIjIYj6/rhEAARERERkUKxs05EREREpFAsgyEiIiIio2EZjH44sk5EREREpFDsrBMRERERKRTLYIiIiIjIaFgGox+OrBMRERERKRQ760RERERECsUyGCIiIiIyHlbB6IUj60RERERECsWRdSIiIiIyGt5gqh+OrBMRERERKRQ760RERERECsUyGCIiIiIyGpbB6Icj60RERERECsXOOhERERGRQrEMhoiIiIiMhmUw+uHIejbs2rENTQPqo4p3BXRq3wZXLl+SO5JOcuasWak49n7TA3d/nID4C3PQoraH1vb8efNg9dftcffHCYj8ZTp+WNgLJQo7a+1TvGBe7JrdDaGHv8azE1OxdUZX5M+bx2i/Q5rLly5i6OABaFTPH5U8y+DkieNGz5AdfF4ajggZATFyipDx+bNn+DpwLBrUro6a1bzRpUNrBN+6KXesdERoS0CMnCJkBMTJScbFznoWjhw+hLmzg9C330Ds2rsfPj6+GNS/L8KePJE7mha5c9paW+CvkDCMmL9f5/bdc7qjuHtetB+7CdW7L0bo0xc4tKQvbKzMAQA2VuY4uLgPJABNh6xB/X4rYWFuiu/mfWH0d+Dx8XEoXaYMxn81yajn1Yfc1zu7RMgpQkZAjJwiZIyNjUHvL7rAzMwMi5evxp7vD2L4qLGws7OTO5oWEdoSECOnCBkBcXKS8akkSZLkDpEbElIMc5yundqjnIcHJk6aqlnXqkVT1KvfEMNGjDLMSQwgN3M6+Y/Ta//4C3PQYewm/HjmFgCgZGEX/LVnDHw6L0DwvWcAABMTFUIPf42Jyw9j44GLaFC1FH5Y2AtujabgZVwiAMDRzhphx6ag2ZdrcOriP1meN+rXOXr+Zlmr5FkGCxYvR/0GDQ1yPEO97+Dz0nBEyAiIkTO3MyanpOb4GEsXzcf1a1exduPWHB9LF3Mzw4yBiXC9ATFyipARyN2cVgorenbuvkPuCBqRmzvLHSFLHFnPRHJSEoJv3YRfDX+t9X41auL6tasypUpP6TktLd78lUhIStasS02VkJSsRg2vYpp9JElCYvJ/77ISkpKhVqdq9qE3lH6904iQU4SMgBg5RcgIAGdOn0K58uUxbvRwNKpbE106tMG+73bLHUuLKG0pQk4RMgLi5CR5sLOeiegX0VCr1XB21q6tdnZ2QUREuEyp0lN6ztv3n+NBWBSmD2wKRztrmJuZYnS3unBzsUcBZ3sAwB83QvE6IRkzBzeDtaU5bKzMETTkU5iammj2oTeUfr3TiJBThIyAGDlFyAgAjx89xHe7d6JIkaJYunIN2rbviG/mzMLBH/fLHU1DlLYUIacIGQFxchqMSkGLABTxwUhwcDAuXLgAPz8/lC1bFn///TcWL16MxMREfP7556hfv36mj09MTERiYqLWOsnUEpaWlgbJ927NtCRJiryTWak5U9Sp6Dx+K1ZOaIewY1OQkqLGyYv/4Mj5vzX7RLx4ja5fbcWSsa0xqEMNpKZK2H3sOq78/Qjq1Jx/9P0hUur1fpcIOUXICIiRU+kZU1MleJQvj8FDRwAAypbzwN1//8F3u3eieYtW8oZ7h9LbMo0IOUXICIiTk4xL9s76kSNH0LJlS+TJkwdxcXHYt28funfvDi8vL0iShMaNG+Pnn3/OtMMeFBSEqVOnaq2b8PVkTJw0JUfZnBydYGpqioiICK31UVGRcHZ2ydGxDUmEnFdvP0b17othb2sFC3NTRLx4jTPrBuNy8CPNPif+CEH5dnPh7GCDFHUqYl4l4N5PE/HgyXUZkyuPCNcbECOnCBkBMXKKkBEAXPK5oPgnJbTWFf/kE5w8flSmROmJ0pYi5BQhIyBOTpKH7GUw06ZNw5gxYxAZGYkNGzagS5cu6Nu3L44dO4bjx49j7NixmD17dqbHCAwMRExMjNYyZlxgjrOZW1ignEd5XDh/Tmv9hfPn4VXJO8fHNxRRcgJA7OsERLx4jRKFneFTthAO/v8m1LdFxsQh5lUC6viWQH4nWxz8Nf0+HzNRrrcIOUXICIiRU4SMAOBVyQcP7t/XWvfgwX24ubvLE0gHUdpShJwiZATEyWkoKpVKMYsIZB9Zv3nzJjZv3gwA6NChA7p164a2bdtqtnfu3Bnr1q3L9BiWlulLXgw1G0y3Hj0xYfxYeHh6wsvLG9/t2YWwsDC079jJMCcwELlz2lpboESh/2rtirnnRcVSboiOjcfDZy/Qpn4FhL94jYdPX8CzRAF8M7IFfjxzEyf+CPnvd/i0Mm7ff47wF69QrUJRfDOiBZbuPIuQ0Ahdp8w1cXGvERoaqvn58eNH+PvvYDg4OMDNTRn/oMt9vbNLhJwiZATEyClCxi6f90CvHl2wfu23aBTQBDdv/IV9e/dgwqSpWT/YiERoS0CMnCJkBMTJScYne2f9bSYmJrCysoKjo6NmnZ2dHWJiYmTL1KRpM8S8iMbqlSsQHv4cJUuVxvJVq+HuXlC2TLrIndOnXCEcXdFf8/Pc4S0AAFt+uoR+0/eggIsd5gxrjvx58+BpxEtsO3wFQetPaB2jdFEXTBvUBHntrfEgLBpzN57Ckh2/GiX/227euIG+vbprfp4/NwgA0KJla0yfmfmnPMYi9/XOLhFyipARECOnCBnLe1bANwuWYNmShVj77Qq4FyyEUWPHo+mnLeSOpkWEtgTEyClCRkCcnGR8ss+z7uXlhTlz5qBJkyYAgBs3bqBs2bIwM3vzPuLs2bPo3r077t69q9dxDTWyTvrPsy6X3Jhn3dAE+cSNSJEMMc96bjPUPOtEhqS0edbz9dwldwSN8A0d5Y6QJdkv38CBA6FWqzU/e3p6am0/fPhwlrPBEBERERF9iGTvrA8YMCDT7TNnzjRSEiIiIiLKbaLc2KkU/LyOiIiIiCibVqxYgeLFi8PKygq+vr749dfM76/btm0bvLy8YGNjAzc3N/Ts2RORkZHZPh8760RERERE2bBr1y4MHz4cEyZMwNWrV1GrVi00bdpUaxa5t6Xde9m7d2/cvHkTe/bswcWLF9GnT59sn5OddSIiIiIyHpWCFj0tWLAAvXv3Rp8+fVCuXDksWrQIhQsXxsqVK3Xuf+HCBRQrVgxDhw5F8eLF4e/vj/79++PSpUvZPic760REREREWUhKSsLly5cREBCgtT4gIADnz5/X+ZgaNWrg0aNHOHToECRJwrNnz7B37158+umn2T4vO+tERERE9FFKTExEbGys1pKYmKhz34iICKjVari6umqtd3V1xdOnT3U+pkaNGti2bRs6duwICwsLFChQAI6Ojli6dGm2M7KzTkRERERGo1KpFLMEBQXBwcFBawkKCsoy/9skScpwhptbt25h6NChmDRpEi5fvowjR47g3r17Wc6G+DbZp24kIiIiIpJDYGAgRo4cqbXO0tJS574uLi4wNTVNN4r+/PnzdKPtaYKCglCzZk2MGTMGAFCxYkXY2tqiVq1amDFjBtzc3LLMyJF1IiIiIvooWVpawt7eXmvJqLNuYWEBX19fHDt2TGv9sWPHUKNGDZ2PiYuLg4mJdnfb1NQUwJsR+ezgyDoRERERGY3IX4o0cuRIdOvWDZUrV4afnx9Wr16N0NBQTVlLYGAgHj9+jM2bNwMAWrRogb59+2LlypVo3LgxwsLCMHz4cFStWhXu7u7ZOic760RERERE2dCxY0dERkZi2rRpCAsLg6enJw4dOoSiRYsCAMLCwrTmXP/iiy/w8uVLLFu2DKNGjYKjoyPq16+POXPmZPucKim7Y/CCSUiRO8GHw8l/nNwRsiXq1+w/8eUi8GACkeySU1LljpAlczNWl5LyWClsaNat33dyR9AIW91W7ghZ4l8VIiIiIiKFYmediIiIiEihFPbBCBERERF9yES+wVQOHFknIiIiIlIodtaJiIiIiBSKZTBEREREZDysgtELR9aJiIiIiBSKI+uUpeizyp+/HACcqgyRO0KWoi8ukzsCUTqifNsG5zAnoo8RO+tEREREZDScDUY/HKYgIiIiIlIojqwTERERkdFwZF0/HFknIiIiIlIodtaJiIiIiBSKZTBEREREZDQsg9EPR9aJiIiIiBSKnXUiIiIiIoViGQwRERERGQ+rYPTCkXUiIiIiIoViZ52IiIiISKFYBkNERERERsPZYPTDkXUiIiIiIoXiyDoRERERGQ1H1vXDkXUiIiIiIoViZ52IiIiISKFYBkNERERERsMyGP1wZJ2IiIiISKHYWc+GXTu2oWlAfVTxroBO7dvgyuVLckfSSYSccmes6VMCexf1x92jMxF/dRla1K2Ybp8yxV2xZ1F/PD0zD8/PfoPTm0ahcAEnzfbihVywa35fhJ4MwrNf52HrnF7In9fOmL8GAPnbMrtEyClCRkD5OS9fuoihgwegUT1/VPIsg5MnjssdKUNKb0tAjIyAGDlFyAiIk5OMi531LBw5fAhzZwehb7+B2LV3P3x8fDGof1+EPXkidzQtIuRUQkZba0v8decxRszerXN78UIuOLF+JO7ce4rGfRejascgBK05goTEZACAjZUFDq4YDEmS0LTfUtTvuRAW5qb4bnF/o36sp4S2zA4RcoqQERAjZ3x8HEqXKYPxX02SO0qmRGhLETICYuQUISMgTk5DUKlUillEoJIkSZI7RG5ISDHMcbp2ao9yHh6YOGmqZl2rFk1Rr35DDBsxyjAnMQARcuZ2RqcqQ/TaP/7qMnQYsRo//vKnZt3m2T2RnKxG768363xMg+pl8cOyQXCrMxYvXycAABztrBF2Zh6aDViKU7/fzvSc0ReX6ZUxIyJcb0CMnCJkBHI3Z278K1DJswwWLF6O+g0aGuyYhvp3VYRrLkJGQIycImQEcjenlcLuUCw+/Ce5I2jcW/Sp3BGypMiRdaW8f0hOSkLwrZvwq+Gvtd6vRk1cv3ZVplTpiZBThIwqlQpN/MsjJPQ5DiwfjAcngnBm82itUhlLCzNIkoTEpP/eDSYkpUCtTkWNSiWMklOEtgTEyClCRkCcnCIQoS1FyAiIkVOEjIA4OQ1GpaBFAIrsrFtaWiI4OFjuGIh+EQ21Wg1nZ2et9c7OLoiICJcpVXoi5BQhY/68eWBna4XRPRvh2PlbaDFwGQ6cuo6d8/vA37ckAOCPv+7jdXwSZg5rCWsrc9hYWSBoeCuYmpqggIu9UXKK0JaAGDlFyAiIk1MEIrSlCBkBMXKKkBEQJyfJQ9YPRkaOHKlzvVqtxuzZszVP2gULFmR6nMTERCQmJmqtk0wtYWlpaZCc79Y0SZKkyDonEXIqOaOJyZv3rgd/+QtLt50CAPx55zGqeX2Cvu38cfbyP4iIfoWuY9dhyVcdMahzHaSmSth95DKu3AqFOjXVqHmV3JZvEyGnCBkBcXKKQIS2FCEjIEZOETIC4uQk45K1s75o0SJ4eXnB0dFRa70kSQgODoatrW22nqRBQUGYOnWq1roJX0/GxElTcpTPydEJpqamiIiI0FofFRUJZ2eXHB3bkETIKULGiOhXSE5WI/humNb623efoob3J5qfT1z4G+U/mwpnR1ukpKQi5lU87h2bhQePI42SU4S2BMTIKUJGQJycIhChLUXICIiRU4SMgDg5DYVvQPQjaxnMzJkzERMTg6+//hqnTp3SLKampti4cSNOnTqFkydPZnmcwMBAxMTEaC1jxgXmOJ+5hQXKeZTHhfPntNZfOH8eXpW8c3x8QxEhpwgZk1PUuHzrAUoXddVaX6pofoSGRafbP/LFa8S8ikedKqWRP28eHDz9l1FyitCWgBg5RcgIiJNTBCK0pQgZATFyipARECcnyUPWkfXAwEA0bNgQn3/+OVq0aIGgoCCYm5vrfRxLy/QlL4aaDaZbj56YMH4sPDw94eXlje/27EJYWBjad+xkmBMYiAg5lZDR1toCJQrn0/xcrKAzKpYuiOjYODx8Go2Fm45jy5xeOHvlH5y+dAcBNTzQrLYnGvdd/N/v8Vl13L73FOHRr1CtYnF8M6Ydlm47hZAHz432eyihLbNDhJwiZATEyBkX9xqhoaGanx8/foS//w6Gg4MD3NzcZUymTYS2FCEjIEZOETIC4uQk45N9Mp8qVarg8uXLGDx4MCpXroytW7cq6uORJk2bIeZFNFavXIHw8OcoWao0lq9aDXf3gnJH0yJCTiVk9PEoiqNrh2l+nju6LQBgy4EL6Dd5Kw6c+hNfztyJMb0CMH9sO9x58Bydx6zF+Wt3NY8pXSw/pn35GfI62ODBkyjMXfczlmzN+hMgQ1JCW2aHCDlFyAiIkfPmjRvo26u75uf5c4MAAC1atsb0mbPlipWOCG0pQkZAjJwiZATEyWkISurniUBR86zv3LkTw4cPR3h4OP766y94eHi897EMNbJO4tB3nnU5GGqedSJDUs6/Apnjv+9E70dp86yXGHVY7gga/85vKneELCnq8nXq1An+/v64fPkyihYtKnccIiIiIiJZKaqzDgCFChVCoUKF5I5BRERERLmAn5LpR5FfikRERERERAocWSciIiKiDxdvMNUPR9aJiIiIiBSKnXUiIiIiIoViGQwRERERGQ2rYPTDkXUiIiIiIoViZ52IiIiISKFYBkNERERERsPZYPTDkXUiIiIiIoViZ52IiIiISKFYBkNERERERsMqGP1wZJ2IiIiISKE4sk5ERERERmNiwqF1fXBknYiIiIhIodhZJyIiIiJSKJbBEBEREZHR8AZT/XBknYiIiIhIodhZJyIiIiJSKJbByOx1YorcEbJkaynG0yTi96VyR8hSwV475I6QLSErO8gdIUtWFmKMNZgI8HmvBEnuCNmigvLbUgSpkhjXW4inpTBPSWUFVQnwd1FJxPjXjoiIiIjoI8TOOhERERGRQolR30BEREREHwRWweiHI+tERERERArFkXUiIiIiMhreYKofjqwTERERESkUO+tERERERArFMhgiIiIiMhqWweiHI+tERERERArFzjoRERERkUKxDIaIiIiIjIZVMPrhyDoRERERkUJxZJ2IiIiIjIY3mOqHI+tERERERArFzjoRERERkUKxDIaIiIiIjIZVMPrhyDoRERERkUKxs05EREREpFDsrGfDrh3b0DSgPqp4V0Cn9m1w5fIlWfNcvXwJY4YNwmcBdVHDpzxOnzqhtX3tquXo1KY56teojMZ1/DB0QG/c/OtPmdJqU1pbZmX92m/hU6Es5s2ZZbRz+pXJh20jauPm4paI3NwZzXwKam23tTTDnG6++GtRSzxa2x6/zW6GnvVLZni8XaPq6DyOoV29fAmjhw1Ci4A68PPxwOlTxzXbUpKTsXzxfHTt0BL1aviiRUAdTP16PMLDn+dqpqysW/MtunZsh5pVfVC/dg2MGDoY9+/dlTVTZpT8+mFbGp7SM4pwzXfv2oEObT6Df3Vf+Ff3RfeuHXH21zNyx0pHhLY0JJVKpZhFBOysZ+HI4UOYOzsIffsNxK69++Hj44tB/fsi7MkT2TIlJMSjZOkyGDlugs7tRYoWxahxE7Bl9z6sXL8Fbu4FMXxwX0RHRxk5qTYltmVmbt74C9/v3Y1SpcsY9bw2lma4GRqNcVsu69w+o6s36ld0w4BVv8Fv/CGsPHIbs7v5oqmOzviAxmUg5Xbg/0tIiEOp0mUwatxEHdsScPvvW+jZZwA2bt+LoG+W4OGD+xg7fLCR0ul25dJFdOzcBZu378LK1euhTknBwH59EB8XJ2suXZT++mFbGpYIGUW45q6urvhy+Chs27kX23buRdVq1TFi6GD8+0+I3NG0iNCWJB+VJEnG+rfcqBJSDHOcrp3ao5yHByZOmqpZ16pFU9Sr3xDDRozK8fFfJ+YsaA2f8giavwR16jXI+ByvXqFR7WpYsnIdKlerrvc5bC0Ncx9ybrelOtVwT+W4uNfo0qENAidMxtrVK1G6bDmMGfdVjo9bpM9OvfaP3NwZ3RadwaErjzXrzs5qin2/h2L+Dzc1605MbYzjfz5B0Hd/adaVL+yIHSNro+GUowhe2jrdcTITsrKDXjnf5efjgdnzl6BOvYYZ7nPr5l/o3a0j9v10HAXc3PU+h5WF4ccaoqKi0KB2DazduAW+lasY5JgmBhq5yc3XT2ou/DPwsbaloYh2vYFcuOa51DupU7Maho8ag9Zt2uX8YLk0MGvotrQxV9YIsu/0U3JH0Lj8dT25I2SJI+uZSE5KQvCtm/Cr4a+13q9GTVy/dlWmVPpJTk7CD9/vQZ48dihp5BFirRyCteXsmdPgX6suqvnVkDtKOhfuhKOpd0G4OVkDAPzL5UfJAnY4+VeYZh9rC1OsGVQD47ZcxvOYBLmiZurVq5dQqVSws7OXO4rGq1cvAQAODg4yJ9Em2usHYFvmhAgZdVHqNU+jVqtx5PBPiI+PQ0WvSnLHyZTS2zKnVCrlLCLg1I2ZiH4RDbVaDWdnZ631zs4uiIgIlylV9pw78wsmBY5GQkICnF3yYdHKNXB0cpItj0ht+fPhn/D3rVvYsnOv3FF0CtxyBYt6V8WNxa2QnJKKVEnC8HV/4Pc7EZp9ZnTxwR8hETiczZF0Y0tMTMTKJQsR0ORT2ObJI3ccAIAkSZg/dza8fXxRslRpueNoEen1A7Atc0qEjO9S8jUPuXMbPT7vjKSkRFjb2GD+omUoUSLj+3zkpuS2JHkorrMeHR2NTZs2ISQkBG5ubujRowcKFy6c6WMSExORmJiotU4ytYSlpaVBMr17A4IkSYq/KcGnSlVs2vEdXrx4gQP79uLrcaOwZvMO5M3rnPWDc5HS2/Lp0zDMmz0LK1avM9jzx9D6BZRG5RLO6LLgNB5GxqFGmXyY16MynsXE4/TNZ2jiXRC1PFxR7+sjckfVKSU5GZMCRyFVSsWYwElyx9GYPXM6Qu7cxobN2+WOkiGlv37SsC0NQ4SMaZR8zYsVL46de/fh5ctYnDh2FJMmjsfaDVsU22FXclsailKfx0olexmMu7s7IiMjAQD37t2Dh4cH5syZg5CQEHz77beoUKEC/v7770yPERQUBAcHB61l3pygHGdzcnSCqakpIiIitNZHRUXC2dklx8fPTdbWNihUpCg8K3rhq8nTYWpqioP7v5ctjyhtGXzzJqKiItG1Y1tUqVQeVSqVx+VLF7Fz2xZUqVQearVa1nxW5qaY2L4iJm6/ip+vPcGthy+w9ngI9v0eisFNywEAanm4onj+PLi7qi2ebeiIZxs6AgA2DvXHD4H15YyPlORkTBg/Ek8eP8aSFesUM6o+e9Z0nD51EmvWb4ZrgQJyx0lHlNcPwLY0BBEyvk3p19zc3AJFihRF+fIVMHT4KJQuXRY7tm6WO5ZOSm9LkofsI+tPnz7VdIC++uorlC1bFj/99BNsbGyQmJiIdu3a4euvv8aePXsyPEZgYCBGjhyptU4yzfmoqLmFBcp5lMeF8+fQoGEjzfoL58+jbv2Mb+hUIkmSkJSUJNv5RWnLqtWrY/f3B7TWTfn6KxQr/gm+6NUHpqamMiV7w9xUBQsz03Q3iKlTJZj8f6Bi8cFb2PLLv1rbzwU1w8RtV3HkqnxlMWkd9UehD7Bs9UY4ODrKliWNJEmYM2s6Tp44jjUbNqNgoUJyR9JJhNcP29JwRMgIiHPN05P330NdxG1LMgbZO+tv+/3337F27VrY2NgAACwtLTFx4kS0a5f5HduWlulLXgw1G0y3Hj0xYfxYeHh6wsvLG9/t2YWwsDC079jJMCd4D3Fxr/HoYajm57DHj3DndjDs7R3g4OiITWtXw79OPTi75ENszAt8v2cnwp8/Q/1GjWXLDCizLd9la5snXY2gtbU1HBwdjVY7aGtphuKu/404F8mXB55FHBH9OgmPI+NwNvgZpnaqhIQkNR5GvEbNsvnR0b8Yvt7+5saz5zEJOm8qfRT5GqERr3Mt97vPyyePH2uely758uOrscNx++9gfLN4BVLVakT+v/bW3sEB5uYWuZYrM0EzpuHwoYNYuGQ5bG1tNfXAefLYwcrKSpZMGVH664dtaVgiZBThmi9dvAA1/WujQIECeP36NX4+cgiXLv6B5SvXyB1NiwhtaUisgtGPIjrrabVLiYmJcHV11drm6uqK8HD5bqhp0rQZYl5EY/XKFQgPf46SpUpj+arVcHfP3S+Yyczft25iSL+emp+XLJgLAGjWoiXGfDUZD+7fw6GDPyDmRTQcHBxRtrwnVqzbjE9krs9TYlsqUaXieXHgq/9Gz2Z29QEA7Pj1Loas+R19V5zH1+298O0APzjmscCjiDjM3PsnNpz8R67IAN48Lwf3+0Lz85IFcwAAzVq0Qp/+g/Hr6TdTdXXv1EbrcctXb4RP5apGy/m2Pbt2AAD69uyutX7qjFn4rFUbXQ+RjdJfP2xLwxIhowjXPDIyEhO/GouI8HDksbNDqVJlsHzlGlSvUVPuaFpEaEuSj+zzrJuYmMDT0xNmZmYICQnB5s2b0bp1a832M2fOoEuXLnj06JFexzXUyHpuy+k868ZgqHnWc5sh51nPLfrOsy6XnM6zbgy5Mc96bjDU3OC5Kbfm3TY0EdpSBKJcb6N9o1tOCPKUVNo861Vn/SJ3BI0/vqord4Qsyd4Lmzx5stbPaSUwaX788UfUqlXLmJGIiIiIKJdwNhj9KK6z/q558+YZKQkRERERkbKI8TkyEREREdFHSPaRdSIiIiL6eLAKRj8cWSciIiIiUiiOrBMRERGR0fAGU/1wZJ2IiIiISKHYWSciIiIiUiiWwRARERGR0bAKRj8cWSciIiIiUih21omIiIiIFIplMERERERkNJwNRj8cWSciIiIiUiiOrBMRERGR0XBgXT8cWSciIiIiUih21omIiIiIFIplMERERERkNLzBVD8cWSciIiIiUih21omIiIiIFIplMERERERkNCyD0Q876zKztjCVO8IHw0SAF//v37SSO0K2eAcekjtClm4vaCF3hA9GbFyK3BGyxdHWXO4IHwQR/lYCAASJSZTbWAZDRERERKRQHFknIiIiIqMR5cMdpeDIOhERERGRQnFknYiIiIiMhjeY6ocj60RERERECsXOOhERERGRQrEMhoiIiIiMhlUw+uHIOhERERGRQrGzTkRERESkUCyDISIiIiKj4Www+uHIOhERERGRQrGzTkRERESkUCyDISIiIiKjYRWMfjiyTkRERESkUBxZJyIiIiKjMeHQul44sk5EREREpFDsrBMRERERKRTLYIiIiIjIaFgFox+OrGfDrh3b0DSgPqp4V0Cn9m1w5fIluSNpWbfmW3Tt2A41q/qgfu0aGDF0MO7fuyt3LJ2U3pYAcPnSRQwdPACN6vmjkmcZnDxxXNY8P+3bjcE92qNd45po17gmRg3ojksXzgIAUlKSsX7lIgzq0Q5tGlVHt1aNMH/GRERGPM/1XFVL5MW6flXwx/RGeLCkBQIqFNDa/mBJC51L//olNPtYmJlgaltPXJ3VGMHzmmJt3yoo4GiV69nfJcLzElBWzutXLmH8yMFo06we6lT1xK+/nNDaHhUZgaCpE9CmWT0E1KqMMUP741HoA5nSpqektsyICBkBMXKKkBEQJycZFzvrWThy+BDmzg5C334DsWvvfvj4+GJQ/74Ie/JE7mgaVy5dRMfOXbB5+y6sXL0e6pQUDOzXB/FxcXJH0yJCWwJAfHwcSpcpg/FfTZI7CgDAJb8rvhgwFIvXbMfiNdtR0acKpgcOx4N7/yAxIQH/3glG5x59sWTdTkyYOR+PHz7AtPHDcz2XjYUZgh/HYtKev3RurzzhqNYyets1pKZKOHQ9TLPPpDbl0dirAIZsvIx2i8/B1tIM6/tVhYkRR11EeV4qLWd8QjxKliqD4WO+SrdNkiRMGDMMTx4/wsxvlmDt1j1wdXPHyCF9EB8v/98lpbWlLiJkBMTIKUJGQJycZHwqSZIkuUPkhoQUwxyna6f2KOfhgYmTpmrWtWrRFPXqN8SwEaNyfPzUXGj+qKgoNKhdA2s3boFv5So5Pp6h7trO7bbMjWdyJc8yWLB4Oeo3aGiQ4z2OjjfIcTo2q41eg0agcfPW6bbdCb6BEf0+x4a9h5Hf1e29jt9ghn6fJjxY0gJ911zE0b+eZrjP6j5VkMfSFF2WXwAA2FmZ4cqsxhix5SoOXn3zj1F+e0tcmNYIX6z6HWf+Ds/0nLcXtNArY0Zy+3lpKLmZ88Xr5Bw9vk5VT8yYuxi16jYAADx8cB+ft2+OjTv2o3iJkgAAtVqNVo1ro/+QEWjeqt17ncfR1jxHOdOIcM1FyAiIkVOEjEDu5rRSWNFz4xW/yx1B4+dB1eSOkCWOrGciOSkJwbduwq+Gv9Z6vxo1cf3aVZlSZe3Vq5cAAAcHB5mT/EfUtlQatVqN08ePICEhHuXKV9S5z+vXr6BSqZAnj52R02XMxc4C9cvnx64LDzXrKhR2gIWZiVan/HlsIm6HxcK3uJNRconyvBQlZ5qk5CQAgIWlhWadqakpzMzN8dd1efOK0JYiZATEyClCRkCcnCQPdtYzEf0iGmq1Gs7OzlrrnZ1dEBGR+aifXCRJwvy5s+Ht44uSpUrLHUdDxLZUkvv/hqBtgB9aNaiK5fNnYOLMBShSvES6/ZISE7Fx1RLUadgUNrZ5ZEiqW9uqhfE6IQVH3iqByWdvhcQUNWLjtUd1I14mIZ+9cerWRXleipIzTdFixVHAzR2rly/Gy9gYJCcnY9umtYiKjECkzHlFaEsRMgJi5BQhIyBOTnpjxYoVKF68OKysrODr64tff/010/0TExMxYcIEFC1aFJaWlihRogTWr1+f7fPJ3lm/evUq7t27p/l569atqFmzJgoXLgx/f3/s3Lkzy2MkJiYiNjZWa0lMTDRYRtU7ZSCSJKVbpxSzZ05HyJ3bCJo7X+4oOonUlkpSsEgxLF2/CwtWbUazlh2wYOYkhN77V2uflJRkzJkyDlJqKgaPSl9HLKcO1Ytg/6XHSExJzXJfFd48L4xJlOelKDnNzMwxbfZCPAq9j+YNa6Jx7cq4dvkiqtWoBRNTU7njARCjLUXICIiRU4SMgDg5c8pEpZxFX7t27cLw4cMxYcIEXL16FbVq1ULTpk0RGhqa4WM6dOiAEydOYN26dbh9+zZ27NiBsmXLZr+99I9pWL1798b9+/cBAGvXrkW/fv1QuXJlTJgwAVWqVEHfvn2zfPcRFBQEBwcHrWXenKAcZ3NydIKpqSkiIiK01kdFRcLZ2SXHxze02bOm4/Spk1izfjNcCxTI+gFGJFpbKo25uTncCxVBqbLl8cWAoShesjR+2Ltdsz0lJRmzJ43Fs7AnmLFwlaJG1at8khclXfNg52/af8jCYxNgaWYKe2vtOmRnOwtEvDTcm+3MiPK8FCXn28qUK491277DTyd/w/eHTmHekm8RG/MCbu4FZc0lQluKkBEQI6cIGQFxchKwYMEC9O7dG3369EG5cuWwaNEiFC5cGCtXrtS5/5EjR3D69GkcOnQIDRs2RLFixVC1alXUqFEj2+eUvbN++/ZtlCjx5uP8FStWYNGiRVi8eDEGDBiAhQsX4ttvv8X8+ZmPEgcGBiImJkZrGTMuMMfZzC0sUM6jPC6cP6e1/sL58/Cq5J3j4xuKJEmYPXMaTh4/hm/Xb0TBQoXkjpSOKG0pDElCctKbuuC0jvqTR6GYuXAV7B0c5c32jo5+RfBn6AsEP4nVWv/XwxgkpaSiVtn//iHKb2+JMm72uHwv2ijZRHleipJTlzx57ODolBePQh/gdvBN+NeuJ2seEdpShIyAGDlFyAiIk9NQVCqVYhZ9JCUl4fLlywgICNBaHxAQgPPnz+t8zIEDB1C5cmXMnTsXBQsWROnSpTF69GjEx2d/wgnZ7w+2trZGeHg4ihQpgsePH6NaNe27cqtVq6ZVJqOLpaUlLC0ttdYZajaYbj16YsL4sfDw9ISXlze+27MLYWFhaN+xk2FOYABBM6bh8KGDWLhkOWxtbTX1bXny2MHKyvhzVmdEhLYEgLi411ofZz1+/Ah//x0MBwcHuLm5Gz3Ppm+XwLe6P/Lld0V8XBxOnziCv65dwrRvlkOdkoJZX4/Bv3eCMXnOEqhTUxEV+WZkxs7eAebmhpk9QxcbC1MUy2er+bmwsw08CtrjRVwynvx/1ps8Vmb4tJIbZuy/le7xLxNSsOtCKCa2Ko8Xr5PxIi4JE1p64O8nsTh723g1mqI8L5WWMy4uDo8f/fc6CXvyGCF3/oa9vQNcC7jh1PGf4ejkBNcCbrj7TwiWLpgN/zr1UaV6TVnyvk1pbamLCBkBMXKKkBEQJ+eHJjExMV3ptK5+JQBERERArVbD1dVVa72rqyuePtU9G9rdu3dx9uxZWFlZYd++fYiIiMCgQYMQFRWV7bp12TvrTZs2xcqVK7F27VrUqVMHe/fuhZeXl2b77t27UbJkSdnyNWnaDDEvorF65QqEhz9HyVKlsXzVarjL/FHu2/bs2gEA6Nuzu9b6qTNm4bNWbeSIpJMIbQkAN2/cQN9e/7Xl/LlvSqpatGyN6TNnGz1PdHQU5s+YgKjICNja5kGxEqUx7Zvl8K7ih2dhj/H72V8AAF/27Kj1uKAla1DRO+dTd2akYhFH7Br638d4k9qUBwDs+f0hRm+7BgBo4eMOlUqFA5cf6zzG9O9vQq2WsLynL6zMTXHuTjhGrf4DqUYsWRfleam0nLeDb2D4wF6an5cvmvsm56ctETh5JiIjw7F80VxER0XC2SUfGjf7DN17D5Al67uU1pa6iJARECOnCBkBcXJ+aIKCgjB16lStdZMnT8aUKVMyfIw+9xakpqZCpVJh27Ztmln6FixYgHbt2mH58uWwtrbOMqPs86w/efIENWvWRJEiRVC5cmWsXLkSvr6+KFeuHG7fvo0LFy5g3759aNasmV7HNdTIem7LjXnWDc1Q86znNgGa0mDzrOc2fedZl4Oh5lmnnM+zbiyGmmed6GOjtHnWP/32D7kjaHz/hVe2R9aTkpJgY2ODPXv2oHXr/77nZNiwYbh27RpOnz6d7jE9evTAuXPn8M8//2jWBQcHw8PDA3fu3EGpUqWyzCh7zbq7uzuuXr0KPz8/HDlyBJIk4Y8//sDRo0dRqFAhnDt3Tu+OOhERERFRViwtLWFvb6+16OqoA4CFhQV8fX1x7NgxrfXHjh3L8IbRmjVr4smTJ3j16pVm3Z07d2BiYoJC2bzHUPbOOgA4Ojpi9uzZuHnzJuLj45GYmIj79+9j27ZtqFy5stzxiIiIiIgwcuRIrF27FuvXr0dwcDBGjBiB0NBQDBjwpswvMDAQ3bv/V0rbpUsXODs7o2fPnrh16xbOnDmDMWPGoFevXtkqgQEUULNORERERB8PFcQor9WlY8eOiIyMxLRp0xAWFgZPT08cOnQIRYsWBQCEhYVpTVKRJ08eHDt2DF9++SUqV64MZ2dndOjQATNmzMj2OWWvWc8trFk3HNasGw5r1g2HNeuGw5p1og+b0mrWm397Ue4IGgf7595EDIaisMtHRERERB+y9/nm0I+ZImrWiYiIiIgoPXbWiYiIiIgUimUwRERERGQ0GX2BEOnGkXUiIiIiIoViZ52IiIiISKFYBkNERERERsMqGP1wZJ2IiIiISKHYWSciIiIiUiiWwRARERGR0YjyzehKwZF1IiIiIiKF4sg6ERERERkNB9b1w5F1IiIiIiKFYmediIiIiEihWAZDREREREajYh2MXjiyTkRERESkUBxZl5kKyn93GZ+kljtCtlhbmModIUuF8lrLHSFbbi9oIXeELDnVmyR3hGyJPjVN7ghZcrAxlzsCERFlgJ11IiIiIjIaVsHoh2UwREREREQKxc46EREREZFCsQyGiIiIiIzGhHUweuHIOhERERGRQnFknYiIiIiMhuPq+uHIOhERERGRQrGzTkRERESkUNkqgwkNDdXroEWKFHmvMERERET0YVPxBlO9ZKuzXqxYMb0aVq0W4xsviYiIiIiULFud9fXr1/NdEBERERGRkWWrs/7FF1/kcgwiIiIi+hiYcPxXLzm6wTQ+Ph6PHz9GSkqKofIQEREREdH/vVdn/dSpU/Dz84OdnR2KFi2KP//8EwAwePBgfP/99wYNSERERET0sdK7s37y5EkEBAQgISEBo0ePRmpqqmabi4sLNm7caMh8RERERPQBUalUillEoHdnfdKkSWjWrBmuXr2KGTNmaG3z8vLCtWvXDJWNiIiIiOijlq0bTN929epV7NmzB0D6eTLz5cuH58+fGyYZEREREX1wBBnQVgy9R9bNzMyQnJysc9vz589hZ2eX41BERERERPQenfUqVapgy5YtOrft3bsXfn5+OQ6lNLt2bEPTgPqo4l0Bndq3wZXLl+SOlM7lSxcxdPAANKrnj0qeZXDyxHG5I+Hq5UsYNWwQmjeqg+reHjh9SjuTJElYs2oZmjeqgzrVvTGwTw/c/TdEprTaRLjmImQE5M05+vNaOLu6P57/PAEPDozF7lmdUaqwc7r9JvSsh7v7RiPq+Nf4eUlPlCuWT7PNyc4aC4Y3w/VtQxF5bCLu7B2J+cOawd7W0mi/RxqlX3Ml/h3KiNLbEhAjIyBGThEyAuLkJOPSu7M+fvx47Nu3D61bt8aBAwegUqnw+++/Y8iQIdi7dy/Gjh2bGzllc+TwIcydHYS+/QZi19798PHxxaD+fRH25Inc0bTEx8ehdJkyGP/VJLmjaMTHx6FU6TIYNX6izu1bNq7Djq2bMGr8RKzfuhvOzi4YOqAPXr9+beSk2kS45iJkBOTPWatSMaza9zvq9F+N5iM2wdTUBAcX9ICNlblmn1Fd/DG0ox9GLPwJ/n2/xbOoV/hpYQ/ksbYAALi52MHN2Q6By39G5R7L0XfWPjSqVhKrxrcyyu+QRu62zA4l/h3SRYS2FCEjIEZOETIC4uQ0BLlvKhXtBlOVJEmSvg/aunUrhg8fjqioKM06R0dHLF26FF27djVowPeVYKCp37t2ao9yHh6YOGmqZl2rFk1Rr35DDBsxKsfH17/1s1bJswwWLF6O+g0aGuR4CcnqHB+jurcH5ixYgjr13mSSJAnNA+qgY5fu6N6zDwAgKSkJzRrUwuBhI9G6XUe9z2FtYZrjnEDuX3NDECEjkLs5nerp3yF0cbTBwx/Ho+GQdTh3/QEA4O7+MVi++zfM334WAGBhbooHP4zFxFXHsO6A7lGtNnXLY/3XbeEcMANqdarOfdJEn5qmd05dcrMtRfg7BBiuzlWE148IGQExcoqQEcjdnFZ636GYu7pv/1PuCBqbu1SUO0KW3mue9c8//xwPHz7E0aNHsXXrVhw5cgQPHz5UTEfdUJKTkhB86yb8avhrrferURPXr12VKdWH4cnjR4iMiEA1vxqadRYWFvD2rYy/rl+TLZcI11yEjIAyc9rbWgEAomPjAQDF3Jzg5myH4xf/0eyTlKzGr9fuo7pn4YyPk8cSsXGJWXbUDUWJbSkqEdpShIyAGDlFyAiIk5Pk8d7vtaytrdGwYc5HTL788kt06NABtWrVyvGxDC36RTTUajWcnbVrXJ2dXRARES5Tqg9DZEQEACBvXhet9XmdXfA0TL6P/ES45iJkBJSZc86QJjh3/QFu3Xsza1UB5zwAgOdR2qVXz6Nfo0gBR53HyGtvjcAedbHuB+PVkiqxLUUlQluKkBEQI6cIGQFxchqKiRjVJ4rxXiPrsbGxCAoKQkBAAHx9fREQEICgoCC8ePFC72MtX74cdevWRenSpTFnzhw8ffpU72MkJiYiNjZWa0lMTNT7OBl5t6ZJkiRh6pyUTqltq9RcbxMhI6CcnAtHfIoKJVzRY+qedNskaNeBqFRvcr7LzsYS++Z+juD74Zi54VSuZc2IUtryQyBCW4qQERAjpwgZAXFyknHp3Vm/d+8eKlasiAkTJiAkJAQWFhYICQnBhAkT4OXlhbt37+od4ujRo2jWrBm++eYbFClSBC1btsTBgwe1vh01M0FBQXBwcNBa5s0J0jvHu5wcnWBqaoqI/48Cp4mKioSzs0sGj6LscHZ5036RkdojBtFRkcibN/1sHcYiwjUXISOgrJwLhjdD85pl0XjYBjwOj9Wsfxr5CgDgmjeP1v75HG3xPOqV1ro81hY48E03vIpPQscJO5BipBIYQFltKToR2lKEjIAYOUXICIiT01DkvqlUtBtM9e6sDxs2DAkJCTh37hzu3buH3377Dffu3cPZs2eRmJiI4cOH6x2iQoUKWLRoEZ48eYKtW7ciMTERrVq1QuHChTFhwgT8888/mT4+MDAQMTExWsuYcYF653iXuYUFynmUx4Xz57TWXzh/Hl6VvHN8/I+Ze8FCcHZxwR8XftOsS05OwtXLl1DBq5JsuUS45iJkBJSTc+HwT9GytgeaDN+AB2EvtLbdD4tGWORLNKhSUrPO3MwUtSoVw4UbDzXr7GwscXBBDySlqNFu/HYkJhnoDvZsUkpbfghEaEsRMgJi5BQhIyBOTpKH3jXrJ0+exOLFi9PNp16jRg3MmDHjvTrraczNzdGhQwd06NABoaGhWL9+PTZu3IjZs2dDrc54RhJLS0tYWmrPeWyo2WC69eiJCePHwsPTE15e3vhuzy6EhYWhfcdOhjmBgcTFvUZoaKjm58ePH+Hvv4Ph4OAANzd32TI9evhfpiePH+PO7WDY2zuggJs7Onbpjk3rVqNwkaIoXKQoNq1bDSsrKwQ0bS5L3jQiXHMRMgLy51w0sjk6NqyA9l/twKu4JM0IesyrBCT8v8O9fPdvGPN5LfzzMBL/PIrE2G61EZ+YjF3H3sxWkMfaAgcXdIe1lTl6Tt8Le1tLzRzr4S9eIzU1F6ZS0UHutswOJf4d0kWEthQhIyBGThEyAuLkJOPTu7NuaWmJwoV1z5JQpEiRdJ3m91WkSBFMmTIFkydPxvHj8n2xRpOmzRDzIhqrV65AePhzlCxVGstXrYa7e0HZMuly88YN9O3VXfPz/LlvyoBatGyN6TNny5Ip+NZNDO77hebnxfPnAACatWiFSdNmodsXvZGYmIB5QdPwMjYW5T0rYvHKtbC1tZUlbxoRrrkIGQH5c/ZvXRUAcGxpL631fWd9j62HrwEA5m8/CytLcywa1RxOeaxwMfgxmo/cjFfxSQAA7zLuqFr+zd+8W7tGaB2nTPsFCH36Ind/if+Tuy2zQ4l/h3QRoS1FyAiIkVOEjIA4OQ1BjOIT5dB7nvVevXrB1NQUa9asSbetb9++SEpKwqZNm7J9vOLFi+PSpUvp7oDOKUONrOe23Jjf2NAMMc+6MRhqnnUSw/vMsy4HQ82znptE+DsEGG6edaKPjdLmWe+18y+5I2is71RB7ghZytblu3Lliub/u3Tpgt69e6N9+/bo0qULChQogKdPn2Lbtm24dOkS1q1bp1eAe/fu6ZeYiIiIiOgjka3OeuXKlbXumJUkCQ8fPsT333+vtQ4AAgICMq0vJyIiIqKPlwk/JtNLtjrrGzZsyO0cRERERET0jmx11nv06JHbOYiIiIiI6B0Ku+WAiIiIiD5krILRz3t11qOiorB9+3YEBwcjPj5ea5tKpdL7JlMiIiIiIkpP7856aGgoqlSpgri4OMTFxcHFxQVRUVFQq9VwcnKCg4NDbuQkIiIiog+AikPrejHR9wHjx49H+fLl8ezZM0iShMOHD+P169dYunQprKys8NNPP+VGTiIiIiKij47enfXffvsNAwcOhJWVFYA3UzZaWFhg8ODB6N27N8aMGWPwkEREREREHyO9O+vPnj2Dm5sbTExMYGpqitjYWM22OnXq4OzZswYNSEREREQfDpVKOYsI9O6su7q6IioqCgBQrFgxXLp0SbPt/v37MDPjBDNERERERIagd8+6evXquHr1Kj777DO0adMG06ZNQ2JiIiwsLDBv3jzUr18/N3ISEREREX109O6sjx49Gvfv3wcATJo0CcHBwZg8eTIkSULt2rWxaNEiA0ckIiIiog+FiSj1Jwqhd2fd19cXvr6+AABbW1scOHAAsbGxUKlUsLOzM3hAIiIiIqKPld4167rY29vDzs4OZ86cYRkMEREREZGBGPRu0PDwcJw+fdqQhyQiIiKiDwirYPRjkJF1IiIiIiIyPM6zSERERERGo+LQul44sk5EREREpFDsrBMRERERKVS2ymAqVqyYrYPFxsbmKMzHSIRPgqwtTOWOQJRO9KlpckfIFqdPv5E7Qpaifxotd4RsiUtUyx0hS1bmHAP7mJiYCPCPuALxVaKfbHXW8+bNm636ImdnZxQvXjzHoYiIiIiIKJud9V9++SWXYxARERER0bs4GwwRERERGQ1ng9EPy4aIiIiIiBSKI+tEREREZDS8L1c/HFknIiIiIlIodtaJiIiIiBSKZTBEREREZDQsg9HPe3fW//77b5w+fRoRERHo3bs3ChQogCdPnsDJyQnW1taGzEhERERE9FHSu7OuVqvRr18/bNy4EZIkQaVSoWnTpihQoAD69+8Pb29vTJsmxjcLEhEREREpmd416zNnzsT27dsxb9483LhxA5IkabY1bdoUR44cMWhAIiIiIvpwqFQqxSwi0HtkfePGjfj6668xcuRIqNVqrW3FixfHvXv3DBaOiIiIiOhjpvfI+uPHj+Hn56dzm5WVFV6+fJnjUERERERE9B6d9fz58+Pu3bs6t92+fRuFChXKcSgiIiIi+jCZqJSziEDvznqzZs0wc+ZMPH78WLNOpVIhJiYGS5YsQYsWLQwakIiIiIjoY6V3Z33atGlISUmBh4cH2rZtC5VKha+++gqenp5ISEjA119/nRs5iYiIiOgDoFIpZxGB3p11V1dXXLx4EZ07d8bly5dhamqK69evo2nTpjh//jzy5s2bGzmJiIiIiD467/WlSK6urli1apWhsxARERER0Vv0Hln/GO3asQ1NA+qjincFdGrfBlcuX5I7kk4i5BQhIyBGThEyAmLklDtjTc9C2Du1Ne5uH4D4n0ejhV/JDPddOrQR4n8ejSGtfTLcZ/+MtlkeJ7fI3ZZZSUlJwbfLF6NN80ao4+eNti0CsG71CqSmpsodTWPd2m/RtVM71Kzmg/p1amDE0MG4f0/3xA5yEiGnCBnfpvTXj6GYqFSKWUSgd2e9V69emS69e/fOjZyyOXL4EObODkLffgOxa+9++Pj4YlD/vgh78kTuaFpEyClCRkCMnCJkBMTIqYSMtlbm+Ovuc4xYfiLT/Vr4lUSVsm54EpHxFLlftvbV+rI6Y1JCW2Zl68a12PfdLowaNxE7vzuIwcNGYfvm9dizc5vc0TSuXLqIjp26YPO2XVi5ej3U6hQM7N8H8XFxckfTIkJOETKmEeH1Q/JQSXr+VS9WrFi6b3yKjIzEq1ev4OjoCEdHxwyndjSmhBTDHKdrp/Yo5+GBiZOmata1atEU9eo3xLARowxzEgMQIacIGQExcoqQERAjZ25ndPr0G732j/95NDpM2Y8ff/tHa727cx6cWdwVLSbsxb5pbbBs/2Us23dFa58Kn+TD99Naw//Lrbi/c5DO4+gS/dNovTJmJLfbMi5RnfVOWRg1dCDyOjtjwuQZmnWBo4fBysoKk2fMyfHxrcwN/4F1VFQUGtSpgbUbtsC3chWDH99QRMhp6IwmBpz7LzdfP1bvVfSce8YfuiN3BI3ZzUrLHSFLev9VuX//Pu7du6e1xMbG4vjx48ifPz9++OGH3Mgpi+SkJATfugm/Gv5a6/1q1MT1a1dlSpWeCDlFyAiIkVOEjIAYOUXICLyZsWDd2GZYuPcigh9E6tzH2tIMm8Y3x4jlJ/As2vijhqK0pZe3Dy79cQGhD+4DAELu/I3r167Az7+2vMEy8erVm09SHBwcZE6SORFyKjWjKK8fQzFR0CICg+WsX78+hgwZgmHDhun92KVLl6JHjx7YvXs3AGDLli3w8PBA2bJl8dVXXyElxUDD5HqKfhENtVoNZ2dnrfXOzi6IiAiXJZMuIuQUISMgRk4RMgJi5BQhIwCM6lAVKepULN9/JcN95vavhwu3HuPgb/8aMdl/RGnLbl/0QaMmzdCpzafwr1oRPTq3Rccu3RDQ5FO5o+kkSRLmz5sNbx9flCyl3BFAEXIqOaMorx+Sh0E/GPHw8MD48eP1esz06dMxb948BAQEYNiwYbh37x7mzZuHESNGwMTEBAsXLoS5uTmmTp2a4TESExORmJiotU4ytYSlpeV7/R7verfsR5KkdOuUQIScImQExMgpQkZAjJxKzuhd0hWDW/mixuDNGe7zafUSqFupCKoPyngfY1FyWwLA8aOH8fOhg5g6ax6Kf1ISIbf/xqL5QXDJlx+ftmgld7x0Zs+cjpA7t7Fh03a5o2RKhJwiZFT664fkYdDO+unTp+Hi4qLXYzZu3IiNGzeiTZs2uH79Onx9fbFp0yZ07doVAFC2bFmMHTs20856UFBQuu0Tvp6MiZOm6P07vM3J0QmmpqaIiIjQWh8VFQlnZ/1+z9wkQk4RMgJi5BQhIyBGThEy1qxQEPkdbXBna3/NOjNTE8zuWxdDWvmibI81qFupCD5xc8TT77/UeuyOrz/DuRuP0XjsrlzPKUJbAsCyRd+8GV1v3AwAULJUaTx9+gSbN6xRXGd99qzpOP3LSazbuBWuBQrIHSdDIuRUekZRXj+Gwvcf+tG7sz5t2rR06xITE/Hnn3/i8OHDGDNmjF7HCwsLQ+XKlQEAXl5eMDExQaVKlTTbfXx88CSLO6EDAwMxcuRIrXWSac5H1c0tLFDOozwunD+HBg0badZfOH8edes3yPHxDUWEnCJkBMTIKUJGQIycImTcfvwWTl4J1Vr346y22H7iFjYfvQEA+GbX79hw+C+tfS6v/gJjvz2Fny4Y54Z/EdoSABIS4mFiol0BamJiAklBUzdKkoQ5s6bj5MnjWLN+MwoWKiR3JJ1EyClCRkCc1w/JQ+/O+pQpU9Kts7S0RLFixTBt2jS9O+sFChTArVu3UKRIEYSEhECtVuPWrVsoX748AODmzZvInz9/psewtExf8mKo2WC69eiJCePHwsPTE15e3vhuzy6EhYWhfcdOhjmBgYiQU4SMgBg5RcgIiJFTCRltrcxRwt1R83OxAg6o+Ek+RL9MwMPwl4h6maC1f3JKKp5Fv0bIo2gAwLPoOJ03lT58/hIPnsXkava3KaEts+Jfux42rvsWrgXc8EmJkrj9dzB2bt2E5i3byB1NI2jmNBw+dBALFy+Hra2tpmY5Tx47WFlZyZzuPyLkFCFjGhFeP4YiyvzmSqF3Z93QXxzRpUsXdO/eHS1btsSJEycwbtw4jB49GpGRkVCpVJg5cybatWtn0HPqo0nTZoh5EY3VK1cgPPw5SpYqjeWrVsPdvaBsmXQRIacIGQExcoqQERAjpxIy+pQugKPzOmp+njugHgBgy9Eb6Df/iNFy5JQS2jIrI8dOwOoVS/BN0DRERUchX778aNW2A3r1Gyh3NI09u3YAAPr26q61fur0WfislXLeVIiQU4SMaUR4/ZA89JpnPT4+Hr1798agQYPg7++f9QOyQa1WY/bs2bhw4QL8/f0xbtw47Ny5E2PHjkVcXBxatGiBZcuWwdbWVq/jGmpknYgoJ/SdZ10OhppnPbcZYp713JYb86yTchlynvXcpLR51r8+EiJ3BI3pTUrJHSFLen8pkq2tLQ4fPozatZU7Jy3AzjoRKQM764bDzjopDTvr72fSz8rprE9rrPzOut5/VSpVqoQbN27kRhYiIiIiInqL3p312bNnY+7cuTh9+nRu5CEiIiIiov/L1gcjZ86cgY+PD/LkyYNBgwbh1atXqF+/PpycnODm5qY1Yb9KpcL169dzLTARERERiUuQ6iHFyFZnvV69evjtt99QtWpVODs76/3FR0REREREpL9sddbfvgf1l19+ya0sRERERET0FoXdH0xEREREHzJ+KZJ+sn2DqYoNS0RERERkVNkeWa9Xrx5MTLLu26tUKsTEGO/rrYmIiIhIHBz/1U+2O+t169ZFvnz5cjMLERERERG9Jdud9UmTJqFq1aq5mYWIiIiIiN7CG0yJiIiIyGg4z7p+9P4GUyIiIiIiMg521omIiIiIFCpbZTCpqam5nYOIiIiIPgIqsA5GHxxZJyIiIiJSKN5gSkRERERGwxtM9cORdSIiIiIihWJnnYiIiIhIoVgGQ0RERERGwzIY/bCzLjNJkjtB1lSCvKhi4pLljpAlBxtzuSNkS8TLRLkjZMnFzlLuCNkS/dNouSNkqUi/3XJHyJbQ1R3kjkBEZHQsgyEiIiIiUiiOrBMRERGR0ahE+cheITiyTkRERESkUOysExEREREpFMtgiIiIiMhoOBuMfjiyTkRERESkUBxZJyIiIiKj4f2l+uHIOhERERGRQrGzTkRERESkUCyDISIiIiKjMWEdjF44sk5EREREpFDsrBMRERERKRTLYIiIiIjIaDjPun44sk5ERERElE0rVqxA8eLFYWVlBV9fX/z666/Zety5c+dgZmaGSpUq6XU+dtaJiIiIiLJh165dGD58OCZMmICrV6+iVq1aaNq0KUJDQzN9XExMDLp3744GDRrofU521omIiIjIaFQq5Sz6WrBgAXr37o0+ffqgXLlyWLRoEQoXLoyVK1dm+rj+/fujS5cu8PPz0/uc7KwTERER0UcpMTERsbGxWktiYqLOfZOSknD58mUEBARorQ8ICMD58+czPMeGDRvw77//YvLkye+VkZ11IiIiIjIaE6gUswQFBcHBwUFrCQoK0pk7IiICarUarq6uWutdXV3x9OlTnY8JCQnB+PHjsW3bNpiZvd+8LpwNJht27diGjRvWISI8HCVKlsLY8V/Bx7ey3LE01q35FieOH8X9e3dhaWUFr0reGD5iNIoV/0TuaOkorS23bliDM6eO48GDe7C0tIJnxUoYMGQEihQrrtlHkiRsWLMCP+7bi5cvY+FRvgJGjJ2I4iVKypb78qWL2Lh+HYJv3UB4eDgWLlmO+g0aypZn+6a1OPvLCYQ+uAdLS0t4VKiEfoOHo3DR/9oxPi4Oa1YswrnTJxEbG4MCBdzRukMXfNa2o2y5AeW1ZWbkev0MbVYWn/oWQik3O8QnqXHpn0hM2/sn/n36UrPPpz4F0b1uCVQs6gRnO0vUn3wUNx6+0Gwv7GyDy/Oa6zx+7xXn8eOlR7n9a2hR2t8iXUTICIiRU4SMgDg5PySBgYEYOXKk1jpLS8tMH6N6p35GkqR06wBArVajS5cumDp1KkqXLv3eGTmynoUjhw9h7uwg9O03ELv27oePjy8G9e+LsCdP5I6mcfnSH+jYuSs2b9+NVas3QJ2ixsB+vREfFyd3NC1KbMtrVy6hdfvOWLV+OxYsWw21OgWjvuyH+Pj/2m775vXYvX0zho/5Cqs37kReZxeMHNIXca9fy5Y7Pj4OZcqUwfgJk2TL8LY/r17CZ207YdnarZi7ZDXUajXGDhug1Y4rFs3FxQvnEDglCBt27Efbzt2wdMFsnDtzSsbkymvLjMj5+qlRJh/Wn/wHTWecQIf5p2FqqsLukbVhY2Gq2cfG0gx/hERgxt4/dR7jcVQ8PIcf0Frm7LuB1wnJOPmX7hGp3KLEv0XvEiEjIEZOETIC4uT80FhaWsLe3l5ryaiz7uLiAlNT03Sj6M+fP0832g4AL1++xKVLlzBkyBCYmZnBzMwM06ZNw/Xr12FmZoaTJ09mK6NKkiRJ/19N+RJSDHOcrp3ao5yHByZOmqpZ16pFU9Sr3xDDRozK8fFzo/WjoqJQv7Yf1m3cCt/KVXJ8PEN9K3But2VMXHKOj/EiOgqfBdTGkm83opJPZUiShNZN66F9527o2qM3gDc1a60a10H/L0egZZsOeh3fwcY8xxnf5VW+jMFHgyNe6q7Xy64X0VFo27QuFq5cj4reb0aFendpjboNm6Bbr/6a/Qb06IhqNWqhZ/8hep/DxS7zkY/3kRttaSi5+fop0m+3Xvs721kieHFLfDb7JC7cidDaljaC/u7Iui4nJjfCn6HRGLHhUrbOG7pav9dbRnL7b5EhiJARECOnCBmB3M1ppbA6ihXn78sdQWNQjWJ67V+tWjX4+vpixYoVmnUeHh5o2bJluvKZ1NRU3Lp1S2vdihUrcPLkSezduxfFixeHra1tlueUfWQ9LCwMkyZNQv369VGuXDl4enqiRYsWWLduHdRqtazZkpOSEHzrJvxq+Gut96tRE9evXZUpVdZevXrz0bSDg4PMSf4jSlu+evUKAGBv/6btwh4/QlRkBKpUr6HZx8LCAl4+lXHjz2tyRBTC6/+3o539f89BTy8f/PbrLwh//gySJOHq5T/w6OEDVK5WI4OjUBqlvX7srd+86XzxOum9j1GxqBMqFHXC9jP3DBUrW5TWlrqIkBEQI6cIGQFxchIwcuRIrF27FuvXr0dwcDBGjBiB0NBQDBgwAMCbspru3bsDAExMTODp6am15M+fH1ZWVvD09MxWRx2QuWb90qVLaNiwIYoXLw5ra2vcuXMHXbt2RVJSEkaPHo1169bh559/hp2dnSz5ol9EQ61Ww9nZWWu9s7MLIiLCZcmUFUmSMH9uELx9fFGy1PvXRxmaCG0pSRKWLZyLipV88EnJUgCAyMg3o4Z582rnzpvXGU+f8qNJXSRJwsrF8+Dp5Y3iJUpp1g8ZOR7zg6ag02eNYGpqBhMTFUZ9NQUVKvnImFYMSnv9TO3ohQt3wvH349j3PkbXWsVx+0kMLv4bacBkWVNaW+oiQkZAjJwiZATEyUlAx44dERkZiWnTpiEsLAyenp44dOgQihYtCuDNIHRWc67rS9bO+vDhwzFixAjNVDZbt27FsmXLcOHCBURHR6N+/fqYOHEiFi9enOlxEhMT002zI5laZnmDQHZl90YCJQiaOQ137tzBxs3b5Y6ik5LbcuHcmbj7zx0sW7M5/UZduaGM3Eqz5JtZuPtPCBav3qi1ft/ubQi+8Semz1sC1wLu+OvaZSyeNxN5nfPBt2p1ecIKRgmvn9mf+8CjsCNaBGWv1lIXK3NTtKleBAt+vJX1zrlECW2ZFREyAmLkFCEjIE7OnDIR/FcaNGgQBg0apHPbxo0bM33slClTMGXKFL3OJ2sZzJUrV9CtWzfNz126dMGVK1fw7NkzODk5Ye7cudi7d2+Wx9E17c68Obqn3dGHk6MTTE1NERGhXZMZFRUJZ2eXHB/f0GbPmo7Tp05i7fpNcC1QQO44WpTelovmzcK5M6ewaOV65Hf9r+3SskVFaueOjo6C0zsjIAQs/SYIv/36C+avWIt8+f9rx8SEBKxbuQQDh41BjVp1UaJUabRq3xl1GzTGnu0bZcsrCqW8fmZ18UbjSu5oM/cXhEXHv/dxWlQuBGsLU+w+/8CA6bJHKW2ZGREyAmLkFCEjIE5OkoesnfX8+fMjLCxM8/OzZ8+QkpICe3t7AECpUqUQFRWV5XECAwMRExOjtYwZF5jjfOYWFijnUR4Xzp/TWn/h/Hl4VfLO8fENRZIkBM2chhPHj2L1+k0oWKiw3JHSUWpbSpKEhXNn4syp41i0cj3cCxbS2u5WsBDyOrvg0u+/adYlJyfj+pVL8KxYychplUuSJCz5ZhZ+PX0C3yxbCzd37XZMUacgJSUl3QiRiakpUlM/yHvcDUoJr5+grt741Lcg2sz9BaEROZsJqUut4vj52hNE5vBG5vehhLbMiggZATFyipARECcnyUPWMphWrVphwIABmDdvHiwtLTF9+nTUqVMH1tbWAIDbt2+jYMGCWR7H0jJ9yYuhZoPp1qMnJowfCw9PT3h5eeO7PbsQFhaG9h07GeYEBjBrxlQcPnQQi5asgK2traa+LU8eO1hZWcmc7j9KbMuFc2bg+M+HMOubJbCxsUXk/0c18uTJA0srK6hUKrTv3A1bN6xBocJFUKhwUWzduAaWVlZo1PhT2XLHvX6tVRP3+NEj/B0cDAcHB7i5uxs9z5J5M3Hi6GFMn7sYNra2mk8ibG3ftKOtbR54eVfG6mULYGlpBVc3N1y/chnHDv+IgUNHGz3v25TWlhmR8/Uz53MftKleBN2XnMPrhBTkt3/zdyU2PhkJyW8mAnC0tUChvDZwdXyzrUSBN/caPY9JwPPYBM2xiufPA7/S+dB50a+5njsjSvxb9C4RMgJi5BQhIyBOTkMw+QBLe3KTrFM3vnr1Cr1798b3338PtVoNPz8/bN26FcWLv/kilaNHjyImJgbt27fX+9iG6qwD//+SgvXrEB7+HCVLlcaYcYEGmRIRMMzUjZU8y+hcP3VGEFq2apPj4xvyNZWbbfk+UzfWruKpc33gpBlo2qIVgP++FOnA93vw6mUsypWviBFjJ2huQtWHoaZuvPjH7+jTs3u69Z+1bI3ps2bn+Pj6Tt3YoHpFnevHTJyOJs1bAnhTSrR2xWJc+uM3vIyNgWsBN3zash3ade72XjWZhpq6Mbfb0pBy6/WT1dSNz9frnjLxy3V/YNe5+wCAjjWLYWnvqun2mffDTcz74abm56/aVED7GkXhM+ag3n//DDV1I5C7f4sMRYSMgBg5RcgI5F5OpU3duPqC8UvgMtKvelG5I2RJEfOsJyQkICUlBXny5DHcMQ3YWc9N8rd+1kR5A2yIedZzW27Ms54bcjrPujHkxjzrHyt951mXiyE760QfE6V11tf8rpzOet9qyu+sK+LyKalUg4iIiIhIKWT/UiQiIiIiItJNESPrRERERPRx4A2m+uHIOhERERGRQrGzTkRERESkUCyDISIiIiKjYRWMfjiyTkRERESkUBxZJyIiIiKj4UixftheREREREQKxc46EREREZFCsQyGiIiIiIxGxTtM9cKRdSIiIiIihWJnnYiIiIhIoVgGQ0RERERGwyIY/XBknYiIiIhIodhZJyIiIiJSKJbBEBEREZHRmHA2GL1wZJ2IiIiISKE4sk5ERERERsNxdf1wZJ2IiIiISKE4si4zEcq2YuKS5Y6QLfbW5nJH+GC42FnKHeGDkaxOlTtClkJXd5A7QrY4tVwid4QsRf8wVO4IRPSBYWediIiIiIxGhIFKJWEZDBERERGRQrGzTkRERESkUCyDISIiIiKjUbEORi8cWSciIiIiUih21omIiIiIFIplMERERERkNBwp1g/bi4iIiIhIoTiyTkRERERGwxtM9cORdSIiIiIihWJnnYiIiIhIoVgGQ0RERERGwyIY/XBknYiIiIhIodhZJyIiIiJSKJbBEBEREZHRcDYY/XBknYiIiIhIodhZJyIiIiJSKJbBEBEREZHRcKRYP2yvbNi1YxuaBtRHFe8K6NS+Da5cviR3JJ2UlvPalUsYP2IwWjeth9pVPPHrLye0ts+aMgG1q3hqLQN6dpEp7X8uX7qIoYMHoFE9f1TyLIOTJ47LHUknpV3vjIiQU+kZv12xDJUrltNaGterJXcsneRsy5rl3bF3Ugvc3dwL8T8NRYvqn2htt7Uyx8IBdfDPpl6I+n4Qrq76HH2bVdBsd8pjiQUD6uD6t90Q+d1A3NnQE/P714a9jYXRfoe3Kf15mUaEnCJkBMTJScaliM7669evsWbNGvTs2RNNmzZFs2bN0LNnT6xduxavX7+WNduRw4cwd3YQ+vYbiF1798PHxxeD+vdF2JMnsuZ6lxJzJsTHo0TpMhg+5qsM96nm5499h3/RLHMXrTRiQt3i4+NQukwZjP9qktxRMqTE662LCDlFyAgAn5QoiSMnz2iWnd/9IHekdORuS1src/x1LxwjVp3WuX1u31po5FsUPb/5GZUGbMHS/VexYEAdNP9/p97N2RZueW0RuO4sKg/ejr4Lj6GRb1GsGtbQKPnfJndbZpcIOUXICIiT0xBUKpViFhHI3lm/desWSpcujbFjxyI6OhpFihRBoUKFEB0djTFjxqBMmTK4deuWbPm2bNqA1m3bok279vikRAmMDZyAAm4FsHvXDtky6aLEnNVr1kLfgUNRp36jDPcxt7CAs4uLZrF3cDBiQt38a9XBkKEj0KBRgNxRMqTE662LCDlFyAgAZmZmcHHJp1mc8uaVO1I6crfl0csPMHXLBfxw/l+d26uVdcPWE8H49a/HCH3+EuuP3MSf9yLgUzI/AODWgyh0nnUIh/64h3tPY3D6z0eYsvk3NKtWHKYmxv1HXe62zC4RcoqQERAnJxmf7J31wYMHo3bt2nj27Bn279+Pb7/9FqtXr8b+/fvx7Nkz1K5dG4MHD5YlW3JSEoJv3YRfDX+t9X41auL6tauyZNJFlJy6XLt8EZ8F1EaXtp9i7ozJiI6KlDuS4olyvUXIKULGNKEPHqBJg9r4rElDBI4diUePHsodSYsIbXn+1hM0r/YJ3J1tAQC1KxZCKXdHHL/yIMPH2NtYIjYuCepUyVgxhWhLQIycImQExMlJ8pD9BtPff/8dly5dgoVF+ppACwsLfPXVV6hataoMyYDoF9FQq9VwdnbWWu/s7IKIiHBZMukiSs53Vavhj3oNA+BawB1hTx5j3aqlGD6wN9Zs2a3z+UBviHK9RcgpQkYA8KxQEVNnzkbRosUQGRWBdatXoXe3Lti17wAcHZ3kjgdAjLYc9e1prPiyAf7d3BvJKWqkSsDAxSdw/laYzv3z2lkhsHMVrDv8l1FzitCWgBg5RcgIiJPTUMQoPlEO2TvrTk5OCAkJgYeHh87t//zzD5ycMv/HKDExEYmJiVrrJFNLWFpaGiTjuzVNkiQpss5JlJxpGgQ01fz/JyVLoYxHeXRo0Qi/nT2daekMvSHK9RYhp9Iz1qxVW/P/JVEaFStWQqtPG+PggR/wefcv5Aumg5LbcvBnXqhatgDaTv0Roc9j4e9ZEIsH1cXT6Nc4dU37kwo7awvsm/IZgkOjMHP7H7LkVXJbvk2EnCJkBMTJScYlexlM37590aNHD3zzzTe4fv06nj59imfPnuH69ev45ptv0KtXL/Tv3z/TYwQFBcHBwUFrmTcnKMfZnBydYGpqioiICK31UVGRcHZ2yfHxDUWUnFlxcckHVzd3PHoYKncURRPleouQU4SMuljb2KBEqVJ4+OC+3FE0lN6WVhammNq9Bsat/RWH/riHG/cjsergn9j7awiGt/HR2jePtTkOTG+JVwlJ6DjjJ6SoU42aVeltmUaEnCJkBMTJSfKQvbM+ZcoUBAYGYsGCBfD29kbBggXh7u4Ob29vLFiwAOPHj8ekSZnPyhEYGIiYmBitZcy4wBxnM7ewQDmP8rhw/pzW+gvnz8OrkneOj28oouTMSsyLFwh/9hTOLvzDlBlRrrcIOUXIqEtSUhLu370Ll3z55I6iofS2NDc1hYW5KVLfqT1Xp6bC5K2RSztrCxyc3gpJyWq0m3YQiclqY0dVfFumESGnCBkBcXIaikqlnEUEspfBAMC4ceMwbtw43Lt3D0+fPgUAFChQAMWLF8/W4y0t05e8JKQYJlu3Hj0xYfxYeHh6wsvLG9/t2YWwsDC079jJMCcwECXmjIuLw+O3RsnDnjxGyO2/Ye/gADt7B2xYvRx16jeCs0s+PA17jNXLF8PB0Qm16xp/mrS3xcW9Rmjof7kfP36Ev/8OhoODA9zc3GVM9h8lXm9dRMgpQsZF38xFrbp1UaCAO6KjIrFu9Sq8fv0KzT9rJXc0LXK3pa2VOUq4/zejVLEC9qj4iQuiXybgYfgrnPnzEWb18kd8UgpCn79ErQoF0bV+OYxb+yuANyPqB2e0grWlGXp+cxT2NhaaOdbDY+LTdfRzk9xtmV0i5BQhIyBOTjI+RXTW0xQvXjxdB/3hw4eYPHky1q9fL0umJk2bIeZFNFavXIHw8OcoWao0lq9aDXf3grLkyYgSc94OvoFhA3ppfl62cC4AoMmnLTFq/Ne4+28Ifj70I169jIWzSz54+1bFlFnfwMbWVq7IAICbN26gb6/ump/nz31TUtWiZWtMnzlbrlhalHi9dREhpwgZnz1/ignjRuNF9As45XWCZwUvbNi6E24KygjI35Y+pfLj6Oy2mp/n9n1T67/l+C30W3gc3ecewbQeNbBxdGM42Vkh9Hkspmz+DWsOvbmB1LtkflQtWwAAcGtdD61jl+m5AaHPXxrl9wDkb8vsEiGnCBkBcXIagglvMdWLSpIk4w0VvIfr16/Dx8cHarV+H0UaamSdgJi4ZLkjZIu9tbncEbIkykduZDjJRq53fh/mprJXRGaLU8slckfIUvQPQ+WOQJSOlaKGZoEf/3omdwSNFhVc5Y6QJdkv34EDBzLdfvfuXSMlISIiIiJSFtk7661atYJKpUJmA/yctoiIiIjow8BunX5k/+zTzc0N3333HVJTU3UuV65ckTsiEREREZEsZO+s+/r6Ztohz2rUnYiIiIjoQyV7GcyYMWPw+vXrDLeXLFkSp06dMmIiIiIiIsotKs4GoxfZO+u1atXKdLutrS3q1KljpDRERERERMohexkMERERERHpJvvIOhERERF9PDgbjH44sk5EREREpFAcWSciIiIiozHhDaZ64cg6EREREZFCsbNORERERKRQLIMhIiIiIqPhDab64cg6EREREZFCsbNORERERKRQLIMhIiIiIqNhGYx+OLJORERERKRQ7KwTERERESkUy2CIiIiIyGhU/FIkvXBknYiIiIhIoTiyTllysDGXOwKRsBKSUuWOkCVzazHGbZ7uHSJ3hCw5tVomd4QsRe9XfjvSh82EA+t6EeMvNBERERHRR4iddSIiIiIihWIZDBEREREZDW8w1Q9H1omIiIiIFIqddSIiIiIihWIZDBEREREZjYpVMHrhyDoRERERkUJxZJ2IiIiIjIY3mOqHI+tERERERArFzjoRERERkUKxDIaIiIiIjMaEVTB64cg6EREREZFCsbNORERERKRQLIMhIiIiIqPhbDD64cg6EREREZFCsbNORERERKRQLIMhIiIiIqNRsQpGLxxZJyIiIiJSKHbWs2HXjm1oGlAfVbwroFP7Nrhy+ZLckXQSIacIGQExcoqQERAjp9IyXrtyCWNHDELLJnXhX7k8zvxyQmt7XNxrLJgzA62b1Uf9mj7o2q4F9u3dKVNabUpryyuXL2Lk0IFo1qg2qlYqh19OHtfaLkkSVq9chmaNaqNWtUoY0Ls7/v0nJNfyjG7vi7ML2uP57n54sLUXdk9ohlIFHbX2mdClKq6t7IqIvf3xZGcf/DSjJaqUdtVsd8pjiQX9a+P6qq6I3Nsfd9b3wPx+tWBvY5FruTOjtGuuiwgZAXFy5pRKQYsIFN9Zf/bsGaZNmybb+Y8cPoS5s4PQt99A7Nq7Hz4+vhjUvy/CnjyRLZMuIuQUISMgRk4RMgJi5FRixvj4eJQsVQYjx07QuX3pgjn4/bez+HrabGzb8yM6dOmGRfNm4ddfTho5qTYltmVCfDxKlS6DMeMn6ty+eeNa7Ni6EWPGT8TGbbvh7OKCLwf2xuvXr3MlTy1Pd6z66S/UGb0Xzb/+AaamJjg4/TPYWP5XlfrP4xcYseo0Kg/egQZjv8eDZ7H4cfpncLG3AgC4OdvCLa8tAtefQ+UhO9B30XE08i2KVcPq50rmzCjxmr9LhIyAODnJ+FSSJElyh8jM9evX4ePjA7VardfjElIMc/6undqjnIcHJk6aqlnXqkVT1KvfEMNGjDLMSQxAhJwiZATEyClCRkCMnLmd8WV8zv4Y+Vcuj1nfLEHtug0067p1aIkGAU3wRZ+BmnW9Pm8Pv5q10HfgUL3PYWdtmNuXcrstE5NTc/T4qpXKYe6CpahbvyGAN6PqzRrVRqeu3dGjZ18AQFJSEprU98eQ4aPQpl1Hvc9RoP0KvfZ3sbfCw+190HDc9zh3U3enzM7aHM/39EfTCfvxy/VHOvdpU7ME1o8OgHPbVVCnZv7PevT+IXplzAxf44aTmzmtFHaH4rmQaLkjaNQs5SR3hCzJPrL+559/Zrrcvn1btmzJSUkIvnUTfjX8tdb71aiJ69euypQqPRFyipARECOnCBkBMXKKkFGXipV8cPbMKYQ/fwZJknDl0u94GHofVf1qypZJxLZ88vgRIiMiUP2tdrOwsIBP5Sr400iZ7W0tAQDRrxJ0bjc3M0HvJp548SoRf92LyPQ4sXFJWXbUDUmEay5CRkCcnIZiolIpZhGB7O+1KlWqBJVKBV0D/GnrVTI1ZvSLaKjVajg7O2utd3Z2QUREuCyZdBEhpwgZATFyipARECOnCBl1GT4mEHNmTEbrZvVhamoGExMVxk2cBq9KvrJlErEtIyPedH7z5nXRWp83rzPCwoxTejCnjz/O3XyCWw+i/tfefcfXfD1+HH9fGTdDEhlIYiQkxCwSK4hRGo0ZWykppUtbRFOr/UatUFrUatUqVVTNKrWaajVWBDVStFSMIJEpIePm8/vDz60rN6uSez5H388+7uPRfO7n3vtyb8bJce5hcDyomSfWvB8IG60FbiVnoNuH23E3zfiA3snOChMHNsWK3WdNkawnw2suQyMgTyeJIXyw7uzsjNmzZ6Njx45Grz937hy6d+9e6H1kZWUhKyvL4JhipoVWqy2Vxid/WRD5C0RhZOiUoRGQo1OGRkCOThkaH7dpwzqcO/M7Zn26CK5u7jgdE41PZk+Ds0tFNGvhL7RNtucSyL+NnKma573RFg09ndHx/c35rjv4+3W0eHcjXOytMKxzfXw9/kW0HbcJCan3Dc6zs7bA1vBuiI1Lxoz1x8u82RgZXnMZGgF5Osm0hC+D8fPzw82bN+Hh4WH0UqVKFaOz7o+LiIiAg4ODwWXO7IinbnOs4AgzMzMkJhr+1WNS0l04O7sUcCvTk6FThkZAjk4ZGgE5OmVofFLWgwdYtng+3gl9H23adoB3LR/0GTAYHV8IwvqvVwnrkvG5dHZ52HX3rmFzcnISnJycjd2k1Hz6elt0a1EDnSdtxY27+d/MmpmVi8vxqTh24Tbe/Own5OblISSwnsE55a0tsGNqD9x7kIMBM3YhV/d0a/pLSobXXIZGQJ7O0iJ6BxjuBlNCr7/+Ojw9PQu8vnr16li1qvAfQBMnTkRqaqrBJWz8xKdus7C0RN169XEk6jeD40eiotCocZOnvv/SIkOnDI2AHJ0yNAJydMrQ+KTc3Fzk5uZCozH89l2uXDkoJlyv/CQZn0v3KlXh7OKCo4ej9MdycrIRE30cz5Vh87w32qJnq5p4cfI2XL2dXqzbaABoLcz0H9tZW2DntJ7Izs1D32k/ICunZJswlAYZXnMZGgF5OkkM4ctgevXqVej1jo6OCAkJKfQcrTb/kpfS2g1mSMgwTJ7wPuo1aIBGjZpg86aNiI+PR78BA0vnAUqJDJ0yNAJydMrQCMjRqcbGzMwM3LgWp/84/sZ1XLoQCzsHB7i6uqOxbzMsWTAXWq0Wrm7uOBVzHD/u2oF3xr4vrBlQ73N5Pe6f5/Lmjeu4+Ecs7B0c4OrmjoGDh2L1imWo5uGB6tU9sGr5MlhZW6FzULcy6Zn/ZjsMaFcb/ab/gHuZOahcwQYAkJqZhQfZOthozTF+QFP8cPQKbiVlwsneCq91aYAqLuWx5dCfAB7OqO+c1hPWWnMMm7sX9taWsLd+uMd6Qtp95JnwlzY1vuZPkqERkKeTTE/4YL0o165dQ3h4OFauXCnk8V8M6oLUlGQsW7oECQl34F2rNhZ/vgzu7lWE9BREhk4ZGgE5OmVoBOToVGPjH+fP4d03huk/XjjvYwBAULeemDxlJj6aOQdfLJ6PqR+OR1paKlxd3fHam+8iuE/JtxosTWp8LmPPncObI/+Z8Jn/yWwAQNfuwQifFoGhr4xA1oMsfDxzKtLT0lC/4XNYuHQ5bG1ty6Tn9a4NAQD7ZvU2OD5y3n58feAP6PIU+FR1xMsd68DZ3hpJaQ8Qfek2Oo3fgti4h29CbeJdCc3ruAIAzi8fanA/PsO/Qtyd4s3WlwY1vuZPkqERkKezVMiy/kQluM86EVEZetp91k2htPZZL2tPu8+6KZR0n3URSnOfdZKD2vZZP/JXiugEvZZeFUQnFEn4y7djx45Cr798+bKJSoiIiIiorGk4tV4iwgfrwcHBBe6z/gi3LSIiIiKi/yLhu8G4ublh8+bNyMvLM3qJiYkRnUhEREREJITwwbqfn1+hA/KiZt2JiIiISB4ajXouMhC+DCYsLAwZGfn/QYhHvL29ERkZacIiIiIiIiJ1ED5YDwgIKPR6W1tbtGvXzkQ1RERERETqIXywTkRERET/HZKsPlEN4WvWiYiIiIjIOA7WiYiIiIhUistgiIiIiMh0uA6mRDizTkRERESkUpxZJyIiIiKT0XBqvUQ4s05EREREpFIcrBMRERERqRSXwRARERGRyWi4CqZEOLNORERERKRSHKwTEREREakUl8EQERERkclwFUzJcGadiIiIiEilOLNORERERKbDqfUS0SiKooiOKAsPckUXEBEBuTr1f4s1N+NPzv8Sx9ZhohOKJenQHNEJRZJlVxMrlU3NxlxNE52g5+thLzqhSFwGQ0RERESkUir7XYuIiIiInmUaroMpEc6sExERERGpFAfrREREREQqxcE6EREREZmMRqOey7+xZMkS1KhRA1ZWVvDz88Ovv/5a4LlbtmzBCy+8gIoVK8Le3h7+/v7Ys2dPiR6Pg3UiIiIiomLYuHEjxowZg8mTJ+PkyZMICAhAUFAQ4uLijJ7/yy+/4IUXXsCuXbtw4sQJdOjQAd27d8fJkyeL/ZjcupGIqAxx60ZSG27dWHq4deO/cyouXXSCXuPqdiU6v0WLFvD19cXSpUv1x+rWrYvg4GBEREQU6z7q16+PAQMG4H//+1+xzlfZy0dEREREzzI1/Y6TlZWFrKwsg2NarRZarTbfudnZ2Thx4gQmTJhgcDwwMBBRUVHFery8vDykp6fDycmp2I1cBkNERERE/0kRERFwcHAwuBQ0Q56YmAidTofKlSsbHK9cuTJu3bpVrMf75JNPkJGRgf79+xe7kTPrRERERGQ6KppanzhxIkJDQw2OGZtVf5zmifVPiqLkO2bM+vXrMWXKFGzfvh2VKlUqdiMH60RERET0n1TQkhdjXFxcYGZmlm8W/c6dO/lm25+0ceNGvPrqq9i0aRM6depUokYugyEiIiIiKoKlpSX8/Pywb98+g+P79u1Dq1atCrzd+vXr8corr+Cbb75B165dS/y4nFknIiIiIpPRqGkdTAmFhoZiyJAhaNq0Kfz9/bFs2TLExcXhjTfeAPBwWc2NGzewZs0aAA8H6kOHDsWCBQvQsmVL/ay8tbU1HBwcivWYHKwTERERERXDgAEDcPfuXUydOhXx8fFo0KABdu3aBQ8PDwBAfHy8wZ7rX3zxBXJzczFq1CiMGjVKfzwkJASrV68u1mNyn3UiojLEfdZJbbjPeunhPuv/zu/X7olO0HuuWnnRCUVS2ctHRERERM8yWX7JUQu+wZSIiIiISKU4WCciIiIiUikO1oth4/p1CAp8Hs2aNMTAfr0RcyJadJJRMnTK0AjI0SlDIyBHp9obN21cjwF9eqCtvx/a+vvhlZcH4LdffxGdZZTan8tHZOgU2di6cQ18N3cYLu/8APePzkH3tvUNrp884gWc2hiGxJ9n4Oa+j/DDwtfQrH41/fWO9tb4dFxPnP42DHcPzsDF7ZPwSWhP2NtamezP8MiJ6ON4d9QbeKFDGzRu4IOfDuw3eUNxyfB5WRo0KrrIQDWD9evXr+PevfxvOMjJycEvv4j7ofTj7l34eFYERr72JjZ+tw2+vn546/WRiL95U1iTMTJ0ytAIyNEpQyMgR6cMjZUrV8Y7Y8Zh7frvsHb9d2jWvCVCR4/CX39eEp1mQIbnEpCjU3SjrbUlzly6ibFztxm9/s+4BIyduw1NB32Cjq8twdX4JHz/2Ui4VLAFALi52MOtogMmfrYTTQd9ipFTN+IFfx98/kE/k/Q/7v79TNT28cGESf8z+WOXhOjXnNRL+G4w8fHx6NmzJ06cOAGNRoPBgwdj8eLFKF/+4btzb9++DXd3d+h0uhLdb2ntBjN4YD/UrVcPH/zvI/2x4O5B6PB8J4weO650HqQUyNApQyMgR6cMjYAcnWXdWFa7wXRo0wKjQ8MQ3LvvU99Xae0GI8PrDcjRWZaNJd0N5v7ROegfthrf/3KuwHPsbLW489N0BI36Aj9H/2n0nN7PP4eVH70E5/aTodPlFfm4ZbEbTOMGPvh0wWI837Fk/4JkQUrzjZJl+ZqrbTeYszfUsxtMgyrq3w1G+Mz6hAkTYGZmhqNHj+LHH3/E+fPn0b59eyQnJ+vPEfX7RE52NmLPn4N/qzYGx/1btcbpUyeFNBkjQ6cMjYAcnTI0AnJ0ytD4JJ1Ohz27f8D9+5l4rlFj0Tl6sjyXMnTK0Pg4C3MzvBrcEinp93HmUsGzwPblrZCW8aBYA/X/GtleczIt4b9r7d+/H1u3bkXTpk0BAAEBARgwYACef/55HDhwAACgEbTHT3JKMnQ6HZydnQ2OOzu7IDExQUiTMTJ0ytAIyNEpQyMgR6cMjY9cungBw4a8hOzsLFjb2GDu/EWo6eUtOktPludShk4ZGgEgqHVdrJk+GDZWFriVmI5u7yzD3dRMo+c62dtg4vBOWLH1iIkr5SDLa05iCJ9ZT01NhaOjo/5jrVaL7777Dp6enujQoQPu3LlT5H1kZWUhLS3N4JKVlVVqjU/+sqAoirBfIAojQ6cMjYAcnTI0AnJ0ytDoWaMG1m/aitVfb0Df/gMR/sEEXP7L+HIDkWR4LgE5OtXeePDEn2gxZB46jFyMvUcu4OuZQ1DR0TbfeXa2WmydNxyxV25jxvJ9AkrlofbXvLRoVPSfDIQP1mvWrInff//d4Ji5uTk2bdqEmjVrolu3bkXeR0REBBwcHAwuc2ZHPHWbYwVHmJmZITEx0eB4UtJdODu7PPX9lxYZOmVoBOTolKERkKNThsZHLCwsUa26B+rVb4h3Ro9D7dp1sH7dGtFZerI8lzJ0ytAIAJkPcnD5+l0cOxuHN2dsQq5Oh5AezQ3OKW+jxY75I3AvMxsDxn+FXC6BMUqW15zEED5YDwoKwrJly/IdfzRgb9y4cZFr1idOnIjU1FSDS9j4iU/dZmFpibr16uNI1G8Gx49ERaFR4yZPff+lRYZOGRoBOTplaATk6JShsSCKoiA7O1t0hp4sz6UMnTI0GqOBBlqLf1bX2tlqsfOzkcjO0aHve6uQlV1KOz88g2R9zck0hK9ZnzFjBjIzja9xMzc3x5YtW3D9+vVC70Or1UKr1RocK63dYIaEDMPkCe+jXoMGaNSoCTZv2oj4+Hj0GzCwdB6glMjQKUMjIEenDI2AHJ0yNC5a8Clat2mLyq6uyMjIwN4fd+FE9DEsXPql6DQDMjyXgBydohttrS3hVfWfGV1Pdyc8V8sdyWmZuJuagfHDOuKHX8/jVmIanBxs8Voff1Sp5IAtBx7+TXl5m4cDdWutJYaFr4e9rZV+j/WElHvIyzPdxhGZmRmIi4vTf3zjxnX88UcsHBwc4ObmbrKOooh+zU3pGVzZU6aED9bNzc1hb29f4PU3b97ERx99hJUrV5qw6h8vBnVBakoyli1dgoSEO/CuVRuLP18Gd/cqQnoKIkOnDI2AHJ0yNAJydMrQmJR0Fx9Ofh+JCQkoX94OtWr7YOHSL9HSv7XoNAMyPJeAHJ2iG33rVsXepW/qP/54bA8AwNqd0Xhn9mb4eFTCy12awrmCLZJSMxAdex2dXl+C2Cu3AQBN6lRB8wYeAIDzWyYY3LdP8EzExSfDVM6dPYuRw4fqP/7k44fLZLv37IVpM2aZrKMool9zUi/h+6wX5fTp0/D19RW2zzoR0dMoq33WS1Np7bNOcijpPuuilMU+66VNlhlite2zfv5mhugEvXru+d8UrTbCX74dO3YUev3ly5dNVEJEREREZU2S33FUQ/hgPTg4GBqNptA3kT6L2xYRERERERVF+G4wbm5u2Lx5M/Ly8oxeYmJiRCcSERERUWnRqOgiAeGDdT8/v0IH5EXNuhMRERERPauEL4MJCwtDRkbBbzTw9vZGZGSkCYuIiIiIiNRB+GA9ICCg0OttbW3Rrl07E9UQERERUVnSyLL+RCWEL4MhIiIiIiLjOFgnIiIiIlIp4ctgiIiIiOi/gztylwxn1omIiIiIVIoz60RERERkMpxYLxnOrBMRERERqRQH60REREREKsVlMERERERkOlwHUyKcWSciIiIiUikO1omIiIiIVIrLYIiIiIjIZDRcB1MinFknIiIiIlIpDtaJiIiIiFSKy2CIiIiIyGQ0XAVTIhpFURTREWXhQa7oAjK17Nw80QlFkqERAMpb8ff40vJsfocVI0en/q8fS3P1/4V1QlqW6IRiaR2+R3RCkS7O6yE6oVjU9i39zzv3RSfoeVeyFp1QJJW9fERERET0LOPEesmofwqAiIiIiOg/ioN1IiIiIiKV4jIYIiIiIjIdroMpEc6sExERERGpFAfrREREREQqxWUwRERERGQyGq6DKRHOrBMRERERqRQH60REREREKsVlMERERERkMhqugikRzqwTEREREakUZ9aJiIiIyGQ4sV4ynFknIiIiIlIpDtaJiIiIiFSKy2CIiIiIyHS4DqZEOLNORERERKRSHKwTEREREakUl8EQERERkclouA6mRDhYL4aN69dh9aoVSExIgJd3Lbw/YRJ8/ZqKzspHhk61N/YI6oj4mzfzHe874CWMn/Q/AUUPnYqJxjdrVuKP2PO4m5iAiLmfoW2HjvrrV3yxGPv37Mad27dgYWEBn7r18Npbo1G/4XPCmh9R+2sOqL/xRPRxfLVqBWLPn0VCQgI+XbAYz3fsJDorHxk61fo1boyaPi+/+Wo5Dh08gGtXr0Cr1aJew8YY+dYYVPOoYfT8ebOm4oft3+HN0WHoM3BImXU193LCGx290bB6BVR2sMKIL49h7++39NfHLexh9HYztp3DFwf+AgBYmpfD5OB66OlXBVYWZvjtYiImf/s7bqU8KLPugqjpNSf1UMUymLt37yIyMhJJSUkAgMTERMyePRtTp05FbGys0LYfd+/Cx7MiMPK1N7Hxu23w9fXDW6+PNPrNXiQZOmVo/GrdJuw+8Iv+suiLFQCATi+8KLTr/v378K7tg9Dxk41eX626B0LHT8aajVuxZMVauLpVwdhRI5GcnGTiUkMyvOYyNN6/n4naPj6YoLLB5JNk6FTr1/iT1PZ5+fvJaPTsMxALv/wasxcsgy5Xh/Fj3sD9+5n5zv3t4E/44/wZOLtUKvMuG605zt9Iw4ebzhi93m/SHoPLuK9PIi9Pwe5T8fpzwns3wIvPueHt1SfQZ/4h2GjNsOr1Fihn4slftb3mZUmjUc9FBsIH68eOHYOXlxc6duwIb29vnDhxAs2bN8eKFSuwdu1a+Pn5ISYmRljf2q9WoVefPujdtx9qennh/YmT4ermim83rhfWZIwMnTI0Ojo5wcWlov5y6JefUbVadfg2bSa0y791AF57azTaP/+C0esDg7qhWQt/VKlaDTW9vPFu6PvIyLiHvy5dNHGpIRlecxka2wS0w9vvjkXHFwJFpxRKhk61fo0/SW2fl7Pmf47OXXvCs6Y3vGr5IOyDqbhzKx6X/jhvcF7indtY+MlMTJwSAXPzsv/L+5/P38HcH/7Aj6fjjV6fkJ5lcAl8zhWHLyUi7u7DXzLsrMwxwL86pm87h0MXEnHuehrGfBWDOu72aONTscz7H6e215zUQ/hgffLkyejXrx9SU1MxadIkBAcHo2PHjrh48SIuXbqEQYMGYdq0aULacrKzEXv+HPxbtTE47t+qNU6fOimkyRgZOmVofFJOTjZ2//A9egT3hkaWX7/xsHv7lk0oX94O3rV8xHVI8JrL0EhlR61f4zJ8XmbcuwcAsLN30B/Ly8vDrKmT0H/wK/Cs6S0qrUAudlo8X78yNhyO0x9rWL0CLM3L4ZfYBP2x22lZuBCfhqY1nUzWJsNrTuIIH6yfOHECoaGhsLOzw+jRo3Hz5k2MHDlSf/2oUaNw/PhxIW3JKcnQ6XRwdnY2OO7s7ILExIQCbmV6MnTK0Pikn386gHvp6ejWo5folGL57Zef0alNU3Tw98XGb9Zg/pIvUcHRUViPDK+5DI1UdtT6Na72z0tFUfD5Z3PQoFET1PCqpT++Ye1KmJmZo1f/wQLrCta3eTVkPMg1mIWvaKdFVo4OqfdzDM5NTMtCRTutydrU/pqXNo2KLjIQ/gbT7OxsWFtbAwAsLCxgY2MDFxcX/fXOzs64e/duofeRlZWFrKwsg2OKmRZabel8oT0546IoiqpmYR6RoVOGxkd2bN0M/9YBqFip7NddlgbfZs2xev1mpKSk4Put3+HDCePw5Vfr4ejkXPSNy5AMr7kMjVT61P41rtbPy4VzZ+Lyn5cw/4vV+mMX/ziPrd+uw9LVG1XRaEx//2rYGn0dWbl5RZ6r0WigmKDJ2OM+Ti2vOYklfGa9WrVquHz5sv7jDRs2wM3NTf9xfHy8weDdmIiICDg4OBhc5syOeOo2xwqOMDMzQ2JiosHxpKS7cHYuvMmUZOiUofFx8Tdv4NjRwwju3Vd0SrFZW9ugajUPNGjYCBP/Nw1mZmb4ftsWYT0yvOYyNFLZUPPXuJo/Lxd+EoHDh37G3MXLUbGSq/74mVMnkJKchEG9OiOwTRMEtmmC27du4ouFn2BwL/Fv3m3u5QTvynYGS2CAh2vatRZmcLC2MDjubGeJxHTDScCypObXnMQTPlgfOHAg7ty5o/+4a9eu+pl2ANixYweaN29e6H1MnDgRqampBpew8ROfus3C0hJ169XHkajfDI4fiYpCo8ZNnvr+S4sMnTI0Pu777Vvh6OSE1gHtRKf8a4qiICcnW9jjy/Cay9BIZUPNX+Nq/LxUFAUL587EoZ8PYM6i5XBzr2pwfaeg7li29jt88dW3+ouzSyX0G/wKZs1fKqT5cQP8q+P3uBTE3kgzOH4mLgXZuXkIqPPPm0kr2Wvh42aP6Mum201Lja95WRK9A4xsu8EIXwYTHh5e6PWTJ0+GmZlZoedotfmXvDzIfeo0AMCQkGGYPOF91GvQAI0aNcHmTRsRHx+PfgMGls4DlBIZOmVoBB6+Ser77VvQtXuwSXYzKI7MzAxcv/bPjNDNm9dx8UIs7O0d4FChAr5asQxt2nWAi0tFpKakYMumDUi4cxsdOnUWWC3Hay5DY2ZmBuLi/nn9b9y4jj/+iIWDgwPc3NwFlhmSpVONX+NPUtvn5WdzZ+CnvbsxdfYC2NjYIunuwxlgW9vy0FpZwcGhAhwcKhjcxtzcHE5OzgXuxV4abCzN4FnRVv9xNWcb1Ktij5TMHNxMvg8AKG9ljq6N3TF967l8t09/kIuNh+PwQa/6SM7IRkpmNj4Iro8/bqbh0AXTrhVX22tO6qHO71KPuXv3LsLDw7Fy5Uohj/9iUBekpiRj2dIlSEi4A+9atbH482Vwd68ipKcgMnTK0AgAx44cxq34ePQI7i06Re+P8+fwzuvD9B8v/PRjAEBQt54ImxSOq39fwe6d25Gakgx7hwqoW78Blixfg5peYndkkOE1l6Hx3NmzGDl8qP7jTz5+uMyve89emDZjlqisfGTpVOPX+JPU9nn5/ZZvAQDjRg03OB72wTR07tpTRBIA4LnqFfDt6Nb6j8N7NwAAbDoah3FfnwIA9PCtAo0G2H7ihtH7mLrlLHLz8rBkeFNYWZTDbxcSEfr1UeSZeNG62l5zUg+Noigi3kNRbKdPn4avry90Ol2JbldaM+skj+xivGlINBkagYczUVQ61P0dVi45OvV//ViaC19dWqSENNOtxX4arcP3iE4o0sV5xv+FVLVR27f068nilmg+qaqjpeiEIgl/+Xbs2FHo9Y+/+ZSIiIiI6L9E+GA9ODj44RZJhUw/cdsiIiIiomcDh3UlI/zv69zc3LB582bk5eUZvcTExIhOJCIiIiISQvhg3c/Pr9ABeVGz7kREREREzyrhy2DCwsKQkZFR4PXe3t6IjIw0YRERERERlRWugikZ4YP1gICAQq+3tbVFu3bq+0criIiIiIjKmvBlMEREREREZJzwmXUiIiIi+u/gbjAlw5l1IiIiIiKV4mCdiIiIiEiluAyGiIiIiExGw/1gSoQz60REREREKsWZdSIiIiIyHU6slwhn1omIiIiIVIqDdSIiIiIileIyGCIiIiIyGa6CKRnOrBMRERERqRQH60REREREKsVlMERERERkMhqugykRzqwTEREREamURlEURXREWXiQK7qAiIhIfXJ1cvzYNzdT//SrY8uxohOK5X70PNEJBu6k54hO0KtkZyE6oUhcBkNEREREJqPhfjAlwmUwREREREQqxZl1IiIiIjIdTqyXCGfWiYiIiIhUioN1IiIiIiKV4jIYIiIiIjIZroIpGc6sExERERGpFAfrREREREQqxWUwRERERGQyGq6DKRHOrBMRERERqRRn1omIiIjIZPgvmJYMZ9aJiIiIiFSKg3UiIiIiIpXiMhgiIiIiMhm+wbRkOLNORERERKRSHKwTEREREakUB+tERERERCrFwToRERERkUpxsF4MG9evQ1Dg82jWpCEG9uuNmBPRopOMkqFThkZAjk4ZGgE5OmVoBOTolKERkKNT7Y0x0ccx5u030LljAPyeq4PIn/aLTiqQmp/L917piPvR8zAnNFh/rJJTeSwLfwmXd0/B3UOzsf2z1+BVzUVcJAml2sF6zZo1cenSJdEZ+HH3Lnw8KwIjX3sTG7/bBl9fP7z1+kjE37wpOs2ADJ0yNAJydMrQCMjRKUMjIEenDI2AHJ0yNN6/fx+1fepg/MQPRacUSs3PpV+9ani1lz9+v3jD4Pi3c19FjSrO6DduBVoOnou4W8nYteRN2FhZCiotXRqNei4y0CiKoogM+Oyzz4weDw0Nxfvvvw9XV1cAwLvvvlui+32Q+9RpAIDBA/uhbr16+OB/H+mPBXcPQofnO2H02HGl8yClQIZOGRoBOTplaATk6JShEZCjU4ZGQI7OsmzM1ZX+j32/5+pg7vxF6PB8p1K7T3Oz0hlJleVz6dhy7L++ra21JQ5/PQ6jZ2/GhFdfwO8XbiDs023wrl4RZ7ZMgm//2Yi9fAsAUK6cBnF7p+GDhd9j9fajJX6s+9Hz/nVnWUi5rxOdoFfB2kx0QpGEz6yPGTMGc+bMwbx58wwueXl5WLNmDebNm4f58+cLacvJzkbs+XPwb9XG4Lh/q9Y4feqkkCZjZOiUoRGQo1OGRkCOThkaATk6ZWgE5OiUoVEWan4u54/vix9/i0XksYsGx7UWD/8JnAdZOfpjeXkKsnN1aNW4pkkby4pGRf/JQPhgfeTIkXBxccGuXbtw5coV/cXMzAx79+7FlStXcPnyZSFtySnJ0Ol0cHZ2Njju7OyCxMQEIU3GyNApQyMgR6cMjYAcnTI0AnJ0ytAIyNEpQ6Ms1Ppc9gtsgsZ1quDDRTvzXXfh79u4ejMJ097uhgp21rAwN8N7IR3h5mIPVxd7AbUkmvDB+hdffIHw8HB07twZixYt+lf3kZWVhbS0NINLVlZWqTVqnljUpChKvmNqIEOnDI2AHJ0yNAJydMrQCMjRKUMjIEenDI2yUNNzWbVyBcwZ1wvDP1yHrOz8a3ZzdXl46f1V8K5eEfGRM5F0aDYC/Lzw42/nocvLE1BMogkfrANAcHAwDh8+jK1btyIoKAi3bt0q0e0jIiLg4OBgcJkzO+KpuxwrOMLMzAyJiYkGx5OS7sLZWT3vypahU4ZGQI5OGRoBOTplaATk6JShEZCjU4ZGWajxuWxSpyoqO9sham0o0o/MRfqRuWjr5423BgYg/chclCunwck/rqPl4Lmo3G4iarwYjp7vLoOzgy3+vpEkpLm0iX5TqWxvMFXFYB0AqlSpgv3796Nt27Zo0qQJSvK+14kTJyI1NdXgEjZ+4lM3WVhaom69+jgS9ZvB8SNRUWjUuMlT339pkaFThkZAjk4ZGgE5OmVoBOTolKERkKNThkZZqPG5jDx+CX4DZqPF4Ln6y4lzcdjwYwxaDJ6LvLx/xj9pGQ+QmJIBr2ou8K1bDTsPnhXSTGKZiw54nEajwcSJExEYGIhDhw7Bzc2tWLfTarXQarUGx0prN5ghIcMwecL7qNegARo1aoLNmzYiPj4e/QYMLJ0HKCUydMrQCMjRKUMjIEenDI2AHJ0yNAJydMrQmJmZgWtxcfqPb964jgt/xMLewQFubu4Cywyp7bm8l5mF838ZriDIeJCNpJQM/fHeHRshIeUert1KQQNvN8wd1wvfHzyDA0cviEgmwVQ1WH/Ez88Pfn5+AIBr164hPDwcK1euFNLyYlAXpKYkY9nSJUhIuAPvWrWx+PNlcHevIqSnIDJ0ytAIyNEpQyMgR6cMjYAcnTI0AnJ0ytB4/txZvP5qiP7jT+fMAgB06xGMj6bPEpWVjwzP5ZNcXewxe2xPVHK2w63ENKz7IRoRy/eKzio1kqw+UQ3h+6wX5fTp0/D19YVOV7I9OUtrZp2IiOhZUhb7rJeF0tpnvSw9zT7rpqS2fdbTH6jnjbJ2VqpZEV4g4TPrO3bsKPR6Uds2EhERERGJJnywHhwcDI1GU+gbSrlVFREREdEzgsO6EhE+9+/m5obNmzcjLy/P6CUmJkZ0IhERERGREMIH635+foUOyIuadSciIiIieWhU9J8MhC+DCQsLQ0ZGRoHXe3t7IzIy0oRFRERERETqIHywHhAQUOj1tra2aNeunYlqiIiIiIjUQ/hgnYiIiIj+O7hvSMkIX7NORERERETGcbBORERERKRSXAZDRERERCbDVTAlw5l1IiIiIiKV4mCdiIiIiEiluAyGiIiIiEyH62BKhDPrREREREQqxZl1IiIiIjIZDafWS4Qz60RERERExbRkyRLUqFEDVlZW8PPzw6+//lro+QcPHoSfnx+srKxQs2ZNfP755yV6PA7WiYiIiIiKYePGjRgzZgwmT56MkydPIiAgAEFBQYiLizN6/pUrV9ClSxcEBATg5MmTmDRpEt59911s3ry52I+pURRFKa0/gJo8yBVdQEREpD65Ojl+7JubqX+phGPLsaITiuV+9DzRCQbUNEazKuGC8BYtWsDX1xdLly7VH6tbty6Cg4MRERGR7/zx48djx44diI2N1R974403cPr0aRw+fLhYj8mZdSIiIiKiImRnZ+PEiRMIDAw0OB4YGIioqCijtzl8+HC+8zt37ozo6Gjk5OQU63H5BlMiIiIi+k/KyspCVlaWwTGtVgutVpvv3MTEROh0OlSuXNngeOXKlXHr1i2j93/r1i2j5+fm5iIxMRFubm5FRypULA8ePFDCw8OVBw8eiE4pkAyNiiJHpwyNiiJHpwyNiiJHpwyNiiJHpwyNiiJHpwyNiiJHpwyNz5rw8HAFgMElPDzc6Lk3btxQAChRUVEGx6dPn674+PgYvU2tWrWUmTNnGhw7dOiQAkCJj48vVuMzu2a9tKWlpcHBwQGpqamwt7cXnWOUDI2AHJ0yNAJydMrQCMjRKUMjIEenDI2AHJ0yNAJydMrQ+Kwpycx6dnY2bGxssGnTJvTq1Ut/fPTo0Th16hQOHjyY7zZt27ZFkyZNsGDBAv2xrVu3on///sjMzISFhUWRjVyzTkRERET/SVqtFvb29gYXYwN1ALC0tISfnx/27dtncHzfvn1o1aqV0dv4+/vnO3/v3r1o2rRpsQbqAAfrRERERETFEhoaiuXLl2PlypWIjY3F2LFjERcXhzfeeAMAMHHiRAwdOlR//htvvIGrV68iNDQUsbGxWLlyJVasWIH33nuv2I/JN5gSERERERXDgAEDcPfuXUydOhXx8fFo0KABdu3aBQ8PDwBAfHy8wZ7rNWrUwK5duzB27FgsXrwY7u7u+Oyzz9CnT59iPyYH68Wk1WoRHh5e4F+NqIEMjYAcnTI0AnJ0ytAIyNEpQyMgR6cMjYAcnTI0AnJ0ytBIwFtvvYW33nrL6HWrV6/Od6xdu3aIiYn514/HN5gSEREREakU16wTEREREakUB+tERERERCrFwToRERERkUpxsF6EX375Bd27d4e7uzs0Gg22bdsmOimfiIgINGvWDHZ2dqhUqRKCg4Nx4cIF0Vn5LF26FM8995x+H1N/f3/s3r1bdFahIiIioNFoMGbMGNEpBqZMmQKNRmNwcXV1FZ2Vz40bN/Dyyy/D2dkZNjY2aNy4MU6cOCE6y4Cnp2e+51Kj0WDUqFGi0/Ryc3PxwQcfoEaNGrC2tkbNmjUxdepU5OXliU4zkJ6ejjFjxsDDwwPW1tZo1aoVjh8/LrSpqO/hiqJgypQpcHd3h7W1Ndq3b49z586pqnHLli3o3LkzXFxcoNFocOrUKZP2FaczJycH48ePR8OGDWFrawt3d3cMHToUN2/eVE0j8PB7Z506dWBrawtHR0d06tQJR48eNWljcTof9/rrr0Oj0WD+/Pkm6yN14WC9CBkZGWjUqBEWLVokOqVABw8exKhRo3DkyBHs27cPubm5CAwMREZGhug0A1WrVsWsWbMQHR2N6OhoPP/88+jZs6fJfzAW1/Hjx7Fs2TI899xzolOMql+/PuLj4/WXM2fOiE4ykJycjNatW8PCwgK7d+/G+fPn8cknn6BChQqi0wwcP37c4Hl89I9X9OvXT3DZP2bPno3PP/8cixYtQmxsLD7++GPMmTMHCxcuFJ1mYMSIEdi3bx/Wrl2LM2fOIDAwEJ06dcKNGzeENRX1Pfzjjz/Gp59+ikWLFuH48eNwdXXFCy+8gPT0dNU0ZmRkoHXr1pg1a5bJmgrqKKgzMzMTMTEx+PDDDxETE4MtW7bg4sWL6NGjh2oaAaB27dpYtGgRzpw5g0OHDsHT0xOBgYFISEhQVecj27Ztw9GjR+Hu7m6iMlIlhYoNgLJ161bRGUW6c+eOAkA5ePCg6JQiOTo6KsuXLxedkU96erpSq1YtZd++fUq7du2U0aNHi04yEB4erjRq1Eh0RqHGjx+vtGnTRnRGiY0ePVrx8vJS8vLyRKfode3aVRk+fLjBsd69eysvv/yyoKL8MjMzFTMzM2Xnzp0Gxxs1aqRMnjxZUJWhJ7+H5+XlKa6ursqsWbP0xx48eKA4ODgon3/+uYDCwn/OXLlyRQGgnDx50qRNxhTn5+GxY8cUAMrVq1dNE/WE4jSmpqYqAJT9+/ebJsqIgjqvX7+uVKlSRTl79qzi4eGhzJs3z+RtpA6cWX8GpaamAgCcnJwElxRMp9Nhw4YNyMjIgL+/v+icfEaNGoWuXbuiU6dOolMKdOnSJbi7u6NGjRoYOHAgLl++LDrJwI4dO9C0aVP069cPlSpVQpMmTfDll1+KzipUdnY2vv76awwfPhwajUZ0jl6bNm1w4MABXLx4EQBw+vRpHDp0CF26dBFc9o/c3FzodDpYWVkZHLe2tsahQ4cEVRXuypUruHXrFgIDA/XHtFot2rVrh6ioKIFlz4bU1FRoNBrV/W3aI9nZ2Vi2bBkcHBzQqFEj0TkG8vLyMGTIEISFhaF+/fqic0gw/qNIzxhFURAaGoo2bdqgQYMGonPyOXPmDPz9/fHgwQOUL18eW7duRb169URnGdiwYQNiYmKEr7UtTIsWLbBmzRrUrl0bt2/fxvTp09GqVSucO3cOzs7OovMAAJcvX8bSpUsRGhqKSZMm4dixY3j33Xeh1WoN/ilmNdm2bRtSUlLwyiuviE4xMH78eKSmpqJOnTowMzODTqfDjBkz8NJLL4lO07Ozs4O/vz+mTZuGunXronLlyli/fj2OHj2KWrVqic4z6tatWwCAypUrGxyvXLkyrl69KiLpmfHgwQNMmDABgwYNgr29vegcAzt37sTAgQORmZkJNzc37Nu3Dy4uLqKzDMyePRvm5uZ49913RaeQCnCw/ox5++238fvvv6t2JsvHxwenTp1CSkoKNm/ejJCQEBw8eFA1A/Zr165h9OjR2Lt3b74ZQjUJCgrS/3/Dhg3h7+8PLy8vfPXVVwgNDRVY9o+8vDw0bdoUM2fOBAA0adIE586dw9KlS1U7WF+xYgWCgoJUtz5048aN+Prrr/HNN9+gfv36OHXqFMaMGQN3d3eEhISIztNbu3Ythg8fjipVqsDMzAy+vr4YNGjQU/3Lfabw5N+iKIqiqr9ZkU1OTg4GDhyIvLw8LFmyRHROPh06dMCpU6eQmJiIL7/8Ev3798fRo0dRqVIl0WkAgBMnTmDBggWIiYnh5yEB4BtMnynvvPMOduzYgcjISFStWlV0jlGWlpbw9vZG06ZNERERgUaNGmHBggWis/ROnDiBO3fuwM/PD+bm5jA3N8fBgwfx2WefwdzcHDqdTnSiUba2tmjYsCEuXbokOkXPzc0t3y9hdevWRVxcnKCiwl29ehX79+/HiBEjRKfkExYWhgkTJmDgwIFo2LAhhgwZgrFjxyIiIkJ0mgEvLy8cPHgQ9+7dw7Vr13Ds2DHk5OSgRo0aotOMerSD0qMZ9kfu3LmTb7adiicnJwf9+/fHlStXsG/fPtXNqgMPv196e3ujZcuWWLFiBczNzbFixQrRWXq//vor7ty5g+rVq+t/Dl29ehXjxo2Dp6en6DwSgIP1Z4CiKHj77bexZcsW/PTTT6r9wWiMoijIysoSnaHXsWNHnDlzBqdOndJfmjZtisGDB+PUqVMwMzMTnWhUVlYWYmNj4ebmJjpFr3Xr1vm2EL148SI8PDwEFRVu1apVqFSpErp27So6JZ/MzEyUK2f47drMzEx1Wzc+YmtrCzc3NyQnJ2PPnj3o2bOn6CSjatSoAVdXV/0OQMDDdcwHDx5Eq1atBJbJ6dFA/dKlS9i/f79qluQVRW0/h4YMGYLff//d4OeQu7s7wsLCsGfPHtF5JACXwRTh3r17+PPPP/UfX7lyBadOnYKTkxOqV68usOwfo0aNwjfffIPt27fDzs5OP0vk4OAAa2trwXX/mDRpEoKCglCtWjWkp6djw4YN+Pnnn/Hjjz+KTtOzs7PLt9bf1tYWzs7OqnoPwHvvvYfu3bujevXquHPnDqZPn460tDRVLYkYO3YsWrVqhZkzZ6J///44duwYli1bhmXLlolOyycvLw+rVq1CSEgIzM3V922xe/fumDFjBqpXr4769evj5MmT+PTTTzF8+HDRaQb27NkDRVHg4+ODP//8E2FhYfDx8cGwYcOENRX1PXzMmDGYOXMmatWqhVq1amHmzJmwsbHBoEGDVNOYlJSEuLg4/Z7lj34JdnV1Nem/r1BYp7u7O/r27YuYmBjs3LkTOp1O/7PIyckJlpaWwhudnZ0xY8YM9OjRA25ubrh79y6WLFmC69evm3yr1qJe8yd/0bGwsICrqyt8fHxM2kkqIXIrGhlERkYqAPJdQkJCRKfpGesDoKxatUp0moHhw4crHh4eiqWlpVKxYkWlY8eOyt69e0VnFUmNWzcOGDBAcXNzUywsLBR3d3eld+/eyrlz50Rn5fP9998rDRo0ULRarVKnTh1l2bJlopOM2rNnjwJAuXDhgugUo9LS0pTRo0cr1atXV6ysrJSaNWsqkydPVrKyskSnGdi4caNSs2ZNxdLSUnF1dVVGjRqlpKSkCG0q6nt4Xl6eEh4erri6uiparVZp27atcubMGVU1rlq1yuj14eHhqul8tK2ksUtkZKQqGu/fv6/06tVLcXd3VywtLRU3NzelR48eyrFjx0zWV5xOY7h143+bRlEUpfR/BSAiIiIioqfFNetERERERCrFwToRERERkUpxsE5EREREpFIcrBMRERERqRQH60REREREKsXBOhERERGRSnGwTkRERESkUhysExERERGpFAfrRFSmVq9eDY1Go7+Ym5ujatWqGDZsGG7cuGGSBk9PT7zyyiv6j3/++WdoNBr8/PPPJbqfqKgoTJkyBSkpKaXaBwCvvPIKPD09izyvffv2aNCgQak85qPXJjo6ulTu7/H7/Pvvv0vtPomI/ss4WCcik1i1ahUOHz6Mffv2YeTIkVi/fj0CAgKQkZFh8hZfX18cPnwYvr6+JbpdVFQUPvroozIZrBMRERljLjqAiP4bGjRogKZNmwIAOnToAJ1Oh2nTpmHbtm0YPHiw0dtkZmbCxsam1Fvs7e3RsmXLUr9fIiKi0saZdSIS4tFg+erVqwAeLgMpX748zpw5g8DAQNjZ2aFjx44AgOzsbEyfPh116tSBVqtFxYoVMWzYMCQkJBjcZ05ODt5//324urrCxsYGbdq0wbFjx/I9dkHLYI4ePYru3bvD2dkZVlZW8PLywpgxYwAAU6ZMQVhYGACgRo0a+mU9j9/Hxo0b4e/vD1tbW5QvXx6dO3fGyZMn8z3+6tWr4ePjA61Wi7p162LNmjX/6jksSHR0NAYOHAhPT09YW1vD09MTL730kv65flJycjKGDRsGJycn2Nraonv37rh8+XK+8/bv34+OHTvC3t4eNjY2aN26NQ4cOFCq7UREZIiDdSIS4s8//wQAVKxYUX8sOzsbPXr0wPPPP4/t27fjo48+Ql5eHnr27IlZs2Zh0KBB+OGHHzBr1izs27cP7du3x/379/W3HzlyJObOnYuhQ4di+/bt6NOnD3r37o3k5OQie/bs2YOAgADExcXh008/xe7du/HBBx/g9u3bAIARI0bgnXfeAQBs2bIFhw8fNlhKM3PmTLz00kuoV68evv32W6xduxbp6ekICAjA+fPn9Y+zevVqDBs2DHXr1sXmzZvxwQcfYNq0afjpp5+e/kn9f3///Td8fHwwf/587NmzB7Nnz0Z8fDyaNWuGxMTEfOe/+uqrKFeuHL755hvMnz8fx44dQ/v27Q2W+3z99dcIDAyEvb09vvrqK3z77bdwcnJC586dOWAnIipLChFRGVq1apUCQDly5IiSk5OjpKenKzt37lQqVqyo2NnZKbdu3VIURVFCQkIUAMrKlSsNbr9+/XoFgLJ582aD48ePH1cAKEuWLFEURVFiY2MVAMrYsWMNzlu3bp0CQAkJCdEfi4yMVAAokZGR+mNeXl6Kl5eXcv/+/QL/LHPmzFEAKFeuXDE4HhcXp5ibmyvvvPOOwfH09HTF1dVV6d+/v6IoiqLT6RR3d3fF19dXycvL05/3999/KxYWFoqHh0eBj/1Iu3btlPr16xd53uNyc3OVe/fuKba2tsqCBQv0xx+9Nr169TI4/7ffflMAKNOnT1cURVEyMjIUJycnpXv37gbn6XQ6pVGjRkrz5s3z3eeTzxEREf07nFknIpNo2bIlLCwsYGdnh27dusHV1RW7d+9G5cqVDc7r06ePwcc7d+5EhQoV0L17d+Tm5uovjRs3hqurq34ZSmRkJADkW//ev39/mJsX/vacixcv4q+//sKrr74KKyurEv/Z9uzZg9zcXAwdOtSg0crKCu3atdM3XrhwATdv3sSgQYOg0Wj0t/fw8ECrVq1K/LgFuXfvHsaPHw9vb2+Ym5vD3Nwc5cuXR0ZGBmJjY/Od/+Rz1qpVK3h4eOif06ioKCQlJSEkJMTgz5eXl4cXX3wRx48fF/JGYSKi/wK+wZSITGLNmjWoW7cuzM3NUblyZbi5ueU7x8bGBvb29gbHbt++jZSUFFhaWhq930fLOu7evQsAcHV1Nbje3Nwczs7OhbY9WvtetWrV4v1hnvBoqUyzZs2MXl+uXLlCGx8dK63tDgcNGoQDBw7gww8/RLNmzWBvbw+NRoMuXboYLBt6/LGNHXvU++jP17dv3wIfMykpCba2tqXST0RE/+BgnYhMom7duvrdYAry+GzzIy4uLnB2dsaPP/5o9DZ2dnYAoB+Q37p1C1WqVNFfn5ubqx90FuTRuvnr168Xel5BXFxcAADfffcdPDw8Cjzv8cYnGTv2b6SmpmLnzp0IDw/HhAkT9MezsrKQlJRk9DYF9Xh7ewP458+3cOHCAnfRefJvSIiIqHRwsE5EqtatWzds2LABOp0OLVq0KPC89u3bAwDWrVsHPz8//fFvv/0Wubm5hT5G7dq14eXlhZUrVyI0NBRardboeY+OPzk73blzZ5ibm+Ovv/7Kt4zncT4+PnBzc8P69esRGhqq/+Xk6tWriIqKgru7e6GdxaHRaKAoSr4/w/Lly6HT6YzeZt26dQbdUVFRuHr1KkaMGAEAaN26NSpUqIDz58/j7bfffupGIiIqPg7WiUjVBg4ciHXr1qFLly4YPXo0mjdvDgsLC1y/fh2RkZHo2bMnevXqhbp16+Lll1/G/PnzYWFhgU6dOuHs2bOYO3duvqU1xixevBjdu3dHy5YtMXbsWFSvXh1xcXHYs2cP1q1bBwBo2LAhAGDBggUICQmBhYUFfHx84OnpialTp2Ly5Mm4fPkyXnzxRTg6OuL27ds4duwYbG1t8dFHH6FcuXKYNm0aRowYgV69emHkyJFISUnBlClTjC5FKUhaWhq+++67fMcrVqyIdu3aoW3btpgzZw5cXFzg6emJgwcPYsWKFahQoYLR+4uOjsaIESPQr18/XLt2DZMnT0aVKlXw1ltvAQDKly+PhQsXIiQkBElJSejbty8qVaqEhIQEnD59GgkJCVi6dGmx+4mIqAREv8OViJ5tj3YHOX78eKHnhYSEKLa2tkavy8nJUebOnas0atRIsbKyUsqXL6/UqVNHef3115VLly7pz8vKylLGjRunVKpUSbGyslJatmypHD58WPHw8ChyNxhFUZTDhw8rQUFBioODg6LVahUvL698u8tMnDhRcXd3V8qVK5fvPrZt26Z06NBBsbe3V7RareLh4aH07dtX2b9/v8F9LF++XKlVq5ZiaWmp1K5dW1m5cqUSEhJS7N1gABi9tGvXTlEURbl+/brSp08fxdHRUbGzs1NefPFF5ezZs/meh0evzd69e5UhQ4YoFSpUUKytrZUuXboYPK+PHDx4UOnatavi5OSkWFhYKFWqVFG6du2qbNq0Kd99cjcYIqLSoVEURRH0ewIRERERERWCWzcSEREREakUB+tERERERCrFwToRERERkUpxsE5EREREpFIcrBMRERERqRQH60REREREKsXBOhERERGRSnGwTkRERESkUhysExERERGpFAfrREREREQqxcE6EREREZFKcbBORERERKRS/wfCnyAwIHIOsAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 88.69%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\sclsdl_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 90.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\sclsdl_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 89.00%\n"
     ]
    }
   ],
   "source": [
    "class_names = [str(i+1) for i in range(len(np.unique(y_labels)))]\n",
    "confusion_matrices_dir = 'confusion_matrices'\n",
    "os.makedirs(confusion_matrices_dir, exist_ok=True)\n",
    "print(f\"Saving confusion matrices to: {confusion_matrices_dir}\")\n",
    "plot_conf_matrix('e2e_cnn', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('cae_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('cae_mlp', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('tscl_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('tscl_mlp', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('sclsdl_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('sclsdl_mlp', class_names, confusion_matrices_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:50:55.341215Z",
     "iopub.status.busy": "2025-05-08T19:50:55.341215Z",
     "iopub.status.idle": "2025-05-08T19:50:55.348469Z",
     "shell.execute_reply": "2025-05-08T19:50:55.348469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Test_Accuracy\n",
      "0      E2E CNN          98.62\n",
      "1    LRM (CAE)          79.03\n",
      "2    MLP (CAE)          77.04\n",
      "3     TSCL LRM          89.00\n",
      "4     TSCL MLP          88.69\n",
      "5  SCL_SDL LRM          90.60\n",
      "6  SCL_SDL MLP          89.00\n",
      "\n",
      "In Desc. Order (Test Accu)\n",
      "         Model  Test_Accuracy\n",
      "0      E2E CNN          98.62\n",
      "5  SCL_SDL LRM          90.60\n",
      "3     TSCL LRM          89.00\n",
      "6  SCL_SDL MLP          89.00\n",
      "4     TSCL MLP          88.69\n",
      "1    LRM (CAE)          79.03\n",
      "2    MLP (CAE)          77.04\n"
     ]
    }
   ],
   "source": [
    "final_results_df = pd.DataFrame({\n",
    "    \"Model\": [\"E2E CNN\", \"LRM (CAE)\", \"MLP (CAE)\", \"TSCL LRM\", \"TSCL MLP\", \"SCL_SDL LRM\", \"SCL_SDL MLP\"],\n",
    "    \"Test_Accuracy\": [test_accuracy, lrm_test_accuracy * 100, cae_mlp_test_accuracy_pct, \n",
    "                      tscl_lrm_test_accuracy * 100, tscl_mlp_test_accuracy_pct, \n",
    "                      sclsdl_lrm_test_accuracy * 100, sclsdl_mlp_test_accuracy_pct]\n",
    "})\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "print(final_results_df)\n",
    "print(f\"\\nIn Desc. Order (Test Accu)\\n{final_results_df.sort_values('Test_Accuracy', ascending=False)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
